\documentclass[a4paper,fleqn,11pt]{article}
%\usepackage{times}
\usepackage{natbib}
\usepackage{rotating}
\usepackage{longtable, lscape}
\usepackage{threeparttablex}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{latexsym}
%\usepackage[top=2.5cm, bottom=2.5cm, left=2cm , right=1.8cm]{geometry}
\usepackage[pdftex,svgnames]{xcolor}
\usepackage{verbatim}
\usepackage{pictexwd}
%\usepackage{supertabular}
%\usepackage{tabls}
%\usepackage{url}
\usepackage{colortbl}
\usepackage{scrextend}
\usepackage{enumitem}

\usepackage[pdfstartview={},
            pdftex,
%            pdftitle=RSiena\ Manual,
            pdfdisplaydoctitle,
            plainpages=false,
            bookmarks=true,
            bookmarksopen=true,
            bookmarksnumbered=true,
            colorlinks,
            linkcolor=Crimson,
            anchorcolor=Maroon,
            citecolor=MidnightBlue,
            urlcolor=VioletRed
            ]{hyperref}

\setlength{\bibsep}{0.01in}

%\setlength{\oddsidemargin}{15mm}


%\usepackage[pdftex]{graphicx}
%\usepackage[pdftex,dvipsnames]{color}

%%\renewcommand\floatpagefraction{1}
%\renewcommand\textfraction{0}

%\def\bibsection{\section{\refname}}
\renewcommand\bibsection{\section{\refname}}

\newcommand{\opmerking}[1]{\par \fbox{\Large #1} \par}
%\newcommand{\opmerking}[1]{}
\newcommand{\ch}{\mbox{$\chi^{2}$ }}
\newcommand{\boldpi}{\mbox{\boldmath$\pi$ }}
\renewcommand{\l}{\mbox{$\lambda$ }}
\newcommand{\informationy}{\mbox{${\cal E}$}}
\newcommand{\var}{\mbox{var}}
\newcommand{\cov}{\mbox{cov}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\mathbold}[1]{\mbox{\boldmath $\bf#1$}}
\newcommand{\Reals}{\mbox{I} \! \mbox{R}}
\newcommand{\+}{\, + \,}
\newcommand{\half}{{\textstyle \frac{1}{2}}}
\newcommand{\neqsum}[3]
{\, \sum_{\stackrel{\scriptstyle #1 = 1}{\scriptstyle #2 \neq #3}}^n \,}

\newcommand{\firsttabitem}{\hspace{4mm} $\bullet$ \hspace{1mm}}
\newcommand{\tabitem}{\\ \\ \hspace{4mm} $\bullet$ \hspace{1mm}}

\newcommand{\E}{\mbox{$\cal E$}}
\renewcommand{\P}{\mbox{P}}
\newcommand{\se}{\mbox{s.e.}}

\newcommand{\sfn}[1]{\textsf{#1}}

\newcommand{\R}{{\sf R }}
\newcommand{\Rn}{{\sf R}}
\newcommand{\rs}{{\sf RSiena}}
\newcommand{\rst}{{\sf RSienaTest}}
\newcommand{\RS}{{\sf RSiena }}
\newcommand{\SI}{{\sf SIENA }}
\newcommand{\SN}{{\sf StOCNET }}
\newcommand{\si}{{\sf SIENA}}
\newcommand{\sn}{{\sf StOCNET}}
\newcommand{\SAOM}{{Stochastic Actor-Oriented Model }}
\newcommand{\saom}{{Stochastic Actor-Oriented Model}}

\newcommand{\mcc}[2]{\multicolumn{#1}{c}{#2}}
\newcommand{\mcp}[2]{\multicolumn{#1}{c|}{#2}}

\renewcommand{\th}[1]{$\theta_{#1}$}
\newcommand{\be}[1]{$\beta_{#1}$}
\newcommand{\ga}[1]{$\gamma_{#1}$}
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
%\renewcommand{\bibitem}[1]{\bigskip \par \noindent \hspace{-4pt}}
\makeatletter
\newenvironment{indentation}[2]
{\par \setlength{\leftmargin}{#1}       \setlength{\rightmargin}{#2}
  \advance\linewidth -\leftmargin       \advance\linewidth -\rightmargin
  \advance\@totalleftmargin\leftmargin  \@setpar{{\@@par}}%
  \parshape 1 \@totalleftmargin         \linewidth \ignorespaces}{\par}
\makeatother
%\renewcommand{\bibitem}[1]{\par \noindent \hskip-\parindent}

\newcommand{\separationb}{\\[0.5ex]\hline\rule{0pt}{2ex}}


\newcommand{\vit}{\theenumi}
\newcounter{savenumi}

\newenvironment{startenum}
{\begin{enumerate}}{\setcounter{savenumi}{\value{enumi}\end{enumerate}}}

\newenvironment{followenum}
{\begin{enumerate}\setcounter{enumi}{\value{savenumi}}}
{\setcounter{savenumi}{\value{enumi}\end{enumerate}}}

\newcounter{thisno}
\newcommand{\startno}{\setcounter{thisno}{0}}
\newcommand{\nextno}{\addtocounter{thisno}{1}\thethisno .\ }

\hyphenation{Snij-ders Duijn Huis-man Steg-lich Schwein-ber-ger siena-Data-Create-From-Session
             siena-Data-Create siena-Algorithm-Create siena-Com-position-Change
             siena-Bayes RSiena-Test siena-Group siena-Dependent}

\newcommand{\interruptenum}{
      \setcounter{savenumi}{\value{enumi}}
      \end{numlijst}
      \end{slid} \begin{slid}
      \begin{numlijst}
      \setcounter{lijstnum}{\value{savenumi}}}


\renewcommand{\baselinestretch}{1.0}


\setlength{\oddsidemargin}{0.6cm}
\setlength{\textwidth}{15cm}

\ifx\pdfoutput\undefined
\else
  \ifx\pdfoutput\relax
  \else
    \ifnum\pdfoutput>0
      % PDF output
      \pdfminorversion=5
      \pdfcompresslevel=9
      \pdfobjcompresslevel=3
    \fi
  \fi
\fi

\title{{\Huge Manual for \textsf{RSiena} } }
%\protect\newline \normalsize } }
\author{\Large Ruth M.\ Ripley, Tom A.B.\ Snijders\\[1ex]
        \Large Zs\'{o}fia Boda, Andr\'{a}s V\"{o}r\"{o}s, Paulina Preciado  \\[4ex]
       {\large University of Oxford: Department of Statistics; Nuffield College}\\[1ex]
       {\large University of Groningen: Department of Sociology}\\[1ex]
    }
%\date{}

\definecolor{lc}{cmyk}{0,0.5,0,0.5}

\begin{document}
\addtocontents{toc}{\small}

\maketitle

\vfill
\begin{center}
\includegraphics*[scale=3]{ilcampo.jpg}
\end{center}
\vfill

\begin{abstract}
\noindent \SI (for {\sf Simulation Investigation for Empirical
Network Analysis}) is a computer program that carries out the
statistical estimation of models for the evolution of social
networks according to the dynamic actor-oriented model of \citet{Snijders01,
Snijders05}, \citet*{SnijdersEA07}, and \citet*{SnijdersEA10a}.
This is the manual for \rs,
a contributed package to the statistical system \Rn.
It complements, but does not replace the help pages
for the \RS functions!
It also contains contributions written
by Mark Huisman, Michael Schweinberger, and Christian Steglich.

This manual is frequently updated, mostly only in a minor way.
This version was renewed for \RS version 1.2-13.
\end{abstract}


%\addtocontents{toc}{\setlength{\parsep}{1pt plus1pt minus1pt}}

%\addtocontents{toc}{\setlength{\itemsep}{1pt plus1pt minus1pt}}

\vfill
\newpage
\tableofcontents
\newpage

\makeatletter
\def\@linkcolor{lc}
\makeatother


\section{General information}


\si
\footnote{This program was first presented at the
International Conference for Computer Simulation and the Social
Sciences, Cortona (Italy), September 1997, which originally was
scheduled to be held in Siena. See \citet{SnijdersDuijn97}.},
shorthand for {\sf Simulation Investigation for Empirical
Network Analysis}, is a set of methods
implemented in a computer program that carries out the
statistical estimation of models for repeated measures of social
networks according to the Stochastic Actor-oriented Model
 (`SAOM') of \citet{SnijdersDuijn97}, \citet{Snijders01},
\citet{SnijdersEA07},  \citet{SnijdersEA10a}, \citet{SLT2013},
and \citet{Greenan15}; also see \citet{SteglichEA10}.
A tutorial for these models is in \citet{SnijdersEA10b}.
A review article is \citet{Snijders2017}.
Books are in preparation \citep{AMAND,SNDE}.

A website for \SI is maintained at
{\small\url{http://www.stats.ox.ac.uk/~snijders/siena/}~}.
At this website (`publications' tab)
you shall also find references to introductions in various other languages,
as well as the file
\href{http://www.stats.ox.ac.uk/~snijders/siena/Siena_algorithms.pdf}{\texttt{Siena\_algorithms.pdf}}
 which
gives a sketch of the main algorithms used in \rs.
The website further contains references to many published examples,
example scripts illustrating various possibilities of the package,
course announcements, etc.

This is a manual for \rs, which also might be called \SI version 4.1.2;
the manual is provisional in the sense
that it is continually being updated, taking account of
updates in the package.
\RS is a contributed package for the \R statistical system
which can be downloaded from
\url{http://cran.r-project.org}. For the operation of \Rn,
the reader is referred to the corresponding literature and help pages.
%If desired, \SI can be operated \emph{apparently}
%independently of \Rn, as is explained in Section~\ref{Gui}.

For working with \rs, please use jointly the following
information:
\begin{enumerate}
  \item The help pages for the functions in \rs, which can be consulted
        in the usual \R way by entering ? followed by the function name;\\
        note that by clicking on the version mentioned at the bottom
        of each help page, you are brought to a directory of all help
        pages for the package;
  \item this manual (of which the web version is updated quite frequently);
  \item the website
{\small\url{http://www.stats.ox.ac.uk/~snijders/siena/}~},
        e.g., its \texttt{News} page and its \texttt{RSiena scripts} page;
  \item the yahoo users' group for \SI meant to exchange information
        and technical advice; the address is
        {\small\url{http://groups.yahoo.com/groups/stocnet/}~}.
\end{enumerate}

\RS was originally programmed by Ruth Ripley and Krists Boitmanis,
in collaboration with Tom Snijders.
Since May 2012 the maintainer is Tom Snijders.
Further contributions were made by Josh Lospinoso, Charlotte Greenan,
Felix Sch\"{o}nenberger,
Christian Steglich, Johan Koskinen, Mark Ortmann, Nynke Niezink,
and Robert Hellpap.
Currently, \RS is maintained by a research group
at the University of Groningen, seconded by researchers in Z\"{u}rich,
Konstanz, and Manchester.

In addition to the `official' \R distribution of \rs, there is
an additional distribution at R-Forge, which is
a central platform for the development of \R packages
offering facilities for source code management.
It is quite usual that recent versions of \RS are available at
\url{http://r-forge.r-project.org/R/?group_id=461}
before being incorporated into the R package that can be downloaded from CRAN.
In addition, at R-Forge there is a package {\sf RSienaTest} which may include
additional options that are still in the testing stage.
Some of the options described in this manual may apply to
{\sf RSienaTest} only, with the plan to transfer this to \RS
in the future.

\subsection{Acknowledgements}

The development of \RS was carried out by researchers of the Universities
of Oxford, Groningen, and Konstanz.
We are grateful to NIH (National Institutes of Health, USA)
for their funding of programming \RS during 2008-2014.
This was done
as part of the project \emph{Adolescent Peer Social Network Dynamics
and Problem Behavior}, funded by NIH (Grant Number 1R01HD052887-01A2),
Principal Investigator John M.\ Light (Oregon Research Institute).

For earlier work on \si, we are grateful to NWO (Netherlands Organisation for
Scientific Research) for their support to the project
\emph{Models for the Evolution of Networks and Behavior}
(project number 461-05-690),
the integrated research program
\emph{The dynamics of networks and behavior} (project number 401-01-550),
the project \emph{Statistical methods for the joint development of
individual behavior and peer networks} (project number 575-28-012),
the project \emph{An open software system for the statistical
analysis of social networks} (project number 405-20-20),
and to the foundation ProGAMMA,
which all contributed to the work on \si.

\newpage
%\addtocontents{toc}{\vspace{-2ex}}  % hack to avoid a 3-page table of contents

\newpage

\subsection{Giving references to RSiena}

When using \si, it is appreciated that you refer to this manual and to one or
more relevant references of the methods implemented in the program.  The
reference to this manual is the following.  \smallskip

\noindent
Ruth M. Ripley, Tom A.B. Snijders, Zs\'{o}fia Boda,
 Andr\'{a}s V\"{o}r\"{o}s, and Paulina Preciado, \the\year.
Manual for SIENA version 4.0 (version \today).
Oxford: University of Oxford, Department of Statistics; Nuffield College.
\textsf{http://www.stats.ox.ac.uk/~snijders/siena/}.
\smallskip


A tutorial is \citet*{SnijdersEA10b}.
A basic reference for the network dynamics model is \citet{Snijders01}
or \citet{Snijders05}.
Basic references for the model of network-behavior co-evolution
are \citet*{SnijdersEA07} and \citet*{SteglichEA10}.
Review articles are \citet{Snijders2017} and \citet{SnijdersPickup16}.

More specific references are \citet{KoskinenEdling2012} for the
dynamics of two-mode networks and \citet{SLT2013} for the
co-evolution of multiple networks -- two mode or one-mode or both.
For the model for diffusion of innovations in dynamic networks,
please refer to \citet{Greenan15}.
More technical references are
\citet{Schweinberger12} for the score-type tests
and \citet{SchweinbergerSnijders07a} for the calculation of
standard errors of the Method of Moments estimators.
For assessing and
correcting time heterogeneity, and goodness of fit assement and associated model
selection considerations, refer to \citet*{Lospinoso2011} and \citet{Lospinoso2012}.
A basic reference for the Bayesian estimation is \citet{KoskinenSnijders07}
and for the maximum likelihood estimation \citet*{SnijdersEA10a}.
For Generalized Method of Moments estimators,
the reference is \citet*{ASS2015}.

\newpage
%\addtocontents{toc}{\vspace{-2ex}}  % hack to avoid a 3-page table of contents

\section{Getting started with \SI}
\label{S_minsi1}

There may be various strategies for getting acquainted with \rs.
In any case, it is a good idea to study the tutorial  \citet{SnijdersEA10b}.
Two recommended options for learning the `how to' are the following:
\begin{enumerate}
\item One excellent option is to read the User's Manual
from start to finish (leaving aside the Programmer's Manual).
\item A second option is to read this Minimal Introduction, to get a sense
 of the rest by looking at the table of contents, and then follow
			the references to specific sections of your interest.
  The searchable pdf file makes it easy to look for the relevant words.
\end{enumerate}

\noindent
This Minimal Introduction explains the basics of {\saom}s
and gives practical information on running \rs.
We start with section \ref{S_logic} which gives a brief and non-technical
introduction to the types of {\saom}s, to the most important concepts related
to them, to the data required to apply \si, and to further features of the program.
In Section~\ref{S_use} we explain how to install and run \SI
as the package \RS from within \Rn. Section~\ref{R_scripts} and
Section~\ref{S_exec} provide example \R scripts and guidance for
understanding the results.
If you are looking for help with a specific problem, read
Section~\ref{sec:problems}.


\subsection{The logic of {\saom}s}
\label{S_logic}

\SI (Simulation Investigation for Empirical Network Analysis) is a
statistical tool developed for the analysis of longitudinal network data,
collected in a network panel study with two or more `waves' of observations.
It incorporates different variants of a dynamic network model family:
the \SAOM (SAOM). In this section, we give
a very concise introduction to how these models work in principle and what
type of data they are suitable to analyze. For sake of simplicity,
SAOMs implemented in \SI are often referred to as `\SI models'.
In this subsection, we only consider the case of network evolution;
see below for the more complex cases of coevolution.
For a further introduction, consult  \citet{SnijdersEA10b}.
An introduction for applications in the context of adolescent
development is \citet{VeenstraEtAl2013}.

The defining characteristic of {\saom}s
is their `actor-oriented' nature which means that they model
change from the perspective of the actors (nodes).
That is, {\saom}s always ``imagine" network evolution
as individual actors creating, maintaining or terminating ties to other actors.
When thinking about network dynamics, researchers usually assume that these
decisions (conscious or subconscious) of actors are influenced by the structure
of the network itself and the characteristics and behaviors of the focal actor
(ego) who is making a decision and those of other actors in the network (alters).
{\saom}s provide a means to quantify the ways, the
extent and the uncertainty with which these factors are associated with
network evolution between observations.

The \SAOM can be regarded as an agent-based (`actor-based') simulation
model of the network evolution; where all network changes are decomposed into
very small steps, so-called \emph{ministeps}, in which
one actor creates or terminates one outgoing tie.
These ministeps are probabilistic and made sequentially.
The transition from the observation
at one wave to the next is done by means of normally a large number of ministeps.
The actors respond to the network in the sense that the probabilities
of these changes depend on the current (unobserved) state of the network.
Each further ministep changes the network state and therefore the actors
are each others' ever changing context  \citep{Zeg94}.
This allows the model to represent the feedback process
that is typical for network dynamics. These changes are not
individually observed, but they are simulated;
what is observed is the state obtained at the next observation wave.

This simulation model implements the statistical model
for the network dynamics. The statistical procedures utilize
a large number of repeated simulations of the network evolution
from each wave to the next. They estimate and test the parameters
producing a probabilistic network evolution
that `could have' brought these observations to follow one another.

To avoid misunderstandings, two notes have to be made about the
meaning of actor ``decisions" and the role of {\saom}s in causal inference.
First, the fact that \SI models are actor-oriented does not imply the assumption
that the actors take
decisions in any real sense. It means that the changes in the network are
organized, so to say, by the nodes in the network. This aligns very well
with a substantive standpoint where the nodes have agency \citep{Snijders96}
but it does not necessarily reflect a commitment to or belief in any particular
theory of action elaborated in
the scientific disciplines. In fact, the purpose of \SI in this matter is
to assist substantive researchers in further developing their theories
of action by e.g.\ exploring the relative importance of individual,
contextual, and social factors in network change. The second, and related,
point is that, like other generalized regression models, \SI does not
by itself solve all causal questions. When inferring causality from model
results, one has to face difficulties very similar to those with other
statistical methods; see, e.g., \citet{LSST11} and \citet{Goldthorpe2001}.
In any case, causal interpretations should be supported by further results
from the discipline the explanations originate in.
However, {\saom}s do allow research to profit from a longitudinal
design -- therefore, they may be helpful in tackling some issues related
to causality, like the selection-influence problem \citep{SteglichEA10, LSST11}.

\subsubsection[Types of {\saom}s]
     {Types of {\saom}s: \protect\newline
     evolution of one-mode networks, two-mode networks and behaviors}
\label{S_types}

So far, we have mostly talked about \SI as a tool to analyze the evolution
of a single network. However, there are different variants of {\saom}s that
can be applied to more complex data structures.
The availability of these options depends on the research question and the
quantity and type of data one has. In this section, we briefly discuss the
currently implemented model types, which will help researchers determine what
kind of analyses they are able to carry out with {\saom}s
given the data at hand.

A minimal dataset suitable for analysis with \SI consists of two observations of
a single network defined on the same set of nodes. In this case, one is able to
test how the structure of the network contributes to its own evolution.
However, depending on the data available, further modeling options may be
applicable. Currently, the implemented {\saom}s
are suitable for the analysis of
\begin{enumerate}
	\item	the evolution of a directed or non-directed one-mode network
        (e.g., friendships in a classroom) \citep{Snijders01};
	\item	the evolution of a two-mode network
        (e.g., club memberships in a classroom: the first mode
        is constituted by the students, the second mode by the clubs)
        \citep{KoskinenEdling2012};
	\item	the evolution of an individual behavior (e.g., smoking), and
	\item	the co-evolution of one-mode networks, two-mode networks and
        individual behaviors (e.g., the joint evolution friendship and smoking;
        or of friendship and club membership) \citep{SteglichEA10, SLT2013}.
\end{enumerate}
In all these cases, the data can also include covariates: observed variables
that influence the dynamics, but of which the values are not themselves
modeled.

In the first two cases, one can assess with \SI the ways and the extent
to which changes in a given one- or two-mode network depend on the network
structure itself and on covariates. The third option, modeling changes in
an individual behavior on its own, without reference to its embeddedness
in a network, is rarely used.
For this type of data numerous alternative longitudinal modeling techniques
exist.

Accordingly, the fourth model type has been becoming widely used.
Analyzing the joint evolution of networks and behavior allows researchers
to address questions related to selection and influence processes, for
example, whether smokers tend to become friends with each other or friends
 tend to become similar in their smoking habits. The strength of the \SI
co-evolution models is that one can simultaneously take into account
the impact of network structure on network evolution, the actual level
of a behavior on behavior change, the network structure on behavior change,
and the actual level of behavior on network evolution. Besides network and
behavior co-evolution, this class of {\saom}s
also allow for the joint analysis of multiple networks (e.g. friendship
and advice, friendship and dislike, or all three of them), and the
analysis of ordered multiple networks (where the presence of a tie
in one network presumes the existence of a tie in the other network,
like in the case of friendships and best friend relations).


\subsubsection{Data, variables and effects}
\label{S_datvareff}

Now that we have discussed some core features of {\saom}s and introduced
the different implemented model types,
we turn our attention, still just presenting an outline, to
data types and the specification of a model. In general, the
number of waves must be at least two in order to analyze a
data set with {\saom}s. In case of modeling
 evolution across more than two observations in time, estimated
parameter values are assumed to be equal in all periods (unless time
heterogeneity is specifically represented by changing parameters --
see Section~\ref{S_timetest1} for further details).

This section focuses on three related topics: the type of network and
behavioral data \SI works with, the meaning of explanatory variables,
or so called effects, in {\saom}s, and the
different dependent variables with which \SI captures network and
behavior evolution.\\

\noindent
\textbf{Network data}\\

{\saom}s operate on binary networks,
that is, on relations on a given set of actors,
where tie variables between actors have two states:
existent (1) or non-existent (0).
Weighted networks are not allowed, but as mentioned above, it is
possible to define multiple networks representing discrete levels
of relationships. It is possible to specify that some ties in the
network are impossible ("structural zeros") or necessary (``structural ones")
(see Section~\ref{S_struct} for more details).
For the network evolution, {\saom}s how ties
are being created, maintained or terminated by actors.\\

\noindent
\textbf{Behavioral data}\\

Behavioral variables in {\saom}s can be
thought of as indicating the presence or intensity of a behavior.
For example, behavioral data can represent whether an actor is a
smoker or not, as well as a number of ordered categories
expressing the number of cigarettes usually smoked.
The term ``behavior" should not be taken literally here, it is
possible to model changes in attitudes or other actor attributes.
In the models, behavioral variables can be binary or ordinal discrete
(the extension for continuous behavioral data is currently being
developed). The number of categories should be small
(mostly 2 to 5; larger ranges are possible).
In the case of behaviors, {\saom}s express
how actors increase, decrease, or maintain the level of their behavior.\\

A special case of the fourth type is the
\emph{diffusion of innovations in dynamic networks}
\citep{Greenan15}:
here the behavior variable representing
having adopted the innovation is binary, coded 0 or 1, and
once an actor has the value 1 s/he is stuck with it.
The only possible transitions are $0 \Rightarrow 1$, representing
that the actor adopts the innovation.
See Section~\ref{S_behRate}.\\

\noindent
\textbf{Covariates}\\

In every model type, it is possible to define and use covariates,
which are variables that are exogenous in the sense that
their values are not modeled, but used to explain network or behavior
change. Covariates can be dummy variables (e.g., sex)
or continuous (e.g., attitudes or age).
Also, they may have constant values across all observations or their
value may change across time periods -- this is the
distinction between constant and varying covariates
(e.g., sex and salary). Finally, there are
individual (monadic) and dyadic covariates that refer, respectively, to
characteristics of individual actors (e.g., sex) and to attributes
of pairs of actors (e.g., living in the same neighborhood or kinship).\\

\noindent
\textbf{Missing data and composition change}\\

{\saom}s distinguish between two types
of missing values: absence of actors from the network and
random missingness. The first case refers to changing composition:
it is possible to specify that some actors leave or join the
network between two observations (during the simulation process).
This then applies to all dependent variables (networks, behaviors)
simultaneously (see Section~\ref{S_comp} for more details).
In the second case, missing values are treated as randomly missing
(see Section~\ref{S_missing} for more details).
{\saom}s can deal with some, but not too much,
randomly missing data (as a rule of thumb, more than 20\% is
considered to be too much). With too many missing values,
the simulation can become unstable, and also the estimated
parameters may not be substantively reliable anymore.
And of course, missing data are likely to are caused by
processes that are not totally random, and therefore risk
to bias the resuls.\\

\noindent
\textbf{Explanatory variables: the effects}\\

When defining {\saom}s, we have to specify
the exact ways in which current network structure or covariates may affect
network or behavior change. This is defined
by combinations of configurations (or situations) which
are called ``effects" in {\saom}s.
Effects can be treated as the explanatory variables of the models.
Effects can be structural (depending on the network structure itself,
also called endogenous), or covariate-related; also various combinations
between structure and covariates are possible. Some examples for effects:
\begin{itemize}
	\item \emph{structural effects:} reciprocity, transitivity;
	\item \emph{covariate effects:} sex of the tie sender, sex of the receiver,
                same sex, similarity in salary;
	\item \emph{combinations:} average level of smoking of friends,
                interaction between sex of the sender and reciprocity.\\
\end{itemize}

\noindent
\textbf{Dependent variables: network evaluation, creation and endowment functions}\\

As we discussed earlier, \SI is capable of analyzing and modeling the
evolution of networks and behavior, jointly or separately.
Consequently, a model may have more than one dependent variable.
Here we introduce the ways network and behavior dependent variables
can be defined in {\saom}s. We start with network evolution.

\def\Fspace{\space\space\space\space}
\begin{table}[h]
	\centering
	\caption{Possible tie change patterns for two observations ($t_1$ and $t_2$)}
	\label{tab:TCpat}
	\vspace{\baselineskip}
	\begin{tabular}{c | c | l}
		$t_{1}$ 				& $t_{2}$ 				&														\\ \hline
		$i$ \Fspace $j$ & $i  \to 		 j$	& creation of a tie 				\\
		$i  \to			 j$	& $i  \to 		 j$	& maintenance of a tie 			\\
		$i  \to			 j$	& $i$ \Fspace $j$ & termination of a tie 			\\
		$i$ \Fspace $j$	& $i$ \Fspace $j$ & maintenance of a 'no-tie' \\
	\end{tabular}
\end{table}

Given two observations of a binary network, a single network tie variable
can follow four patterns, as shown in Table \ref{tab:TCpat}.
In {\saom}s, however, tie change can be
defined in three ways: we can model the creation of previously not
existing ties (creation), the maintenance of existing ties (endowment),
or the presence of ties regardless of whether they were newly created
or maintained (evaluation). These are the three possible values of the
change in tie variables, constituting the dependent
variables of the network evolution model.
The effects model the odds
(more precisely: they are components of the linear
predictor for the log-odds)
for the creation, maintenance or
presence of network ties. Table~\ref{tab:TCece} helps to imagine
what the odds refer to in each case: we compare the probability of
green cases to that of blue cases.

\begin{table}[h]
\centering
	\caption{Tie changes considered by the evaluation, creation and endowment functions}
	\label{tab:TCece}
	\vspace{\baselineskip}
	\parbox{.30\linewidth}{
		\centering
		\begin{tabular}{c | c}
			\multicolumn{2}{c}{$a)$ $evaluation$}\\
			$t_{1}$ 				& $t_{2}$ 					 \\
			\hline
			\rowcolor{LimeGreen}
			$i$ \Fspace $j$ & $i \to j$ 				 \\
			\rowcolor{LimeGreen}
			$i  \to	j$			& $i \to j$ 				 \\
			\rowcolor{RoyalBlue}
			$i  \to	j$			& $i$ \Fspace $j$		 \\
			\rowcolor{RoyalBlue}
			$i$ \Fspace $j$	& $i$ \Fspace $j$		 \\
		\end{tabular}
	}
	\parbox{.30\linewidth}{
		\centering
		\begin{tabular}{c | c}
			\multicolumn{2}{c}{$b)$ $creation$}															\\
			$t_{1}$ 										& $t_{2}$ 												  \\
			\hline
			\rowcolor{LimeGreen}
			$i$ \Fspace $j$ 						& $i \to j$			  								  \\
			\textcolor{Grey}{$i \to j$} & \textcolor{Grey}{$i \to j$} 			\\
			\textcolor{Grey}{$i \to j$} & \textcolor{Grey}{$i$ \Fspace $j$} \\
			\rowcolor{RoyalBlue}
			$i$ \Fspace $j$							& $i$ \Fspace $j$ 								  \\
		\end{tabular}
	}
	\parbox{.30\linewidth}{
		\centering
		\begin{tabular}{c | c}
			\multicolumn{2}{c}{$c)$ $endowment$}																	\\
			$t_{1}$ 				& $t_{2}$ 																						\\
			\hline
			\textcolor{Grey}{$i$ \Fspace $j$} & \textcolor{Grey}{$i \to j$} 			\\
			\rowcolor{LimeGreen}
			$i \to j$													& $i \to j$ 												\\
			\rowcolor{RoyalBlue}
			$i \to j$													& $i$ \Fspace $j$ 									\\
			\textcolor{Grey}{$i$ \Fspace $j$}	& \textcolor{Grey}{$i$ \Fspace $j$} \\
		\end{tabular}
	}
\end{table}

According to this distinction, network evolution may be modeled
in \SI by three functions: the evaluation, creation and endowment functions.
Effects can appear as components of one or two of these functions in a single model,
but never in all three (this would lead to perfect collinearity).
Using only the evaluation effect assumes that the creation and endowment
effects are equal (and equal to the evaluation effect). The estimated
parameters for each effect should be interpreted as log-odds ratios.
From a practical point of view, it is meaningful to start modeling with
evaluation effects, unless one has a clear idea about how tie creation
and endowment may be different in the analyzed data set.
Separating the contribution of an effect into two functions requires
more of the data, and if a given effect is similarly strong for the
creation and maintenance of ties the statistical power will
decrease by this split.
 For these reasons, most  \SI studies limit their
 attention to evaluation effects. However, if there is enough data,
 the distinction between creation and maintenance of ties can
 produce powerful insights \citep[e.g.,][]{Cheadle_etal2013}.\\

\noindent
\textbf{Dependent variables: behavior evaluation, creation and endowment functions}\\

The distinction between the different behavior evolution functions follows
a logic similar to the case of network evolution. The three possibilities
for change in behavior are increasing or decreasing the level of behavior
by one unit, or maintaining its actual level. In case of the evaluation
function, the model does not distinguish between upward and downward changes,
only looks at the resulting level of behavior. By using the creation and
endowment functions, we can obtain separate parameters (and assess the
different impact) of effects for the increase and the decrease of behavior.

\subsubsection{Outline of estimation procedure}
\label{S_estim}
\noindent
\SI estimates parameters by the function \sfn{siena07()}
and (alternatively) \sfn{sienacpr()}, using the following procedure:
\begin{enumerate}
\item  Certain statistics are used that reflect the parameter values;\\
  the finally obtained parameters should be such that the \emph{expected
    values}
  of the statistics are equal to the \emph{observed values}.\\
  Expected values are approximated as the averages over a lot of simulated
  networks.\\
  Observed values are calculated from the data set. These are also called the
  \emph{target values}.
\item To find these parameter values, an \emph{iterative stochastic simulation
    algorithm}
  is applied.
  This works as follows:
\begin{enumerate}
\item In Phase 1, the sensitivity of the statistics to the parameters is roughly
  determined.
\item In Phase 2, provisional parameter values are updated iteratively:\\
  this is done by simulating a network according to the provisional parameter
  values, calculating the statistics and the deviations between these simulated
  statistics and the \emph{target values}, and making a little change (the
  `update') in the parameter values
  that hopefully goes into the right direction. A lot of such updating steps
  are taken, each using the parameter that was produced in the preceding step.\\
  (Only a `hopefully' good update is possible, because the simulated network is
  only a random draw from the distribution of networks, and not the expected
  value itself.)
\item In Phase 3, the final result of Phase 2 is used, and it is checked if the
  average statistics of many simulated networks are indeed close to the target
  values. This is reflected in the so-called
  \texttt{overall maximum convergence ratio} and the \texttt{t statistics for deviations
  from targets}. If some of these are too high (a threshold of 0.25 is used for the
  overall maximum convergence ratio, and a threshold of 0.1 for the absolute value
  of the t statistics for deviations from targets), the estimation must be repeated.
   Standard errors for the parameters are also estimated in this
  phase.

  If the estimation has to be repeated, this can be done by employing the
  argument \texttt{prevAns} in the call of \sfn{siena07()}
  (or \sfn{sienacpr()}).
  See the help page for  \sfn{siena07()}.
\end{enumerate}
\end{enumerate}


\subsubsection{Design issues for longitudinal network modeling}

Issues concerning the design of longitudinal network models
according to the \SAOM are discussed in
\citet{StadfeldSnijdersSteglichVanDuijn2018}.

\subsubsection{Further useful options in \RS}
\label{S_etc}
\begin{itemize}
	\item	Checking for time heterogeneity (Sections~\ref{S_timetest1}
            and \ref{S_timetest2})
	\item	Goodness of fit (Section~\ref{S_gof})
	\item	Meta-analysis of \SI results (Section~\ref{S_Siena08})
	\item	Simulation without estimation (Section~\ref{S_sim})
\end{itemize}

\subsection{Installing \R and \SI }
\label{S_use}
\noindent
This and the next section give an overview of steps one needs to go through from
installing \R to running models in \rs.
Installing needs to be done only once (but should be repeated when next versions
of the software appear).

\begin{enumerate}
	\item	Install \Rn.\\
            This can be done from \url{http://cran.r-project.org/} .\\
            Many users prefer some kind of additional environment, such as \texttt{RStudio}, or
            the combination of \texttt{Notepad++} with \texttt{NppToR}.\\
            For Mac, you will also need \sfn{X11}, because this is
            required for \sfn{tcltk}. See the FAQ list for R on Mac,
	\item	Install the package \RS or \sfn{RSienaTest}, with dependencies.
            The other packages used are \sfn{tcltk}, \sfn{parallel}
            and \sfn{tools} (all included in the basic \R distribution);
            \sfn{Matrix}, \sfn{MASS}, \sfn{lattice}, \sfn{codetools}
            (`recommended' packages included in most R distributions);
            \sfn{network} and \sfn{xtable}; and, for \sfn{RSienaTest},
            \sfn{RUnit}.
            For goodness of fit testing it will be useful also to
            install \sfn{sna} and \sfn{igraph}.\\
            You can just install \RS and the other packages
            in the regular way from CRAN.
            If you want to have detailed information about
            what is available at CRAN, go to\\
\url{http://cran.r-project.org/web/packages/RSiena/} .\\
            However, it is advisable to have the latest version of \RS
            or \sfn{RSienaTest} from R-Forge or the \SI website.
            You can go to\\
               \url{http://r-forge.r-project.org/R/?group_id=461} \\
               or to\\
              \url{http://www.stats.ox.ac.uk/~snijders/siena/siena_downloads.htm}\\
            and there download the appropriate version of the package
            appropriate for your operation system (Windows, Mac, Unix). \\
            Installation can be done in various ways --- by the function \texttt{install.packages()}
            in \Rn,
            via the drop-down menu in the \R console, or in command mode which for Mac is
            the `terminal'.
            If a binary file is available (\texttt{.zip} for Windows, \texttt{.tgz} for Mac),
            then using the binary is recommended.
            Installation from binary is much faster than installation from source.

            Installation from the R-Forge repository can be done as follows.
            In these commands, \texttt{RSienaTest} can be replaced by \texttt{RSiena}.
            \begin{itemize}
            \item for Windows:\\
            \texttt{install.packages("RSienaTest", repos="http://R-Forge.R-project.org")}
            \item for Mac the binary file code is not available on R-Forge, but the source code
            may also work:\\
            \texttt{install.packages("RSienaTest", repos="http://R-Forge.R-project.org", type = "source")}\\
            If this does not work, try one of the following methods.
            \end{itemize}

            Installation from a downloaded file can be done as follows, assuming
            the root name of the file is \texttt{RSienaTest\_1.2-13}, and filling in the correct path name.
            It will be convenient to first navigate to the directory
            containing the \RS binary or source file so that this is the current directory.
            Then the pathname consists only of the filename.
            \begin{itemize}
            \item In \R from binary:\\
            for Windows:\\
             \texttt{install.packages("pathname to RSienaTest\_1.2-13.zip", repos = NULL, type="binary")}\\
            for Mac:\\
             \texttt{install.packages("pathname to RSienaTest\_1.2-13.tgz", repos = NULL, type="binary")}
             \item In \R from source:\\
            \texttt{install.packages("RSienaTest\_1.2-13.tar.gz", repos = NULL, type="source")}
            \item In \text{command.com} or in batch mode (Windows) from binary:\\
            \texttt{R CMD INSTALL RSienaTest\_1.2-13.zip}
            \item In the terminal (Mac) from binary:\\
            \texttt{R CMD INSTALL RSienaTest\_1.2-13.tgz}
            \item In \text{command.com} or in batch mode (Windows) or in the terminal (Mac) from source:\\
            \texttt{R CMD INSTALL RSienaTest\_1.2-13.tar.gz}
            \item In drop-down menu in \Rn:\\
            for Windows:  go to Packages  $\rightarrow$ Install package(s) from local zip file\\
            for Mac:  go to Packages \& Data $\rightarrow$ Package Installer
            \item In \sfn{RStudio}:\\
            go to Tools  $\rightarrow$ Install packages $\rightarrow$ Install From: Package archive file (zip; tar.gz)
            \end{itemize}
   \end{enumerate}


\subsection{Using \SI within \Rn}

   \begin{enumerate}
	\item	Load data (networks, behavior, covariates) into \R
            (see Section~\ref{S_datatypes}):
	\begin{enumerate}
		\item Network data should be in objects of class matrix or
            sparse matrix (edgelist);
		\item	Behavioral data should be in objects of class matrix;
		\item	Individual constant covariates should be in objects of
            class vector or should be in columns or rows of a matrix;
		\item	Individual varying covariates should be in objects of class matrix;
		\item	Dyadic covariates should be in objects of class matrix.
	\end{enumerate}
	\item	All missing data should be set to \texttt{NA} (see Section~\ref{S_missing}).
	\item Check whether your data objects meet the following criteria:
	\begin{enumerate}
		\item	Each object contains the same nodes/actors;
		\item	Nodes are in the same order in each object;
		\item	Nodes are in the same order in rows and columns of matrix
                objects (in case of one-mode networks)\footnote{For
		directions on how to handle composition change, see Section~\ref{S_comp}}.
	\end{enumerate}
   If a two-mode network is studied, then of course there will
   be two node sets.
	\item	Create \SI objects for each data object using the appropriate
                functions (see Section~\ref{S_datatypes}):
	\begin{enumerate}
		\item	\sfn{sienaDependent()} for networks and behavior variables;
		\item	only for two-mode networks, \sfn{sienaNodeSet()} for defining nodesets;
		\item	\sfn{coCovar()} and \sfn{varCovar()} for constant and
                changing/varying individual covariates respectively;
		\item	\sfn{coDyadCovar()} and \sfn{varDyadCovar()} for
                constant and changing/varying dyadic covariates respectively;
		\item	In case of two-mode networks, for each object it should
                be specified which nodeset it is defined on, using the
                \sfn{nodeSets} argument in the above functions.
	\end{enumerate}
	\item	Create a \SI data object containing all the \SI objects
            specified above using the function \sfn{sienaDataCreate()}
            (see Section~\ref{S_datatypes}).
	\item	Use \sfn{getEffects()} to create an effects object.
            This already gives a very simple model specification
            containing the outdegree and a reciprocity effects
            (see Section~\ref{S_imp_str1} - for two-mode networks see
            Section~\ref{S_imp_str2}).
	\item	Use \sfn{sienaAlgorithmCreate()} to create an algorithm object
                (see Section~\ref{S_modspec}).
	\item	Use \sfn{print01Report()} to produce an output file
                 presenting some descriptive statistics
                for the objects included in the model.
	\item	Use functions \sfn{includeEffects()}, \sfn{setEffect()} and
            \sfn{includeInteraction()} to further specify the model
            (see Sections~\ref{S_imp_str1}~--~\ref{S_eff_beh}).
	\item	Use \sfn{siena07()} or \sfn{sienacpr()}
            to run the estimation procedure.\footnote{The
            use of multiple processes can speed up the estimation.
            For directions on how to utilize multiple processors,
            see Section~\ref{S_multipleProcesses}.}
	\item	Basic output is written to a log file in the actual working directory.
             The filename is the project name specified in the
             \sfn{sienaAlgorithmCreate()} function. Results can also be
             inspected in \R using various functions.
\end{enumerate}

\subsection{Example \R scripts for getting started}
\label{R_scripts}
The following scripts on the \RS website go through the steps
outlined in the previous section, providing additional details and options: \\
\begin{itemize}
    \item \sfn{basicRSiena.r}: a minimal example of a basic sequence of commands
           for estimating a model by function \sfn{siena07()} of \rs.
	\item \sfn{Rscript01DataFormat.R}: gives a brief overview of \R functions
            and data formats that are essential for using \rs.
	\item \sfn{Rscript02SienaVariableFormat.R}: shows how to prepare data
            for a \SI analysis, including the creation of \RS objects;
            and how to specify effects for \RS models.
	\item \sfn{Rscript03SienaRunModel.R}:
           shows how to carry out the estimation and look at the results;
	\item \sfn{Rscript04SienaBehaviour.R}: illustrates
      how to specify models for dynamics of networks and behaviour.
\end{itemize}
The website contains a lot of other scripts illustrating other functionalities
of \rs.


\subsection{Steps for looking at results: Executing \si .}
\label{S_exec}

\begin{enumerate}
\item Look at the start of the output file obtained from
       \sfn{print01Report()} for general data
      description (degrees, etc.), to check your data input
      and get a general overview of the data set.

      In this file, there is a section ``Change in networks'' which contains
      some basic descriptives. Some of these refer to the \emph{periods}:
      these are the combinations of two successive waves.
      For example, a two-wave data set has one period, and a
      three-wave data sets has periods $1 \Rightarrow 2$ and $2 \Rightarrow 3$.
      The \texttt{Distance} mentioned there
      is the Hamming distance between successively observed networks, i.e.,
      the number of tie variables that differ.
      The \texttt{Jaccard} index is the Jaccard distance between the
      successive networks:
      \[
         \frac{N_{11}}{N_{01}+N_{10}+N_{11}} \ ,
      \]
      where $N_{hk}$ is the number of tie variables with value $h$ in one
      wave and value $k$ in the next wave. The Jaccard index is a measure for
      stability; see \citet{SnijdersEA10b}.
      Both for the Hamming distance and the Jaccard index, only those cells
      in the adjacency matrix are counted that have available data in the wave
      at the start \underline{and} the wave at the end of the period concerned.

      If Jaccard indices are very low while the average
      degree is not strongly increasing, this indicates
      that the turnover in the network may be too high to consider
      the data as an evolving network, and perhaps the \SI method
      is not suitable for the data set.
      For networks of the type that are mostly used for this method
      (sparse but not too sparse,
      with average degrees not too different from wave to wave
      and between 2 and 15 for all waves),
      Jaccard values of .3 and higher
      are good; values lower than .2 indicate that there might be difficulties
      in estimation; values lower than .1 are quite low indeed.
      Using the \SI method for two waves with an extremely low Jaccard
      index and average degrees that remain more or less constant
      will mean that the first wave hardly plays a role in the results, and
      for non-conditional estimation it will be close to treating the second wave as
      a sample from the stationary distribution of the network dynamics.

      If Jaccard indices are low because the network is mainly increasing
      (creation of new ties) or decreasing (termination of ties),
      this is no problem for the \SI method. Very sparse networks
      (with most degrees less than 2) also may have lower Jaccard values
      without negative consequences for estimation.
\item When parameters have been estimated, first look at the
     \texttt{overall maximum \\convergence ratio} and the \texttt{t statistics for deviations
      from targets}.
      We say that the algorithm has converged if the former is less than 0.25,
      and the latter all are smaller than 0.1 in absolute value;
      and that it has nearly converged if the former is less than 0.35, and the latter are all
      smaller than 0.15. Results obtained for non-converged estimation
      runs may be misleading. (Very small deviations from these
      values are of course immaterial.) See Section~\ref{S_ccheck}.
\item In rare circumstances, when the data set leads to instability
      of the algorithm, the following may be of use.
      The \textsf{Initial value of the gain parameter} determines the
      step sizes in the parameter updates in the iterative
      algorithm.
      This is the parameter called \textsf{firstg}
      in function \textsf{sienaAlgorithmCreate}.
      A too low value implies that it takes very long to attain a
      reasonable parameter estimate when starting from an initial
      parameter value that is far from the `true' parameter estimate.
      A too high value implies that the algorithm will be unstable,
      and may be thrown off course into a region of unreasonable
      (e.g., hopelessly large) parameter values. It usually is unnecessary
      to change this, but in some cases it may be useful.
\item If all this is to no avail, then the conclusion may be that the model
      specification is incorrect for the given data set.
\item Further help in interpreting output is in Section~\ref{S_output} of
      this manual.
\end{enumerate}


\subsection{Getting help with problems}
\label{sec:problems}

For methodological help, consult the tutorial  \citet{SnijdersEA10b} or this manual.
The website, {\small\url{http://www.stats.ox.ac.uk/~snijders/siena/}~}, contains
various further publications (also in other languages than English) that may
be helpful, as well as example scripts.
There is a users' group for \SI to exchange information and seek technical
advice; the address is {\small\url{http://groups.yahoo.com/groups/stocnet/}~}.

For technical problems running \rs, follow the following points.
\begin{description}
\item[Help pages] Study the \R help page for the function you are using and that seems to give
      the problems. This manual complements the help pages,
      but does not replace them!
\item[Check your version of \RS]
  The `News' page of the \SI website gives information about new versions
  of \rs. Details of the latest version available can
  be found at \small{\url{http://r-forge.r-project.org/R/?group_id=461}}.
  The version is
  identified by a version number (e.g.\ 1.2-13) and an R-Forge revision
  number. You can find both numbers of your current installed version by
  opening \R, and typing \\
  \verb|packageDescription("RSiena")|. The version is
  near the top, the revision number near the end. Both are also displayed at the
  start of \SI output files.
\item[Check your version of \Rn] When there is a new version or revision of \RS
  it will only be available to you automatically if you are running the most
  recent major version of \Rn. (You can force an installation if
  necessary by downloading the tarball or binary and installing from that, but
  it is better to update your \Rn.)
\item [Check both repositories] We have two repositories in use for \rs: CRAN
  and R-Forge. The latest version will always be available from
  R-Forge. (Frequent updates are discouraged on CRAN, so bug-fixes are likely to
  appear first on R-Forge.)
\item[Installation] When using the repository at R-Forge, \emph{install} the
  package rather than updating it. Then check the version and revision numbers.
\item[Users' group] Consult the archives of the Users' Group mentioned above, or post
     a message to the Users' Group. In your message,
     please tell which operating system, which version of \Rn, and which version
     of \RS you are using.
\item[R-Forge help list]
     If you are a programmer, then
     for technical questions about the \RS code (as distinct from the
     methodology), you can send an email to
     rsiena-help@lists.r-forge.r-project.org, or post in the help forum for \RS in
     R-Forge. You need to be a registered member of R-Forge (and possibly of \rs)
     to post to a forum, but anyone can send emails (at present!). In your message,
     please tell us which operating system, which version of \Rn, and which version
     of \RS you are using.
\end{description}
%\addtocontents{toc}{\vspace{-2ex}}  % hack to avoid a 3-page table of contents

\newpage

\section{Steps of modelling}
\label{S_parts}

The operation of the \SI program is comprised of five main parts:
\begin{enumerate}
 \item input of basic data description (see Section~\ref{S_InputData});
 \item model specification (see Section~\ref{S_modspec});
 \item estimation of parameter values using stochastic simulation
        (see Section~\ref{S_Est});
    the main output of the estimation procedure
    is written to a text file named
    \textsf{\textsl{pname}.out}, where \textsf{\textsl{pname}} is the name
    specified in the call of \textsf{sienaAlgorithmCreate()};
 \item testing parameters and assessing goodness of fit
        (see Sections~\ref{S_se} and \ref{S_test});
 \item simulation of the model with given and fixed parameter values
        (see Section~\ref{S_sim}).
\end{enumerate}

The normal operation is to start with data input, then specify a
model and estimate its parameters,
assess goodness of fit and the significance of the parameters,
and then possibly continue with new
model specifications followed by estimation or simulation.


\vfill
\begin{center}
\includegraphics*[scale=0.7]{RSienaArchitecture.png}
\end{center}
\vfill




\newpage

\section{Input data}
\label{S_InputData}

\SI is a program for the statistical analysis
of repeated measures of social networks, and requires, at the very
least, network data collected at two or more time points. It is also possible
to include other types of variables in the models -- these are discussed in
Section~\ref{S_datatypes}. Section~\ref{S_internal} describes the most
commonly occuring
data transformations that are done internally by \si.
Finally, Section~\ref{S_usertrans}
shows further options for users to define their data.


\subsection{Data types}
\label{S_datatypes}

As we discussed in Section~\ref{S_datvareff}, dependent variables in {\saom}s are defined from
network or behavioral data. Independent variables (effects) are defined
from individual or dyadic covariate data, which can be constant or varying.
\SI requires each of these data types to have a specific format -- this is
presented in the current section.

In general, data specification in \RS consists of two steps.
First, the role of each variable to be used must be defined using
the functions \sfn{sienaDependent()}, \sfn{coCovar()}, \sfn{varCovar()},
\sfn{coDyadCovar()}, \sfn{varDyadCovar()}, or \sfn{sienaCompositionChange()}.
Second, the variables must be combined into one \RS data set by the function
\sfn{sienaDataCreate()}.
This function puts together the data set and carries out some
preliminary calculations.

It is advisable to use names of variables
consisting of at most 12 characters. This is because they are used as parts
of the names of effects which can be included in the model, and the effect
names should not be too long.

\RS does not work with case numbers. The correspondence between cases
in the different components of the data set is by the order of the rows
in the data matrices. For a data set with $n$ actors,
each data matrix should have $n$ rows and always the $i$'th row
should correspond to the $i$'th actor.

It is also useful to note here that in case of co-evolution models (those with
more than one dependent networks and/or behaviors), data for all dependent
variables must be available for the same set of time points.


\subsubsection{Network data}

There can be one or more networks in the data set.
Networks can be one-mode or two-mode.
Modes are identified with node sets.
All one-mode networks must have the same node set,
also referred to as `actors'.
If there are some one-mode networks and any two-mode networks,
the first node set of all two-mode networks should be the node set
(actor set) of the one-mode networks.
The choice between one- and two-mode is specified by the argument
\texttt{type} in  the \textsf{sienaDependent} function, which for
networks can be \texttt{oneMode} or \texttt{bipartite};
the latter signifies a two-mode network.

For data specification by  \textsf{sienaDependent}, the network
must be specified as a matrix or array or list of sparse matrix of triples.
The help page for \textsf{sienaDependent} has an example of input
by sparse matrices.

For data specification by
%the graphical interface \textsf{siena01Gui} (documented separately) or by
the function \textsf{sienaDataCreateFromSession},
edge list formats are also allowed. This can be either the
format of the Pajek program, or a raw edge list, here called Siena format.
For large number of nodes (say, larger than 100), the edge list
format is more efficient in use of computer memory.

Note that  \textsf{sienaDataCreateFromSession} is available only
in  \textsf{RSienaTest}.

Sparse matrices, which can be used by input via
\sfn{sienaDependent()}, have for running the estimations
the same efficiency as Pajek or Siena format.
%Data input as edge lists will also be made available by means of the
%\textsf{sienaDependent} function (in some future version of \sn).
The three possible formats for digraph input are as follows.
\begin{enumerate}
\item \emph{Adjacency matrices}.\\
      These can be used in  \sfn{sienaDependent} and in
      \sfn{sienaDataCreateFromSession}.\\
      In the usual case of a one-mode network the adjacency matrix
      is given in a matrix of $n$ rows and $n$ columns
      containing integer numbers.
      The diagonal values are meaningless but must be present.
      In the case of a two-mode network (which is a network with two
      node sets, and all ties are between the first and the second node set)
      the matrix does not have to be
      square, as usually the number of nodes in the first set will not be
      equal to the number of nodes in the second set;
      and if it would be square, the diagonal still would be meaningful.

      Although this section talks only about digraphs (directed graphs),
      for one-mode networks it is
      also possible that all observed adjacency matrices are symmetric.
      This will be automatically detected by \si, and
      the program will then utilize methods for non-directed networks.

      The values of the ties must be 0, 1, or \texttt{NA}
      (not available = missing);
      or 10 or 11 for structurally determined values (see below).

      The help file for \sfn{sienaDependent} shows by examples how the
      specification can be given by sparse matrices.
    \item \emph{Pajek format}.\\
      These can be used in \sfn{sienaDataCreateFromSession}.\\
      If the digraph data file has extension name \texttt{.net}, then the
      program assumes that the data file has Pajek format.
      The file should relate to one observation only,
      and should contain a list of vertices (using the
      keyword \texttt{*Vertices}, together with (currently) a list of arcs,
      using the keyword \texttt{*Arcs}
      followed by data lines according to the Pajek rules.
      These keywords must be in lines that contain no further characters.
      An example of such input files is given in the s50 data set
      that is distributed in the \texttt{examples} directory of the
      source code.
    \item \emph{Siena format}.\\
      These can be used in \sfn{sienaDataCreateFromSession}.\\
      An edge list is a matrix containing three or four columns:
      from, to, value, wave (optional).\\
      Like the Pajek format, this has the advantage that absent ties (tie
      variables with the value 0) do not need to be mentioned in the data
      matrix. By specifying the waves in the fourth column in the
      \sfn{Siena} format, one matrix can be used to contain data for all
      the waves.
\iffalse
RSiena can read multi wave files but not deal with multi wave R objects.
The format for the multi wave files is

from to value wave

where the from and to are sequential numbers. The waves can be any
numbers, as long as they are in the correct order: RSiena will relabel
them 1:nwaves. And use sienaDataCreateFromSession to read the files in.

Within R it is easy to split data frames by a factor such as wave, using
split(). But you end up with a list which you must then process. If you
are not familiar with R my advice would be to do your data manipulation
outside R. \fi
\end{enumerate}

Missing values must be indicated in the way usual for \Rn,
by \texttt{NA}.
For data specification by the function
\textsf{sienaDataCreateFromSession},
instead of \texttt{NA} any numerical code can be used
given that this is indicated to be a missing value code.

If the data set is such that it is never observed that ties are terminated,
then the network dynamics is automatically specified internally in such a way
that termination of ties is impossible.
(In other words, in the simulations of the actor-based model
the actors have only the option to create new ties or to retain
the status quo, not to delete existing ties.)
Similarly if ties never are created (but only terminated),
then this will be respected in the simulations.
See Section~\ref{S_monotone} and note the possibility
of using \sfn{allowOnly=TRUE}.

\subsubsection{Transformation between matrix and edge list formats}
\label{S_trafos}

The following \R commands can be used for transforming an
adjacency matrix to an edge list, and back again.
If \texttt{a} is an adjacency matrix, then the following commands
can be used to create the corresponding edge list,
called \texttt{edges} here.
 \begin{verbatim}
 # create indicator matrix of non-zero entries of a
 ones <- !a %in%  0
 # create empty edge list of desired length
 edges <- matrix(0, sum(ones), 3)
 # fill the columns of the edge list
 edges[, 1] <- row(a)[ones]
 edges[, 2] <- col(a)[ones]
 edges[, 3] <- a[ones]
 # if desired, order edge list by senders and then receivers
 edges      <- edges[order(edges[, 1], edges[, 2]), ]
 \end{verbatim}
Some notes on the commands used here:\\
These commands can be used not only if the adjacency matrix
contains only 0 and 1 entries, but also if it contains values
\texttt{NA}, 10, or 11. The possibility of \texttt{NA}
entries requires special attention;
\texttt{\%in\%}
does just what we need, as it quietly says that
\texttt{NA}'s are not \texttt{\%in\%}
anything, returning \texttt{FALSE}, which is transformed to
\texttt{TRUE} by the \texttt{!} function.
The edge list is created having all 0 values and at the end
should have no 0 values at all.

It is more efficient, however, to work with sparse matrices;
this also is done internally in \rs.
Using the \texttt{Matrix} package for sparse matrix manipulations,
the same results can be obtained as follows.
\begin{verbatim}
library(Matrix)
tmp <- as(a, "dgTMatrix")
edges2 <- cbind(tmp@i + 1, tmp@j + 1, tmp@x)
\end{verbatim}
Conversely, if \texttt{edges} is an edge list, then the following commands
can be used to create the corresponding
adjacency matrix, called \texttt{adj},
with $n$ nodes. (For a bipartite network the two dimensions
will normally be distinct numbers.)
\begin{verbatim}
# create empty adjacency matrix
adj <- matrix(0, n, n)
# put edge values in desired places
adj[edges[, 1:2]] <- edges[, 3]
\end{verbatim}
Note that this starts with a matrix having all 0 entries,
and results in a matrix with no 0 entries at all.
To check the results, after doing these two operations, the command
\begin{verbatim}
length(which(a != adj))
\end{verbatim}
should return the value 0.

Note that the basic edge list, \verb|edges|, lacks information as to the size of
the adjacency matrix. \verb|tmp| above is a sparse matrix which is in edge list
format but includes information on the size of the adjacency matrix, and can be
used in a similar way to the original matrix \verb|a| while saving memory space.


\subsubsection{Behavioral data}

\SI also allows dependent behavior variables. This can be used in studies
of the co-evolution of networks and behavior, as described
in \citet*{SnijdersEA07} and \citet*{SteglichEA10}.
These behavior (or `action') variables represent
the actors' behavior, attitudes, beliefs, etc.
The difference between dependent behavior variables and changing actor
covariates (see below) is that the latter
have values determined by the input data and are assumed to
change exogenously, i.e., according
to mechanisms not included in the model, while the dependent
action variables change endogenously, i.e.,
depending on their own values and on the changing network.
Unlike the changing individual covariates,
the values of dependent action variables are not assumed to be
constant between observations.

Dependent behavioral variables must have nonnegative integer values;
e.g., 0 and 1, or a range of integers like 0,1,2 or 1,2,3,4,5.
The number of different values should not be too high: ten values
is on the high side.
Each dependent action variable must be given in one
matrix, containing $M$ columns, corresponding to the $M$
observation moments.

If any values are not integers, a warning will be printed on the initial report
given by \sfn{print01Report()} and the values will be truncated towards zero.

A special case of behavioral data can be used for
\emph{diffusion of innovations} \citep{Greenan15}:
here the behavior variable representing
having adopted the innovation is binary, coded 0 or 1, and
changes $1 \Rightarrow 0$ are impossible.
Model specifications that are especially useful for this data type
are presented in Section~\ref{S_behRate}.

\subsubsection{Individual covariates}

Individual (i.e., actor-bound, or monadic) variables
are defined by the functions
\sfn{coCovar} in the case they are constant over time,
and \sfn{varCovar} if they are changing over time.

Each constant actor covariate has one value per actor
valid for all observation moments, and has the role of an
independent variable.

Changing variables can change between observation moments;
then they are called `changing individual covariates',
and have the role of independent variables.

Changing individual covariates are assumed to have constant values from one
observation moment to the next. If observation moments for the
network are $t_1, t_2, ..., t_M$, then the changing covariates
should refer to the $M-1$ moments $t_1$ through $t_{M-1}\,$, and
the $m$-th value of the changing covariates is assumed to be valid
for the period from moment $t_m$ to moment $t_{m+1}\,$.
The value at $t_M$, the last moment, does not play a role.
Changing covariates, as independent variables, are meaningful
only if there are 3 or more observation moments,
because for 2 observation moments the distinction between
constant and changing covariates is not meaningful.

Each changing individual covariate must be specified
in a separate call of \sfn{varCovar}, using for input
an $n \times (M-1)$ matrix where the columns correspond to the $M-1$ periods
between observations.

By default, the mean is subtracted from the covariates.
This can be turned off by constructing the covariate with the keyword
\texttt{centered=FALSE}. Centering of covariates improves
convergence of the estimation algorithm.
Therefore the advice is to use the default (centering) unless there are reasons to
use non-centered covariates, such as when they are used as weights in effects
(e.g., for inPopX).
It is possible to include a given actor variable as a covariate in the centered
as well as the non-centered version in the Siena data set.
See Section~\ref{S_center} on centering.

When an actor covariate is constant within waves, i.e.,
within each wave it has the same value for all actors;
or, more generally, when within each wave it has the same value for
all actors
within components separated by structural zeros (which means that
ties between such components are not allowed), then only the ego effect
of the actor covariate is made available.
This is because the other effects then are meaningless.
This may cause problems for combining several data sets
in a multi-group project (see Section~\ref{S_multigroup}).
If at least one case is missing (i.e., has the missing value data code),
then the other covariate effects are made available.
When analysing multiple data sets in parallel,
for which the same set of effects is desired to be included,
it is therefore advisable to give data sets in which
a given covariate has the same value for all actors
one missing value in this covariate; purely to make
the total list of effects independent of the observed data.



\subsubsection{Dyadic covariates}

Like the digraph data, also each measurement of a dyadic covariate
must be contained in a separate matrix.
For one-mode data this is a square data matrix,
and the diagonal values are meaningless.
%Pajek input format is currently not possible for dyadic covariates.

A distinction is made between constant and changing dyadic
covariates, where change refers to changes over time. Each constant
covariate has one value for each pair of actors, which is valid for
all observation moments, and has the role of an independent
variable. Changing covariates, on the other hand, have one such
value for each period between measurement points. If there are $M$
waves (i.e., observation moments) of network data,
this covers $M-1$ periods, and accordingly,
for specifying a single changing dyadic covariate,
a $n \times n \times (M-1)$ array is needed.

Like is the case for monadic  covariates,
changing dyadic covariates are assumed to have constant values from one
observation moment to the next. If observation moments for the
network are $t_1, t_2, ..., t_M$, then the changing covariates
refer to the $M-1$ moments $t_1$ through $t_{M-1}\,$, and
the $m$-th value of the changing covariates is assumed to be valid
for the period from moment $t_m$ to moment $t_{m+1}\,$.
The value at $t_M$, the last moment, does not play a role.

Constant dyadic covariates are specified using function
\sfn{coDyadCovar}, and changing dyadic covariates by \sfn{varDyadCovar}.

The mean is always subtracted from the covariates.
See Section~\ref{S_center} on centering.

\subsection{Internal data treatment}
\label{S_internal}

\subsubsection{Interactions and dyadic transformations of covariates}

For actor covariates (also called monadic covariates),
two kinds of transformations to dyadic covariates
are made internally in \si, by the definition of the
corresponding effects. Denote the actor covariate by $v_i$,
and the two actors in the dyad by $i$ and $j$.
Suppose that the range of $v_i$ (i.e., the difference between the
highest and the lowest values) is given by $r_V$.
The two transformations are the following:
\begin{enumerate}
\item \emph{dyadic similarity} is defined by
\begin{equation}
 \text{sim}^V_{ij} \,=\, 1 - \frac{ \vert v_i - v_j \vert }{ r_V } \ .
            \label{simV}
\end{equation}
      This similarity measure is 1 if
      the two actors have the same value, and 0 if one has the highest and the
      other the lowest possible value.
      For the various similarity effects, this measure
      is centered by subtracting the mean over all dyads,
      so the mean of this similarity variable becomes 0.    \\
      The advantage of this similarity measure is that its coefficients
      are comparable in the sense that the measure always ranges
      between 0 and~1.  \\
      The mean of (\ref{simV}) is calculated by function
      \sfn{sienaDataCreate} and stored as the \sfn{simMean} attribute
      of \texttt{mydata\$cCovars\$myvar}, where \texttt{mydata} is the name
      of the object created by \sfn{sienaDataCreate}, and \texttt{myvar}
      is the name of the variable used as the argument for
      \sfn{sienaDataCreate}, while the name \texttt{cCovars} applies for
      constant monadic covariates, and is to be replaced by \texttt{vCovars}
      for changing (varying) monadic covariates;
      for centering issues, further see Section~\ref{S_center}.
\item \emph{same $V$} is defined by
\begin{equation}
 \text{same}^V_{ij} \,=\,
        \left\{ \begin{array}{ll} 1 & \text{ if } v_i \,=\, v_j \\
                          0 & \text{ if } v_i \,\neq\, v_j \ .
    \end{array} \right.
\end{equation}
      This can also be referred to as \emph{dyadic identity}
      with respect to $V$.
\end{enumerate}
Dyadic similarity is relevant for variables that can be treated as
interval-level variables; dyadic identity is relevant for categorical variables.

In addition, \SI offers the possibility of user-defined two- and three-variable
interactions between covariates; see Section~\ref{S_int_eff}.


\subsubsection{Centering}
\label{S_center}

Individual as well as dyadic covariates can be centered
by the program in the following way.

For individual covariates, the mean value is subtracted
by function \sfn{SienaDataCreate}. The centered values then are stored
(see below),
and all calculations use these centered variables.
For the changing covariates, the mean
value used is the global mean (averaged over all periods).
The values of these subtracted means are reported in the output
of \sfn{print01Report()}.
For the multi-group option (section \ref{S_multigroup}),
the subtracted values are the global means across all groups.

Centering is the default.
Centering of covariates can be turned off by specifying
\texttt{centered=FALSE} in the call of \sfn{coCovar()},
\sfn{varCovar()}, \sfn{coDyadCovar()}, or \sfn{varDyadCovar()}, respectively.
Centering of covariates improves
convergence of the estimation algorithm.
Therefore the advice is to use the default (centering) unless there are reasons to
use non-centered covariates, such as when they are used as weights in effects
(as is the case, e.g., for effect \texttt{inPopX}).
If some actor variable is to be used as a non-centered covariate,
it is recommended to include it as a covariate in the centered
as well as the non-centered version in the Siena data set,
and use the non-centered version only when it is necessary
to get the appropriate effect definition.

For the dyadic covariates and the similarity variables derived
from the individual covariates, the grand mean is calculated
and stored by function \sfn{SienaDataCreate()};
the stored values of the variables are not centered, but the means
are subtracted during the program calculations. (Thus,
dyadic covariates are treated internally by the program differently than
individual covariates in the sense that the mean is subtracted at
a different moment, but the effect is the same; except for multi-group
projects, see below.)
Unlike the `covariate similarity' effect,
the `same covariate' effect is not centered but keeps its 0-1 values.

For the multi-group option (section \ref{S_multigroup}),
dyadic covariates are treated \underline{differently} from
individual covariates:
for dyadic covariates in multi-group projects, centering is done by the
within-group mean;
actor covariates in multi-group projects
are centered by the overall mean.

For dependent behavioral variables, the effects are defined
in Section~\ref{S_ff_b} as functions of centered variables.
% See overallMean() in BehaviorLongitudinalData.h

The means of covariates are stored as attributes on the object created by
\sfn{SienaDataCreate}.
If you wish to access them, the following steps can show
where these means can be found.
For example, suppose that the command given was
\begin{verbatim}
mydata <- sienaDataCreate( friendship, smoke1, alcohol )
\end{verbatim}
The structure of this object is obtained by requesting
\begin{verbatim}
str(mydata, 1)
\end{verbatim}
Looking at the response, you
will see that this object contains (among other things):
\begin{enumerate}
\item the constant actor covariates as \texttt{mydata\$cCovars}
\item the varying actor covariates as \texttt{mydata\$vCovars}
\item the constant dyadic covariates as \texttt{mydata\$dycCovars}
\item the varying dyadic covariates as \texttt{mydata\$dyvCovars}
\item the dependent behavioral variables as \texttt{mydata\$depvars}
\end{enumerate}
Since \texttt{smoke1} is a constant covariate and \texttt{alcohol}
a changing covariate, their means can be requested by
\begin{verbatim}
attr(mydata$cCovars$smoke1, "mean")
attr(mydata$vCovars$alcohol, "mean")
\end{verbatim}
and the centered values for, e.g, the variable \texttt{alcohol} by
\begin{verbatim}
mydata$vCovars$alcohol
\end{verbatim}
The mean of the similarity variable is stored as the \sfn{simMean} attribute,
and is obtained by, e.g.,
\begin{verbatim}
attr(mydata$cCovars$smoke1, "simMean")
\end{verbatim}

The formula for balance is a kind of dissimilarity between rows of
the adjacency matrix. The mean dissimilarity is subtracted in this
formula, having been calculated according to a
\hyperlink{T_meanbal}{formula given in Chapter}~\ref{S_math}.
It is also reported in the
 output file produced by \sfn{print01Report()} and available -- e.g., for the first
dependent variable -- as \texttt{attr(mydata\$depvars[[1]], "balmean")}.
Instead of \texttt{[[1]]} you can request a different number or
the name of the variable.

%The dependent behavior variable is not centered.

\subsubsection{Monotonic dependent variables}
\label{S_monotone}


In some data sets, a dependent variable only increases, or only decreases.
For a network, this means that ties can be created but not terminated,
or the other way around.
This may be the case for all periods (a period is defined by the
two consecutive observation waves at its start and end points)
or just in some of the periods.
\RS will note when a dependent variable only increases or only decreases
in any given period,
and mention this in the output file generated by \textsf{print01Report}.
This constraint then is also respected in the simulations, in the periods
where it is observed.
This is represented
internally by a variable called \texttt{uponly} indicating that the
dependent variable cannot decrease,
and a variable \texttt{downonly} indicating that the
dependent variable cannot increase.
The constraints signaled by the  \texttt{uponly} and  \texttt{downonly}
variables can be lifted by using \texttt{allowOnly = FALSE}
in the call of \sfn{sienaDependent} (see the help file for this function).

If a dependent variable is only increasing or only decreasing
for all periods and \sfn{sienaDependent} was called with
\sfn{allowOnly=TRUE} (the default),
then two basic effects are not identified.
These are the outdegree effect for a dependent network variable,
and the linear shape effect for a dependent behavior variable;
these effects define the balance between the probabilities of
going up and going down.
These effects then are dropped automatically from the effects object.
If this is not desired, this can be prevented
by calling \sfn{sienaDependent} with \sfn{allowOnly=FALSE}.


\subsubsection{Multivariate dependent variables with constraints}
\label{S_constraints0}

When analysing multiple dependent networks, it is possible that they
are related in some deterministic way. For example, two networks
might be mutually exclusive (this could be the case for negative and positive
ties -- although there are many cases where positive
and negative ties may coexist!), or networks could be ordered, i.e.,
one network could be a sub-network of the other
(networks with ordinal tie values represented as a multivariate network).
This is treated in Section~\ref{S_constraints}.


\subsection{Further data specification options}
\label{S_usertrans}

\subsubsection{Structurally determined values}
\label{S_struct}

It is allowed that some of the values in the digraph are
structurally determined, i.e., deterministic rather than random.
This is analogous to the phenomenon of `structural zeros' in
contingency tables, but in \SI not only structural zeros but also
structural ones are allowed. A structural zero means that it is
certain that there is no tie from actor $i$ to actor $j$; a
structural one means that it is certain that there is a tie. This
can be, e.g., because the tie is impossible or formally imposed,
respectively.

Structural zeros provide an easy way to deal with actors leaving
or joining the network between the start and the end
of the observations: specify all their incoming and outgoing tie
variables, at the moment that they are not present, as structural zeros.
Note that actors having all values specified as structural zeros in this way
take part of the simulations only starting at the observation moment
where they are not totally structurally zero;
therefore, this way of representing partially absent actors
is not meaningful for actors who are present only at the very last wave.
In particular, this includes the case where there are two waves only
for actors who join the network after the first wave.

Another way (more complicated but more flexible,
because it gives possibilities to represent actors
entering or leaving at specified moments between observations)
is the method of joiners and leavers, described in Section~\ref{S_comp}.
For actors present only at the last wave, the method of
joiners and leavers is preferable.

When endowment or creation effects are to be included in the
model specification, changing structural values should not be used,
and the method of joiners and leavers then also is preferable.

Structurally determined values are defined by reserved codes in
the input data: the value 10 indicates a structural zero, the
value 11 indicates a structural one. Structurally determined
values can be different for the different time points. (The
diagonal of the data matrix for a one-mode network
always is composed of structural
zeros, but this does not have to be indicated in the data matrix
by special codes.) The correct definition of the structurally
determined values can be checked from the brief report of this in
the output file of \sfn{print01Report} --- which is given only,
however, if the diagonal entries of the one-mode networks are also
set to 10.

If there are a lot of structurally determined values
then unconditional estimation  (see Section~\ref{S_cond})
is preferable.

Structural zeros offer the possibility of analyzing several
networks simultaneously under the assumption that the parameters
are identical.
However, a preferable option to do this is given in Section~\ref{S_mulev}.
E.g., if there are three networks with 12, 20 and
15 actors, respectively, then these can be integrated into one
network of 12 + 20 + 15 = 47 actors, by specifying that ties
between actors in different networks are structurally impossible.
This means that the three adjacency matrices are combined in one
$47 \times 47$ data matrix, with values 10 for all entries that
refer to the tie from an actor in one network to an actor in a
different network. In other words, the adjacency matrices will be
composed of three diagonal blocks, and the off-diagonal blocks
will have all entries equal to 10. In this example, the number of
actors per network (12 to 20) is rather small to obtain good
parameter estimates, but if the additional assumption of identical
parameter values for the three networks is reasonable, then the
combined analysis may give good estimates.

In such a case where $K$ networks (in the preceding paragraph, the
example had $K = 3$) are combined artificially into one bigger
network, it will often be helpful to define $K-1$ dummy variables
at the actor level to distinguish between the $K$ components.
These dummy variables can be given effects in the rate function
and in the evaluation function (for ``ego"), which then will
represent that the rate of change and the out-degree effect are
different between the components, while all other parameters are
the same.

It will be automatically discovered by \SI when monadic covariates
depend only on these components defined by structural zeros,
between which tie values are not allowed.
For such variables, only the ego effects are defined
and not the other effects defined for the regular
actor covariates and described in Section ~\ref{S_eff_cov}.
This is because the other effects then are meaningless.
If at least one case is missing,
then the other covariate effects are made available.

When \SI simulates networks including some structurally determined values,
if these values are constant across all observations then
the simulated tie values are likewise constant.
If the structural fixation varies over time, the situation
is more complicated.
Consider the case of two consecutive observations
$m$ and $m+1$,
and let $X^{\text{sim}}_{ij}$ be the simulated value
at the end of the period from $t_m$ to $t_{m+1}$.
If the tie variable $X_{ij}$ is structurally fixed at time $t_m$
at a value $x_{ij}(t_m)$,
then $X^{\text{sim}}_{ij}$ also is equal to $x_{ij}(t_m)$,
independently of whether this tie variable is structurally fixed
at time $t_{m+1}$ at the same or a different value or not at all.
This is the direct consequence of the structural fixation.
On the other hand, the following rule is also used.
If $X_{ij}$ is \emph{not} structurally fixed at time $t_m$
but it is structurally fixed at time $t_{m+1}$ at some value $x_{ij}(t_{m+1})$,
then in the course of the simulation process from  $t_m$ to $t_{m+1}$
this tie variable can be changed as part of the process in the usual way,
but after the simulation is over and before the statistics are calculated it will be fixed
to the value $x_{ij}(t_{m+1})$.

The target values for the algorithm of the Method of Moments estimation
procedure are calculated for all observed digraphs $x(t_{m+1})$.
However, for tie variables $X_{ij}$ that are
structurally fixed at time $t_m$, the observed value  $x_{ij}(t_{m+1})$
is replaced by the structurally fixed value  $x_{ij}(t_{m})$.
This gives the best possible correspondence between target values
and simulated values in the case of changing structural fixation.


\subsubsection{Missing data}
\label{S_missing}

\SI allows that there are some missing data on network variables,
on covariates, and on dependent action
variables.  Missing data must be indicated by
the usual missing data code for \Rn, \texttt{NA}.

Missingness of data is treated as non-informative.
One should be aware that having many missing data can seriously
impair the analyses: technically, because estimation will be
less stable; substantively, because the assumption of
non-informative missingness often is not quite justified.
Up to $10\%$ missing data will usually not give many difficulties
or distortions, provided missingness is indeed non-informative
\citep{HuismanSteglich08}.
When one has more than $20\%$ missing data on any variable, however,
one may expect problems in getting good estimates.

In the current implementation of \si, missing data are treated in
a simple way, trying to minimize their influence on the estimation
results.
This method is further explained in \citet{HuismanSteglich08},
where comparisons are also made with other ways of dealings with the missing
information. The default method in \RS for handling missings in the dependent
variable is the fourth method as described in \citet{HuismanSteglich08}.

The basic idea is the following.
\medskip

A brief sketch of the procedure is that
missing values are imputed to allow meaningful simulations;
for the calculation of the target statistics in the Method of Moments,
tie variables and actor variables with missings are not
used.
More in detail, the procedure is as follows.

The simulations are carried out over all variables,
as if they were complete.
To allow this, missing data are imputed.
In the initial observation, missing entries in the adjacency
matrix are set to 0,
i.e., it is assumed that there is \emph{no} tie;
this is done because normally data are sparse, so `no tie'
almost always is the modal value of the tie variable.
In the further observations, for any tie variable,
if there is an earlier observed value of this variable then
the last observed value is used to impute the current
value (the `last observation carry forward' option,
cf.\ \citet{Lepkowski89}); if there is no earlier observed
value, the value 0 is imputed.
For the dependent behavior variables a similar principle
is used: if there is a previous observation of the same variable
then this value is imputed, if there is none but there
is a next observation then this is imputed, if this also is absent
then the observationwise mode of the variable is imputed.
Missing covariate data are, by default, replaced by the
variable's global mean; but in the definition of actor covariates,
by the functions \sfn{coCovar()} or \sfn{varCovar()}, the user
has the option to supply other values for imputation of the missings.
In the course of the simulations, however, the imputed values of the dependent
behavior variables and of the network variables are allowed to change.
\medskip

In order to ensure a minimal impact of missing data treatment on
the results of parameter estimation (Method of Moments estimation)
and/or simulation runs, the calculation of the target statistics
used for estimation by the Method of Moments, and reporting in these
procedures uses only non-missing data.
When for an actor in a given period, any variable is missing that is
required for calculating a contribution to such a statistic, this
actor in this period does not contribute to the statistic in
question. For network and dependent behavior variables, the tie variable
or the actor variable, respectively,
must provide valid data both at the beginning and at the end of a
period for being counted in the respective statistics.
This is implemented as follows: if a tie variable is missing in wave $m$,
for the calculation of observed as well as simulated target statistics
for periods $m-1$, $m$, and $m+1$ it is replaced by the value 0;
if a dependent behavior variable is missing in wave $m$,
for the calculation of observed as well as simulated target statistics,
where always the centered values are used, for periods $m-1$, $m$, and $m+1$
the value is replaced by 0 (which, given the centering,
is equivalent to the overall mean).

For non-centered covariates, the treatment of missing data is less
well thought out; this may cause problems in the analysis
of data with a lot of missing values for non-centered covariates.
\medskip

By using the argument \texttt{imputationValues} in \sfn{coCovar()}
and \sfn{varCovar()}, other values
(i.e., values different from the mean that is used by default
for imputation) can be given for imputation of missings
in monadic covariates.
These are then used for the simulations; since they were indicated as missings
(\texttt{NA}) in the data themselves, they will not be used for the calculation
of target statistics in the Method of Moments.
\medskip

For estimation by Maximum Likelihood, missing values in the dependent variables
at the end of a period are treated in a model-based way.
For missings at the start of a period, independent priors are used.
However, periods are treated separately: simulations in period $m$ do not help
provide information for period $m+1$.
See
\href{http://www.stats.ox.ac.uk/~snijders/siena/Siena_algorithms.pdf}{\texttt{Siena\_algorithms.pdf}}
for a further description.

\subsubsection{Composition change: joiners and leavers}
\label{S_comp}

\SI can also be used to analyze networks of which the composition
changes over time, because actors join or leave the network
between the observations.
This can be done in two ways: using the method of \citet{HuismanSnijders03},
or using structural zeros.
(For the maximum likelihood estimation option, the Huisman-Snijders method
is not implemented, and only the structural zeros method can be used.)
Structural zeros can specified for all elements of the tie variables
toward and from actors who are absent at a given observation moment.
How to do this is described in subsection~\ref{S_struct}.
This is straightforward and not further explained here.
This subsection explains the method of Huisman and Snijders
(2003), also called the method of joiners and leavers,
which uses the information about composition change
in a somewhat more efficient way.

Network composition change, due to actors joining or leaving the
network, is handled separately from the treatment of missing data.
The data matrices must contain all actors who are part of the
network at any observation time.
If adjacency matrices are used as data input, they must therefore
all have the same number of $n$ rows, each actor
having a separate (and fixed) line in these matrices, even for
observation times where the actor is not a part of the network
(e.g., when the actor did not yet join or the actor already left
the network).

The \emph{times of composition change} can be given
either in a data file or in a list available in the \R session.
For networks with constant composition
(no entering or leaving actors), this file or list is
omitted and the current subsection can be disregarded.

If there is composition change, estimation by the Method of Moments
is forced to be unconditional (see Section~\ref{S_cond}).

For these waves, where the actor is not in the network, the entries
of the adjacency matrix can be specified in two ways. First as
missing values using missing value code \texttt{NA}. In the estimation
procedure, these missing values of the joiners before they joined
the network are regarded as 0 entries, and the missing entries of
the leavers after they left the network are fixed at the last
observed values. This is different from the regular missing data
treatment. Note that in the initial data description the missing
values of the joiners and leavers are treated as regular missing
observations. This will increase the fractions of missing data and
influence the initial values of the density parameter.

A second way is by giving the entries a regular observed code,
representing the absence or presence of a tie (as
if the actor was a part of the network). In this case, additional
information on relations between joiners and other actors in the
network before joining, or leavers and other actors after leaving
can be used if available. Note that this second option of
specifying entries always supersedes the first specification: if a
valid code number is specified this will always be used.

The functions used to specify the times actors
join or leave the network (i.e., the times of composition change)
are \sfn{sienaCompositionChangeFromFile()} in case a file is used,
and \sfn{sienaCompositionChange()} in case a list is used.
How to use a separate input file,
called the \emph{exogenous events file}, is
described in the help page for \sfn{sienaCompositionChangeFromFile()}.

In the second case, a list must be given of length $n$,
where $n$ is the number of actors in the node set.
The $i$'th element of this list must be a vector of numbers (characters are also allowed),
composed of an even number of elements, indicating the intervals during
which actor $i$ was present. For example, \texttt{1 4} indicates that the actor
was present from wave 1 to wave 4 (end points included) and
\texttt{1 3.2 5.01 7}
indicates that the actor was present from wave 1 to 20\% of the time between
waves 3 and 4, and then again from just after wave 5 to wave 7.

As an example, suppose we have 50 actors and 6 waves;
almost all actors were present all the time, but actor 11 was present
from wave 3 onward, actor 20 was present until wave 4, and
actor 33 was present from mid-way between waves 1 and 2 until wave 3, and then
again from just after wave 4 to wave 6.
Then the list can be created by the following commands.
\begin{verbatim}
comp <- rep(list(c(1,6)), 50)
comp[[11]] <- c(3,6)
comp[[20]] <- c(1,4)
comp[[33]] <- c(1.5,3,  4.01,6)
changes <- sienaCompositionChange(comp)
\end{verbatim}
(The use of blanks in the line for \texttt{comp[[33]]} is only for visually
keeping the pairs of start-end times together.)

The first line, creating a list with the (default) first and
last end point for everybody, could also be replaced by
\begin{verbatim}
comp <- vector("list", 50)
comp[] <- list(c(1,6))
\end{verbatim}
Here it may be noted that \texttt{[]} keeps structures etc.\ unchanged
while replicating the expression to fit.

The object \texttt{changes} created by the functions
\sfn{sienaCompositionChangeFromFile} or
\sfn{sienaCompositionChange} is of class
\sfn{compositionChange} and can be used in the function
\sfn{sienaDataCreate}.

The method of joiners and leavers for representing composition change
does not combine properly with the \sfn{sienaGOF} function
(Section~\ref{S_gof}).
But if you use \texttt{NA} codes for the tie variables of absent actors,
and these are indicated as such by a \sfn{compositionChange} object, then
\sfn{sienaGOF}  will work properly.

The implementation of endowment and creation effects does not agree
with changing structural zeros or ones. Therefore, if there is
changing composition in a data set and the model should contain endowment
and/or creation effects, the changing composition should be reflected by
a changing composition and not by structural zeros.


\newpage
\section{Model specification}
\label{S_modspec}

\subsection{Definition of the model}
\label{S_defmod}

After defining the data, the next step is to specify a model.
The model specification consists of a selection of `effects'
for the evolution of each dependent variable (network or behavior).
To understand this, first a brief review of the definition of the
actor-oriented model is given
\citep*[for further explanations see][]{Snijders01, Snijders05,
SnijdersEA07, SnijdersEA10b}.

The model is based on four functions, which first are explained in an
intuitive way.
They are defined specifically for all dependent variables (network, behavior,
or more of these if included in the model).
These functions depend on the actor (hence the name `actor-oriented')
and on the state of the network, behavior, and covariates.
All these functions are constituted by a weighted sum
of so-called \emph{effects}, which define the characteristics of
the network (and behavior, if this is included as a dependent variable)
that determine the probabilities of changes.


\begin{itemize}
\item \emph{rate function}\\
The rate function models the speed by which the dependent variable
changes; more precisely: the speed by which each network actor
gets an opportunity for changing her score on the dependent
variable.\\
Advice: in most cases, start modeling with a constant rate function without
additional rate function effects.

When there are important differences between
actors in some measure of size or importance,
it is possible that different advice must be given.
This can be the case, e.g., when the network has a clear
core-periphery structure; or when the outdegree distribution
is very skewed.
Then it may be necessary to let the rate function
depend on the outdegrees or on an individual covariate indicating this size.

\item {\em evaluation function }\\
The evaluation function\footnote{The evaluation function was called
\emph{objective function} in \citet{Snijders01}.}
is the primary determinant of the probabilities of changes.
Probabilities are higher for moving towards states with a higher value
of the evaluation function.
One way of representing this is that the evaluation function
models the actor's `satisfaction'\footnote{The term
`satisfaction' should be interpreted here in a very loose sense;
the satisfaction interpretation is not necessary at all, but it does give
a convenient intuitive way of thinking about the model.}
with her/his local
network neighborhood configuration. It is assumed that actors
change their scores on the dependent variable such that they
improve their total satisfaction -- with a random element
to represent the limited predictability of behavior.
In contrast to the creation and endowment
functions (described below), the evaluation function evaluates only
the local network neighborhood configuration that results from the
change under consideration, without considering `where you come from'.
In most applications, the evaluation function will
be the main focus of model selection.

\newpage
\item {\em creation function }\\
The creation function\footnote{A special case of the {\it gratification
function} in \citet{Snijders01}.}
distinguishes between new and old network
ties (when evaluating possible network changes) and between
increasing or decreasing behavioral scores (when evaluating
possible behavioral changes).
It is a component of the probabilities of change only for changes in
an upward direction: creation of new ties, augmentation of values
of the behavior dependent variable.
Creation effects can be the creation parts of an evaluation effect,
or elementary effects (see below).

In the interpretation using satisfaction, the creation function
models the gain in satisfaction incurred when network ties are created
or behavioral scores are increased.

\item {\em endowment or maintenance function}\\
The endowment function\footnote{The endowment function also is
a special case of the {\it gratification function} in \citet{Snijders01}.},
which also may be called \emph{maintenance function},
also distinguishes between new and old network
ties (when evaluating possible network changes) and between
increasing or decreasing behavioral scores (when evaluating
possible behavioral changes).
It is a component of the probabilities of change only for changes in
a downward direction: maintenance vs.\ termination of existing ties,
decrease of values of the behavior dependent variable.

Again, endowment effects can be the maintenance parts of an evaluation effect,
or elementary effects (see below).

In the interpretation using satisfaction, the endowment function
models the loss in satisfaction incurred when network ties are dissolved or
behavioral scores are decreased (hence the label `endowment').
\end{itemize}

Leaving aside the rate effects, a given effect can normally be included
in the model in any of the three `types' or `roles' of
evaluation, creation, or endowment effect.
In almost all cases, the advice is to
start modeling without any creation or endowment effects,
and add them perhaps at a later stage.
For example, if the network dynamics in a given data set is such
that ties mainly are created, and they are dissolved rather rarely,
then the data will contain little information about the question whether
creating ties follows different rules than dissolving ties,
and if one would try to include   creation or endowment effects
for effects already included in the evaluation function,
this would lead to large standard errors.
Creation and endowment effects for behavior for behavior variables with more
than 2 values are still under investigation, and their interpretation
for practical research still is uncertain.

A model specification with only evaluation effects and without creation and
endowment effects leads to exactly the same network dynamics as a specification
where these effects are turned into creation and endowment effects,
if the same parameters would have exactly the same values.
For any given effect, it makes no sense to include the effect
in all three roles: evaluation, creation, endowment.
If one wishes to go beyond evaluation effects, then the user has to choose
between adding an effect in either the creation or the endowment role.

For any effect, the model specifications of (evaluation \& creation),
(evaluation \& endowment), and (creation \& endowment) are equivalent,
and pairs of parameters can be directly transformed into each other
(cf.\ Section~\ref{S_c}),
but the estimates by the Method of Moments will not have the same correspondence
because different pairs of target statistics are used.
Each of the pair specifications could be tried out, in principle.
Perhaps the first two pair specifications, containing the evaluation
effect and one of the other two, give the most precise estimates;
but this is not necessarily always the case.


\subsubsection{Elementary effects}
\label{S_elementary}

Not all contributions  to the probability of change can be written
as the change in some basic function (evaluation function).
Therefore we sometimes need to directly represent contributions to a
tie change or behavior change, without invoking an evaluation function.
This can be done by using elementary effects.
(In \citet{Snijders01} this was called a gratification function;
as a more neutral term, we now use the word `elementary effects'.)
\smallskip

\noindent
\begin{minipage}[t]{.8\textwidth}
The basic example here is transitive closure, which can be represented
by the tendency toward forming closed triplets as in this figure.
When the focal actor is $i$, ties that lead to the closure are
$i \rightarrow j$ and $i \rightarrow h$; but the first of these ties
means the closing of a two-path $i \rightarrow h \rightarrow j$, while
the second means forming a tie to an actor $h$ who made the same outgoing
choice to the third actor $j$, a sign of structural equivalence;
so these are distinct processes.
The evaluation effect corresponding to the tendency toward forming
closed triples
is the \texttt{transTrip} effect, which is composed of the
two distinct elementary effects
\texttt{transTrip1}, contributing to creating or maintaining the $i \rightarrow j$ tie,
and \texttt{transTrip2}, contributing to the $i \rightarrow h$ tie;
see Section~\ref{S_math}.
\end{minipage}
\hfill
\begin{minipage}[t]{.1\textwidth}
\linethickness{0.3pt}
\vfill
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\end{minipage}
\smallskip

An elementary effect is a contribution to the creation or maintenance of a tie,
defined directly, i.e., without expressing it based on the
change in some evaluation function.
This means that elementary effects are more general than
evaluation effects, and all effects could be represented as elementary effects.
For the sake of interpretation, however, the evaluation function formulation
is used whenever possible.

Elementary effects can apply similarly to the creation and maintenance of a tie;
or they can apply exclusively to tie creation, or exclusively to tie
maintenance. In \RS the difference between elementary effects and evaluation effects
is only in the internal programming code, and the
possible values of the \texttt{type} of effect
as specified in the effects object and the
functions \sfn{includeEffects()} and \sfn{setEffect()}
are only \texttt{eval}, \texttt{creat}, and \texttt{endow}.
In Chapter~\ref{S_math} almost all effects are evaluation effects,
and the effects that are elementary (and not evaluation) effects
are mentioned as such.

\subsubsection{Specification in \SI}

The model specification is defined in \SI by the so-called
\emph{effects object}, which formally is an object of class
\sfn{sienaEffects} or, for multiple groups as discussed in Chapter~\ref{S_mulev}
of class \sfn{sienaGroupEffects}.
This object is originally created by the function \sfn{getEffects} and
subsequently modified by the functions \sfn{includeEffects} and/or
\sfn{setEffects}.
The scripts on the \SI website give examples.
An important ingredient here is the so-called \sfn{shortName}
of each effect, which is used to identify it;
effects of covariates need, in addition, the name of the covariate
because the \sfn{shortName} does not specify the covariate.
If there are several dependent variables (networks and/or behavioral variables),
the variable name (\sfn{name}) also is required to specify the effect.
The \sfn{shortName}s are part of the effects object.
For the practical use of \si, the \sfn{shortName}s are important.
A list of effects with their \sfn{shortName}s can be displayed in a browser
by using the function:

\verb|effectsDocumentation()| \\

For example, the command
\begin{verbatim}
cbind(myeff$effectName, myeff$type, myeff$shortName)[1:20,]
\end{verbatim}
gives a list of the first 20 effects in the \texttt{myeff} object.
As another example,
\begin{verbatim}
cbind(myeff$effectName, myeff$type, myeff$shortName)[myeff$type=="eval",]
\end{verbatim}
lists all evaluation effects in \texttt{myeff}.


\subsubsection{Mathematical specification}
\label{S_mathmod}

To attach precise meaning to the intuitive explanations above,
the mathematical definition of the model is given as follows.
To keep notation simple, we leave all statistical parameters out of the
formulae. To keep the section short, we do not give a lot of explanation,
but refer to the mentioned literature for that purpose.

As explained in \citet*{SnijdersEA10b}, the model is a continuous-time
Markov chain, and represents how the network (and behavior) has changed
in small steps (the so-called \emph{ministeps}) from one observed
to a later observed value. Each ministep entails a change in only
one tie value, or one behavioral variable, and is modeled as follows.

First consider the network dynamics.
At any given moment, let the network be denoted $x^0$.
The rate function for actor $i$ is denoted $\lambda_i(x)$;
the evaluation function is $f_i(x)$; the creation function is $c_i(x)$;
and the endowment function is $e_i(x)$.

At any given moment, let the current network be denoted $x^0$.
The time duration until the next opportunity of change
is exponentially distributed with parameter
\[
  \lambda_+(x^0) \,=\, \sum_i \lambda_i(x^0) \ .
\]
This means that the expected time duration is
\[
   \frac{1}{\lambda_+(x^0)} \ .
\]
The probability that actor $i$ will be the next to
have an opportunity for change is
\[
  \frac{\lambda_i(x^0)}{\lambda_+(x^0)} \ .
\]
Now suppose that actor $i$ is the one who has the next opportunity
for change; one could say, this is the focal actor.
Actor $i$ then has the possibility to change one network tie,
or to keep the network as it is.
Denote by $\mathcal C$ the set of all networks that can be obtained
as a result.
Then the probability of the network obtained from this step depends on
something called the objective function $u_i(x^0, x)$ which will be defined
in a moment.
The probability that the next network is $x$ is given by
\begin{equation}
     \frac{\exp(u_i(x^0, x)\big)}
          {\sum_{x' \in \mathcal C} \exp\big(u_i(x^0, x')\big)} \ . \label{probab}
\end{equation}
The numerator is required to make all probabilities for this step sum to 1.

The objective function is defined as follows.
If there is only an evaluation function (mathematically, this means that
the creation and endowment functions are 0), then
the objective function is equal to the evaluation function for the new state,
\[
   u_i(x^0, x) \,=\, f_i(x) \ .
\]
Because of the properties of the exponential function one can just as
well define the objective function as the gain in evaluation function,
\[
   u_i(x^0, x) \,=\, f_i(x) - f_i(x^0) \ .
\]
To define the general case, note that if $x^0$ and $x$ are not the same,
then they differ in only one tie variable $x_{ij}$.
Define  $\Delta^+(x^0, x) = 1$ if $x$ has one tie more than $x^0$,
meaning that a tie is created by this change, and $\Delta^+(x^0, x) = 0$
otherwise.
Similarly, define  $\Delta^-(x^0, x) = 1$ if $x$ has one tie less than $x^0$,
meaning that a tie is dissolved by this change, and $\Delta^-(x^0, x) = 0$
otherwise.
Then the general definition of the objective function is
\begin{align}
   u_i(x^0, x)  \,=\,  \label{u_i}   &
      \big(f_i(x) -  f_i(x^0)\big)  \\
                &   \,+\,   \Delta^+(x^0, x)\,\big(c_i(x) - c_i(x^0)\big)
                   \,+\,  \Delta^-(x^0, x)\,\big(e_i(x) - e_i(x^0)\big)    \ . \nonumber
\end{align}
This shows that the change in creation function plays a role
only if a tie is created ($\Delta^+(x^0,x) = 1$), and the change in
endowment function plays a role
only if a tie is dissolved ($\Delta^-(x^0,x) = 1$).

If also elementary effects are included, then denote the linear combination
for a tie variable $x_{ij}$
for general (evaluation-type) elementary effects by  $f^{\rm{el}}_{ij}(x)$, for creation
elementary effects by  $c^{\rm{el}}_{ij}(x)$, and for endowment elementary effects
by  $e^{\rm{el}}_{ij}(x)$.
To the objective function $ u_i(x^0, x)$ we then still have to add
\[
     f^{\rm{el}}_{ij}(x) \,+\,   \Delta^+(x^0, x)\, c^{\rm{el}}_{ij}(x)
                   \,+\,  \Delta^-(x^0, x)\,e^{\rm{el}}_{ij}(x) \ .
\]

For behavior dynamics the definitions are analogous.
Here a basic assumption is that, when there is an opportunity for change,
the possible new values for the behavior variable are the current
value, this value + 1, and this value --1, as long as these changes
do not take the value out of the permitted range.
More elaborate explanations are in
\citep*{SnijdersEA07, SnijdersEA10b, SteglichEA10, VeenstraEtAl2013}.

\subsection{Important structural effects for network dynamics:
           \protect\newline one-mode networks}
\label{S_imp_str1}

For the structural part of the model for network dynamics,
for one-mode (or unipartite) networks,
the most important effects are as follows.
The mathematical formulae for these and other effects are given
in Chapter~\ref{S_math}. Here we give a more qualitative description.

A default model choice could consist of (1) the out-degree and reciprocity
effects; (2) one network closure effect,
e.g.\ transitive triplets, transitive ties, or gwesp;
the transitive reciprocated triplets effect
and/or the 3-cycles effect;
(3) the in-degree popularity effect (raw or square root version);
the out-degree activity effect (raw or square root version);
and either the in-degree activity effect or the out-degree popularity effect
(raw or square root function).
The two effects (1) are so basic they cannot be left out.
The effects selected under (2) represent the dynamics in local (triadic) structure
\citep[also see][for the transitive reciprocated triplets effect]{Block2015};
and the three effects selected under (3) represent the dynamics
in in- and out-degrees (the first for the dispersion of in-degrees,
the second for the dispersion of out-degrees, and the third for the
covariance between in- and out-degrees) and also should offer
some protection, albeit imperfect, for potential ego- and alter-effects
of omitted actor-level variables.

Information about basic contact opportunities, if available,
should also be taken into account. This can be, e.g., membership
of the same classroom or department, or some measure of
proximity used as a dyadic covariate. Especially for large networks
(more than 100 nodes) this is important.

The basic list of these and other effects is as follows.

\begin{enumerate}
\item The \emph{out-degree effect} which always must be included.
\item The \emph{reciprocity effect} which practically always must be included.
\item There is a choice among several network closure effects.
      Usually it will be sufficient to express the tendency to network
      closure by including one or two of these. They can be selected
      by theoretical considerations and/or by their empirical
      statistical significance and contribution to a good fit.
      
      In older publications, when the gwesp effect was not available, it was
      sometimes advised to include the transitive triplets together with the transitive 
      ties effect. Currently, the impression is that often the gwesp effect
      is at least as good as a combination of transitive triplets and transitive
      ties. For many data sets, a model containing either the transitive triplets 
      effect or the gwesp effect (not both) is adequate to represent transitivity,
      and the user may try out which of these yields the best fit.
      \begin{enumerate}
      \item[a.]
      \begin{minipage}[t]{.6\textwidth}
      The \emph{transitive triplets effect}, which is
               the classical representation of network closure by the number of transitive
               triplets.
               For this effect the contribution
               of the tie $i \rightarrow j$ is proportional to the total number
               of transitive triplets that it forms -- which can be transitive triplets
               of the type
               $\{i \rightarrow j \rightarrow h ;\ i \rightarrow h \}$
               as well as $\{i \rightarrow h \rightarrow j ;\ i \rightarrow j \}$;
      \end{minipage}
\hfill
\begin{minipage}[t]{.2\textwidth}
\linethickness{0.3pt}
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\end{minipage}
      \item[b.] The \emph{transitive ties effect} is similar to the transitive
                triplets effect, but instead of considering for each other actor $j$
                how many two-paths $i \rightarrow h \rightarrow j $ there are,
                it is only considered whether there is at least one such indirect connection.
                Thus, one indirect tie suffices for the network embeddedness.
      \item[c.] The \emph{gwesp} effect; see later in this manual.
                Figure~\ref{F_gwesp2} shows that the contribution of the number of
                two-paths for the gwesp effect is between that for the transitive
                ties effect ($\alpha = 0$) and for the transitive
                triplets effect ($\alpha = \infty$). The default for gwesp
                is  $\alpha = 0.69$, corresponding to an internal effect
                parameter of 69.
      \item[d.] There are various other effects that may express network closure,
                such as the \emph{balance} effect, the
                \emph{Jaccard similarity effects} for incoming and for outgoing ties,
                and the \emph{number of actors at distance two effect}.
                The balance and Jaccard similarity effects are ways to express
                tendencies to structural equivalence.
                The number of actors at distance two effect expresses network
                closure inversely:
                stronger network closure (when the total number of ties is fixed)
                will lead to fewer geodesic distances equal to 2.
                When this effect has a negative parameter, actors will have a preference
                for having few others at a geodesic distance of 2 (given their
                out-degree, which is the number of others at distance 1);
                this is one of the ways for expressing network closure.
                However, it is theoretically ambiguous, because the number of
                others at a geodesic distance of 2 can be decreased in two
                quite different ways: dropping ties to those who have many
                connections `further out', or making ties to those who have many
                connections to others to whom one is already directly connected.
      \end{enumerate}
\item
      \begin{minipage}[t]{.7\textwidth}
      The \emph{three-cycles effect}, which can be regarded as
      generalized reciprocity (in an exchange interpretation
      of the network) but also as the opposite of hierarchy
      (in a partial order interpretation of the network).
      A negative three-cycles effect, together with a positive
      transitive triplets or transitive ties effect, may be
      interpreted as a tendency toward local hierarchy.
      The three-cycles effect also contributes to
      network closure.\\
      \citet{Block2015} has argued convincingly that instead of the
      three-cycles effect, it is often advisable to use the
      transitive reciprocated triplets effect.\\
      In a non-directed network, the three-cycles effect is identical
      to the transitive triplets effect.
      \end{minipage}
\hfill
\begin{minipage}[t]{.2\textwidth}
\linethickness{0.3pt}
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.9 2.559  to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\end{minipage}
\item Another triadic effect is the \emph{betweenness effect},
      which represents brokerage: the tendency for actors
      to position themselves between not directly connected
      others, i.e., a preference of $i$ for ties
      $i \rightarrow j$ to those $j$
      for which there are many $h$ with
      $h \rightarrow i$ and $h \not\rightarrow j$.
      This can, however, not be combined with the transitive triplets
      effect because it is a different mechanism leading to the
      same structures.\\
      The betweenness effect has the property that it is defined using
      configurations characterized by the \underline{absence} of certain ties,
      not only by their presence.
      This leads to difficulties in interpretation, and may be undesirable.

\item[{\hspace*{-1ex}$\bigodot$}]
     The following eight degree-related effects may be important especially for networks
     where degrees are theoretically important and represent social status
     or other features important for network dynamics;
     and/or for networks with high dispersion in in- or out-degrees
     (which may be an empirical reflection of the theoretical importance
     of the degrees).\\
     The out-degree popularity and in-degree activity effects are closely
     related; their raw (not-sqrt) versions are exactly collinear in the
     Method of Moments.\\
     Degree assortativity are higher-order effects, and will be included
     mainly if there are strong theoretical reasons for them.

\item The \emph{in-degree popularity effect} (again, with or without `sqrt',
     with the same considerations applying)
     reflects tendencies to dispersion in in-degrees of the actors;
     or, tendencies for actors with high in-degrees to attract extra incoming ties
     `because' of their high current in-degrees.
\item The \emph{out-degree popularity effect} (again, with or without `sqrt',
     with the same considerations applying)
     reflects tendencies for
     actors with high out-degrees to attract extra incoming ties
     `because' of their high current out-degrees.
     This leads to a higher correlation between in-degrees and out-degrees.
\item The \emph{in-degree activity effect} (with or without `sqrt')
     reflects tendencies for
     actors with high in-degrees to send out extra outgoing ties
     `because' of their high current in-degrees.
     This leads to a higher correlation between in-degrees and out-degrees.
     The in-degree activity and out-degree popularity effects are
     not distinguishable in Method of Moments estimation; then the choice between them
     must be made on theoretical grounds.
\item The \emph{out-degree activity effect} (with or without `sqrt')
     reflects tendencies for
     actors with high out-degrees to send out extra outgoing ties
     `because' of their high current out-degrees.
     This also leads to dispersion in out-degrees of the actors.
\item The \emph{in-in degree assortativity effect} (where parameter 2 is the same
    as the sqrt version, while parameter 1 is the non-sqrt version)
     reflects tendencies for actors with high in-degrees
     to preferably be tied to other actors with high in-degrees.
\item The \emph{in-out degree assortativity effect} (with parameters
     2 or 1 in similar roles)
     reflects tendencies for actors with high in-degrees
     to preferably be tied to other actors with high out-degrees.
\item The \emph{out-in degree assortativity effect} (with parameters
     2 or 1 in similar roles)
     reflects tendencies for actors with high out-degrees
     to preferably be tied to other actors with high in-degrees.
\item The \emph{out-out degree assortativity effect} (with parameters
     2 or 1 in similar roles)
     reflects tendencies for actors with high out-degrees
     to preferably be tied to other actors with high out-degrees.
\end{enumerate}

\subsubsection{Rate function}

In some cases the rate function needs special attention.
This can be the case, e.g., when the network has a clear
core-periphery structure; or when the outdegree distribution
is very skewed.
Then it may be necessary to let the rate function
depend on the outdegrees, using one of the three effects \texttt{outRateLog},
\texttt{outRateInv}, or \texttt{outRate};
or on an individual covariate indicating this size.
Experience shows that often a rate dependence on outdegrees gives
best results, and that \texttt{outRateLog} often is preferable.
See Section~\ref{S_r}.


\subsection{Important structural effects for network dynamics: \protect\newline
            two-mode networks}
\label{S_imp_str2}

The \SAOM for two-mode (or bipartite) networks
is treated in \citet{KoskinenEdling2012}.
The co-evolution of one-mode and two-mode networks is treated in
\citet{SLT2013}.
The most important effects are as follows.
The mathematical formulae for these and other effects are given
in Chapter~\ref{S_math}. Here we give a more qualitative description.
\begin{enumerate}
\item The \emph{out-degree effect} which always must be included.
      \vspace{-3em}
% Unclear why there is such a large vertical white space if
% this negative space is not put here.
\item \begin{minipage}[t]{.6\textwidth}
      Transitivity in two-mode networks is expressed in the first
      place by the number of \emph{four-cycles} \citep{RobinsAlexander04}.
      This reflects the extent to which actors who make one choice in common
      also make other choices in common.
      \end{minipage}
\hspace{1em}\hfill
\begin{minipage}[t]{.2\textwidth}
\linethickness{0.3pt}
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 0.5 to 4.5, y from 0 to 5
\put{\large$\bullet$} at  1 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  1 3
\put{\large$\bullet$} at  4 3
\put{$i_2$} at 0.5 1
\put{$i_1$} at 0.5 3
\put{$j_2$} at 4.5 1
\put{$j_1$} at 4.5 3
\arrow <2mm> [.2,.6]  from 1.2 3 to 3.8 3
\arrow <2mm> [.2,.6]  from 1.2 2.9 to 3.8 1.1
\arrow <2mm> [.2,.6]  from 1.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 1.2 1.1 to 3.8 2.9
\endpicture
\end{center}
\end{minipage}
\item[{\hspace*{-1ex}$\bigodot$}]
     The following three degree-related effects may be important especially for networks
     where degrees are theoretically important and represent social status
     or other features important for network dynamics;
     and/or for networks with high dispersion in in- or out-degrees
     (which may be an empirical reflection of the theoretical importance
     of the degrees).
     Include them if there are theoretical reasons for doing so,
     but only in such cases.

\item The \emph{out-degree activity effect} (with or without `sqrt'; often the sqrt
     version, which transforms the degrees in the explanatory role by the square root, works better)
     reflects tendencies to dispersion in out-degrees of the actors.
\item The \emph{in-degree popularity effect} (again, with or without `sqrt',
     with the same considerations applying)
     reflects tendencies to dispersion in in-degrees of the column units.
\item The \emph{out-in degree assortativity effect} (where parameter 2 is the same
    as the sqrt version, while parameter 1 is the non-sqrt version)
     reflects tendencies for actors with high out-degrees
     to preferably be tied to column units with high in-degrees.
\end{enumerate}

\subsection{Effects for network dynamics associated with covariates}
\label{S_eff_cov}

For each individual covariate, there are several effects which
can be included in a model specification, both in the network
evolution part and in the behavioral evolution part (should there be
dependent behavior variables in the data).
Of course for two-mode networks, the covariates must be compatible
with the network with respect to number of units (rows/columns).
%The following list is very incomplete.
\begin{itemize}
\item {\em network rate function}
\begin{enumerate}
\item the covariate's effect on the rate of network change of the
actor;
\end{enumerate}
\item {\em network evaluation, creation, and endowment functions}
\begin{enumerate}
\item the covariate-similarity effect, which is suitable for variables
      measured on an interval scale (or at least an ordinal scale
      where it is meaningful to use the absolute difference
      between the numerical values to express dissimilarity);
      a positive parameter implies that actors prefer
      ties to others with similar values on this variable --
      thus contributing to the
      network-autocorrelation of this variable not by changing
      the variable but by changing the network;\\
      for categorical variables, see the `same covariate'
      effect below;
\item the effect on the actor's activity (covariate-ego);
      a positive parameter will imply the tendency that
      actors with higher values on this covariate
      increase their out-degrees more rapidly;
\item the effect on the actor's popularity to other actors (covariate-alter);
      a positive parameter will imply the tendency that
      the in-degrees of actors with higher values on this covariate
      increase more rapidly;
\item the effect of the squared variable
      on the actor's popularity to other actors (squared covariate-alter)
      (included only if the range of the variable is at least 2).
      This normally makes sense only if the covariate-alter effect
      itself also is included in the model.
      A negative parameter implies a unimodal preference
      function with respect to alters' values on this covariate;
\item the interaction between the value of the covariate
      of ego and of the other actor (covariate ego $\times$ covariate alter);
      a positive effect here means, just like a positive similarity effect,
      that actors with a higher value on the covariate
      will prefer ties to others who likewise have a relatively high
      value;
      when used together with the alter effect of the squared variable
      this effect is quite analogous to the similarity effect,
      and for dichotomous covariates, in models where the ego and
      alter effects are also included, it even is equivalent
      to the similarity effect (although expressed differently),
      and then the squared alter effect is superfluous;
\item the `same covariate', or covariate identity, effect, which expresses the tendency of the
      actors to be tied to others with exactly the same value on the covariate;
      whereas the preceding four effects are appropriate for interval scaled
      covariates (and mostly also for ordinal variables),
      the identity effect is suitable for categorical variables;
\item the interaction effect of covariate-similarity with reciprocity;
\item the effect of the covariate of those to whom the actor is
      indirectly connected, i.e., through one intermediary but not
      with a direct tie; this value-at-a-distance can represent
      effects of indirectly accessed social capital.
%\item
%several other interaction effects of the covariate or
%covariate-similarity with endogenous network effects;
\end{enumerate}
\end{itemize}
The usual order of importance of these covariate effects on
network evolution is: evaluation effects are most important, followed
by creation, endowment and rate effects. Inside the group of evaluation
effects, for variables measured on an interval scale
(or ordinal scale with reasonable numerical values),
it is the covariate-similarity effect that is most
important, followed by the effects of covariate-ego and
covariate-alter.

When the network dynamics is not smooth over the observation waves --- meaning that
the pattern of ties created and terminated, as reported in the initial part of the
output file produced by \sfn{print01Report()}
under the heading \emph{Initial data description -- Change in networks --
Tie changes between subsequent observations},
is very irregular across the observation periods --- it can be important to include
effects of time variables on the network.
Time variables are changing actor covariates that depend only on the
observation number and not on the actors. E.g., they could be dummy variables,
being 1 for one or some observations, and 0 for the other observations.

For actor covariates that have the same value for all actors within observation
waves,
or -- in the case that there are structurally determined values --
that are constant for all actors within the same connected components,
only the ego effects are defined, because only those
effects are meaningful.
This exclusion of the alter, similarity and other effects for
such actor variables applies only to variables without any missing values.

For each dyadic covariate, the following network evaluation effects
can be included in the model for network evolution:
\begin{itemize}
\item {\em network evaluation, creation, and endowment functions}
\begin{enumerate}
\item main effect of the dyadic covariate;
\item the interaction effect of the dyadic covariate with reciprocity.
\end{enumerate}
\end{itemize}
The main evaluation effect is usually the most important.
But dyadic covariates can also be transformed, e.g., to patterns
of indirect connections, which then are again usable as dyadic covariates.
Dyadic covariates can also be used in various ways as weights
for behavioral evolution.

\subsection{Cross-network effects for dynamics of multiple networks}


If there are multiple dependent network variables, these can be
one-mode networks, two-mode networks, or a combination of these.
The co-evolution of one-mode and two-mode networks is treated in
\citet{SLT2013}, but this paper can also be used as an introduction
to the dynamics of multiple one-mode networks.
For multiple dependent network variables,
the following effects may be important.
This is explained here jointly for the case of one-mode and two-mode
networks. The \emph{number of columns} is defined as the number of actors
for one-mode networks, and as the number of units/nodes/...
in the second node set for two-mode networks.
For cross-network effects the network in the role of dependent variable
is denoted by $X$ and the network in the role of explanatory variable
by $W$; thus, effects go from $W$ to $X$.
All these effects are regarded as effects determining the dynamics of network $X$.

\begin{enumerate}
\item If both networks have the same number of columns,
      then the basic effect is the entrainment of $X$ by $W$,
      i.e., the extent to which the existence of a tie
      $i \stackrel{W}{\rightarrow} j$ promotes
      the creation or maintenance of a tie $i \stackrel{X}{\rightarrow} j$.
\item If both networks are one-mode,
      then a next effect is the reciprocity effect with $W$ on  $X$,
      representing the extent to which the existence of a tie
      $j \stackrel{W}{\rightarrow} i$ promotes
      the creation or maintenance of a tie,
      in the reverse direction, $i \stackrel{X}{\rightarrow} j$.
\item If both networks are one-mode,
      then a next effect is the mutuality effect with $W$ on  $X$,
      representing the extent to which the existence of a mutual tie
      $i \stackrel{W}{\leftrightarrow} j$ promotes
      the creation or maintenance of a tie $i \stackrel{X}{\rightarrow} j$.
\item The \emph{outdegree W activity effect} (where parameter 2 is
    the sqrt version, while parameter 1 is the non-sqrt version -- see above
    for explanations of this) reflects the extent to which actors
    with high outdegrees on $W$ will make more choices in the
    $X$ network.

\item[{\hspace*{-1ex}$\bigodot$}] Several mixed transitivity effects can be important.
\item
\begin{minipage}[t]{0.7\textwidth}
If $X$ is a one-mode network, the \emph{from W agreement} effect
      represents the extent to which agreement between $i$ and $j$
      with respect to outgoing
      $W$-ties promotes the creation or maintenance
      of a tie $i \stackrel{X}{\rightarrow} j$.
\end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\vspace{-1em}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3.0 0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}

\vspace{-1em}
\item
\begin{minipage}[t]{0.7\textwidth}
If $W$ is a one-mode network, the \emph{W to agreement} effect
      represents the extent to which a $W$ tie $i \stackrel{W}{\rightarrow} h$
      leads to agreement between $i$ and $h$
      with respect to outgoing $X$-ties to others, i.e.,
      $X$-ties to the same third actors $j$,
      $i \stackrel{X}{\rightarrow} j$ and $h \stackrel{X}{\rightarrow} j$.
\end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\vspace{-1em}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $X$}} at 3.9 1.9
\put{{\small $X$}} at 3.0 0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1           % i -> j
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559  % i -> h
%\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559  % j -> h
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732   % h -> j
\endpicture
\end{center}
\vfill
\end{minipage}

\vspace{-1em}
\item
\begin{minipage}[t]{0.7\textwidth}
If $X$ and $W$ both are one-mode networks, the \emph{closure of W} effect
 represents the tendency closure of $W-W$ two-paths\\
 $i \stackrel{W}{\rightarrow} h \stackrel{W}{\rightarrow} j$
 by an $X$ tie
  $i \stackrel{X}{\rightarrow} j$.
\end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\vspace{-1em}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3.0 0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}

\end{enumerate}


\subsection{Constraints between networks}
\label{S_constraints}

When analysing multiple dependent networks, the following constraints
between networks can be considered:
\begin{description}
  \item[disjoint:] for any given pair of actors $(i,j)$,
      it is impossible that ties exists in both networks;
  \item[higher:] for any given pair of actors $(i,j)$,
      it is impossible that a tie exists in the first
      but not in the second network;
  \item[atleastone:] for any given pair of actors $(i,j)$,
     there must be a tie in at least one of the networks.
\end{description}
Whether this is so, is indicated in the attributes of the data set
(of class \texttt{siena}).
These constraints are observed and set during the creation of the
\texttt{siena} object in \sfn{sienaDataCreate}.
When one of the constraints is true,
this will be reported in the output of \sfn{print01Report}.
These constraints will continue to be respected during the simulations.
The constraints for the simulations can be changed by function
\sfn{sienaDataConstraint}.

This does not work for multigroup projects! By implication,
it does not work for \sfn{sienaBayes}.


\subsection{Effects on behavior evolution}
\label{S_eff_beh}

For models with one or more dependent behavior variables, i.e.,
models for the co-evolution of networks and behavior,
the most important effects for the behavior dynamics are the following;
see \citet*{SteglichEA10}.
In these descriptions, with the `alters' of an actor
we refer to the other actors to whom
the focal actor has an outgoing tie.
The dependent behavior variable is referred to as $Z$.
\begin{enumerate}
\item The shape effect, expressing the basic drive toward high values on $Z$.
      A zero value for the shape will imply a drift toward the midpoint
      of the range of the behavior variable.
\item The effect of the behavior $Z$ on itself,
      or quadratic shape effect, which is relevant
      only if the number of behavioral categories is 3 or more.
      This can be interpreted as giving a quadratic preference function
      for the behavior.
      When the coefficient for the shape effect is $\beta^Z_1$ and for the
      effect of $Z$ on itself, or quadratic shape effect, is $\beta^Z_2$,
      then the contributions
      of these two effects are jointly $\beta^Z_1\, (z_i - \bar z) \,+\,
                   \beta^Z_2\, (z_i - \bar z)^2$.
      With a negative coefficient $\beta^Z_2$, this
      is a unimodal preference function, with the maximum attained
      for $z_i \,=\, \bar z - 2\,\beta^Z_1/\beta^Z_2$.
      (Of course additional effects will lead to a different picture;
      but as long as the additional effects are linear in $z_i$ -- which is not
      the case for similarity effects! --, this will change the location of the maximum
      but not the unimodal shape of the function.)
      This can also be regarded as negative feedback, or a self-correcting
      mechanism: when $z_i$ increases, the further push toward higher values
      of $z_i$ will become smaller and when $z_i$ decreases, the further push toward lower values
      of $z_i$ will become smaller. On the other hand, when the coefficient $\beta^Z_2$
      is positive, the feedback will be positive, so that changes in $z_i$
      are self-reinforcing. This can be an indication of addictive behavior.
\item The average similarity effect, expressing the preference of actors
      to being similar with respect to $Z$ to their alters,
      where the total influence of the alters is the same
      regardless of the number of alters.
\item The total similarity effect, expressing the preference of actors
      to being similar to their alters,
      where the total influence of the alters is proportional to
      the number of alters.
\item The average alter effect, expressing that actors
      whose alters have a higher average value of the behavior $Z$,
      also have themselves a stronger tendency toward high values on the behavior.
\item The total alter effect, expressing that actors
      whose alters have a higher total value of the behavior $Z$,
      also have themselves a stronger tendency toward high values on the behavior.
\item The indegree effect, expressing that actors with a higher indegree
      (more `popular' actors) have a stronger tendency toward high values on the behavior.
\item The outdegree effect, expressing that actors with a higher outdegree
      (more `active' actors) have a stronger tendency toward high values on the behavior.
\end{enumerate}
Effects 1 and 2 will practically always have to be included as control variables.
(For dependent behavior variables with 2 categories, this applies only to effect 1.)
When the behavior dynamics is not smooth over the observation waves --- meaning that
the pattern of steps up and down, as reported in the initial part of the
output file produced by \sfn{print01Report()}
under the heading \emph{Initial data description -- Dependent actor variables -- Changes},
is very irregular across the observation periods --- it can be important to include
effects of time variables on the behavior.
Time variables are changing actor covariates that depend only on the
observation number and not on the actors. E.g., they could be dummy variables, being 1
for one or some observations, and 0 for the other observations.

The average similarity, total similarity, average alter, and total effects
are different specifications of social influence.
The choice between them will be made on theoretical grounds
and/or on the basis of statistical significance.
Do not include them all together in one model, as this would most likely
lead to multicollinearity and non-convergence.
\medskip

For each actor-dependent covariate as well as for each of the other
dependent behavior variables,
the effects on $Z$ which can be included is the following.
\begin{enumerate}
\item The main effect: a positive value implies that actors with a
      higher value on the covariate will have a stronger tendency
      toward high $Z$ values.
\item Various effects of the combination of covariate values for members
      of the personal network of the focal actor (outgoing ties, incoming
      ties, distance-two ties): search in this manual for \texttt{avXAlt,
      avXInAlt, avXAltDist2, avXInAltDist2} and their manifold variations.
\item Interactions between two or three actor variables, see
      Section~\ref{S_int_eff}.
\end{enumerate}


\iffalse

\subsection{Model Type}
\label{S_modeltype}

When the data is perfectly symmetric, this will be detected by \si.
Then the analysis options for nondirected networks will be followed.

%The Model Type is specified in the
%\hyperlink{T_S_options}{model options} as (part of) the
%\hyperlink{T_modelcode}{Model Code}.

\subsubsection{Model Type: directed networks}

These are currently not implemented in \SI 4.
\fi

\iffalse
For directed networks, the Model Type distinguishes between
the model of \citet{Snijders01} (Model Type 1),
that of \citet{Snijders03} (Model Type 2),
and the tie-based model described in \citet{Snijders06} (Model Type 3).
Model Type 1 is the default model and is
described in the basic publications on {\saom}s for network dynamics.

Model type 2 is at this moment not implemented in \SI version 3.
\medskip
\fi

\iffalse
In Model Type 2, the `decisions' by the actors
consist of two steps: first a step to increase or decrease their
out-degree; when this step has been taken, the selection of the
other actor towards whom a new tie is extended (if the out-degree
rises) or from a an existing tie is withdrawn (if the out-degree
drops).
The decision by an actor to increase or decrease the number of outgoing ties
is determined on the basis
of only the current degree; the probabilities of increasing or
decreasing the out-degree are expressed by the distributional
tendency function $\xi$ (indicated in the output as \emph{xi}) and
the volatility function $\nu$ (indicated as \emph{nu}). Which new
tie to create, or which existing tie to withdraw, depends in the
usual way on the evaluation, creation, and endowment functions. Thus, the
outdegree distribution is governed by parameters that are not
connected to the parameters for the structural dynamics. The use of
such an approach in statistical modeling minimizes the influence of
the observed degrees on the conclusions about the structural aspects
of the network dynamics. This is further explained in \citet{Snijders03}.

For Model Type 2, in the rate function, effects connected to these
functions $\xi$ and $\nu$ are included. On the other hand, effects
in the evaluation function that depend only on the out-degrees are
canceled from the model specification, because they are not
meaningful in Model Type 2. To evaluate whether Model Type 1 or
Model Type 2 gives a better fit to the observed degree distribution,
the output gives a comparison between the observed out-degrees and
the fitted distribution of the out-degrees (as exhibited by the
simulated out-degrees). For Model Type 2 this comparison is always
given. For Model Type 1, this comparison is given by adding 10 to the
Model Code in the advanced options. (For \LaTeX\ users: the log
file contains code that can be used to make a graph of the type
given in \citet{Snijders03}.

For using Model Type 2, it is advised to first estimate some model
according to Model Type 1 (this may be a simple model containing a
reciprocity effect only, but it could also include more effects),
and then -- using the parameters estimated under Model Type 1 --
change the specification to Model Type 2, and use the
\hyperlink{T_S_cond}{unconditional estimation method}
(see Section~\ref{S_cond}) (instead of the conditional method which is the
default). It is likely that the very first model estimated under
Model Type 2 will have results with poor
\hyperlink{T_convergence}{convergence properties}, but in such
cases it is advised just to estimate the same model another time,
now using the parameter values obtained under the previous Model
Type 2 run as the initial values for the estimation.

To obtain a good model specification with respect to the rates of
change in dependence of the out-degrees, three effects can be
included:
\begin{enumerate}
\item the out-degrees effect
\item the factorial out-degree effect
\item the logarithmic out-degree effect.
\end{enumerate}
These are the effects defined in formula (18) of \citet{Snijders03}
and indicated with the parameters $\alpha_1$, $\alpha_2$,
and $\alpha_3$, respectively.
The user has to see from the estimation results which, or which two,
out of these effects
should be included to yield a good fit for the out-degrees.
% klopt dit wel met de mintekens??????????
\medskip
\fi

\iffalse
In addition these types, there is
Model Type 6 which implements the reciprocity model of \citet{Wasserman79}
and \citet{Leenders95}  \citep[also see][]{Snijders99, Snijders05} ---
provided that no other effects are chosen than
the outdegree effect, the reciprocity effect and perhaps
the reciprocity endowment effect,
and possible also effects of actor covariates or dyadic covariates.
This model is meaningful only as a ``straw man" model to provide a test
of the null hypothesis that the dynamics of the dyads are mutually
independent, against the alternative hypothesis
that there do exist network effects (which make the dyad processes
mutually dependent).
For this purpose, Model Type 6 can be chosen,
while for one or more network effects such as the effects
representing transitivity, the null hypothesis is tested that their
coefficients are zero (see Section~\ref{S_test}).


\fi

\subsection{Model Type: non-directed networks}
\label{S_modeltype_nd}

Dynamics for non-directed networks is explained in \citet{SnijdersPickup16}.

\SI detects automatically when the networks all are non-directed,
and then employs a model for this special case.
For non-directed networks, the Model Type has five possible values,
as described in \citet{SnijdersPickup16}.
This is specified by the parameter \sfn{modelType} in function
\sfn{sienaAlgorithmCreate}.
Value \texttt{modelType = 1} is for directed networks, values
\texttt{2-6} for non-directed networks.

% DependentVariable.h gives the order of the model types:
% 0-6 =
%	enum NetworkModelType { NOTUSED, NORMAL, AFORCE, AAGREE, BFORCE, BAGREE, BJOINT };
% See Siena_algorithms;
% A = unilateral, B = two-sided initiative
% help file: modelType Type of model to be fitted:
% 1=directed, 2:6 for symmetric networks: 2=forcing, 3=Initiative model,
% 4=Pairwise forcing model, 5=Pairwise mutual model, 6=Pairwise joint model

\begin{enumerate}
\item Directed networks option \texttt{modelType = 1} is not used for non-directed networks.
\item Forcing model, \texttt{modelType = 2}: \\ % AFORCE
      one actor takes the initiative and unilaterally
      imposes that a tie is created or dissolved.
\item Unilateral initiative and reciprocal confirmation,
      \texttt{modelType = 3}:\\ % AAGREE
      one actor takes the initiative and proposes a new tie
      or dissolves an existing tie; if the actor proposes a new tie, the other
      has to confirm, otherwise the tie is not created;
      for dissolution, confirmation is not required.\\
      For the confirmation decision, an offset is added to the objective
      function, representing the difference between a binary yes/no choice
      and the multinomial choice of one among $n-1$ tie variables to change.
      This offset is a fixed parameter, not estimated.
      The higher the offset, the more likely it is that the confirmation
      will be given. It is determined
      by the value of \texttt{Offset} in function
      \sfn{sienaAlgorithmCreate}. This parameter must be given as a
      named vector; see the help page for \sfn{sienaAlgorithmCreate}.
      Plausible values for this offset are in the range from 0 to 3,
      and should slowly increase with $n$ (roughly proportionally to $\log(n)$).
\iffalse
\item Tie-based model:\\
      a random pair of actors is chosen (actor-specific rate functions
      are not used here),
      and the average change in objective function (\ref{u_net})
      for toggling $(i,j)$ and $(j,i)$
      is the log-odds of the probability of changing the tie variable.
\fi
\item Pairwise disjunctive (forcing) model, \texttt{modelType = 4}:\\ %BFORCE
      a pair of actors is chosen and reconsider
      whether a tie will exist between them;
      the tie will exist if at least one of them chooses for the tie,
      it will not exist if both do not want it.
\item Pairwise conjunctive model, \texttt{modelType = 5}:\\  % BAGREE
      a pair of actors is chosen and reconsider
      whether a tie will exist between them;
      the tie will exist if both agree,
      it will not exist if at least one does not choose for it.
\item Pairwise compensatory (additive) model,
      \texttt{modelType = 6}:\\ %BJOINT
      a pair of actors is chosen and reconsider
      whether a tie will exist between them;
      this is based on the sum of their objective functions
      for the existence of this tie.
\end{enumerate}
In the first two of these models, where the initiative is one-sided,
the rate function is comparable to the rate function in directed models.
In the last three models, however, the pair of actors is chosen at a rate
which is the \emph{product} of the rate functions
$\lambda_i$ and $\lambda_j$ for the two actors.
This means that opportunities for change of the single tie variable $x_{ij}$
occur at the rate $\lambda_i \times \lambda_j$.
The numerical interpretation is different from that in the first two models.

Some effects specially designed for non-directed networks
are presented in Section~\ref{S_NonDirEff}.

\subsection{Model Type: behavior}
\label{S_modeltype_beh}

As of version 1.1-306, there are two model options for dynamics
of behavior, specified by the parameter \sfn{behModelType} in function
\sfn{sienaAlgorithmCreate}.
They differ in the treatment of the boundaries of the range of
the behavioral variable.
Recall that the behavioral microsteps consist of the addition
of --1, 0, or +1 to the dependent variable, under the condition
of remaining within the integer range from the minimum~$z^-$ to
the maximum~$z^+$.

If the current value of the behavior is at the boundary,
$z^-$ or $z^+$, then only two possible outcomes remain.
The default is the option available before, with
\texttt{behModelType = 1}. This is also called the \emph{restricting}
model, because the probabilities of the two options are given by
(\ref{probab}), where the set of possible new states
$\mathcal C$ is just the restricted set $\{z^-, z^-+1\}$ in the case
of the minimum, and $\{z^+-1, z^+\}$ in the case of the maximum.

The second option, for
\texttt{behModelType = 2}, is called the \emph{absorbing}
model, because the probabilities of the two options are calculated
as if the variable could go outside of the range, but when such an excursion
occurs it is absorbed into the range again.
Thus, probabilities are calculated according to
(\ref{probab}), with
$\mathcal C = \{z^--1, z^-, z^-+1\}$ or
$\mathcal C = \{z^+-1, z^+, z^++1\}$,
respectively; but the outcome $z^--1$ when it occurs is replaced
by $z^-$, and  $z^++1$ when it occurs is replaced
by $z^+$.
The objective function for the virtual outcome $z^--1$
is taken to be the same as for $z^-$, and similarly for $z^++1$
it is taken to be the same as for $z^+$.


\hypertarget{T_int_eff}{
\subsection{Additional interaction effects}
}
\label{S_int_eff}

It is possible for the user to define additional interaction effects for the
network and the behavior.
The basis is provided by the initial definition, by \si, of `unspecified
interaction effects'.
The interaction is defined by
the columns \texttt{effect1} and \texttt{effect2},
and for three-way effects, \texttt{effect3},
in the effects object; they contain the \texttt{effectNumber}
(sequence number) of the effects that are interacting.
The interaction effect must be `included' to be part of the model,
but the underlying effects need only be `included' if
they are also required individually.
(In most cases this is advisable.)
The number of possible user-defined interaction effects is limited,
and is set in the call of \sfn{getEffects()}.

Interactions can be specified by the function \sfn{includeInteraction},
explained in the following subsections.

All effects have a so-called  \texttt{interactionType},
defined by the column \texttt{interactionType} in the effects data frame.
This interaction type defines what is allowed for  definition of interaction effects;
an explanation of the background of this
is given in section ``Statistics for MoM'' of
\href{http://www.stats.ox.ac.uk/~snijders/siena/Siena_algorithms.pdf}{\texttt{Siena\_algorithms.pdf}}.

For network effects, the interaction type is "ego", "dyadic", or "" (blank);
for behaviour effects, it is "OK" or "".

The information necessary for working with interaction effects
-- the interaction types, short names, and sequence numbers
of the effects -- are contained in the document produced
for a given effects object, say \texttt{myeff}, by the function call

\verb|effectsDocumentation(myeff)|

\noindent
Further see the help page for the function \sfn{effectsDocumentation()}.
Chapter~\ref{S_math} of this manual also gives the short names of all effects.
The short name of all unspecified interaction effects is \texttt{unspInt}
for network effects, and \texttt{behUnspInt} for behaviour effects.


\subsubsection{Interaction effects for network dynamics}

The following kinds of user-defined interactions are possible
for network dynamics.
\begin{description}
\item[a.]
  Ego effects of actor variables can interact with all effects.
  \item[b.] Dyadic effects can interact with each other.
\end{description}
Whether an effect is an ego effect or a dyadic effect is defined by
the column \texttt{interactionType} in the effects data frame.
This column is shown in the list of effects that is displayed
in a browser by using the function:

\verb|effectsDocumentation()|
\bigskip

Thus a two-way interaction must be between two dyadic effects or between one
ego effect and another effect. A three-way interaction may be between three
dyadic effects, two dyadic effects and an ego effect, or two ego effects and
another effect.

All effects used in interactions must be defined on the same network
(in the role of dependent variable): that for
which the ``unspecified
interaction effects'' is defined.  And all must be
of the same type (evaluation, endowment, or creation effects).

Examples of the use of \sfn{includeInteraction} are as follows.
\begin{verbatim}
myeff <- includeInteraction( myeff, egoX, recip,
                                    interaction1 = c("smoke1", "") )
myeff <- includeInteraction( myeff, egoX, egoX,
                                    interaction1 = c("smoke1", "alcohol") )
\end{verbatim}
Note the \texttt{interaction1} parameter; this parameter is used also
when defining these effects using \sfn{includeEffects} or
\sfn{setEffect}. In this case, however, two effects are defined,
and accordingly the \texttt{interaction1} parameter has two components,
combined by the \sfn{c} function.
For effects such as \texttt{recip} that have no \texttt{interaction1}
parameter, the corresponding string is just the empty string, \texttt{""}.
(Note that the name \texttt{interaction1} does not itself refer to interactions
in the sense of this section.)

Interactions between three effects are defined similarly,
but now the \texttt{interaction1} parameter must combine three components.

The number of network interaction effects that can be created is defined by the
parameter \texttt{nintn} in function \sfn{getEffects()}. If you need more
interactions than permitted, just make a new effects object with the
suitably increased value of \texttt{nintn}.

The list of effects in Chapter~\ref{S_math} contains a variety of
interaction effects that cannot be created in this way;
for example, those with short names
\texttt{transRecTrip}, \texttt{simRecipX},  \texttt{avSimEgoX},
and \texttt{covNetNet} (there are many more).

\subsubsection{Interaction effects for behavior dynamics}
\label{S_beh_infl}

For behavior dynamics, interaction effects can be defined
by the user, for each dependent behavior variable separately,
as interactions of two or three actor variables,
again using the function \textsf{includeInteraction}.
These are interactions on the ego level, in line with the
actor-oriented nature of the model.

There are some restrictions on what is permitted
as interactions between behavior effects.
Of course,  they should refer to the same dependent behavior variable.
What is permitted depends on the so-called \texttt{interactionType} of the
effects, which for behavior effects can be \texttt{OK}\footnote{The value
is \texttt{OK} for the effects of which the
formula as defined in Section~\ref{S_f_b}
is given by $z_i$ multiplied by something not dependent on $z_i$.}
or blank.
A further explanation is given under the heading `User-defined interaction effects'
in Section~\ref{S_ff_b}.
The \texttt{interactionType} of the effects
is shown in the list of effects displayed in a browser by using the function:

\verb|effectsDocumentation()|
\bigskip

The behavioral effects with non-\texttt{OK} (i.e., blank)
\texttt{interactionType} include,
in particular, all effects of which the name
includes the word ``similarity",
or alternatively, the short name includes the string ``sim".

The requirement for behavior interactions is that,
of the interacting effects, all or all but one have
the value \texttt{OK}. Thus, for an interaction between two effects,
one or both should be \texttt{OK}; for a three-effect interaction,
two or all three should be \texttt{OK}.

The number of behavior interaction effects that can be created is defined by the
parameter \texttt{behNintn} in function \sfn{getEffects()}. If you need more
interactions than permitted, just make a new effects object with the
suitably increased value of \texttt{behNintn}.

As an example, suppose that we have a data set with a dependent
network variable \texttt{friendship} and a dependent behavior variable
\texttt{drinkingbeh} (drinking behavior), and we are interested whether
social influence, as represented by the `average alter' effect, differs
between actors depending on whether currently they drink little or much.
Then the commands
\begin{verbatim}
myeff <- includeEffects(myeff, avAlt,
                name="drinkingbeh", interaction1="friendship")
myeff <- includeInteraction(myeff, quad, avAlt,
                name="drinkingbeh", interaction1=c("","friendship"))
\end{verbatim}
define a model with the average alter effect (representing social influence)
and an interaction between this and the quadratic shape effect.
Recall that the latter can be regarded
as the effect of drinking behavior on drinking behavior.
Briefly, the interaction is between current drinking behavior
and the average drinking behavior of friends.
By consulting Section~\ref{S_f_b} on the mathematical definitions of the
effects one can derive that this leads to the following objective function;
where it is assumed that also the linear and quadratic shape effects are
included in the model.
\[
f^{\rm beh}_i(x, z) \,=\, \beta^{\rm beh}_1 z_i \,+\, \beta^{\rm beh}_2 z_i^2
        \,+\, \beta^{\rm beh}_3 z_i \,
        \frac{ \sum_j x_{ij}\, z_j }{\sum_j x_{ij}}
       \,+\, \beta^{\rm beh}_4 z_i^2 \,
              \frac{ \sum_j x_{ij}\, z_j }{\sum_j x_{ij}} \ .
\]
\medskip

In addition, there are predefined interactions available
between actor variables and influence, as described in Section~\ref{S_f_b}.

\iffalse
\subsection{Random effects models: unobserved actor heterogeneity}

The network (and behavior) evolution may be affected
by the fact that actors are heterogeneous.
If all relevant actor heterogeneity is observed in the form of actor
covariates,
then actor heterogeneity can be taken into account by including
covariates in the model.
If not all relevant actor heterogeneity is observed,
then more complex models are required, such as random effects models.
Random effects models \citep[see][]{SchweinbergerSnijders07b} allow to take
unobserved actor heterogeneity into account
by assuming that the network (and behavior) evolution is affected
by unobserved
outcomes of actor-dependent random variables (random effects),
which represent the combined effect of the unobserved actor
heterogeneity on the network (and behavior) evolution.

These models can be estimated only using the maximum likelihood
estimation option, see Section~\ref{S_Est}.
The maximum likelihood estimation of random effects models requires
MCMC-based data
imputation of the unobserved random effects (which can be regarded
as missing data).
\SI supplies three alternative MCMC algorithms for the MCMC-based
data imputation of the random effects:
\begin{itemize}
\item[(1)] random walk M-H,
\item[(2)] autoregressive M-H,
\item[(3)] independence sampler (default).
\end{itemize}
The algorithms require the determination of the scale factor of
the so-called proposal distribution,
which may affect the efficiency of the algorithms and
the accuracy of the results (for a given number of iterations).
It is recommended to choose the default algorithm (3);
and to choose as scale factor of the proposal distribution $0$---which
would be a pointless scale factor, but which communicates to \SI
that the user wishes to leave the determination of the scale factor to
the defaults within the algorithm,
which features an adaptive method for determining suitable scale factors.
In the ideal case, the choice of algorithm does not affect the
parameter estimates---though the efficiency of
the algorithms and the accuracy of the results
(for a given number of iterations) may be affected.

The estimation of random effects models
(i.e., the estimation of the parameters,
including the variances of the random effects)
may be done by either Maximum Likelihood
or Bayesian estimation (see Section~\ref{S_Bayes}).

%The interpretation of the parameter estimates is straightforward;
%the estimates of the variances of the random effects indicate the magnitude
%of the unobserved actor heterogeneity.
\fi

\subsection{Time heterogeneity in model parameters}
\label{S_timetest1}

When working with two or more periods, i.e., three or more waves,
there is the question whether parameters are constant across the periods.
This can be tested by the \sfn{sienaTimeTest} function, as explained
in Section~\ref{S_timetest2}.
To specify a model with time heterogeneous parameters, the function
\sfn{includeTimeDummy} can be used, as follows.
Consider the reformulation of the evaluation function into
\begin{align}
f^{(m)}_{ij}(\mathbf{x})= \sum_k \Big(\beta_k + \delta_k^{(m)} h_k^{(m)}\Big)
                              \,      s_{ik}\big(\mathbf{x}(i \leadsto j)\big)
\label{eq:fmij}
\end{align}
where $m$ denotes the period (from wave $m$ to wave $m+1$
in the panel data set)
and $\delta_k^{(m)}$ are parameters for the effects interacted
with time dummies. You
can include these in your model simply via the function
\begin{verbatim}
myeffects <- includeTimeDummy(myeffects,
                              density, reciprocity, timeDummy="2,3,6")
\end{verbatim}
which would add three time dummy terms to each effect listed in the function.

We recommend that you start with simple models,
and base the decision to include time heterogeneous parameters
on your theoretical and empirical insight in the data
(e.g., whether the different waves cover a period where the importance
of some of the modeled `mechanisms' may have changed) and
the score type test that is implemented in the \sfn{sienaTimeTest} function,
see Section~\ref{S_timetest2}.

See \citet{Lospinoso2011} for a technical presentation
and examples of how the test works,
and \citet{Lospinoso2010b} for a walkthrough on model selection.


\subsection{Limiting the maximum outdegree}
\label{S_maxdegree}

It is possible to request that all networks simulated have a
maximum outdegree less than or equal to some given value.
This is meaningful only if the observed networks also do
not have a larger outdegree than this number, for any actor at any wave.

This is carried out by specifying the maximum allowed value
in the \textsf{MaxDegree} parameter of the \textsf{sienaAlgorithmCreate}
function, which determines the settings of the algorithm.

\textsf{MaxDegree} is a named vector, which means that its elements
have names. The length of this vector
is equal to the number of dependent networks.
Each element of this vector must have a name
which is the name of the corresponding network.
E.g., for one dependent network called \texttt{mynet}, one could use
\begin{verbatim}
MaxDegree = c(mynet=10)
\end{verbatim}
to restrict the maximum degree to 10.
For two dependent networks called \texttt{friends} and \texttt{advisors},
one could use
\begin{verbatim}
MaxDegree = c(friends=6, advisors=4)
\end{verbatim}

For a single network, the default value 0 is used
to specify that the maximum is unbounded.
For multiple networks, if for one network
there is a bound for the maximum outdegree
 but for another network this should not be bounded, then
 the value 0 will not work,
 but one should use a bound which is at least $n-1$,
where $n$ is the number of actors in the network (or the largest number,
if there are multiple groups).

If the \textsf{MaxDegree} parameter is used for data where
all, or almost all, degrees are equal to this maximum value,
then it is likely that the estimation algorithm will not converge.
A fixed choice design for network data collection is not
compatible with the free choice nature of the \saom.
See \citet{HollandLeinhardt1973} for a discussion of
fixed choice designs and \citet{Znidarsic2012}
for references to more recent literature.

The \textsf{MaxDegree} option does not work for likelihood-based
estimation; therefore, neither ML estimation using \textsf{siena07}
nor multilevel estimation using \textsf{sienaBayes} support
this option.


\subsection{Goodness of fit with auxiliary statistics}
\label{S_gof}

There is available in RSienaTest a function \verb!sienaGOF!
which permits users to assess the fit of the model with respect to
auxiliary statistics of networks, e.g. geodesic distributions,
that are not explicitly fit by a particular effect,
but are nonetheless important features of the network to represent by the
probability model.
This can be used to check, when one has followed the approach to
model specification explained in Sections~\ref{S_imp_str1}
to~\ref{S_eff_beh} -- and explained also in \citet{SnijdersEA10b} --,
whether the end result gives a good representation
also of these other statistics.

The \sfn{sienaGOF} function, proposed and elaborated by
\citet{Lospinoso2012}, operates basically by comparing
the observed values, at the ends of the periods, with the
simulated values for the ends of the periods.
The differences are assessed by combining the auxiliary statistics
using the Mahalanobis distance.

Various auxiliary statistics are available directly (`out of the box'),
e.g., distributions of indegrees and outdegrees and of behavioral
variables. These are listed in the help page for
\verb!sienaGOF-auxiliary!. Some other auxiliary statistics, requiring
additional packages such as \texttt{igraph} and \texttt{sna},
are available by copying script from the examples in the same help page.
(The reason for this construction is to reduce dependencies
of the basic \sfn{RSiena} on other packages.)
\medskip

The results of \verb!sienaGOF! can be plotted which then produces
\emph{violin plots} \citep{HintzeNelson1998}, which present
the distribution of the statistic as a combination
of a box plot and a smooth approximation to the density
(by a kernel density estimate), with the observed values superimposed.
The violin plots tend to become squiggly when the probability distribution
is concentrated on a few points (integers usually) and, as a consequence,
the density plot tries to approximate a discrete distribution.
For the associated \verb!plot! function, options \sfn{center} and \sfn{scale}
are available to equalize the centers and scales of the various statistics
plotted.
For distributions and cumulative distributions over sets of integers
(e.g., of degrees or geodesic distances)
it often is advisable to use the defaults \sfn{center = FALSE},
\sfn{scale = FALSE}, whereas for sets of statistics for which a common scale
is less important, e.g., triad counts, a clearer picture may be obtained by
plotting with \sfn{center = TRUE}, \sfn{scale = TRUE}.

The method of joiners and leavers for representing composition change
(Section~\ref{S_comp}) does not combine properly with the \sfn{sienaGOF} function.

The examples in the help pages for \sfn{sienaGOF} and \sfn{sienaGOF-auxiliary}
give ample help for how to use this function.
Also see the script on the \SI website.

For combining \sfn{sienaGOF} results for multiple groups, the resulting $p$-values
as calculated for each single group can be combined.
The most suitable method here perhaps is the inverse normal method,
also called Lipt\'{a}k's method; see \citet[][Section C.3]{HedgesOlkin85}.
This methods transforms each $p$-value to a standard normal variate, adds these
and divides by $\sqrt{N}$ where $N$ is the number of combined studies,
and tests the result in the standard normal distribution.
%For the p-value of sienaGOF, consult the help page of sienaGOF.
%For the transformation to standard normal,
%you can use qnorm (check whether you need qnorm(p) or qnorm(1-p)).
%For testing in the standard normal you can use pnorm.



\subsubsection{Treatment of missing data and structural values in \sfn{sienaGOF} }

Missing tie values and structurally determined tie values are treated
in the estimation in such a way that they do not contribute directly
to the target statistics. This behavior is mirrored in their treatment
in \sfn{sienaGOF}. The aim is that such values do not contribute
to any differences between observed and simulated values.

Tie variables that are missing at either the beginning or the end of the period
are replaced by 0, both in the observed and in the simulated networks.
For behavioral variables they are replaced by missings (\texttt{NA}).

If there are any differences between structural values at the beginning and
at the end of a period, these are dealt with as follows.
For tie variables that have a structural value at the start of the period,
this value replaces the observed value at the end of the period
(for the goodness of fit assessment only).
For tie variables that have a structural value at the end of the period
but a free value value at the start of the period, the reference value for
the simulated values is lacking; therefore, the simulated values at the end
of the period then are replaced by the structural value at the end of the period
(again, for the goodness of fit assessment only).


\newpage

\section{Estimation}
\label{S_Est}

The model parameters are estimated under the specification given
during the model specification part, using an iterative stochastic
approximation algorithm.
Four estimation procedures are implemented:
the Method of Moments \citep*[`MoM';][]{Snijders01, SnijdersEA07};
the Generalized Method of Moments \citep*[`GMoM';][]{ASS2015};
 the Method of Maximum Likelihood \citep[`ML';][]{SnijdersEA10a};
 and a Bayesian method
 \citep{Koskinen04, KoskinenSnijders07,SchweinbergerSnijders07c}.
 For non-constant rate functions, currently only
 MoM and GMoM estimation is available.
 The Method of Moments is the default;
 ML and Bayesian estimation methods require much more computing time.
 Given the greater efficiency but longer required computing time
 for the ML and Bayesian methods,
 these can be useful especially for smaller data sets
 and relatively complicated models
 (networks and behavior; creation or endowment effects).

In the following, the number of
parameters is denoted by $p$. The algorithm %s are
is based on repeated
(and repeated, and repeated...) simulation of the evolution
process of the network. These repetitions are called `runs' in the
following. The MoM estimation algorithm is based on comparing the
observed network (obtained from the data files)
to the hypothetical networks generated in the simulations.

Note that the estimation algorithm is of a stochastic nature, so
the results can vary! This is of course not what you would like.
For well-fitting combinations of data set and model, the
estimation results obtained in different trials will be very
similar. It is good to repeat the estimation process at least once
for the models that are to be reported in papers or presentations,
to confirm that what you report is a stable result of the
algorithm.

\subsection{The estimation function \textsf{siena07}}
\hypertarget{T_S_options}{   }
% provisionally placed here.

The estimation process implemented in functions \textsf{siena07()}
and \sfn{sienacpr()}
starts with initial values for the parameters,
and returns a so-called \textsf{sienaFit} object, in this example called
\texttt{results1}, which contains the estimates and their standard errors and
a lot of further information.
Since the estimate is iterative (depending on the initial value) and stochastic,
the results are not always completely satisfactory. We shall see below
how the satisfactory convergence of the algorithm can be checked,
and how to go on if this is not satisfactory.

Much of what follows is about the use of \sfn{siena07()}
but applies equally to \sfn{sienacpr()}.
The difference between these two functions is that
estimation by \sfn{sienacpr()} stays entirely in the
`back end' \sfn{C++} part of \si, contrasting with \sfn{siena07()}
which carries out the simulations in \sfn{C++} but the
Robbins-Monro updates in the \sfn{R} `front end' part;
this yields greater computational efficiency for \sfn{sienacpr()}.
Since the simulations take the largest amount of processing time
for medium-sized and large networks, the time difference is
notable, in a proportional sense, mainly for data sets
where simulations run very quickly (i.e., number of actors
and distance between first and last simulations are small).
Further, results from \sfn{sienacpr()} cannot used for
\sfn{sienaGOF()}.
Note that \sfn{sienacpr()} is available only in \sfn{RSienaTest()}.

The estimation algorithm is determined by a call of functions
such as
\begin{verbatim}
algorithm1    <-  sienaAlgorithmCreate(projname = "trypro", useStdInits = FALSE)
results1      <-  siena07(algorithm1, data = mydata, effects = myeff)
\end{verbatim}
The function \textsf{sienaAlgorithmCreate} defines an algorithm specification
object with options for the algorithm, and the function  \textsf{siena07}
carries out the estimation.
If you do not want to see the graphical interface with intermediate
results, or if your computer has problems showing this, then add
the option \texttt{batch = TRUE}, as in
\begin{verbatim}
results1  <-  siena07(algorithm1, data = mydata, effects = myeff,
                      batch = TRUE)
\end{verbatim}
If you wish to have detailed information at the console about the intermediate
steps taken by the algorithm, then add
the option \texttt{verbose = TRUE}, as in
\begin{verbatim}
results1  <-  siena07(algorithm1, data = mydata, effects = myeff,
                      verbose = TRUE)
\end{verbatim}


The estimation produces an output file in the current working directory,
of which the name is defined by the \textsf{projname} option;
in this example, the name is \texttt{trypro.out}.
To look at the information, you may either look at this file
(which can be opened by any text editor), or produce results on the \R console.

A brief summary of the results is given in the \R console by
typing the name of the  \textsf{sienaFit} object. For example,
\begin{verbatim}
results1
\end{verbatim}
could give a summary such as
% see sim_script.R; these are the s50 data, waves 1-2, seed=1234.
\par
{\footnotesize
\begin{verbatim}
Estimates, standard errors and convergence t-ratios
                              Estimate   Standard   Convergence
                                           Error      t-ratio
Rate parameters:
  0       Rate parameter       6.0803  ( 1.0220   )
  1. eval outdegree (density) -2.5270  ( 0.1589   )    0.0152
  2. eval reciprocity          2.1021  ( 0.3038   )    0.0039
  3. eval transitive triplets  0.5470  ( 0.1988   )    0.0214
  4. eval 3-cycles             0.0805  ( 0.3845   )    0.0369
  5. eval smoke1 similarity    0.4400  ( 0.2560   )   -0.0427

Overall maximum convergence ratio:    0.1608
\end{verbatim}
}
Requesting a longer summary by a command such as
\begin{verbatim}
summary(results1)
\end{verbatim}
will produce more information, including, e.g.,
the covariance/correlation matrix of the estimators.
\bigskip

\emph{Convergence check}
\smallskip

\noindent
The column \texttt{\small Convergence t-ratio} shown above, also
called \texttt{\small t statistics for deviations from targets},
is an indicator of convergence. If some of these values
are higher in absolute value than 0.1, convergence is not adequate.
The value \texttt{Overall maximum convergence ratio} is another, stricter,
indicator of convergence.
For adequate convergence, this value should be less than 0.25.

In this example, convergence is good.
If convergence is not adequate, the estimation must be repeated.
Usually the best way to do this is by employing the
argument \texttt{prevAns} in the call of \sfn{siena07()}.
Given that the earlier result was already called \texttt{results1},
this is done, e.g., by
\begin{verbatim}
results1  <-  siena07(algorithm1, data = mydata, effects = myeff,
                      prevAns = results1)
\end{verbatim}
The practical procedure therefore, in usual cases, is that
one runs \sfn{siena07()}, if necessary repeatedly with
subsequent runs using the \texttt{prevAns} parameter as above,
until the \texttt{Overall maximum convergence ratio} is less than 0.25
and all  \texttt{\small convergence t ratios}
are less than 0.1.
(The threshold value of 0.25 is not hewn in stone,
and small deviations are acceptable.)

In some cases this aim is not easily reached;
what to do then is treated in the following.

\subsubsection{Initial Values}
\label{S_initials}

The \emph{initial values} can be given in three ways.
\begin{enumerate}
\item The default: if \texttt{useStdInits = FALSE} and no \textsf{prevAns}
      parameter is given in the call of \textsf{siena07},
      the initial values are taken from the \textsf{sienaEffects} object,
      in this example called \texttt{myeff}.\\
      Requesting
\begin{verbatim}
myeff
\end{verbatim}
      will show the initial values.
      As long as no time dummies have been requested
      using \textsf{sienaTimeFix}, the initial values for the requested
      effects are in the vector
\begin{verbatim}
myeff$initialValue[myeff$include]
\end{verbatim}
      Changing these values is not often necessary, because the
      parameter \textsf{prevAns}, as explained in the next item,
      does this behind the scenes.\\
       If one does wish to change the initial values contained in
      the effects object, this can be done using the
      function \textsf{updateTheta}, which copies the
      estimates from earlier results, contained in a
      \sfn{sienaFit} object, to the effects object.
      For a single effect the initial value can be changed
      by the \textsf{setEffect}
      function in which the \textsf{initialValue} then must be set.
\item If \texttt{useStdInits = FALSE} and the \textsf{prevAns}
      (`previous answer')
      parameter is used, such as in
      \begin{verbatim}
results1 <- siena07(algorithm1, data = mydata, effects = myeff,
                    prevAns = results0)
      \end{verbatim}
      the initial parameter estimates are taken from the results of
      what is given as the
      \textsf{prevAns} parameter. This must be a
      \textsf{sienaFit} object; in this example it is given as
      \texttt{results0}.\\
      If the specification of the effects object used to obtain
      \texttt{results0} was the same as \texttt{myeff}, then not only the initial
      values are copied, but also Phase 1 of the algorithm is skipped,
      because information for the sensitivity of the statistics with
      respect to the parameters is taken from the results of Phase 3
      of \texttt{results0}.\\
      If the specification of the effects object used to obtain
      \texttt{results0} was not the same as \texttt{myeff}, then for those
      parameters that do match, the initial values are copied
      from \texttt{results0} and Phase 1 is carried out as usual.
\item If \texttt{useStdInits = TRUE} is used in the call of
      \textsf{sienaAlgorithmCreate}, standard initial values are used.\\
      These consist of some reasonable values for the rate parameters and the
      outdegree parameter, as well as for the linear shape parameter
      for behavioral dependent variables (if any);
      and 0 parameters for the rest.\\
      The default is  \texttt{useStdInits = FALSE}.
\end{enumerate}

\subsubsection{Convergence Check}
\label{S_ccheck}

When parameters have been estimated, first the
\hypertarget{T_convergence}{convergence} of the
algorithm must be checked. This is done by looking at the
\emph{$t$-ratios for convergence} and the
\emph{overall maximum convergence ratio}.
These are given in the output of the algorithm, presented above.
This check
considers the deviations between simulated values
(in Phase~3, see below) of the
statistics and their observed values (the latter are called the
`targets'). Ideally, these deviations should be 0. Because of the
stochastic nature of the algorithm, when the process has properly
converged the deviations are small but not exactly equal to 0.
The program calculates the averages and standard deviations of the
deviations and combines these in a $t$-ratio (in this case,
average divided by standard deviation).
The overall maximum convergence ratio is the maximum value of
the ratio
\[
 \frac{\text{average deviation}}{\text{standard deviation}}
\]
for any linear combination of the target values.
A precise definition is given in \\
\href{http://www.stats.ox.ac.uk/~snijders/siena/Siena_algorithms.pdf}{\texttt{Siena\_algorithms.pdf}}
which can be downloaded from the \SI website.

Convergence is excellent when the overall maximum convergence ratio
is less than 0.2, and for all the individual parameters the $t$-ratios
for convergence all are less than 0.1 in absolute value;
convergence is reasonable when the former is less than 0.30.
For published results, it is suggested that estimates presented come from runs
in which the overall maximum convergence ratio is less than 0.25.
(These bounds are indications only, and are not meant as severe limitations.)

In the example above, the largest absolute value of the $t$-ratios for convergence
is equal to 0.0427, and the overall maximum convergence ratio is 0.1608;
both are quite good values.

If convergence is not adequate, the best way to continue
is by making another estimation run,
now carrying on from the last obtained result. This is done by
using this result in the \textsf{prevAns} (`previous answer')
parameter, while taking care that  \texttt{useStdInits = FALSE}
has been specified (but this is the default). An example is
\begin{verbatim}
results1 <- siena07(algorithm1, data = mydata, effects = myeff,
                    prevAns = results1)
\end{verbatim}
In this case, this second estimation run produced good results, with a
maximum absolute   $t$-ratio for convergence equal to 0.0777.
The output file gives more extensive results, viz.,
 the averages and standard deviations of the
deviations from targets and the resulting $t$-ratios:

{\footnotesize
\begin{verbatim}
End of stochastic approximation algorithm, phase 3.
---------------------------------------------------

Total of 1822 iterations.
Parameter estimates based on 822 iterations,
basic rate parameter as well as
convergence diagnostics, covariance and derivative matrices based on 1000 iterations.

Information for convergence diagnosis.
Averages, standard deviations, and t-ratios for deviations from targets:
  1.   0.2460  16.1494   0.0152
  2.   0.0560  14.3829   0.0039
  3.   0.9520  44.5338   0.0214
  4.   0.5380  14.5726   0.0369
  5.  -0.2080   4.8672  -0.0427

Good convergence is indicated by the t-ratios being close to zero.
Overall maximum convergence ratio = 0.1608.
\end{verbatim}
}
For example, for the fourth parameter (3-cycles), the average deviation
from the target value was 0.5380, and the standard deviation across the
1000 simulations in Phase~3 was  14.5726. This yields a $t$-ratio
of $ 0.5380 / 14.5726 = 0.0369$.
Large values of the averages and standard deviations are
in themselves not at all a reason for concern; only the
$t$-ratio is important.

\subsubsection{Continued estimation to obtain convergence}
\label{S_contconv}

Above, the \sfn{prevAns} parameter was mentioned which will
lead to using the result from a previous estimation as the initial
value for the next estimation.
If convergence is difficult to obtain, one may use other
settings of the estimation algorithm, given as
parameters in the \sfn{sienaAlgorithmCreate()} function, to try and
improve convergence.
The main parameters of \sfn{sienaAlgorithmCreate()} that can be used
for this purpose are the following.
They are briefly explained in the help file for this function.
For the technical background, see
\href{http://www.stats.ox.ac.uk/~snijders/siena/Siena_algorithms.pdf}{\texttt{Siena\_algorithms.pdf}}
which can be downloaded from the \SI website.

\begin{itemize}
\item \texttt{doubleAveraging}\\
      This replaces the Robbins-Monro updating step by a double averaging
      step \citep{bather1989,SchwabeWalk96,KushnerYin03} which can be
      more efficient. The default is \texttt{doubleAveraging=0}, which starts using
      this step from subphase 2.1.
\item \texttt{diagonalize}\\
    This parameter may range from 0 to 1,
    and determines the extent to which the matrix of derivatives of expected
    values with respect to parameters is diagonalized.
    The value 1 (total diagonalization) gives greatest stability;
    smaller values give greater efficiency.
    The default is 0.2.
\item \texttt{n2start}\\
    This is the minimum length of phase 2.1, i.e., the first subphase of phase~2.
    The default value
     is $2.52\times (p+7)$, where $p$ is the number of estimated parameters.
    The minimum lengths of the subsequent subphases\footnote{These values are
     meant to approximate $(7+p)\times 2^{4(k+2)/3}$.
    With the stepwise gain parameter $a_N$ being halved
    for each new subphase, these values
    imply that $a_N$ is asymptotically of order $N^{-3/4}$, which is
    good for convergence of the algorithm.}
    are $(2.52)^{k-1} \times\,$\texttt{n2start} for subphase~$k$.\\
    This implies the total duration of the algorithm will be roughly proportional to
    \texttt{n2start}. One may try using a value higher than the default.
\item \texttt{firstg}\\
    This determines the step sizes in the estimation algorithm. If the algorithm is unstable,
    use a smaller value (but greater than~0).
    The default value is 0.2.
    Sometimes for difficult data-model combinations, the algorithm
    diverges very quickly, and this may be countered by smaller values of
     \texttt{firstg}, e.g., 0.01 or 0.05.
\end{itemize}


If convergence is not very good even with repeated estimation with
the \sfn{prevAns} option, sometimes it can be useful to try and use
\sfn{updateTheta()} to copy the results from the earlier estimation
rather than \sfn{prevAns}; this will use the same starting values
but not skip Phase~1 of the estimation algorithm, and sometimes
this turns out to lead to faster convergence.
\medskip

The following function will
iterate the execution of \sfn{siena07()} until it has converged.
It can be modified to suit your further purposes.
The argument \texttt{ans0} can be employed to use an earlier existing
`on track' estimation result, if available, as the initial value
for the algorithm.

\begin{verbatim}
siena07ToConvergence <- function(alg, dat, eff, ans0=NULL, ...){
   numr <- 0
   ans <- siena07(alg, data=dat, effects=eff, prevAns=ans0, ...) # the first run
   repeat {
       save(ans, file=paste("ans",numr,".RData",sep="")) # to be safe
       numr <- numr+1           # count number of repeated runs
       tm <- ans$tconv.max      # convergence indicator
       cat(numr, tm,"\n")       # report how far we are
       if (tm < 0.25) {break}   # success
       if (tm > 10) {break}     # divergence without much hope
                                # of returning to good parameter values
       if (numr > 30) {break}   # now it has lasted too long
       ans <- siena07(alg, data=dat, effects=eff, prevAns=ans, ...)
       }
   if (tm > 0.25)
   {
      cat("Warning: convergence inadequate.\n")
   }
   ans
}
\end{verbatim}

Another approach that sometimes can be helpful to obtain convergence in difficult
situations is to gradually build up the model, adding further effects
while using the \sfn{prevAns} parameter to use previous estimates as starting
values for the next, extended model. This may be more successful than
estimating a complicated model right from the start.

When there are difficulties in obtaining convergence, note that one also
should reconsider the model specification; good specification of the model often
considerably improves the converge of the parameter estimation.
When reading the words here because of a concern about convergence,
please read on at least until and including Section~\ref{S_conv}.

\subsection{Use of the algorithm parameters}

The parameters mentioned in the preceding section can be used in the following way
to try and achieve convergence if one does not obtain the desired low level
of \sfn{tconv.max} by successive estimation using the \sfn{prevAns}
parameter sequentially.
The advice is to use (1.) \underline{or} (2.), in both cases together with (3.).

\begin{enumerate}
\item In the estimations where \sfn{prevAns} is used,
    use more than 4 subphases: \sfn{nsub=5} or, if that is not sufficient,
    \sfn{nsub=6}.
\item First do an estimation with the default parameters
    for the algorithm.
    If that has returned a somewhat reasonable provisional estimate
    (among other requirements, with a value of \sfn{tconv.max} that is
    not very high; and \emph{not} with one or more parameter estimates
    being very high in absolute value), continue the estimation, using \sfn{prevAns},
    with \sfn{nsub=1}; a high value for \sfn{n2start};
    and \sfn{firstg} clearly less than the default 0.2; e.g., 0.01.
    What is `a high value' depends on the data set - model combination,
    the number of parameters in the first place.
    The baseline value (see the preceding section\footnote{The value given here
    is the default number of simulation runs in the 4'th subphase.})
    would be \\
    $(p+7)\times (2.52)^4$, where $p$ is the
    number of estimated parameters (excluding the rate parameters
    estimated by conditioning, if conditional estimation is used).
    For a `high value', start with a value that is about twice as large,
    Note that computation time in Phase~2 will be proportional to \sfn{n2start}.
    Continue estimation with these algorithmic parameters using \sfn{prevAns},
    further perhaps increasing \sfn{n2start} if necessary.
\item Use for \sfn{n3} a larger value than the default.
    E.g., \sfn{n3 = 3000} or \sfn{5000};
    if it was necessary to further increase \sfn{nsub} or \sfn{n2start}, it may also be
    necessary to further increase \sfn{n3}.
\end{enumerate}

All these choices clearly increase computing time; but less so, and with
more likely success, than just carrying on very long with \sfn{siena07ToConvergence()}
using the default algorithmic parameters.



\subsection{What to do if there are convergence problems}
\label{S_conv}

If there are persisting convergence problems even after repeated estimations
using the \texttt{prevAns} parameter and trying out various
settings for the algorithm as suggested in the preceding sections,
this may have several reasons.
\begin{itemize}
\item The data specification was incorrect (e.g., because the coding
      was not given properly).
\item The starting values were poor.
      Try restarting from the standard initial values
      (a certain non-zero value for the
      density parameter, and zero values for the other parameters);
      or from values obtained as the estimates for a simpler model
      that gave no problems.
      The initial default parameter values can be obtained
      by choosing the algorithm option ``standard initial values".
\iffalse
      When starting estimations with Model Type 2
      (see Section~\ref{S_modeltype}), there may be some problems to
      find suitable starting values.
      For Model Type 2, it is advised to start with
      \hyperlink{T_S_cond}{unconditional estimation}
      and a simple model,
      and to turn back to conditional estimation, using the current parameter
      values as initial estimates for new estimation runs, only when
      satisfactory estimates for a simple model have been found.
\fi
\item The model does not fit well in the sense that even with well-chosen
      parameters it will not give a good representation of the data.

      This can be the case, e.g., when there is a large heterogeneity
      between the actors which is not well represented by effects
      of covariates.
      The out-degrees and in-degrees are given in the begin of the \SI output
      to be able to check whether there are outlying actors having very high
      in- or out-degrees, or a deviating dynamics in their degrees.
      Strong heterogeneity between the actors will have to be
      represented by suitable covariates; if these are not available,
      one may define one or a few dummy variables each representing
      an outlying actor, and give this dummy variable an ego effect
      in the case of deviant out-degrees, and an alter effect in the
      case of deviant in-degrees.

      Sometimes transitivity can better be modeled by the GWESP effects
      (search for this term in the manual) than by transitive triplers.
      This may help with convergence.

      For modeling large networks, it is important to represent
      meeting opportunities, e.g., by a suitable dyadic covariate,
      or by the \texttt{sameX} effect of a suitable categorical covariate.

      Sometimes there are important differences between the actors in how many
      changes they make in their outgoing ties. This should then
      be reflected by including one or more rate effects.
      The experience is that the main rate effect to include
      is the rate effect of the outdegrees (\texttt{outRate},
      see Section~\ref{S_r}).

      Another possibility is that there is time heterogeneity.
      Indications about this can be gathered also from the descriptives
      given in the start of the output file produced by \sfn{print01Report()}:
      the number of changes
      upward and downward, in the network and also -- if any -- in the
      dependent behavioral variable. If these do not show a smooth
      or similar pattern across the observations, then it may be useful
      to include actor variables representing time trends. These
      could be smooth -- e.g., linear -- but they also could be dummy variables
      representing one or more observational periods; these must be included
      as an ego effect to represent time trends in the tendency to make ties
      (or to display higher values of the behavior in question).
      Further see Section~\ref{S_timetest1} for how to discover and handle
      time heterogeneity.
\item Too many weak effects are included. Use a smaller number of effects,
      delete non-significant ones, and increase complexity step by step.
      Retain parameter estimates from the last
      (simpler) model as the initial values for the new estimation procedure,
      provided for this model the algorithm converged
      without difficulties; here also \texttt{prevAns} may be used.\\
      Effects that are left out of the estimation can still be
      used in the model by specifying them with \texttt{test=TRUE, fix=TRUE};
      this will not burden the estimation process, and give information
      (with a score-type test, see Section~\ref{S_Scoretest})
      about the significance of this excluded effect.\\
      Usually this will be applied with \texttt{initialValue=0}, the default.
      But sometimes it may be done with a plausible non-zero value for
      \texttt{initialValue}.
\item Two or more effects are included that are almost collinear
      in the sense that they can both explain the same observed structures.
      This will be seen in high absolute values of
      correlations between parameter estimates, presented in the
      \sfn{summary} of the results object and also in the output file.
      In this case it may be better to exclude one of these effects from the model.
\item An effect is included that is large but of which the precise
      value is not well-determined (see above:
      \hyperlink{T_fix}{section on fixing parameters}).
      This will be seen in estimates and standard errors both being large
      and often in divergence of the algorithm.
      Fix this parameter to some large value.
      (Note: large here means, e.g., more than 5 or less than -5; depending
      on the effect, of course.)
\end{itemize}

Another trick that may be tried is the following.
Sometimes one (or some) of the rate parameters are especially the causes of
difficulties of convergence.
Then one may fix this parameter at a good value, and estimate the rest
of the parameters. Suppose that this is feasible, i.e., good convergence can be
obtained provided that this rate parameter is fixed. Then by trial and error
one may find a fixed value for this rate parameter for which the $t$-ratio for
convergence for this parameter also is acceptable
(less than 0.2, preferably less than 0.1).
Since normally, rate parameters are nuisance parameters (i.e., not of focal interest),
this can be an acceptable way out.



\subsection{Some important components of the \textsf{sienaFit} object}
\label{S_fitcomp}

If a user would like to do further calculations, it can be
useful to know about the following components of  \textsf{sienaFit} objects.
Suppose the object is called \texttt{ans}. Some of the components
are the following.
Further details are in the help file for \textsf{siena07}.

\begin{tabbing}
 \texttt{ans\$theta  }\hspace{3em}    \=  estimates  \\
                                      \> (but not for the rate parameter used
                                                       for conditioning;\\
                                      \> if time dummies were requested using
                                            \textsf{sienaTimeFix},\\
                                      \> these are also in \texttt{theta}). \\
 \texttt{ans\$covtheta   }            \> covariance matrix of the estimates \\
 \texttt{ans\$se   }               \> standard errors of the estimates \\
 \texttt{ans\$pp}                     \> number of parameters  \\
 \texttt{ans\$targets }               \> targets (observed statistics)
                                         for Method of Moments estimation  \\
 \texttt{ans\$tconv   }               \> $t$-ratios for convergence for  each of the parameters\\
 \texttt{ans\$tmax   }               \> maximum absolute value of these ratios for non-fixed parameters\\
 \texttt{ans\$tconv.max   }         \> maximum $t$-ratio for convergence for \\
                                 \> any linear combination of the parameters,\\
                             \> called the overall maximum convergence ratio \\
 \texttt{ans\$sf    }        \>  generated statistics in Phase 3 (targets subtracted)\\
 \texttt{ans\$msf   }        \>  covariance matrix of
                                           \texttt{ans\$sf    } \\
 \texttt{ans\$dfra  }        \> estimated derivative of expected
                                            statistics w.r.t.\ parameters,  \\
 \texttt{ans\$ac  }        \> autocorrelations of generated statistics in Phase 3  \\
 \texttt{ans\$sims }         \> simulated values of dependent variables
                                      in Phase 3 of the algorithm     \\
                             \>  if \textsf{returnDeps = TRUE}
                                        in the call of \textsf{siena07}; \\
                             \> in case of Maximum Likelihood estimation (see Section~\ref{S_sims}), note that \\
                             \> for observed tie variables the simulated values are
                             equal to the observed; \\
                             \> for missing tie variables, the simulated values can be regarded \\
                             \> as model-based imputations \\
 \texttt{ans\$estMeans }     \> estimated expected values of the target statistics\\
                             \> (if the Dolby option was chosen, this is \\
                             \> not equal to the average of the simulations!)\\
 \texttt{ans\$effects }      \> the effects object with only the requested effects\\
 \texttt{ans\$x }            \> the algorithm object used\\
 \texttt{ans\$f }            \> everything needed for the calculations in C++;\\
                             \> in particular, the data set is hidden in here,
                                and can be reconstructed.\\
                             \> Digging in will show as \texttt{mat1} the network data,
                                 as \texttt{mat2} the missings, \\
                             \>   and as \texttt{mat3} the structurally determined values.\\
                             \> All these are stored as transposed edge lists.\\
                             \> Programmers can consult function \texttt{initializeFRAN()}\\
                             \> for the creation and hence contents of this object.\\
 \texttt{ans\$version }      \> the \textsf{RSiena/Test} version\\
 \texttt{ans\$revision }     \> the \textsf{R-Forge} revision.\\

\end{tabbing}
Like for any \R object, the internal structure of the \textsf{sienaFit} object
can be requested by requesting
\begin{verbatim}
sink("ans.txt")
str(ans)
sink()
\end{verbatim}
This writes the structure to the external file \texttt{ans.txt}, which may
be better than printing it to the console, because it is a long story.\\
A limited representation of the structure of this object is obtained from
\begin{verbatim}
sink("ans.txt")
str(ans, 1)
sink()
\end{verbatim}

To get some further understanding, one could investigate some of the components
of this object as follows.
Note that putting a statement between parentheses like in\\
\texttt{(A <- B)} is just a way for
constructing the object \texttt{A} and showing it at the same time.
\begin{verbatim}
# Compute the covariance matrix of the generated statistics
print(covsf <- cov(ans$sf))
# This is the same as ans$msf, provided there are no fixed parameters.
# The means and standard deviations of the generated statistics minus targets:
(v <- colMeans(ans$sf))
(s <- apply(ans$sf, 2, sd))
# This also allows to compute the convergence t-ratios
v / s
# To get the generated statistics without subtracting the targets,
# we have to add the targets.
# To do this, repeated transposition t can be used:
stats <- t(t(ans$sf) + ans$targets)
# or
stats <- ans$sf + rep(ans$targets, each=nrow(ans$sf))
\end{verbatim}

The \texttt{tconv} components are used
in the function \texttt{siena07ToConvergence}
presented above.

\subsection{Algorithm}
\label{S_algorithm}

The estimation algorithm is an implementation of a procedure of which
the original version was proposed by \citet{RobbinsMonro51}.
The algorithm is
described in \citet{Snijders01, Snijders05}
and in
\href{http://www.stats.ox.ac.uk/~snijders/siena/Siena_algorithms.pdf}{\texttt{Siena\_algorithms.pdf}}
which can be downloaded from the \SI website.
It has %for both the MoM and ML method
three phases:
\begin{enumerate}
\item In phase 1, the parameter vector is held constant at its
initial value.
      This phase is for
      having a first rough estimate of the matrix of derivatives.
\item Phase 2 consists of several subphases.
      More subphases means a greater precision. The default
      number of subphases is 4.
      The parameter values change from run to run, reflecting
      the deviations between generated and observed values of the
      statistics. The changes in the parameter values are smaller
      in the later subphases.\\
      The program searches for parameter values where these deviations
      average out to 0. This is reflected by what is called the
      \hypertarget{T_quasiac}{`quasi-auto\-cor\-relations'}
      in the output screen.
      These are averages
      of products of successively generated deviations between
      generated and observed statistics. It is a good sign
      for the convergence of the process when the
      \hyperlink{T_quasiac}{quasi-auto\-correlations}
      are negative (or positive but close to 0),
      because this means the generated values are jumping
      around the observed values.
      When estimating by the Method of Moments, it is usual for the
      quasi-auto\-correlations to become close to 0.
      For estimation by Maximum Likelihood, they will usually
      eventually tend to fluctuate about some positive values
      determined by the multiplication factor (see Section~\ref{S_ML}).
      Large quasi-auto\-correlations (larger than .5), when using the Method of
      Maximum Likelihood, suggest that either the estimation process
      is still far from its eventual limit (the final estimate), \underline{or}
      the multiplication factor may be too small.
      But in this case, the auto\-correlations given in the output file
      are more important information than those given on the screen.
\item In phase 3, the parameter vector is held constant again,
      now at its final value.
      This phase is for estimating the covariance matrix and the
      matrix of derivatives used for the computation of standard errors.\\
      The default number of runs in phase 3 is 1000. This requires a lot
      of computing time, but when the number of phase 3 runs is too low,
      the standard errors computed are rather unreliable.
\end{enumerate}

The number of subphases in phase 2, and the number of runs in
phase 3, are determined by parameters \textsf{nsub} and \textsf{n3}
in the call of \textsf{sienaAlgorithmCreate}.

During the estimation process, if the graphical user interface
is used (the default \\
\texttt{batch = FALSE} in the call of \textsf{siena07}),
the user can break in and modify the estimation process in two
ways:
\begin{enumerate}
\item it is possible to terminate the estimation;
\item in phase 2, it is possible to terminate phase 2
      and continue with phase 3.
\end{enumerate}

% For the ML estimation option and for the non-longitudinal case,
% tuning the `multiplication factor' and the `initial gain parameter'
% can be important for getting good results;
% for Bayesian estimation the `multiplicaton factor' can likewise
% be important; this is briefly described in Section~\ref{S_exec}.


\subsection{Output}
\label{S_output}

Output can be obtained in several ways.
\begin{enumerate}
  \item On the \R console.\\
        When the \textsf{sienaFit} object produced by \textsf{siena07}
        is called \texttt{ans},
        requesting just \texttt{ans} or \texttt{print(ans)}
        produces output on the \R console. The function
        \texttt{summary(ans)} produces more extensive output.
  \item A table in latex or html format can be produced by the
        \textsf{xtable.sienaFit} method.
        For example,
        \begin{verbatim}
        xtable(ans, file="ans1.htm", type="html")
        \end{verbatim}
        produces in the working directory a html file with the \texttt{ans}
        results in
        tabular form. The \textsf{xtable} package has many further options.\\
  \item In package \sfn{RSienaTest}, the function \sfn{siena.table}
        is available which serves a similar purpose,
        but not using \textsf{xtable}.
        This function writes the table to a file;
        the default file name of the table produced is the name of the
        \sfn{sienaFit} object.
        The choice between \textsf{xtable.sienaFit} and \sfn{siena.table}
        depends on the preference for the tables produced.

        For importing the results of \sfn{xtable} or \sfn{siena.table} into
        MS-Word, the following steps can be used.

        Request \texttt{siena.table(ans)} for some \sfn{sienaFit} object,
        called \texttt{ans} in this example. This will produce,
        under the default settings, the file \texttt{ans.htm} in the current
        working directory.
        Copy-paste this into the MS-Word file.
        In MS-Word then select this table, but
        only the lines of the header and the parameters, not any
        preceding blank line nor the footnote.
        In the MS-Word menu choose ``Insert –- Convert text to table -–
        Autofit to contents''.
        This will produce the table in your MS-Word file.
        You can then further modify the table; e.g., change the double minus
        sign \texttt{--} to the MS-Word minus sign $ - $
        (available under ``insert -– symbol'') and replace the dots for the
        `t stat.' of the rate parameters by blanks.

  \item The function \textsf{siena07}
        writes an output file which is an ASCII (`text') file that can be
        read by any text editor.
        It is called \textsf{\textsl{pname}.out},
        where \textsf{\textsl{pname}} is the name
        specified in the call of \textsf{sienaAlgorithmCreate()}.

        This output file is divided into sections
        indicated by a line {\tt @1},
        subsections indicated by a line {\tt @2}, subsubsections indicated
        by {\tt @3}, etc. For getting the main structure of the output, it
        is convenient to have a look at the {\tt @1} marks first.
\end{enumerate}

The primary information in the output of the estimation process
consists of the following three parts.

\subsubsection{Convergence check}

This was discussed in Section~\ref{S_ccheck} \hyperlink{T_convergence}{above}.
\medskip

\subsubsection{Parameter values and standard errors}

The next crucial part of the output is the list of estimates and
standard errors. Suppose that the
following result was obtained on the \R console.

{\footnotesize
\begin{verbatim}
                              Estimate   Standard   Convergence
                                           Error      t-ratio
Rate parameters:
  0       Rate parameter       6.0742  ( 1.0134   )
  1. eval outdegree (density) -2.5341  ( 0.1445   )   0.0571
  2. eval reciprocity          2.1106  ( 0.2625   )   0.0710
  3. eval transitive triplets  0.5449  ( 0.1781   )   0.0584
  4. eval 3-cycles             0.0779  ( 0.3425   )   0.0777
  5. eval smoke1 similarity    0.4519  ( 0.2497   )   0.0400
\end{verbatim}
}

The rate parameter is the parameter called $ \rho^{\rm net}_m$
in Section~\ref{S_r} below (where $m=1$ because there is only one period).
The value 6.0742 indicates
that the estimated number of opportunities
for change per actor (note that each actor
corresponds to a row in the adjacency matrix)
between the two observations is
6.07 (rounded in view of the standard error 1.01). Note that this
refers to unobserved changes, and that some
opportunities for change lead to the decision `no change',
and moreover some of these changes may
cancel (make a new choice and then withdraw it again), so the
average observed number of differences per actor will be
smaller than this estimated number of unobserved changes.

The other five parameters are the weights in the \emph{evaluation function}.
The terms in the evaluation function in this model specification are
the \hyperlink{T_density}{out-degree effect} defined as $s_{i1}$ in
Section \ref{S_f}, the
\hyperlink{T_reci}{reciprocity effect} $s_{i2}$,
\hyperlink{T_transtrip}{transitive triplets effect} $s_{i3}$,
\hyperlink{T_cycle3}{three-cycles effect} $s_{i5}$,
\hyperlink{T_simx}{sex similarity effect} $s_{i\ref{simx}}$.
Therefore the
estimated evaluation function here is
\[
\,- 2.53 \, s_{i1}(x) \+ 2.11\, s_{i2}(x) \+ 0.54 \, s_{i3}(x)\+ 0.08 \, s_{i5}(x)\+ 0.45 \, s_{i\ref{simx}}(x)
\]
where again some rounding was applied in view of the standard errors.
The parameter estimates can be combined with
the standard errors to test the parameters.
(Testing of parameters is discussed more extensively
in Chapter~\ref{S_test}.)

 For the rate
parameter, testing the hypothesis that it is 0 is meaningless
because the fact that there are differences between the two observed
networks implies that the rate of change must be positive. The
weights in the evaluation function can be tested by $t$-statistics,
defined as estimate divided by its standard error. (Do not confuse
this $t$-test with \hyperlink{T_convergence}{the $t$-ratio for}
checking convergence; these are completely different although both
are $t$ ratios!) Here the $t$-values are, respectively,
 -2.5341/0.1445 = --17.54,
  2.1106/0.2625 = 8.04,
  0.5449/0.1781 = 3.06,
  0.0779/0.3425 = 0.23,
  0.4519/0.2497 = 1.81.
 Since the first three are larger than 2 in absolute value, they are
significant at the 0.05 significance level. It follows that there is
evidence that the actors have a `preference' for reciprocal
and transitive relations.
For thee-cycles, the effect is not significant ($t = 0.23$),
for smoking similarity it is significant at the 0.10 significance level.
The value of the density parameter is not very important; it is
important that this parameter is included to control for the density
in the network, but as all other statistics are correlated with the
density, the density is difficult to interpret by itself.

\subsubsection{Collinearity check}
\label{S_collinear}

In the output file, the covariance matrix
of the estimates is presented.
This can also be requested by \texttt{summary(ans)}.
For conditional estimation, the rate parameters of the dependent variables
used for conditioning are not included in this matrix.
In this case the covariance matrix is as follows.

{\footnotesize
\begin{verbatim}
Covariance matrix of estimates (correlations below diagonal):)
       0.021       -0.018       -0.010        0.006       -0.008
      -0.468        0.069        0.008       -0.034       -0.002
      -0.395        0.180        0.032       -0.049        0.003
       0.130       -0.378       -0.795        0.117       -0.001
      -0.223       -0.037        0.074       -0.007        0.062
\end{verbatim}
}
The diagonal values are the variances, i.e., the squares of the
standard errors (e.g., for the reciprocity effect,
0.069 is the square of  0.2625). Below the
diagonal are the correlations. E.g., the correlation between the
estimated outdegree effect and the estimated reciprocity effect is
--0.468. These correlations can be used to see whether there is an
important degree of collinearity between the effects. Collinearity
means that several different combinations of parameter values
could represent the same data pattern, in
this case, the same values of the network statistics. When one or
more of the correlations are very close to -1.0 or +1.0, this is a
sign of near collinearity. This will also lead to large standard errors
of those parameters. It may then be advisable to omit one of the
corresponding effects from the model, because it may be redundant
given the other (strongly correlated) effect; but see
\hyperlink{T_collinearity}{below}. It is possible that
the standard error of the retained effect becomes much smaller by
omitting the other effect, which can also mean a change of the
$t$-test from non-significance to significance.

The suggestion of omitting effects that lead to high parameter
correlations with other effect does not directly apply to
effects that should be included for other reasons, such as
the density effect for network dynamics and the linear and
quadratic shape effects for behavior dynamics.

\hypertarget{T_collinearity}{However, correlations between
parameter estimates close to -1.0 or +1.0}
should not be used too soon in themselves as reasons to exclude effects
from a model. This is for two reasons.
In the first place, network statistics often are highly correlated
(for example, total number of ties and number of transitive triplets)
and these correlations just are one of the properties of networks.
Second, near collinearity is not a problem in itself,
but the problem (if any) arises when standard errors are high,
which may occur
because the value of the parameters of highly correlated variables
is very hard to estimate with any precision. The problem resides in the
large standard errors, not in itself in the strong correlation between
the parameter estimates. If for both parameters
the ratio of parameter estimate to standard error,
i.e., the $t$-ratio, is larger than 2 in absolute value,
in spite of the high correlations between the parameter estimates, then
the significance of the $t$-test is evidence anyway that both
effects merit to be included in the model.
In other words, in terms of the `signal-to-noise ratio':
the random noise is high but the signal is strong enough
that it overcomes the noise.

As a rule of thumb for parameter correlations,
usually for correlations of estimated structural network effects there is no
reason for concern even when these correlations
are as strong as .9.

In the example above, the strongest correlation was found between
the parameter estimates for transitive triplets and three-cycles.
This is not surprising, because both are triadic effects.
In this case, the three-cycle effect was not significant,
and can be dropped for that reason.

\subsection{Other estimation procedures}

\SI can estimate models by four estimation methods:
the (unconditional or conditional)
Method of Moments \citep*[`MoM', the default; ][]{Snijders01, SnijdersEA07};
the Generalized Method of Moments \citep*[`GMoM', see][]{ASS2015};
the Maximum Likelihood method \citep*[`ML', see][]{SnijdersEA10a},
and Bayesian methods
\citep[see][]{Koskinen04,KoskinenSnijders07,SchweinbergerSnijders07c,KoskinenSnijders15}.

The Generalized Method of Moments is still in development.
It is theoretically more efficient than the Method of Moments.
It is somewhat more time-consuming; on the other hand, function \sfn{sienacpr()}
is coded in a more efficient way than \sfn{siena07()}.

In models for one network, without co-evolution,
in nice situations (data sets that are not too small, model specifications
that do not request too much from the data, good fit between data and
model specification), the four methods tend to agree
and there seems to be no reason to use the more time-consuming
ML or Bayesian methods.
For co-evolution models and not-so-nice situations (very small network data sets,
small network and behavior data sets in combination with complex models),
however, ML and Bayesian methods tend to produce more accurate results
(i.e., smaller standard errors) than MoM.
Statistical theory suggests that ML is a more efficient estimation method
than MoM in the sense of producing estimates with smaller standard errors.
But in the `nice situations' the efficiency advantage of ML is very small.
Bayesian estimation is based on a different statistical paradigm, and
assumes and requires that the uncertainty about parameters is expressed
itself in a probability distribution.
For co-evolution, estimation by the Generalized Method of Moments
will be made available in future versions.

Estimation by the regular Method of Moments (MoM)
is implemented in the functions \sfn{siena07()} and \sfn{sienacpr()}.
Estimation by the Generalized Method of Moments (GMoM)
is implemented in the function \sfn{sienacpr()}.

ML estimation is done by the function \sfn{siena07()}, using a set of options
created by \sfn{sienaAlgorithmCreate()} with \sfn{maxlike=TRUE}.
Bayesian estimation is done by the function \sfn{sienaBayes()},
but is as yet implemented only for multilevel network modeling
(Section~\ref{S_sienaBayes}).


\subsection{Generalized Method of Moments estimation}
\label{S_GMoM}

Estimation by the Generalized Method of Moments (GMoM)
was proposed in \citet{ASS2015} and is implemented
in the function \sfn{sienacpr()}, available in \sfn{RSienaTest()}.

If the algorithm object created by \sfn{sienaAlgorithmCreate()}
uses \texttt{maxlike=FALSE}, the estimation function \sfn{sienacpr()}
will use the MoM or the GMoM; the latter will be used as soon as
at least one of the effects were specified in the effects object with
\texttt{type='gmm'}.

The specification of the effects object for GMoM estimation requires
that in the effects object, apart from the basic rate effects,
some of the effects were specified
in  \sfn{includeEffects()} with \texttt{type='eval'}
(the default, which means that this does not need to be stated)
and the others with \texttt{type='gmm'}.
The first then are evaluation effects defining the model specification,
the second are statistics used for estimation.
The method requires that the number of statistics (\texttt{type='gmm'})
is equal to or larger than the number of
evaluation effects (\texttt{type='eval'}).
For example, the commands

\begin{verbatim}
net <- sienaDependent(array(c(s501,s502,s503), dim=c(50,50,3)))
dataset <- sienaDataCreate(net)
eff <- getEffects(dataset)
eff <- includeEffects(eff, density)
eff <- includeEffects(eff, density, type='gmm')
eff <- includeEffects(eff, recip)
eff <- includeEffects(eff, recip, realrecip, persistrecip, type='gmm')
eff <- includeEffects(eff, transTrip)
eff <- includeEffects(eff, transTrip, agreetrans, realtrans, type='gmm')
eff
\end{verbatim}
will print the resulting effects object
\begin{verbatim}
  For estimation by the Generalized Method of Moments
  Effects
  effectName                   include fix   test  initialValue parm type
1 constant net rate (period 1) TRUE    FALSE FALSE    4.69604   0    rate
2 constant net rate (period 2) TRUE    FALSE FALSE    4.32885   0    rate
3 outdegree (density)          TRUE    FALSE FALSE   -1.46770   0    eval
4 reciprocity                  TRUE    FALSE FALSE    0.00000   0    eval
5 transitive triplets          TRUE    FALSE FALSE    0.00000   0    eval

 Statistics
  effectName          include type
1 outdegree (density) TRUE    gmm
2 reciprocity         TRUE    gmm
3 persistent recip.   TRUE    gmm
4 real recip.         TRUE    gmm
5 transitive triplets TRUE    gmm
6 real trans. trip.   TRUE    gmm
7 agree trans. trip.  TRUE    gmm
\end{verbatim}
with three evaluation effects and seven statistics.
Like the MoM, the GMoM allows conditional as well as unconditional
estimation (see Section~\ref{S_cond}).
In this example, for conditional estimation the number
of statistics will be nine, including the two statistics
for the rate parameters, viz., Hamming distances
between subsequent waves.

\subsection{Maximum Likelihood and Bayesian estimation}
\label{S_ML}
\label{S_Bayes}

ML estimation is done by the function \sfn{siena07()}, using a set of options
created by \sfn{sienaAlgorithmCreate()} with \texttt{maxlike=TRUE}.
Bayesian estimation is done by the function \sfn{sienaBayes()}.
The following further information in this section is about ML estimation;
Bayesian estimation is as yet implemented only for multilevel network modeling
(see Section~\ref{S_sienaBayes}).

There are some restrictions to the application of ML estimation.
\begin{enumerate}
  \item The method of joiners and leavers (Section\ref{S_comp})
is not available.
  \item The following data configurations are not allowed:
\begin{enumerate}
\item tie variables in two consecutive waves changing from
    structural zero (code 10) to 1;
\item tie variables in two consecutive waves changing from
    structural one (code 11) to 0;
\item tie variables in three consecutive waves changing from
    structural zero (code 10) to \texttt{NA} to 1;
\item tie variables in three consecutive waves changing from
    structural one (code 11) to \texttt{NA} to 0;
\item and, for more than three consecutive waves, similar patterns
    with more NAs in between.
\end{enumerate}
For data sets with multiple periods, the
analysis using ML still is possible by arranging the data
as a multi-group data set (Section~\ref{S_multigroup}).
\end{enumerate}

For ML estimation, an important parameter for tuning the
algorithm is the so-called \textsf{Multiplication factor},
given in \sfn{sienaAlgorithmCreate()} as the argument \texttt{mult}.
This determines the number of Metropolis-Hastings steps taken
for simulating each new network.
The number of steps (sometimes called `sampling frequency' in the literature)
is the multiplication factor multiplied by the sum over dependent variables
of the distances between successive waves.
When this is too low, the
sequentially simulated networks are too similar, which will
lead to high autocorrelation in the generated statistics.
This leads to poor performance of the algorithm.
These autocorrelations are given in the output file. When some
autocorrelations are more than 0.4, it is good to increase the
\textsf{Multiplication factor}.
When the \textsf{Multiplication factor} is unnecessarily high,
on the other hand, computing time will be unnecessarily high.
The advice is to aim at values between 0.1 and 0.3 or 0.4.

A practical way to proceed is as follows.
For initial tuning of the multiplication factor, use the model that
is obtained as the default after creating the effects object,
with very few effects included. The reason for using this model
is the limited computation time and easy convergence.
If the highest autocorrelation is more than 0.3, increase the
multiplication factor (e.g., by making it twice as large;
which will also lead to a twice as long computation time)
and estimate the model again.
If the highest autocorrelation is less than 0.1, then decrease
the multiplication factor and estimate again.
Tune the multiplication factor until the highest autocorrelation
is between 0.1 and 0.3.
Then start with estimating the models of interest.
For other models the autocorrelations may change again, therefore
it still can be important later on to adapt the multiplication factor
to keep the highest autocorrelation less than 0.4.

Another parameter of the algorithm that sometimes needs tuning
(but less often than the multiplication factor)
is the \textsf{Initial value of the gain parameter}.
This determines the step sizes in the parameter updates in the iterative
algorithm.
It influences the stability and speed of moving of the algorithm.
A too low value implies that it takes very long to attain a
reasonable parameter estimate when starting from an initial
parameter value that is far from the `true' parameter estimate.
A too high value implies that the algorithm will be unstable,
and may be thrown off course into a region of unreasonable
(e.g., hopelessly large) parameter values.\\
When using the Method of Moments
(the default estimation procedure), it usually is unnecessary to change
this. In the ML case, when the autocorrelations are smaller
than 0.1 but the \texttt{t statistics for deviations from targets}
are relatively small (less than, say, 0.3) but do not all become
less than 0.1 in absolute value in repeated runs of the
estimation algorithm, then it will be good to decrease the
\textsf{initial value of the gain parameter}. Do this by dividing
it by, e.g., a factor 2 or a factor 5, and then try again
a few estimation runs.


\iffalse
\SI supplies three alternative MCMC algorithms for the
Bayesian estimation of the objective function parameters:
\begin{itemize}
\item[(1)] random walk M-H (default),
\item[(2)] autoregressive M-H,
\item[(3)] independence sampler.
\end{itemize}
The algorithms require the determination of the scale factor of
the so-called proposal distribution, which may affect the efficiency
of the algorithms and the accuracy of the results (for a given number of iterations).
It is recommended to make a short run with the default algorithm (1),
and then to make a longer run with algorithm (3);
and to choose as scale factor of the proposal
distribution $0$---which would be a pointless scale factor,
but which communicates to \SI that the user wishes to
leave the determination of the scale factor to the defaults provided in the algorithm,
which features an adaptive method for determining suitable
scale factors.
In the ideal case, the choice of algorithm does not affect the
results of primary interest, the parameter estimates---though the
efficiency of the algorithms and the accuracy of the results (for a
given number of iterations) may be affected.

Bayesian estimation gives rise to more results than the parameter
estimates printed in the output file.
The additional results can be best inspected by using {\tt R} and the
{\tt R} function {\tt siena}\_{\tt bayes} written by Michael
Schweinberger (see Section \ref{R_functions}).

\subsection{Supplementing {\tt R} functions}
\label{R_functions}

To examine the MCMC output of \SI for Maximum Likelihood (ML) and Bayesian estimation,
the {\tt R} functions {\tt siena}\_{\tt mle} and {\tt siena}\_{\tt bayes} can be used,
respectively,
which were programmed by Michael Schweinberger.
The {\tt R} functions input files generated by {\tt Siena} and output,
among other things,
trace plots and MCMC lag $1, \dots, 100$ autocorrelations of sampled entities
\citep[see][]{SchweinbergerSnijders07b, SchweinbergerSnijders07c},
and,
in the Bayesian case,
in addition $95\%$ posterior intervals, histograms, and Gaussian kernel density
estimates of the marginal posterior densities of the parameters.

The {\tt R} functions {\tt siena}\_{\tt mle} and {\tt siena}\_{\tt bayes}
can be downloaded from the website \\
{\tt http://stat.gamma.rug.nl/stocnet},
and can be used in {\tt R} as follows:

\begin{itemize}
\item[(1)] Load the {\tt R} function:
\begin{itemize}
\item[---] ML estimation: \verb@source("siena_mle.r")@.
\item[---] Bayesian estimation: \verb@source("siena_bayes.r")@.
\end{itemize}
\item[(2)] Call the {\tt R} function:
\begin{itemize}
\item[---] ML estimation: \verb@siena_mle(project_name, full_output,@

\verb@no_random_effects, no_actors)@.

\item[---] Bayesian estimation: \verb@siena_bayes(project_name, full_output,@

\verb@no_random_effects, no_actors)@.

\end{itemize}
\end{itemize}

The arguments are:
\begin{itemize}
\item[---] \verb@project_name@ (string): the name of the {\tt Siena} project
that is to be examined;
note that calling {\tt siena}\_{\tt mle} or {\tt siena}\_{\tt bayes} presumes
that {\tt Siena} carried out ML or Bayesian estimation of the
project \verb@project_name@, respectively.
\item[---] \verb@full_output@ ($0$ or $1$): $1$ indicates that the full output is desired,
while $0$ indicates that selected output is desired.
\item[---] \verb@no_random_effects@ (non-negative integer): the number of
actor-dependent weights (parameters) in the model.
\item[---] \verb@no_actors@ (positive integer): the number of actors.
\end{itemize}
Examples are provided by \verb@siena_mle("alcohol", 1, 3, 50)@ and\\
\verb@siena_bayes("alcohol", 1, 3, 50)@.

\fi

\subsection{Other remarks about the estimation algorithm}

\subsubsection{Conditional and unconditional estimation}
\label{S_cond}

\SI has two methods for MoM estimation and simulation:
\hypertarget{T_S_cond}{conditional and unconditional}. They differ
in the {\em stopping rule} for the simulations of the network
evolution. In unconditional estimation, the simulations of the
network evolution in each time period (and the co-evolution of the
behavioral dimensions, if any are included) carry on until the
predetermined time length (chosen as 1.0
for each time period between consecutive observation moments) has elapsed.

In conditional estimation, in each period
the simulations run on until a stopping
criterion is reached that is calculated from the observed data.
Conditioning is possible for each of the dependent variables
(network, or behavior), where `conditional' means `conditional on
the observed number of changes on this dependent variable'.

Conditioning on the network variable means running simulations
until the number of different entries between the initially
observed network of this period and the simulated network
\hypertarget{T_distance_stop}{is equal to the number} of entries
in the adjacency matrix that differ between the initially and the
finally observed networks of this period.

Conditioning on a behavioral variable means running simulations
until the sum of absolute score differences on the behavioral
variable between the initially observed behavior of this period
and the simulated behavior is equal to the sum of absolute score
differences between the initially and the finally observed
behavior of this period.

Conditional estimation is slightly more stable and efficient,
because the corresponding rate parameters are not estimated by the
Robbins Monro algorithm, so this method decreases the number of
parameters estimated by this algorithm.
% Therefore, it is the
% default for models that do not include any dependent behavior
% variables. For models including dependent behavior variables,
% the default estimation type is unconditional (because in most
% applications, there will be no straightforward choice for the
% conditioning variable).
\medskip

The choice between
unconditional and the different types of conditional estimation is
made in the \textsf{sienaAlgorithmCreate} function by setting the
\textsf{cond} parameter.
For data specifications with multiple dependent variables,
at most one dependent variable can be used for conditioning.
This choice is made dependent on the
\textsf{condvarno} and \textsf{condname} parameters in this function.

If there are changes in network composition (see
Section~\ref{S_comp}), only the unconditional estimation procedure
is available.

If there are a lot of structurally determined values (see Section~\ref{S_struct})
then unconditional estimation is preferable.


\subsubsection{Fixing parameters}
\label{S_fixingparameters}

\hypertarget{T_fix}{Sometimes an effect must be present in the
model, but its precise numerical value is not well-determined.}
E.g., if the network at time $t_2$ would contain only reciprocated
choices, then the model should contain a large positive
reciprocity effect but whether it has the value 3 or 5 or 10 does
not make a difference. This will be reflected in the estimation
process by a large estimated value and a large standard error, a
derivative which is close to 0, and sometimes also by
\hyperlink{T_convergence}{lack of convergence of the algorithm}.
(This type of problem also occurs in maximum likelihood estimation
for logistic regression and certain other generalized linear
models; \label{LargeFix} see \citet[section 1.6]{GeyerThompson92},
\citet{AlbertAnderson84, HauckDonner77}.)
In such cases this effect
should be fixed to some large value and not left free to be
estimated. This can be specified
by using the \textsf{setEffect} function with the
\textsf{fix = TRUE} option.



\subsubsection{Automatic fixing of parameters}
\label{S_fixing}

If the algorithm encounters computational
problems, sometimes it tries to solve them automatically by fixing
one (or more) of the parameters. This will be noticeable because a
parameter is reported in the output as being fixed without your
having requested this. This automatic fixing procedure is used,
when in phase 1 one of the generated statistics seems to be
insensitive to changes in the corresponding parameter.

This is a sign that there is little information in the data about
the precise value of this parameter, when considering the
neighborhood of the initial parameter values. However, it is
possible that the problem is not in the parameter that is being
fixed, but is caused by an incorrect starting value of this
parameter or one of the other parameters.

When the warning is given that the program automatically fixed one
of the parameter, try to find out what is wrong.

In the first place, check that your data were entered correctly
and the coding was given correctly, and then re-specify the model
or restart the estimation with other (e.g., 0) parameter values.
Sometimes starting from different parameter values (e.g., the
default values implied by the algorithm option
of ``standard initial values") will lead to a good result.
Sometimes, however, it works better to delete this effect
altogether from the model.

It is also possible that the parameter does need to be included in
the model but its precise value is not well-determined. Then it is
best to give the parameter a large (or strongly negative) value
and indeed
\hyperlink{T_fix}{require it to be fixed}
(see Section~\ref{S_model}).


\subsubsection{Required changes from conditional to unconditional estimation}

Even though conditional estimation is slightly more efficient than
unconditional estimation, there is one kind of problem that
sometimes occurs with conditional estimation and which is not
encountered by unconditional estimation.

It is possible (but luckily rare) that the initial parameter
values were chosen in an unfortunate way such that the conditional
simulation does not succeed in ever attaining the condition required
by \hyperlink{T_distance_stop}{its stopping rule} (see
Section~\ref{S_cond}).
The solution is either to use different
(perhaps standard) initial values or to go over to
unconditional estimation.


\subsection{Using multiple processes}
\label{S_multipleProcesses}
\begin{enumerate}
\item
  If multiple processors are available, then using
  multiple processes can speed up the estimation in \sfn{siena07},
  \sfn{sienacpp}, and \sfn{sienaGOF}.
  You can find out the number of processes possible by
\begin{verbatim}
library(parallel)
detectCores()
\end{verbatim}
  It is not advisable to utilize all available cores, because
  other processes also have to run. If you are not the only user
  of the machine, then there are obvious issues to be dealt with.

  There are some examples in the help page for \sfn{siena07}.
\item For estimation by Method of Moments (MoM), in Phases 1 and 3
  the simulations are performed in parallel. In Phase 2,
  multiple (viz., \texttt{nbrNodes} which is a parameter
  given in the call of \sfn{siena07()}) simulations are done with the same parameters,
  and the resulting statistics are averaged for the updating step in the
  Robbins Monro algorithm. The gain parameter is increased and the
  number of iterations in phase 2 reduced to take advantage of
  the increased accuracy of the update.\\
  When using the MoM, decrease in computation time will be somewhat less
  than proportional to the number of processes used, if this number is less than
  (say) 10; larger number of processes will have diminishing proportional
  returns.

\item For estimation by Maximum Likelihood (ML) and by \sfn{sienaBayes()},
  parallelization goes by period; for multi-group projects, period $\times$
  group. Therefore, for this type of estimation, the maximum meaningful number
  of parallel processes is \\ (number of waves -- 1) $\times$ (number of groups).

\item The parameters required to run all processes on one computer are fairly
  simple: in your call to \sfn{siena07}, set \sfn{nbrNodes} to the number of
  processes and \sfn{useCluster} and \sfn{initC} to TRUE. The \sfn{Model
    Options} screen also allows you to specify the number of processes, and
  will automatically set the other required parameters for you.

\item To use more than one machine is more complicated, but it can be done by
  using, in addition, the \sfn{clusterString} parameter.  The computers need to
  be running incoming \sfn{ssh}.
\item For machines with exactly the same layout of \R
  directories on each, simply set \sfn{clusterString} to a character vector of
  the names of the machines.
\item For other cases, e.g.\ using Macs alongside Linux,
  see the documentation for the package \sfn{parallel}.

\item \RS uses sockets for inter-process communication.
\item On Windows, sub processes are always started using \R scripts. On Linux
  and Mac there is an option available in \R version 2.14.0 or later via the
  code interface to \sfn{siena07} to ask for the sub processes to be formed by
  forking. See the help page for details.
\item Each process needs a copy of the data in memory. If there is insufficient
  memory available there will be no speed gain as too much time will be spent
  paging.
\item In each iteration the main process waits until all the other processes
  have finished. The overall speed is therefore that of the slowest process, and
  there should be enough processors to allow them all to run at speed.
\end{enumerate}




\newpage
\hypertarget{T_se}{
\section{Standard errors}
}
\label{S_se}

The estimation of standard errors of the MoM estimates requires
the estimation of derivatives,
which indicate how sensitive the expected values of the statistics
(see Section~\ref{S_algorithm}) are with respect to the parameters.
The derivatives can be estimated by two methods:
\begin{itemize}
\item finite differences method with common random numbers,
\item score function method.
\end{itemize}
The finite difference method is explained (briefly) in \citet{Snijders01},
the score function method was developed in \citet{SchweinbergerSnijders07a}
(where also the finite difference method is explained).
The score function method is preferable, because it is unbiased
and demands less computation time than finite differences,
although it requires more iterations in phase 3 of the estimation algorithm
(see Section~\ref{S_algorithm}).
It is recommended to use the score function method with
at least 1000 iterations (default) in phase 3.  For
published results, it is recommended to have 2000 or 4000 iterations in phase 3.

The method for estimating derivatives is set
by the \sfn{findiff} parameter and the number of iterations in phase 3
by the \sfn{n3} parameter, both in function \sfn{sienaAlgorithmCreate()}
that creates the object with specifications for the algorithm.

\subsection{Multicollinearity}

Multicollinearity means that the matrix that is inverted
to give the correlation matrix is ill-conditioned.
Correlations between parameter estimates
close to $\pm 1$ are the most usual signs of this.

If the parameter estimates are perfectly collinear
(standard errors of some parameters, or linear combinations
of parameters, being infinitely large), standard errors
are reported\footnote{Since version 1.1-285.}
as \texttt{NA} (the R term for "not available", missing).
This can happen depending on the data-model combination
(e.g., including the covariate-ego effect for a covariate with variance 0;
or including some effects that are collinear for any data set,
such as the combination of outdegree, transitive triplets,
outdegree activity, and balance effects --- see Snijders, 2005),
or on the combination of data, model and parameters (when a parameter
value was given or was reached where the model is not sensitive to some
parameter or combination of parameters).
The remedy here usually is to drop some of the effects.
\medskip

In cases with strong but not complete multicollinearity,
i.e., correlations between some parameter estimates
(or some of their linear combinations) being close but not equal to --1 or +1,
the estimated standard errors are less reliable.
 Estimates for these correlations
are given under the heading
\texttt{Covariance matrix of estimates (correlations below diagonal)}
in the output file, and in the \textsf{summary(...)} of the estimation results
(see Section~\ref{S_collinear}).
Strong collinearity may in practice lead to large differences
between the estimated standard errors,
and also to considerable differences between the parameter estimates,
when comparing the results produced by different estimation runs.
The remedy is to reduce the model to a more parsimonious one
by excluding non-significant effects of which the parameter
estimates are highly correlated with others.

Provisionally (until further experience has been collected),
the following may be a reasonable guideline.
High parameter correlations with the outdegree effect are not a
reason for worry, but high parameter correlations with other effects are
a reason for checking the stability of the estimated standard errors. The
threshold for finding a parameter correlation `too high' in this respect
can be quite high, such as 0.95 (or 0.90).
In cases of high parameter correlations, estimating the model twice
(or more) and considering the stability of the standard errors will be
a good way for seeing whether there are reasons for special caution.
If the standard errors are stable, then parameter correlations above
0.90 still can be acceptable -- in particular, when they are obtained
for parameters that are significantly different from 0 and of which
estimates as well as standard errors are stable across repeated runs of
the estimation algorithm.

\subsection{Precision of the finite differences method}

The implementation of the finite differences method is not
scale-invariant\footnote{The scales are determined by the
variable \sfn{z\$scale} in function \sfn{robmon}.
A better procedure would be to set the scale adaptively,
but the finite differences method is hardly ever used any more,
having been superseded by the score function method,
and therefore this improvement has not been effectuated.},
with the result that the standard errors produced by this method
are not very reliable if they are of the order of 0.02 or less.


\newpage
\section{Tests}
\label{S_test}

%Three
Two types of tests are available in \si.
\begin{enumerate}
\item $t$-type tests of single parameters can be carried out by
dividing the parameter estimate by its standard error.
Under the null hypothesis that the parameter is 0,
these tests have approximately a standard normal distribution.
These may also be called Wald-type tests.
Section~\ref{Waldtest} indicates how to construct multi-parameter tests
from the same principle.

\item Score-type tests of single and multiple parameters
      are described in Section~\ref{S_Scoretest}.

\iffalse
\item
In the maximum  likelihood estimation method
it is possible to request likelihood ratio tests.
The log likelihood ratio is computed
by bridge sampling \citep{GelmanMeng98, HandcockHunter06}.
This can be requested (a bit deviously) by the number of runs in phase 3
(defined in the  \hyperlink{T_S_options}{specification options}):
\begin{enumerate}
\item If the number of phase 3 runs is a multiple of 100 plus 1
      (e.g., 101, 501, etc.), then
      the log likelihood ratio is calculated comparing
      the estimates obtained with the standard initial values.
\item If the number of phase 3 runs is a multiple of 100 plus 2
      (e.g., 102, 502, etc.), then
      the log likelihood ratio is calculated comparing
      the estimates obtained with the initial values
      used in the current estimation procedure.
\end{enumerate}
The first option will be the most frequently useful, because it
yields log likelihood ratios which,
for different models fitted to a given data set,
all are comparable.
\fi
\end{enumerate}
In addition, there are procedures for assessing goodness of fit
as explained in Section~\ref{S_gof}.

\subsection{Wald-type tests}
\label{Waldtest}

Wald-type tests are based on the parameter estimates
and their covariance matrix.
Recall that the variances of the parameter estimates
are on the diagonal of this covariance matrix, and
the standard errors are the square roots of these diagonal
elements.

In Section \ref{S_fitcomp} we saw that, for a \textsf{sienaFit}
object \texttt{ans}, the estimates are given in
\texttt{ans\$theta}, the covariance matrix in \texttt{ans\$covtheta},
and the standard errors in \texttt{ans\$se}.
For testing the null hypothesis that component $k$ of the parameter
vector is 0,
\[
H_0 : \ \theta_k \,=\, 0 ,
\]
the $t$-test is based on
\begin{equation}
\frac{\hat\theta_k}{\se(\hat\theta_k)} \,=\,
   \texttt{ans\$theta[k] / ans\$se[k] } \ .  \label{t-stat}
\end{equation}
This can be easily calculated by hand from the \RS results.
\medskip

In some cases, however, the $t$-statistic (\ref{t-stat}) does not have
an approximate standard normal distribution under the null hypothesis,
so that this test is not appropriate.
This is the so-called Donner-Hauck phenomenon, named after
\citet{HauckDonner77}, who first drew attention to this phenomenon
in the case of logistic regression. It is discussed also in
\citet[section 1.6]{GeyerThompson92} and \citet{AlbertAnderson84}.
For logistic regression this phenomenon occurs when there is complete,
or almost complete, separation of the set of observed values
for the vector of predictor variables such that this set
consists of values in two half-spaces,
where for one of these half-spaces the
dependent variable always is 0, and for the other half-space always 1.
The data then indicates that the parameter
should be very large in absolute value, but not how large;
mathematically, the estimated value may be infinite.
The parameter as estimated by a practical algorithm
then will be not infinite but large, and the standard error
also will be large;
but the point is that ratio (\ref{t-stat}) does not need to be large,
and the Wald test may be non-significant while
the data flatly contradicts a hypothetical parameter value of 0.
In Section~\ref{S_fixingparameters} we proposed that in such cases,
it may be helpful to fix the parameter at some large value,
without estimating it.
Or, when it is being estimated and the
overall maximum convergence ratio is
small so convergence is judged as good, this estimate can be used,
but in these cases, not its standard error.
One possibility that then is available to test the significance
is to make a second estimation run in which the parameter is fixed at
the value 0, corresponding to the null hypothesis, and test
this null value using the score-type test of Section~\ref{S_Scoretest}.
See the script \texttt{RscriptSienaMultiple.R} on the \SI webpage
for an example.

\subsubsection{Multi-parameter Wald tests}

Now suppose that we wish to test another null hypothesis,
which can be represented as a linear constraint on $\theta$:
\[
H_0 : \ A\,\theta \,=\, 0 ,
\]
where $A$ is a $r \times p$ matrix, the dimension of $\theta$ being $p$.
For example, if $p$ = 5, for testing
\[
H_0 : \ \theta_2 \,=\, \theta_3
\]
we would use the matrix
\[
   A \,=\, (0, 1, -1, 0, 0) \ ;
\]
while for testing
\[
H_0 : \ \theta_2 \,=\, \theta_3 \,=\, 0
\]
if $p$ = 5, we would use the matrix
\[
   A \,=\, \left( \begin{array}{l} 0, 1, 0, 0, 0 \\
                                   0, 0, 1, 0, 0
                  \end{array} \right) \ .
\]
Then the function \sfn{Wald.RSiena()}
can be used to produce
the Wald-type test: the chi-squared value of the
test statistic, the number of degrees of freedom, and the $p$-value.
\iffalse
\begin{verbatim}
Wald.RSiena <- function(A, ans)
{
    if (is.vector(A))
    {
        A  <- matrix(A, nrow=1)
    }
    th     <- A %*% ans$theta
    covmat <- A %*% ans$covtheta %*% t(A)
    chisq  <- drop(t(th) %*% solve(covmat) %*% th)
    d.f.   <- nrow(A)
    pval   <- 1 - pchisq(chisq, d.f.)
    print(c(chisquare = chisq, df = d.f., pvalue = pval), digits=3)
}
\end{verbatim}
This is available as function \sfn{Wald.RSiena()}.
\fi

As an example, for the first two waves of the \textsf{klas12b} data
the following results were obtained,
collected in the \textsf{sienaFit} object \texttt{ans}.
\begin{small}
\begin{verbatim}
                              Estimate   Standard   t statistic
                                           Error
Rate parameters:
  0       Rate parameter      10.4625  ( 1.8917   )
  1. eval outdegree (density) -1.8760  ( 0.1883   )  0.0173
  2. eval reciprocity          1.1405  ( 0.3397   ) -0.0430
  3. eval transitive triplets  0.3703  ( 0.0639   ) -0.0425
  4. eval 3-cycles            -0.3373  ( 0.1238   )  0.0020
  5. eval primary              0.6718  ( 0.2125   ) -0.0619
  6. eval sex alter            0.1390  ( 0.2011   ) -0.0545
  7. eval sex ego              0.3165  ( 0.1938   ) -0.0055
  8. eval sex similarity       0.8197  ( 0.2126   ) -0.0298
\end{verbatim}
\end{small}
The output of \texttt{summary(ans)} also contains the
covariance matrix of the estimates:
\begin{footnotesize}
\begin{verbatim}
Covariance matrix of estimates (correlations below diagonal)
    0.035    -0.030    -0.009     0.011    -0.009     0.004    -0.003    -0.018
   -0.470     0.115     0.009    -0.031    -0.003    -0.009     0.002    -0.006
   -0.767     0.432     0.004    -0.006     0.003     0.001     0.000     0.005
    0.475    -0.731    -0.761     0.015    -0.005    -0.001     0.001    -0.005
   -0.218    -0.044     0.246    -0.180     0.045     0.004    -0.003     0.011
    0.096    -0.132     0.067    -0.058     0.090     0.040    -0.017     0.002
   -0.092     0.029    -0.017     0.037    -0.079    -0.437     0.038     0.009
   -0.442    -0.076     0.369    -0.172     0.234     0.054     0.208     0.045
\end{verbatim}
\end{footnotesize}
To test the null hypothesis that the three sex effects
(ego, alter, similarity) are zero,
the matrix $A$ is constructed as follows, and the Wald test then is requested.
\begin{small}
\begin{verbatim}
A       <- matrix(0, 3, 8)
A[1, 6] <- 1
A[2, 7] <- 1
A[3, 8] <- 1
Wald.RSiena(A, ans)
\end{verbatim}
\end{small}
The result is
\begin{small}
\begin{verbatim}
chisquare        df    pvalue
   16.556     3.000     0.000872
\end{verbatim}
\end{small}
The value $p < 0.001$ expresses strong evidence
that the network dynamics depends on sex.
\bigskip

The Wald test is frequently applied to test the null
hypothesis that several parameters are 0.
The extra work to define the matrix $A$ above can be automated
by using the following function \sfn{Multipar.RSiena()}.
\iffalse
\begin{verbatim}
Multipar.RSiena <- function(ans, ...)
   {
    p <- length(ans$theta)
    k <- length(c(...))
    A <- matrix(0, nrow=k, ncol=p)
    A[cbind(1:k,c(...))] <- 1
    Wald.RSiena(A, ans)
    }
\end{verbatim}
\fi
The test of the preceding example is then produced by the command
\begin{verbatim}
Multipar.RSiena(ans, 6, 7, 8)
\end{verbatim}

\subsubsection{Standard errors of linear combinations}

Sometimes there can be interest in a linear combination of parameters.
Suppose this is for a \sfn{sienaFit} object called \texttt{ans}.
The number of parameters is
\texttt{ans\$pp} which is the same as \texttt{length(ans\$theta)}.
This is the number of estimated parameters, excepting (if any) the rate
parameters used for conditioning in conditional estimation.
Let \texttt{a} be the vector with the coefficients of the linear combination.
Then
\begin{verbatim}
sum(a*ans$theta)
\end{verbatim}
 is the linear combination;
\begin{verbatim}
t(a) %*% ans$covtheta %*% a
\end{verbatim}
is the variance, and
\begin{verbatim}
sqrt(t(a) %*% ans$covtheta %*% a)
\end{verbatim}
is the standard error.



\subsection{Score-type tests}
\label{S_Scoretest}

The Wald test is based on the estimate for the parameter,
and thereby integrates estimation and testing.
Sometimes, however, it can be helpful to separate these two
types of statistical evaluation.
This is the case notably when estimation is instable, e.g.,
when a model is considered with rather many parameters given
the information available in the data set,
or when the precise value of the estimate is not determined
very well as happens under the Donner-Hauck phenomenon
treated in the previous section.
The score-type test gives the possibility of testing
a parameter without estimating it.

This is done using the generalized Neyman-Rao score test
that is implemented for the Method of Moments estimation method
in \si, following the methods of \citet{Schweinberger12}.
For the ML estimation method,
following the same steps produces the \citet{Rao47} efficient score test.
Since the name of ``score test'' is associated with
likelihood-based analysis as in \citet{Rao47}, the test
of  \citet{Schweinberger12} that is associated with the Method of Moments
is called ``score-type test''.

When using the score-type test, some model
is specified in which one or more parameters are restricted to some
constant, in most cases $0$ -- these constant values
define the null hypothesis being tested.
This can be obtained in \RS by appropriate choices in the effects dataframe.
Parameters can be restricted by
putting \texttt{TRUE} in the \sfn{fix} and \sfn{test} columns, and
the tested value in the \sfn{initialValue} column.
The function \sfn{setEffect} is available to do this.
For example, a score test for the evaluation effect of transitive ties
in a network can be requested as follows.
\begin{verbatim}
myeff <- setEffect(myeff, transTies, fix=TRUE, test=TRUE, initialValue=0.0)
\end{verbatim}

The score-type test then
proceeds by simply estimating the restricted model (not the unrestricted model,
with unrestricted parameters) by the standard \SI estimation algorithm.
The result of the score-type test is presented in the \sfn{summary}
of the estimation results (the \sfn{sienaFit} object obtained from
\sfn{siena07}) and also in the output file.
The $t$-ratios for convergence can be disregarded for the parameters
that are fixed and estimated by the score test, as convergence is not an issue
for these parameters.

It should be noted that using the \sfn{prevAns} option in \sfn{siena07}
overrides the initial values in the effects object,
so that using \sfn{siena07} for an effects object with
\texttt{fix = TRUE} for some of the effects, jointly with
the \sfn{prevAns} option, will lead to score-type tests
of hypothesized values as given by the  \sfn{prevAns} option.
Since the presentation of the results includes the
hypothesized value, there is no reason for doubt as to what
has been done. However, mostly this is not what is desired,
and therefore it usually will be preferable to proceed as follows.
First update the initial values using \sfn{updateTheta}, then
set the hypothesized value by \sfn{setEffect}, and then
carry out the estimation and score-type test by \sfn{siena07}.
The following is an example, assuming that an earlier
reasonable estimate was found in \sfn{sienaFit} object \texttt{myans0},
and the user wishes to use this as starting values.
\begin{verbatim}
myeff <- updateTheta(myeff, myans0)
myeff <- setEffect(myeff, transTies, fix=TRUE, test=TRUE, initialValue= 0)
myans1 <- siena07(estimationSettings, data=mydata, effects=myeff)
summary(myans1)
\end{verbatim}


The one-step estimates are given in the file \texttt{pname.out},
mentioned in Section~\ref{S_output}.
These are `quick and easy' estimates that are not totally
reliable, but that can be used as approximations of the unrestricted estimates
(that is, the estimates that would be obtained if the model were estimated
once again, but without restricting the parameter by \texttt{fix=TRUE}).
They are explained mathematically in \citet{Schweinberger12}.
Their computational advantage is based on the fact that they require simulations
only for parameter vectors where this parameter is fixed (usually, to 0;
but other values could be used, and this would be preferable if they are closer
to the resulting estimate).

\subsection{Example: one-sided tests, two-sided tests, and one-step estimates}
\label{example}

Suppose that it is desired to test the goodness-of-fit of the model
restricted by the null hypothesis that the reciprocity parameter is zero.
The following output may be obtained in the file \texttt{pname.out},
mentioned in Section~\ref{S_output}:


{\footnotesize
\begin{verbatim}
@2
Generalised score test <c>
--------------------------

Testing the goodness-of-fit of the model restricted by

 (1)   eval:  reciprocity                                 =  0.0000
________________________________________________

   c =   3.9982   d.f. = 1   p-value =   0.0455
   one-sided (normal variate):   1.9996
________________________________________________

One-step estimates:

l: constant network rate (period 1)                 6.3840
l: constant network rate (period 2)                 6.4112
eval:  outdegree (density)                          0.9404
eval:  reciprocity                                  1.2567
\end{verbatim}
}
To understand what test statistic {\tt <c>} is about, consider the case
where the network is observed at two time points, and let $R$
be the number of reciprocated ties at the second time point. Then it
can be shown that the test statistic is some function of
\[
  \mbox{Expected $R$ under the restricted model } - \mbox{ observed } R.
\]
Thus, the test statistic has some appealing interpretation in terms
of goodness-of-fit: when reciprocated ties do have added value for
the firms---which means that the reciprocity parameter is not 0,
other than the model assumes---then the deviation of the observed
$R$ from the $R$ that is expected under the model will be large
(large misfit), and so will be the value of the test statistic.
Large values of the test statistic imply low $p$-values, which, in
turn, suggests to abandon the model in favor of models incorporating
reciprocity.

The null distribution of the test statistic $c$ tends,
as the number of observations increases, to the chi-square
distribution, with degrees of freedom equal to the
number of restricted parameters. The corresponding $p$-value is
given in the output file.

In the present case, one parameter is restricted (reciprocity),
hence there is one degree of freedom {\tt d.f.\ = 1}. The value of
the test statistic {\tt c = 3.9982} at one degree of freedom
gives {\tt p = 0.0455}.
That is, it seems that reciprocity
should be included into the model and estimated as the other
parameters.

The one-sided test statistic, which can be regarded as normal variate, equals {\tt 1.9996}
indicating that the value of the transitivity parameter is positive.

In this example, the one-step estimate of reciprocity is {\tt 1.2567},
suggesting that this parameter is positive, which agrees with the one-sided test.

\subsubsection{Multi-parameter tests}

In the case where $K > 1$ model parameters are restricted, \SI
evaluates the test statistic with $K$ degrees of freedom. A low
$p$-value of the joint test would indicate that the
goodness-of-fit of the model is intolerable. However, the joint
test with $K$ degrees of freedom gives no clue as to what parameters
should be included into the model: the poor goodness-of-fit could be
due to only one of the $K$ restricted parameters, it could be due to
two of the $K$ restricted parameters, or due to all of them. Hence
\SI carries out, in addition to the joint test with $K$ degrees of
freedom, additional tests with one degree of freedom that test the
single parameters one-by-one. The goodness-of-fit table is as
follows:

{\footnotesize
\begin{verbatim}
@2
Generalised score test <c>
--------------------------

Testing the goodness-of-fit of the model restricted by

 (1)   eval:  covariate_ij (centered)                     =  0.0000
 (2)   eval:  covariate_i alter                           =  0.0000
 (3)   eval:  covariate_i similarity                      =  0.0000
________________________________________________

Joint test:
-----------
   c =  92.5111   d.f. = 3   p-value < 0.0001

(1) tested separately:
----------------------
 - two-sided:
   c =  62.5964   d.f. = 1   p-value < 0.0001
 - one-sided (normal variate):   7.9118

(2) tested separately:
----------------------
 - two-sided:
   c =  16.3001   d.f. = 1   p-value < 0.0001
 - one-sided (normal variate):   4.0373

(3) tested separately:
----------------------
 - two-sided:
   c =  23.4879   d.f. = 1   p-value < 0.0001
 - one-sided (normal variate):   4.8464
________________________________________________

One-step estimates:

l: constant network rate (period 1)                 7.4022
l: constant network rate (period 2)                 6.4681
eval:  outdegree (density)                         -0.4439
eval:  reciprocity                                  1.1826
eval:  transitive triplets                          0.1183
eval:  covariate_ij (centered)                      0.4529
eval:  covariate_i alter                            0.1632
eval:  covariate_i similarity                       0.4147
\end{verbatim}
}

In the example output, three parameters are restricted.
The joint test has test statistic $c$, which has under the
null hypothesis a chi-squared distribution with d.f.\ = 3.
The $p$-value corresponding to the joint test indicates
that the restricted model is not tenable. Looking at the separate
tests, it seems that the misfit is due to all three parameters.
Thus, it is sensible to improve
the goodness-of-fit of the baseline model by including all of these parameters,
and estimate them.

\subsection{Alternative application: convergence problems}
\label{alternative}

An alternative use of the score test statistic is as follows. When
convergence of the estimation algorithm is doubtful, it is sensible
to restrict the model to be estimated. Either "problematic" or
"non-problematic" parameters can be kept constant at preliminary
estimates (estimated parameters values). Though such strategies may
be doubtful in at least some cases, it may be, in other cases, the
only viable option besides simply abandoning "problematic" models.
The test statistic can be exploited as a guide in the process of
restricting and estimating models, as small values of the test
statistic indicate that the imposed restriction on the parameters is
not problematic.

\subsection{Testing differences between independent groups or periods}

Sometimes it is interesting to test differences between parameters estimated for
independent groups. For example, for work-related support networks analyzed in
two different firms, one might wish to test whether the tendency to
reciprocation of work-related support, as reflected by the reciprocity
parameter, is equally strong in both firms.  Such a comparison is meaningful
especially if the total model is the same in both groups, as control for
different other effects would compromise the basis of comparison of the
parameters.

If the parameter estimates in the two networks are $\hat\beta_a$ and $\hat\beta_b$,
with standard errors \textit{s.e}$_a$ and  \textit{s.e}$_b$, respectively,
then the difference can be tested with the test statistic
\begin{equation}
    \frac{\hat\beta_a  - \hat\beta_b}{\sqrt{(s.e_a)^2 + (s.e_b)^2}} \ ,
\end{equation}
which under the null hypothesis of equal parameters,
$\beta_a = \beta_b$, has an approximating
standard normal distribution.

The same method can be used for comparing estimates obtained from
separate analyses for different periods from a data set with three
or more waves. For example, if there are three waves and separate analyses
were done for period~1 (wave~1 -- wave~2) and  period~2 (wave~2 -- wave~3),
then $\hat\beta_a$ could be an estimate obtained for period~1 while
$\hat\beta_b$ would be the estimate for the same parameter for period~2.
This is allowed because the analysis of period~2 conditions on wave~2.


\newpage
\subsection{Testing time heterogeneity in parameters}
\label{S_timetest2}

We initially assume that $\beta$ does not vary over time, yielding a
\emph{restricted model}. Our data contains $|\mathcal{M}|$ observations, and we
estimate the restricted model the method of moments. We wish to test whether the
\emph{restricted model} is misspecified with respect to time
heterogeneity. Formally, define a vector of time dummy terms $\mathbf{h}$:
\begin{align}
h_k^{(m)}=\left\{
\begin{array}{ll}
1& \{m : w_m \in \mathcal{W}, m \neq 1\}\\
0& \mbox{~elsewhere~}
\end{array}
\right . ,
\end{align}
where $k$ corresponds to an effect included in the model.\footnote{The dummy
  $\delta_k^{(1)}$ is always zero so that period $w_1$ is (arbitrarily)
  considered the reference period.} The explanation here
is formulated for the network evaluation function,
but the principle can be applied more generally.
An \emph{unrestricted model} which allows
for time heterogeneity in all of the effects is considered as a modification of
\eqref{f_net}:

\begin{align}
f^{(m)}_{ij}(\mathbf{x})= \sum_k \Big(\beta_k + \delta_k^{(m)} h_k^{(m)}\Big)
           \, s_{ik}\big(\mathbf{x}(i \leadsto j)\big)
\label{eq:fmij2}
\end{align}
where $\delta_k^{(m)}$ are parameters for interactions of the effects
with time dummies. One way
to formulate the testing problem of assessing time heterogeneity is the
following:
\begin{align}
H_0:\delta_k^{(m)} = 0 & \mbox{~for all~} k,m \notag\\
H_1:\delta_k^{(m)} \neq 0 & \mbox{ for some } k,m .
\label{hyptest}
\end{align}

This testing problem can be addressed by the score test in a way that
no extra estimation is necessary. This method was elaborated and proposed by
\citet{Lospinoso2011} and is implemented in RSiena.  To apply the
test to your dataset, run an estimation in the usual way, e.g. as follows
(we specify \texttt{nsub=2, n3=100} just to have an example that runs
very quickly):
\begin{verbatim}
myalgorithm <- sienaAlgorithmCreate(nsub=2, n3=100)
mynet1      <- sienaDependent(array(c(s501, s502, s503), dim=c(50, 50, 3)))
mydata      <- sienaDataCreate(mynet1)
myeff       <- getEffects(mydata)
myeff       <- includeEffects(myeff, transTrip, balance)
ans2        <- siena07(myalgorithm, data=mydata, effects=myeff, batch=TRUE)
\end{verbatim}
and conduct the timetest through
\begin{verbatim}
## Conduct the score type test to assess whether heterogeneity is present.
tt2 <- sienaTimeTest(ans2)
plot(tt2, effects=1:2)
\end{verbatim}
If as a consequence of this analysis you wish to add time dummy terms,
this may be done via
\begin{verbatim}
myeff <- includeTimeDummy(myeff, recip, balance, timeDummy="2")
ans3  <- siena07(myalgorithm, data=mydata, effects=myeff, batch=TRUE)
\end{verbatim}
and testing again,
\begin{verbatim}
tt3 <- sienaTimeTest(ans3)
\end{verbatim}
and so on.

See \citet{Lospinoso2010b} for a walkthrough of the model selection process
for time dummy terms.


\newpage
\section{Simulation}
\label{S_sim}

The simulation option simulates the network evolution for fixed
parameter values. This is meaningful, e.g., for theoretical
exploration of the model, for goodness of fit assessment,
and for studying the sensitivity of the model to parameters.
Simulations are produced by the \textsf{siena07} function
also used for parameter estimation, but by calling it in
such a way that only Phase 3 is carried out
(see section~\ref{S_algorithm}).
This is done by requesting \texttt{nsub = 0} in
the model specification in function \textsf{sienaAlgorithmCreate}.
By also requesting \texttt{simOnly = TRUE} the calculation
of standard errors, which usually is not meaningful when
simulating without estimating, is suppressed.
\begin{verbatim}
sim_model  <-  sienaAlgorithmCreate( projname = "sim_model", cond = FALSE,
                      useStdInits = FALSE, nsub = 0 , simOnly = TRUE)
sim_ans    <-  siena07( sim_model, data = mydata, effects = myeff )
\end{verbatim}
Mostly it is more meaningful to do this for non-conditional simulation
(hence \texttt{cond = FALSE}), and a two-wave data set,
so that the simulations are totally determined
by the parameters and the first observation.
The second wave then must be present in the data set only
because \RS requires it for estimation,
and here we are using a function that is originally
meant for estimation.
Parameter values are obtained from the effects object,
because of the option \texttt{useStdInits = FALSE}.
If the name of the effects object is \texttt{myeff},
the current parameter values are obtained from requesting
\begin{verbatim}
myeff
\end{verbatim}
and different values can be specified by assigning the
desired value to the vector
\begin{verbatim}
myeff$initialValue[myeff$include]
\end{verbatim}

When artificial data sets are generated that have a close link to observed data,
the restriction that simulations follow the monotonicity patterns that
might be present in the data (see Section~\ref{S_monotone}) can be undesirable.
This restriction can be lifted by using \texttt{allowOnly = FALSE}
in the call of \sfn{sienaDependent} (see the help file for this function).
This parameter will then set any \texttt{uponly} and \texttt{downonly}
flags to \texttt{FALSE}, precluding monotonicity constraints.

\iffalse
When only 1 run is requested, an entire data set is generated
and written to file in \SI format and also in Pajek format.
%When exactly 10 runs are requested and the maximum likelihood option is chosen,
%then the sequence of changes
%from each observation to the next is written to file \textsf{{\em pname}.cha}
%in the format described in Section~\ref{S_lalgo}.
\fi

The statistics generated, which are the statistics
corresponding to the effects in the model,
can be accessed from the \textsf{sienaFit}
object produced by \textsf{siena07}.
Denoting the name of this object by \texttt{sim\_ans},
its component  \texttt{sim\_ans\$sf} contains the generated
deviations from targets. As discussed also in Section~\ref{S_fitcomp},
the statistics can be recovered from the deviations and the targets
as follows.
\begin{verbatim}
# To get the generated statistics without subtracting the targets,
# we have to add the targets to the deviations.
# To do this, repeated transposition t can be used:
stats       <-  t(t(sim_ans$sf) + sim_ans$targets)
# Calculate means and covariance matrix:
v           <-  apply(stats,2,mean)
covsf       <-  cov(stats)
# covsf is the same as sim_ans$msf
\end{verbatim}
Of course, any other distributional properties of the
generated statistics can also be obtained by the
appropriate calculations and graphical representations in \Rn.

\subsection{Accessing the generated networks}
\label{S_sims}

If one is interested in the networks generated, not only
in the statistics internally calculated,
then the entire networks can be accessed.
This is done by using the \textsf{returnDeps} option, as follows.
\begin{verbatim}
sim_ans <- siena07( myalgorithm, data = mydata, effects = myeff,
                    returnDeps = TRUE )
\end{verbatim}
The \texttt{returnDeps = TRUE} option attaches a list \texttt{sim\_ans\$sims}
containing all simulated networks
as edge lists to the \texttt{sim\_ans} object.
This uses rather a lot of memory.
Since here the default \texttt{n3 = 1000} was used, \texttt{sim\_ans} will be
a list of 1000 elements; e.g., the 568'th network generated
for wave 2 is given by
\begin{verbatim}
sim_ans$sims[[568]][[1]][[1]][[1]]
\end{verbatim}
The numbering is as follows: first the number of the simulation run (here,
arbitrarily, 568); then the number of the group as defined in
Section~\ref{S_multigroup} (1 in the usual case of single-group data structures);
then the number of the dependent variable (here 1, because it is supposed
that there only is a dependent network);
then the number of the wave minus 1 (here 1 because there are supposed to be
2 waves).
This type of information can be found out by requesting
\begin{verbatim}
str(sim_ans$sims[[568]])
\end{verbatim}

The help page for \textsf{siena07} contains an example for how to access the
generated networks in the case of ML estimation. Note that this is meaningful only in view
of the missing values of dependent variables for waves~2 and further, for which the
simulations in Phase~3 can be regarded as a kind of model-based imputation.

Section \ref{S_trafos} explains how such an edgelist can be
transformed to an adjacency matrix:
\begin{verbatim}
# Determine number of actors (normally the user will know this)
n <- length(mydata$nodeSets[[1]])
# create empty adjacency matrix
adj <- matrix(0, n, n)
# Make shorter notation for edge list
edges <- sim_ans$sims[[856]][[1]][[1]][[1]]
# put edge values in desired places
adj[edges[, 1:2]] <- edges[, 3]
\end{verbatim}

As an example, the following commands turn this list into
a list of edgelists according to the format of the \textsf{sna} package
\citep{Butts08}, and then calculate the maximum $k$-core numbers
in the networks.
This assumes that a one-mode network is being analyzed.
\begin{verbatim}
# First define a function that extracts the desired component
# from the list element,
# gives the column names required for sna edgelists,
# and adds the attribute defining the number of nodes in the graph,
# as required by sna.
make.edgelist.sna <- function(x, n)
                     {
                         x <- x[[1]][[1]][[1]]
                         colnames(x) <- c("snd", "rec", "val")
                         attr(x, "n") <- n
                         x
                     }
# Apply this function to the list of simulated networks
simusnas <- lapply(sim_ans$sims, make.edgelist.sna, 50)
# Define a function that calculates the largest k-core number in the graph
library(sna)
max.kcores <- function(x)max(kcores(x))
# Apply this function and make a histogram
mkc <- sapply(simusnas, max.kcores)
hist(mkc)
\end{verbatim}
\bigskip

Another possibility is to use the extractor functions,
\sfn{sparseMatrixExtraction}, \sfn{networkExtraction}, or \sfn{behaviorExtraction}
that are also used for \sfn{sienaGOF}.


\iffalse
For simulating networks and behavior, the output includes
the autocorrelation statistics known as Moran's $I$ and Geary's $c$.
For formulae and interpretation see, e.g., \citet[98--99]{Ripley81}.
These measure the extent to which the value of the variable
in question is similar between tied actors.
This similarity is expressed by relatively high values for Moran's $I$
and by relatively low values for Geary's $c$.
The null values, which are the expected values for variables
independent of the network, are given by $-1/(n-1)$ for Moran's $I$
and by 1 for Geary's $c$.

(The output of the descriptive statistics, which can be obtained
from \textsf{Siena02}, also contains Moran's $I$ and Geary's $c$,
computed for the observed data, together with their
null means and standard deviations.)
\fi


\subsection{Conditional and unconditional simulation}
\label{S_conds}

The distinction between conditional and unconditional simulation
is the same for the simulation as for
\hyperlink{T_S_cond}{the estimation option}
of \si, described in Section~\ref{S_cond}.
The choice between conditional and
unconditional simulation is
made in the \textsf{sienaAlgorithmCreate} function by setting the
\textsf{cond} parameter, possibly also the
\textsf{condvarno} and \textsf{condname} parameters.

If the conditional option is chosen, then the simulations
carry on until the desired distance is achieved on the dependent
variable used for conditioning.
For networks, the distance is the number of differences in the
tie variables; for behavioral variables, the sum
across actors of the absolute differences.
This is determined as the
distance between the consecutive networks (or, behaviors,
if such a variable is used for conditioning) given in the call of
\textsf{sienaDataCreate}.
The rate parameter for this dependent variable then
has no effect.

If the conditional simulation option was chosen (which is the
default) and the simulations do not succeed in achieving the
condition required by
\hyperlink{T_distance_stop}{its stopping rule}
(see Section~\ref{S_cond}), then the simulation is
terminated with an error message, saying
\emph{Unlikely to terminate this epoch}.
In this case, you are advised to change to unconditional simulation.

\iffalse
\newpage
\section[Options for model type, estimation and simulation]
        {Options for model type, estimation and simulation}
\label{S_options}

\hypertarget{T_S_options}{}
There are several options available in \si. The main options
concern the model type and the estimation procedure used.


\begin{enumerate}
\item There is a choice between conditional (1) and unconditional (0)
Method of Moments estimation. If there are dependent action variables, the default for
conditional estimation is to condition on the observed distance
for the network variable; but it then is possible also to condition
on the distances observed for the dependent action variables.\\
%In addition, there are options for maximum likelihood (2)
%and Bayesian (3) estimation; these are beginning to be documented.
%\item \hypertarget{T_modelcode}{The Model Code}.\\
%   This defines the Model Type and an associated output option.\\
%   In the longitudinal case, the meaning of this code is as follows.\\
%   Model Codes 10 or more give extra output for evaluating the fit of
%   the out-degree distribution and for the explained variation
%   \citet{Snijders04};\\
%   the integer Model Code in the unit position (i.e.,
%   Model Code itself if it is less than 10, and Model Code - 10 if the code is more than 10)
%   defines the Model Type defined in Section~\ref{S_modeltype}.\\[0.5ex]
\item The number of subphases in phase 2 of the estimation algorithm.\\
      This determines the precision of the estimate.
      Advice: 3 for quick preliminary investigations,
      4 or 5 for serious estimations.
\item The number of runs in phase 3 of the estimation algorithm.\\
      This determines the precision of the estimated standard errors
      (and covariance matrix of the estimates),
      and of the overall maximum convergence ratio
      and the $t$-values reported as diagnostics of the convergence.
      Advice: 200 for preliminary investigations when precise standard errors
      and $t$-values are not important,
      1000 for serious investigations,
      2000 to 4000 for estimations of which results are to be reported
      in publications.\\
      (These numbers can be twice as low if, instead of the
      new (from Version 2.3) default option of estimation by the
      Score Function method, the older method of
      Finite Differences is used. The latter method has runs
      that take more time, but needs fewer runs.)
%\item A constant used in other estimation procedures.\\
%      In the ML case, this is the multiplication
%      factor $r$ for the \hyperlink{T_runlength}{run length} used in the
%      MCMC algorithm.
\item The initial gain value, which is the step size in the starting
      steps of the Robbins-Monro procedure, indicated in
      \citet{Snijders01} by $a_1\,$.
\item The choice between standard initial values (suitable
estimates for the density and reciprocity parameters and zero
values for all other parameters) or
the current parameter values as initial values for estimating new
parameter values.
%\item The selection of the period for which a goodness-of-fit
%       on period homogeneity is to be carried out.
%\item The selection of the effect for which a goodness-of-fit
%       on actor homogeneity is to be carried out
%       (1 for the out-degree effect, 2 for the reciprocity effect);
%       if this is selected, a list of actors also has to be supplied.
\item A random number seed. If the value 0 is chosen, the program
      will randomly select a seed. This is advised to obtain truly
      random results. If results from an earlier run are to be
      exactly replicated, the random number seed from this earlier
      run can be used.
\item The method to estimate derivatives;
      0 is the older finite differences method
      %(this is the method used in
      %\SI versions 1 and 2, which has a bias);
      1 is the more efficient and unbiased
      method proposed by \citet{SchweinbergerSnijders07a};
      this is the preferred method. See Section~\ref{S_se}.
\end{enumerate}

\hypertarget{T_S_simoptions}
There is one option for simulations that can be chosen here.
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
\item The number of runs in the straight simulations.\\
      Advice: the default of 1000 will usually be adequate.
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
Depending on the choice for conditional or unconditional
estimation in the estimation options, also the simulations are run
conditionally or unconditionally.\medskip
\fi

\newpage
\section{Getting started}
\label{S_getting}

Note that there is a section `Getting started' in the Minimal
Introduction: Section~\ref{S_minsi1}. It may be best
to go through that section first.

The best way to get started is to download the \R scripts from the
\SI website and start reading and playing with them.

For carrying on and getting a first acquaintance with your own running
of the model, the data set collected by Gerhard van de Bunt
is useful; this data is discussed extensively in
\citet*{vanBunt99, vanBuntEA99},
and used as example also in \citet{Snijders01} and \citet{Snijders05}.
The data files are provided with the program
and at the \SI website. The digraph data files
used are the two networks {\sf vrnd32t2.dat}, {\sf vrnd32t4.dat}.
The networks are coded as 0 = unknown, 1 = best friend, 2 = friend,
3 = friendly relation, 4 = neutral, 5 = troubled relation, 6 = item
non-response, 9 = actor non-response.
Recode the network so that values 1, 2, and 3 are interpreted
as ties for the first as well as the second network, and values 6 and 9
are missing data codes (\texttt{NA}).

The actor attributes are in the file {\sf vars.dat}. Variables
are, respectively, gender (1 = $F$, 2 = $M$), program, and smoking
(1 = yes, 2 = no). See the \sfn{Data sets} tab at the
\SI website, and the references mentioned above for further
information about this network and the actor attributes.

Create the various required objects, using functions
\sfn{sienaDataCreate}, \sfn{getEffects}, and \sfn{sienaAlgorithmCreate},
as indicated in Chapters~\ref{S_InputData} and~\ref{S_Est}.
At first, leave the whole model specification as
it is by default (see Section \ref{S_modspec}):
a constant rate function, the out-degree effect, and
the reciprocity effect.

Then let the program estimate the parameters, using function \sfn{siena07}.
You will see a
screen with intermediate results: current parameter values, the
differences (`deviation values') between simulated and observed
statistics (these should average out to 0 if the current
parameters are close to the correct estimated value), and the
\hyperlink{T_quasiac}{quasi-autocorrelations} discussed in Section
\ref{S_Est}.

It is possible to intervene in the algorithm by clicking on the
appropriate buttons:
the algorithm may be restarted or terminated. In most cases
this is not necessary.

A little bit of patience is needed to let the machine complete its three
phases.
%How this depends on the data set and the number of parameters
%in the model is indicated in Section~\ref{S_timeuse}.
When the algorithm has finished, look at the results in the output file
or by the \sfn{print} or \sfn{summary} function of the
resulting \sfn{sienaFit} object. Check
that the overall maximum convergence ratio is small enough
(ideally less than .25).
If not, continue estimation with the \sfn{prevAns} option
as discussed in Section~\ref{S_ccheck}.
When satisfactory convergence has been obtained, make sense
of the results: for example, is the reciprocity parameter significant?

As further steps, include some extra effects. First candidates
are the transitive triplets effect or the gwesp effect, and any
effects that may follow from your theories about the investigated network
(see, e.g., Section~\ref{S_modspec});
you can find their \sfn{shortName},
needed to specify them, in Chapter~\ref{S_math},
where also the mathematical specifications are given.
When these new effects have been added, follow the same steps:
estimate, check convergence, if this is not yet satisfactory
estimate again with the new initial values, and interpret the
results when converged has been obtained.

To continue,  non-significant effects may
be excluded (but it is advised always to retain the out-degree and
the reciprocity effects) and other effects may be included,
as suggested in Section~\ref{S_modspec}.

\subsection{Model choice}
\label{S_model}

For the selection of an appropriate model for a given data set it
is best to start with a simple model (including, e.g., 2 or 3
effects), delete non-significant effects, and add further effects
in groups of 1 to 3 effects. Like in regression analysis, it is
possible that an effect that is non-significant in a given model
may become significant when other effects are added or deleted!

When you start working with a new data set, it is often helpful first
to investigate the main endogenous network effects (reciprocity,
transitivity, etc.) to get an impression of what the network
dynamics looks like, and later add effects of covariates.
The most important effects are discussed in Section~\ref{S_modspec};
the effects are defined mathematically
in Chapter~\ref{S_math}.

\iffalse
Here we give a more qualitative description.
\begin{enumerate}
\item The \emph{out-degree effect} which always must be included.
\item The \emph{reciprocity effect} which practically always must be included.
\item There is a choice of four network closure effects.
      Usually it will be sufficient to express the tendency to network
      closure by including one or two of these. They can be selected
      by theoretical considerations and/or by their empirical
      statistical significance.
      Some researchers may find the last effect (distances two)
      less appealing because it expresses network closure
      inversely.
      \begin{enumerate}
      \item[a.]
      \begin{minipage}[t]{.6\textwidth}
      The \emph{transitive triplets effect}, which is
               the classical representation of network closure by the number of transitive
               triplets.
               For this effect the contribution
               of the tie $i \rightarrow j$ is proportional to the total number
               of transitive triplets that it forms -- which can be transitive triplets
               of the type
               $\{i \rightarrow j \rightarrow h ;\ i \rightarrow h \}$
               as well as $\{i \rightarrow h \rightarrow j ;\ i \rightarrow j \}$;
      \end{minipage}
\hfill
\begin{minipage}[t]{.2\textwidth}
\linethickness{0.3pt}
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\end{minipage}
      \item[b.] The \emph{balance effect}, which may also be called \emph{structural equivalence
                with respect to outgoing ties}.
                This expresses a preference of actors to have ties to those other actors
                who have a similar set of outgoing ties as themselves.
                Whereas the transitive triplets effect focuses on how many same choices
                are made by ego (the focal actor) and alter (the other actor)
                --- the number of $h$ for which
                $i \rightarrow h$ and $j \rightarrow h $, i.e., $x_{ih} = x_{jh} = 1$
                where $i$ is ego and $j$ is alter --- ,
                the balance effect considers in addition how many the same
                non-choices are made --- $x_{ih} = x_{jh} = 0$.
      \item[c.] The \emph{transitive ties effect} is similar to the transitive
                triplets effect, but instead of considering for each other actor $j$
                how many two-paths $i \rightarrow h \rightarrow j $ there are,
                it is only considered whether there is at least one such indirect connection.
                Thus, one indirect tie suffices for the network embeddedness.
      \item[d.] The \emph{number of actors at distance two effect} expresses network closure inversely:
                stronger network closure (when the total number of ties is fixed)
                will lead to fewer geodesic distances equal to 2.
                When this effect has a negative parameter, actors will have a preference
                for having few others at a geodesic distance of 2 (given their
                out-degree, which is the number of others at distance 1);
                this is one of the ways for expressing network closure.
      \end{enumerate}
\item
      \begin{minipage}[t]{.7\textwidth}
      The \emph{three-cycles effect}, which can be regarded as
      generalized reciprocity (in an exchange interpretation
      of the network) but also as the opposite of hierarchy
      (in a partial order interpretation of the network).
      A negative three-cycles effect sometimes may be
      interpreted as a tendency toward hierarchy.
      The three-cycles effect also contributes to
      network closure.\\
      In a non-directed network, the three-cycles effect is identical
      to the transitive triplets effect.
      \end{minipage}
\hfill
\begin{minipage}[t]{.2\textwidth}
\linethickness{0.3pt}
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.9 2.559  to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\end{minipage}
\end{enumerate}
\fi

Approaches to model specification are presented in Chapter~\ref{S_modspec}
and in \citet*{SnijdersEA10b}.

When the distribution of the out-degrees is fitted poorly
(which can be inspected using the \sfn{sienaGOF} function
of Section~\ref{S_gof}), an improvement
usually is possible either by including non-linear effects of the
out-degrees in the evaluation function, or by other improvements of the model.
This totally depends on the data set at hand.
%, or by changing to Model Type 2
%(see Section~\ref{S_modeltype}).


\newpage
\section{Multilevel network analysis}
\label{S_mulev}

For combining \SI results of several independent networks,
there are four options.
(`Independent'  networks here means that the sets of actors are
disjoint, and it may be assumed that there are no direct influences
from one network to another.)
The first two options assume that the parameters
of the actor-based models for the different
networks are the same -- except
for the basic rate parameters and for
those differences that are explicitly modeled by interactions
with dummy variables indicating the different networks.
All but the second option require that the number of observations
is the same for the different networks.
These methods can be applied for two or more networks.
\medskip

In the following discussion,
the terms `networks' and `sub-projects' are used interchangeably.

\noindent
The four options are:
\begin{enumerate}
\item Combining the different networks in one large network,
      indicating by structural zeros that ties between the
      networks are not permitted.
      This is explained in Section~\ref{S_struct}.\\
      The special effort to be made here is the construction
      of the data files for the large (combined) network.
\item Combining different sub-projects
      into one \emph{multi-group} project,
      and analyzing this by \sfn{siena07}.
      The `sub-projects' are the same as the `different networks'
      mentioned here.
      This is explained in Section~\ref{S_multigroup}.\\
      A difference between options 1 and 2 is that the use
      of structural zeros (option 1) will lead to a default specification
      where the rate parameters are equal across networks
      (this can be changed by making the rate dependent upon dummy actor
      variables that indicate the different networks)
      whereas the multi-group option yields rate parameters
      that are distinct across different networks.\\
      In this option, the assumption is made that all parameters
      are the same for the various networks, except for the basic rate
      parameters; and except for explicitly specified interaction
      effects between variables depending on the sub-project, and other effects.

      Usually, option (2) is preferable to option (1).
\item Analyzing the different networks separately, without any assumption
      that parameters are the same but using the same model specification,
      and post-processing the output files by a meta-analysis
      using \textsf{siena08}.
      This is explained in Section~\ref{S_Siena08}.
\item Combining different sub-projects into one \emph{multi-group} project
      as in option (2), but analyzing this by \sfn{sienaBayes}.
      This is explained in Section~\ref{S_sienaBayes}.\\
      Here the assumption for the parameters is that all basic rate parameters
      may differ arbitrarily between the sub-projects;
      for the other parameters, some are identical and others vary randomly across
      sub-projects according to a multivariate normal distribution.
      The distinction between ``some'' and ``others'' here is made by
      the parameter \texttt{random} in function \sfn{setEffect()}.
\end{enumerate}
The first and second options will yield nearly the same results, with the
differences depending on the basic rate (and perhaps other) parameters
that are
allowed to differ between the different networks, and of course
also depending on the randomness of the estimation algorithm.
The second option is more `natural' given the design of \SI and
will normally run faster than the first.
Therefore the second option seems preferable to the first.

The third option makes much less assumptions because parameters are not
constrained at all across the different networks.
The fourth option is a middle ground between the first two and the third.
Therefore the arguments usual in statistical modeling apply:
as far as assumptions is concerned, options (3) and (4) are safer;
but if the assumptions are satisfied (or if they are a good approximation),
then options (1) and (2) have higher power and are simpler.
Option (3) requires that each of the different network data sets
is informative enough to lead to well-converged estimates;
this will not always be the case for small data sets,
and then option (4) may be preferable.

When the data sets for the different networks are not too small
individually,
then a middle ground might be found in the following way.
Start with option (3). This will show for which parameters there are
important differences between the networks.
Next follow option (2), with interactions between the sub-project dummies
and those parameters for which there were important between-network
differences; or option (4), where the randomness of the effects
is determined by these differences.

When the data sets for the different networks are quite small,
then one might start by option (2), and use \sfn{sienaTimeTest} to test
for which of the effects especially there is a large variation in
parameter values across the sub-projects;
next one could follow approach (4), determining the randomness of the effects
by the results about this variability.

In all cases, it is probably best to use an identical model specification
for the various groups. A problem that may occur especially if the groups
are small is that in some of the groups the change of the dependent variable
(network or behavior) may be upward only or downward only, which by default
then will be regarded by \RS as a constraint for the simulations,
as mentioned in Section~\ref{S_monotone}.
This leads to model differences that in most cases will be undesirable.
Therefore it is advisable in the original construction of the datasets
to use \texttt{allowOnly = FALSE} in the call of \sfn{sienaDependent}.

\subsection{Multi-group Siena analysis}
\label{S_multigroup}

The multi-group option `glues' several projects
(further referred to as \emph{sub-projects}) after each other
into one larger multi-group project.
These sub-projects
must have the same sets of variables of all kinds:
that is, the list of dependent networks, dependent behavioral variables,
actor covariates, and dyadic covariates must be the same
for the various sub-projects.
Also their names must be the same.
The number of actors
and the number of waves can be different, however.
These sub-projects then are combined into one project
where the number of actors is the largest of the number of
actors of the sub-projects, and the number of observations
is the sum of the observations of the sub-projects.
This is done by the function \textsf{sienaGroupCreate} which creates
a so-called \texttt{sienaGroupEffects} object, which is a list of
\texttt{sienaEffect} objects with some additional information.

As an example, suppose that three projects with names {\tt sub1}, {\tt sub2},
and {\tt sub3} are combined. Suppose {\tt sub1} has 21 actors and
2 observations, {\tt sub2} has 35 actors and 4 observations,
and {\tt sub3} has 24 actors with 5 observations.
Then the combined multi-group project has 35 actors and 11 observations.
The step from observation 2 to 3 switches from sub-project {\tt sub1}
to sub-project {\tt sub2}, while
the step from observation 6 to 7 switches from sub-project {\tt sub2}
to {\tt sub3}. These switching steps do not correspond to simulations
of the actor-based model, because that would not be meaningful.

The different sub-projects are considered to be unrelated
except that they have the same model specification,
the same variable names, and the same parameter values.
It is important to check that this is a reasonable assumption.
One aspect of this is by looking at the descriptives for change
produced by \textsf{print01Report}, and checking that the
tendencies in the dependent variable or variables, upward/stable/downward,
are not too different between the sub-projects.
The \textsf{sienaTimetest} function can be used for
formally testing this assumption.
Moderate violations ($p$-values larger than 0.01) will probably
be acceptable in the sense that the combined results
still are a meaningful aggregate, strong violations are not acceptable
and should be remedied by dropping some of the sub-projects or by
including an interaction term.

Given the potentially large number of periods that can be implied
by the multi-group option, it probably is advisable,
when using Method of Moments estimation, to use
the conditional estimation option.

In multi-group projects, individual covariates are centered by subtracting
the overall mean (across all groups), but dyadic covariates are centered
by subtracting the within-group means.



\subsection{Meta-analysis of Siena results}
\label{S_Siena08}

The function \textsf{siena08} is a meta-analysis method for \si.
It combines estimates for a common model
   estimated for several data sets,
   that must have been obtained earlier.
   This function combines
   the estimates in a meta-analysis or multilevel analysis
   according to the methods of \citet{SnijdersBaerveldt03},
   and according to a Fisher-type combination of one-sided $p$-values.

The function  \textsf{siena08} takes as input the \textsf{sienaFit}
objects produced by separate runs of  \textsf{siena08}.
These \textsf{sienaFit} objects must have exactly the same model
specification and the same names of all variables; but it is allowed
that there are differences with respect to parameters being fixed
and perhaps tested. To get the same names of variables, the
variables must be renamed in the call of \textsf{sienaAlgorithmCreate};
an example is in script \textsf{RscriptMultipleGroups.R} at the \SN website.
If in some but not all groups a dependent variable has only upward or
only downward changes, the automatic restriction to follow this pattern also
in the simulations (see Section~\ref{S_monotone}) must be lifted,
because this would make the model specifications different.
This must be done already in the original construction of the datasets that
then later are combined by \textsf{siena08},
by using \texttt{allowOnly = FALSE} in the call of \sfn{sienaDependent},
as mentioned in Section~\ref{S_monotone}.

If there are some parameters that cannot be estimated for some of the data sets
(e.g., the effect of sex in a one-gender school; or because of
near-multicollinearity), these parameters must still be included
in the model for those data sets, but the parameters can be fixed to 0
(and perhaps tested by a score-type test).
\medskip

Each parameter in the model is treated separately
in the meta-analysis, without taking account of the
dependencies between the parameters and their estimates.
Denote the number of combined data sets by $N$.
If we denote a given parameter (e.g., the
coefficient of the reciprocity effect) by $\theta$,
then the \emph{true parameter values} for the
$N$ data sets are denoted $\theta_1, \theta_2, \ldots, \theta_N$,
while their \emph{estimates} are denoted
 $\hat\theta_1, \hat\theta_2, \ldots, \hat\theta_N$.
 \bigskip

The package \sfn{metafor} can also be used for meta-analysis.
This package is extensively documented in \citet{Viechtbauer2010}.
In terms of \citet{Viechtbauer2010}, \sfn{siena08()} follows a
random effects approach and presents the Hedges estimator
which is the procedure of \citet{SnijdersBaerveldt03}, proposed
by \citet{Cochran54}; it also presents the maximum likelihood
estimator.
In \citet{Viechtbauer2005}, an extensive study is made comparing
the various approaches, and it turns out that the comparison is
not unequivocal. His recommendation, however, is to use the
restricted maximum likelihood estimator.
Since this is not implemented in \sfn{siena08()}, this recommendation
suggests that one should rather use  \sfn{metafor}, with the
option \texttt{method = "REML"}.

Still another possibility is offered by the package \sfn{mvmeta}
\citep{Gasparrini2012}.
This was used in conjunction with \SI by
\citet{An2015}, who showed how to use this for incorporating
group-level explanatory variables, using a fixed effects
as well as a random effects approach, the latter with
restricted maximum likelihood.

\subsubsection{Meta-analysis directed at the mean
               and variance of the parameters}

In this meta-analysis it is assumed that the data sets can be
regarded as a sample from a population -- i.e., a population
of dynamic networks -- and accordingly the true parameters
$\theta_j$  are a random sample from a population.
If the number of data sets is small, e.g., less than 20,
and especially if this number is less than 10,
this assumption is not very attractive from a practical point of view,
because the sample then would be quite small
so the information obtained about the population is very limited.

The mean and variance in this population of parameters are denoted
\begin{align*}
 \mu_\theta &= \E\, \theta_j \ , \\
 \sigma^2_\theta &= \var\, \theta_j \ .
\end{align*}
Each of these parameters must have been estimated in a run of
\textsf{siena07}, yielding the estimate $\hat\theta_j$,
which is the true parameter plus a statistical error $E_j$:
\[
\hat\theta_j \,=\, \theta_j + E_j \ .
\]
The standard error of this estimate is denoted by $s_j$.

For each of the parameters $\theta$, the function \textsf{siena08}
estimates the mean $\mu_\theta$
and the variance $\sigma^2_\theta$ of the distribution of $\theta$,
and tests several hypotheses concerning these `meta-parameters':
\begin{enumerate}
\item Test $H_0^{(0)}:\ \mu_\theta = \sigma^2_\theta = 0$
                       (all $\theta_j = 0$),
                      i.e., effect $\theta$ is nil altogether.\\
      This is done by means of a chi-squared test statistic $T^2$
      with $N$ d.f.
\item Estimate  $\mu_\theta $.
\item Test $H_0^{(1)}:\ \mu_\theta = 0$.\\
      This is done by means of a standard normal test statistic
      $ t_{\mu_\theta}$,
      being the ratio of the estimate for $\mu_\theta $
      to its standard error.
\item Test $H_0^{(2)}:\ \sigma^2_\theta = 0$,
                     i.e., $\theta_j = \mu_\theta$ for all $j$. \\
      This is done by means of a chi-squared test statistic $Q$
      with $N-1$ d.f.
\item Estimate  $\sigma^2_\theta$ .
\end{enumerate}
Two approaches are followed and presented in the output.
The first is an iterative weighted least squares method based on
\citet{Cochran54} and \citet{SnijdersBaerveldt03}.
The second is a likelihood-based method under the assumption
of normal distributions: the estimators are maximum likelihood
estimators; the associated confidence intervals
are based on profile likelihoods, and therefore will be
asymmetric. The reported
$p$-values for the population mean (hypothesis $H_0^{(1)}$)
are based on the $t$ distribution with $N-1$ d.f.
In all cases, it is possible that some of the data sets $j$ are
dropped for some of the parameters because the standard error $s_j$
is too large (see below);
in that case, the number $N$ used here
is the number of data sets actually used for the
parameter under consideration.

For both of these two approaches,
it is assumed that the true deviations $\theta_j - \theta$
and the random errors $E_j$ are uncorrelated.
This is not always a plausible assumption; Fisher's combination,
mentioned below, does not make this assumption.
The plots of estimates versus standard errors, produced
by using \textsf{siena08} and following it up by
\textsf{plot.sienaMeta}, can be used as information about the
plausibility of this assumption.

For testing the hypotheses mentioned here, it is also assumed that,
given the true parameter values $\theta_j$, the
estimates $\hat{\theta}_j$ are approximately normally distributed
with mean $\theta_j$ and variance $s^2_j$.
This is often a reasonable assumption.

The likelihood-based methods also assume that the true values
$\theta_j$ are normally distributed in the population.
If this is a reasonable approach, the likelihood-based methods
are preferable.
A disadvantage of the iterative weighted least squares method
is that results are possible
where the outcome of the test of $H_0^{(2)}$ is significant
at a usual level of significance,
i.e., $\sigma^2_\theta$ is thought to be positive, whereas
the estimate is $\hat\sigma^2_\theta = 0$.
This  potential inconsistency is possible because the test
and the estimator in this approach are not directly related
\citep[cf.][]{SnijdersBaerveldt03}.
The likelihood-based method does not suffer from this problem
because the maximum likelihood estimate always is contained
in the confidence interval based on the profile likelihood.
\bigskip

There may be reasons to distrust the estimates which are
large with also a large standard error. (This is known as the Donner-Hauck
phenomenon in logistic regression, discussed in
Section~\ref{S_fixingparameters}.)
Unfortunately, it is impossible to say in
general what is to be regarded as a large standard error.
A threshold of 4 or 5 for the standard error often is reasonable
for most effects; if a tested
parameter has a standard error larger than 4, then it is advisable to redo
the analysis in a specification where this parameter only is fixed to 0 and a
score test is carried out for this parameter. However, for some effects, in
any case for the "average similarity" effect for behavior dynamics,
parameters and standard errors tend to be larger, and a larger threshold
(e.g. 10) is appropriate. The same holds for effects of covariates with small
variances (less than .1).

An alternative, probably better, for the estimation of standard errors
is by using a non-parametric bootstrap confidence interval. For example, the
adjusted percentile ($BC_a$) method
\citep[][Chapter 5]{Efron1987,DavisonHinkley1997}
which is available in function \texttt{boot.ci} in \R package \texttt{boot}.


\subsubsection{Meta-analysis directed at testing the parameters}

Another method for combining the various data sets,
which does not make the assumption
that the parameters are a sample from a population and also
makes no assumptions of absence of correlation\footnote{This correlation
is defined for the population of networks, and if the population
does not exist then also the correlation is not defined.}
between the true deviations $\theta_j - \theta$
and the random errors $E_j$,
is based on Fisher's method for combining independent $p$-values;
the principle of this combination method of \citet{Fisher32} is described in
\citet{HedgesOlkin85}    and (briefly) in \citet[Chapter 3]{SnijdersBosker12}.

This principle here is applied in a double test:
\begin{enumerate}
\item for detecting if there are any networks with a positive parameter value,
         the null hypothesis tested is\\
       $H_0 :$   For all networks, the value of this parameter
            is zero or less than zero;\\
            with the alternative hypothesis;\\
        $H_1 :$
             For at least one network, the value of this parameter
             is greater than zero;
\item for detecting if there are any networks with a negative parameter value,
         the null hypothesis tested is\\
            $H_0 :$ For all networks, the value of this parameter
                  is zero or greater than zero;\\
            with the alternative hypothesis\\
            $H_1 :$ For at least one network, the value of this parameter
                   is less than zero.
\end{enumerate}
      For each of these combined tests, the $p$-value is given.
      In the output these are denoted, respectively,
      as `combination of right one-sided $p$-values' and
      `combination of right one-sided $p$-values'.

      It is advisable to use for each the significance level of $\alpha/2$
      (e.g., 0.025 if $\alpha = 0.05$) which yields an overall combined test
      at significance level $\alpha$.
      Note that four different overall results are possible.
      Indicating the right-sided and the left-sided $p$-values
      by $p_r$ and $p_l$,
      respectively, these possible results are:
      \begin{enumerate}[label=(\emph{\alph*})] % package enumitem
         \item $p_r >   \alpha/2, \  p_l >   \alpha/2$:\\
         No evidence for any nonzero parameter values;
         \item $p_r \leq \alpha/2, \ p_l >   \alpha/2$:\\
         Evidence that some networks have a positive parameter value,
         no evidence for any negative parameter values;
         \item $p_r >   \alpha/2, \ p_l \leq \alpha/2$:\\
         Evidence that some networks have a negative parameter value,
         no evidence for any positive parameter values;
         \item $p_r \leq \alpha/2, \ p_l \leq \alpha/2$:\\
         Evidence that some networks have a negative parameter value,
         and some others have a positive parameter value.
\end{enumerate}
      If all networks have a zero true parameter value,
      i.e., under the combined null hypothesis that
      $\theta_j = 0$  for all $j$,
      the probability of result (1) is less than or equal to $\alpha$;
      this is the way in which this combined test respects the
      overall probability of an error of the first kind.

\iffalse

The result of the score test can be added as follows to the
Fisher-combination results of Siena08:
<ol>
<li> if the one-step estimate is positive, calculate
     c_r = -2*ln(0.5*p) and c_l = -2*ln(1 - 0.5*p)
     where p is the p-value obtained for the score test;<br>

     (the "*" symbol denotes multiplication)<br>
     (it may be noted that these are chi-squared values with d.f. = 2);
<li> if the one-step estimate is negative, calculate
     c_r = -2*ln(1.0 - 0.5*p) and c_l = -2*ln(0.5*p)
     where p is the p-value obtained for the score test;
<li> add c_r to the right-sided chi-squared value
     and c_l to the left-sided chi-square value reported by Siena08;
<li> these are again chi-squared values, but the degrees of freedom
     are 2 higher.
</ol>
A disadvantage of this procedure is that if there are two or more
tested parameters having large standard errors, this procedure
including the estimation
must be carried out SEPARATELY for each tested parameter,
because in testing each parameter
you wish to control for all other effects and therefore not fix any other
effects to 0.
\fi


\subsubsection{Contrast between the two kinds of meta-analysis }

To understand the contrast between the method following the Cochran approach
for inference about a population of networks,
and the Fisher approach for combining independent tests, the following
may be helpful.
Inferring about a population always adds some uncertainty;
this is more serious when the sample size (here: number of combined networks)
is smaller.
In the extreme case, consider the combination of $N=2$ networks,
with estimates $\hat\theta_1 = 1$, standard error $s_1 = 0.1$,
and $\hat\theta_2 = 5, s_2 = 0.1$.
Then for both of the groups the $t$-statistic $\hat\theta_j/s_j$ is very large,
leading to the conclusion that parameters $\theta_1$ and $\theta_2$
are very likely to be positive.
This will lead to a significant result for Fisher's combination of tests.
On the other hand, the mean in the population of networks, given that
there is available a sample of size as low as $N=2$, cannot be determined with
any degree of precision, so the confidence interval for this mean $\mu_\theta$
will be huge, and the result for testing the null hypothesis
$H_0^{(1)}$ will not be significant.
However, the results for testing $H_0^{(0)}$ and $H_0^{(2)}$
will be significant.


\subsection{Random coefficient multilevel Siena analysis}
\label{S_sienaBayes}

  The function \sfn{sienaBayes} is for Bayesian estimation of one group or
  of multiple groups all having the same number of waves and the same
  model specification.
  The parameters -- excepting the basic rate parameters -- can be either
  randomly varying between groups according to a multivariate
  normal distribution, or non-varying and constant across groups.
  The difference is made by setting the parameter \texttt{random} in
  the function \sfn{setEffect}. The default is that only the out-degree (density)
  effect is randomly varying, but it is advisable to specify
  this for a larger set of effects.
  Specifying it for too many effects may, however, lead to unstable estimation.

  The analysis is done by a Bayesian estimation method.
  For the groupwise parameters normal distributions are assumed with conjugate
  priors. The prior distribution for the basic rate parameters is determined
  in a data-dependent way. For the non-varying parameters,
  a flat prior is assumed.

  The procedure consists of three parts: initialization, warming,
  main phase.
  \begin{enumerate}
  \item
  In the initialization phase, initial parameter values and the proposal
  covariance matrix for Metropolis-Hastings steps for groupwise parameters
  are obtained from, first, Method of Moments estimation of a parameter vector
  assumed to be the same across the groups (in a multi-group estimation),
  with step size \sfn{initgainGlobal},
  followed by one subphase of the Robbins-Monro algorithm for Method of
  Moments estimates for the groups separately, with step size \sfn{initgainGroupwise}.
  The proposal covariance matrices then are scaled, in the
  function \sfn{improveMH}, to achieve about 25 out of 100 acceptances of
  Bayes proposals after single MH steps.
  \item
  After initialization and scaling of the proposal covariance matrices,
  a warming phase is done of \sfn{nwarm} Bayesian proposals
  each with a number of MH steps, followed again by the function \sfn{improveMH}.
  \item
  Finally \sfn{nmain} repeats of \big(\sfn{nrunMHBatches} of a
  number of MH steps sampling chains, plus \sfn{nSampVarying} MH steps
  sampling the varying parameters ($\theta_j$) plus \sfn{nSampConst} MH steps
  sampling the non-varying parameters ($\eta$) plus one Gibbs
  step sampling the global mean and covariance matrix of the varying parameters
  ($\mu$ and $\Sigma$)\big) are performed.
  In the warming as well as the final phase, the number of MH steps is
  determined by parameter \sfn{mult} (``multiplication factor'')
  in the call of \sfn{sienaAlgorithmCreate} that created the algorithm object.
\end{enumerate}
  The function \sfn{sienaBayes} is time-consuming. When starting to use it, it is advisable
  to start with low values of \sfn{nmain} to explore computing time.
  When the procedure seems to diverge, and for very small groups, it is
  advisable to use smaller values of the parameters \texttt{initgainGlobal}
  and \texttt{initgainGroupwise}; and perhaps \texttt{reductionFactor}.


\subsubsection{Which data sets to use for sienaBayes}
\label{S_sBData}

\sfn{sienaBayes} uses as data set a \sfn{sienaGroup} object with 2 or more groups.
The number of waves should be the same for all groups.

The following data configurations are not allowed for groups
included in \sfn{sienaBayes} estimation:
\begin{enumerate}
\item tie variables in two consecutive waves changing from
    structural zero (code 10) to 1;
\item tie variables in two consecutive waves changing from
    structural one (code 11) to 0;
\item tie variables in three consecutive waves changing from
    structural zero (code 10) to \texttt{NA} to 1;
\item tie variables in three consecutive waves changing from
    structural one (code 11) to \texttt{NA} to 0;
\item and, for more than three consecutive waves, similar patterns
    with more NAs in between.
\end{enumerate}
To use data sets including such patterns for \sfn{sienaBayes},
you will have to make minimal changes to the data set
so as to avoid these patterns.
For example, replace sequences 10-1 by \texttt{NA}-1,
and 10-\texttt{NA}-1 by \texttt{NA}-\texttt{NA}-1.
An example script to make such replacements is at
{\small{\url{http://www.stats.ox.ac.uk/~snijders/siena/changeForbiddenChanges.R}}}.

\sfn{sienaBayes} should be possible for groups as small as 5 actors.
A restriction (maybe to be lifted later) is that the networks must not be
empty at any wave; and consecutive waves of networks must not be identical
(in other words, all Jaccard indices should be strictly less than 1).

Be prepared for long computation times. The reason is that likelihood-based
computations are used (as distinct from the Method of Moments approach).
If all individual groups have enough information for good estimation by
the Method of Moments according to the intended model,
the use of \sfn{siena07()} with the (default) Method of Moments, followed by a
meta-analysis by means of \sfn{siena08()} or \sfn{metafor}, may be preferable.

It is advisable to first do a multi-group analysis of the same model,
followed by a \sfn{sienaTimeTest}, to get an initial understanding of where problems
might occur. You may then later use the result for the \texttt{prevAns}
parameter of \sfn{sienaBayes}.


\subsubsection{Model specification}

Non-constant rate functions currently are not supported in \sfn{sienaBayes}.

The extra part of model specification for \sfn{sienaBayes},
compared to \sfn{siena07},
is that it is required to specify which parameters are
randomly varying from group to group, and which are fixed across groups.
The specification of fixed vs.\ randomly varying
for the other parameters is done in the function
\sfn{setEffect}, by its parameter \texttt{random}.
To be able to see which of the effects are specified in this way,
please have a look at the help page for \sfn{print.sienaEffects}:
\begin{verbatim}
?print.sienaEffects
\end{verbatim}
and note the parameters \texttt{includeRandoms}
and \texttt{dropRates}, which are helpful especially for
random coefficient multilevel modeling.
Requesting \texttt{includeRandoms=TRUE} will show the column indicating
which effects are random; \texttt{dropRates= TRUE} omits the
rows with rate effects, which can be a lot of superfluous information
that perhaps you do not want to see.

The exception to the rate parameters being always randomly varying
is that they may be fixed --- in which case all of them need to be fixed,
and input parameter \\
\texttt{priorRatesFromData} needs to be set to --2.
\medskip

There currently is little advice about which effects to specify
as randomly varying.
The basic issues are the following.
\begin{description}
\item[\emph{interest:}] is variability of the effect across groups
   a primary part of the research question?\\
   (Usually not; such research questions about variability
   are of a quite secondary nature.)
\item[\emph{knowledge:}] is there prior knowledge about whether
   effects differ between groups?\\
   (Usually not. It is possible to first do a multi-group analysis of the same model,
   followed by a \sfn{sienaTimeTest}, and specify those effects as randomly
   varying for which the time heterogeneity is largest according to the
   groupwise results.)
\item[\emph{misspecification:}] if it would be erroneously assumed
    that the effect is fixed across groups, would this affect
    the parameter estimates of primary interest?\\
    (About this we have little general knowledge; it can be tried out
    by running estimations for different specifications of this
    part of the model.)
\item[\emph{amount of information:}] which specification will
     use the information in the data most efficiently?\\
     (Here finally we do have a provisional answer. Assuming that an effect is fixed
     across groups will give a smaller uncertainty ---posterior standard
     deviation, interpreted as standard error--- in the estimated parameter
     than assuming it varies randomly;
     cf.\ Section~\ref{S_sienaBayesInterpret}.
     This will be the more so as the number of
     groups is smaller. Therefore, for the coefficients for which
     there is no strong prior knowledge that they are variable across groups,
     and which are tested as a primary issue for answering the research question,
     from the point of view of statistical power
     it is advisable to specify that they are fixed.)
\end{description}


\subsubsection{How to enter your data in sienaBayes}

See the example at the bottom of the \sfn{sienaBayes} help page for how a
\sfn{sienaGroup} object can be created and used.
If some but not all of the Siena data objects combined in the \sfn{sienaGroup} have
periods where changes are only upward or only downward,
it will be necessary to use \texttt{allowOnly=FALSE} in the call of
\sfn{sienaDependent}; see the help page for \sfn{sienaDependent}.
The scripts \texttt{RscriptListGroups.R} and \texttt{RscriptMultipleGroups.R}
give further examples and explanation for creating \sfn{sienaGroup} objects.

If you have a large number of groups (more than 30), try first
with a smaller number of groups (10-20). If you need or wish to
make a selection of groups, select the one with few or no missing data and
with Jaccard coefficients at least 0.30.

\subsubsection{How to choose the parameter settings for sienaBayes}
\label{S_sienaBayesParameters}

It may be good to have an initial try run with\\
\texttt{nwarm=5, nmain=10, nrunMHBatches=5, nImproveMH=20}
(for speed) and \texttt{silentstart = FALSE} (for information about the
initialization phase), and then \sfn{print} the result.
This will give information about the results of the initialization
phase and about computing time. If some of the groups have some very
high estimated rate parameters, you should either drop those groups
or decrease the value of \texttt{initgainGroupwise}.
The new value could be, e.g., 0.005 or 0.001 or 0.0. With the lower value
of \texttt{initgainGroupwise}, dropping the groups concerned may be unnecessary,
so don't drop groups too soon.

For normal use, \texttt{nwarm=100, nmain=1000, nrunMHBatches=20, nImproveMH=100}
may be reasonable.
Computing time is roughly proportional to
\texttt{nmain $\times$ nrunMHBatches}.
We still have to develop guidelines about how to choose the number of
iterations. If the tracelines show that the process is still quite
unstable even in the later part of the runs, possibilities are to
increase \texttt{nrunMHBatches} but also to increase the \texttt{mult} parameter in
\sfn{sienaAlgorithmCreate}. Increasing these will for both of them lead to
a proportional increase in computing time.

If multiple processors are available (which most computers have nowadays),
you can make more speed by setting the \texttt{nbrNodes} parameter to a value
larger than 1. Since parallelization goes by period $\times$ group,
it is nice, but not necessary, to have a value for \texttt{nbrNodes} that
is a divisor of (the number of periods multiplied by the number of groups);
higher values are meaningless.
Do not use such a high value for \texttt{nbrNodes} that your computer gets too
 hot or overworked. For Windows machines this can be monitored by opening
 the Task Manager (you will find how to do this by right clicking on the bottom
 toolbar).

\subsubsection{Prior distributions}

The prior mean and prior variance need to be given for the vector of parameters
that are randomly varying between the groups.
These are the rate parameters and the parameters specified with
\begin{verbatim}
random = TRUE
\end{verbatim}
in the call of \texttt{setEffect}.
For an effects object called \texttt{myeff}, you can see which
parameters are specified as randomly varying by
\begin{verbatim}
print(myeff, includeRandoms=TRUE)
\end{verbatim}
This will also tell you the number of random effects, which are the
dimensions for the parameters \texttt{priorMu} and  \texttt{priorSigma}
used to specify the prior distribution.
The rate parameters can be dropped from the \texttt{print} result
by requesting
\begin{verbatim}
print(myeff, includeRandoms=TRUE, dropRates=TRUE)
\end{verbatim}
The list and order of only the randomly varying effects
can be shown by requesting
\begin{verbatim}
myeff[(myeff$randomEffects | (myeff$basicRate & (myeff$group==1) )) & myeff$include, ]
\end{verbatim}
\smallskip

For the non-varying parameters an improper flat prior is used,
and nothing needs to be specified by the user.
\smallskip

The population distribution of the randomly varying parameters
is assumed to be multivariate normal $\mathcal{N}(\mu, \Sigma)$.
The conjugate prior for the multivariate normal distribution is used
to reflect the prior uncertainty in the parameters $\mu$ and $\Sigma$;
cf.\ \citet[][Section 3.6]{BDA3} and \citet[][Chapter 14]{HaganForster2004}.
This conjugate prior is the inverse Wishart distribution for $\Sigma$;
and, conditional on $\Sigma$, for $\mu$ a multivariate normal distribution,
specified as follows:
\begin{subequations}
\begin{align}
  \Sigma \, & \sim \,
    \mathrm{InvWishart}_{{p_1}}(\Lambda_0^{-1},\nu_0) \, ,
    \text{ and conditionally on }  \Sigma \\
   \mu \, & \mid \, \Sigma \sim \mathcal{N}_{p_1}(\mu_0, \Sigma/\kappa_0) \, .
\end{align}
\end{subequations}
Thus, the parameters of the prior are $\nu_0$, $\Lambda_0$, $\mu_0$,
and $\kappa_0$.
These are specified for \sfn{sienaBayes} in \RS in the following way:
\begin{itemize}
  \item $\nu_0$ = \texttt{priorDf};
  \item  $\Lambda_0 = \mathtt{priorDf} \times \mathtt{priorSigma}$;
  \item  $\mu_0$ = \texttt{priorMu};
  \item $\kappa_0$ = \texttt{priorKappa}.
\end{itemize}
This means the following for the prior parameters as
specified for \sfn{sienaBayes}:
\begin{itemize}
  \item  \texttt{priorDf} can be regarded as the
        effective sample size that has led to the prior information.
        For mathematical reasons, this must be at least $p+2$, where
        $p$ is the number of varying parameters.
  \item  \texttt{priorSigma} is your prior guess for the population
        covariance matrix of the varying parameters; in other words,
        this reflects the differences that may exist between the groups.
  \item  \texttt{priorMu} is your prior guess for the population mean $\mu$ of
       the varying parameters.
  \item \texttt{priorSigma / priorKappa} reflects your uncertainty
       about your guess for $\mu$.
\end{itemize}
It is quite a restriction that the covariance matrix expressing the prior
uncertainty about $\mu$ should be proportional to the population
(i.e., `true between-group') covariance matrix of the varying parameters.
This is a mathematical consequence of the use of the conjugate prior.
Often, the prior uncertainty about $\mu$ will be greater than the
assumed between-group differences, leading to a choice of \texttt{priorKappa}
less than 1, e.g., 0.1; note that \texttt{priorKappa} is a ratio
of variances, and the ratio of uncertainties will be better
expressed by its square root.

More research is needed for advice about prior distributions.
Especially for small numbers of groups, the priors may have a strong influence.
\medskip

The prior mean of the varying parameters,
\texttt{priorMu}, is a vector of length equal to the number of varying parameters.
In the object produced by \sfn{sienaBayes}, let us call it \texttt{ans},
this length is stored as \texttt{ans\$p1}.
For example, in a model with 4 waves, one dependent network variable,
and varying parameters specified for outdegree, reciprocity,
transitive ties, and similarity for some covariate $V$,
the length would be 3+4=7 (3 for three periods +
4 for four varying parameters).
The prior covariance matrix of the varying parameters,
\texttt{priorSigma}, is a symmetric square matrix of dimension
equal to the length of \texttt{priorMu}.
\medskip

\noindent
\emph{Rate parameters}
\smallskip

\noindent
If rate parameters are fixed (an exceptional case), they are
not included in the prior.

In other cases, special attention must be given to the rate parameters.
Sometimes, for small groups and complicated models, some of the
rate parameters may be estimated in the multi-group option by very high
numbers. This may be the case especially for groups with low Jaccard
coefficients, or for groups that deviate strongly from the other groups.
It may be advisable to take out the groups with extremely high
rate parameters (e.g., larger than 50 or 80).
To try and include some groups with high estimated rate parameters, the prior
distribution for these parameters may be employed.

By default, the prior for the basic rate parameters is data-dependent,
with a mean and covariance matrix that are robust estimates
based on the estimated rate parameters from the initialization phase.
This mostly will be adequate.

To have explicit control of the prior for the basic rate parameters,
the data dependence can be turned off by using
\texttt{priorRatesFromData = 0}.
Then the choice for \texttt{priorMu} and \texttt{priorSigma}
is going to matter.
Consider the rate parameters as estimated in the multi-group analysis
of the same data set.
Suppose the total number of groups is $N$.
For each separate rate parameter (for a given wave
and for a given dependent variable) there then are $N$ estimates,
some of which may be too high; denote the average and the variance
of the subset of not-too-high values by $m$ and $s^2$, respectively.
These are specific for the  given wave and the given dependent variable.
These values for mean and variance should
represent what one might find plausible values for this rate parameter.

The corresponding elements of \texttt{priorMu} and diagonal elements
of \texttt{priorSigma} should be then set, respectively, to values
close to these $m$ and $s^2$.

As an example, suppose there are $N=20$ groups, 3 waves and one dependent
variable (a network), and 5 varying parameters in addition to the rate parameters.
Then \texttt{p1} = 2+5 = 7.
Suppose that plausible values for the first rate parameter would
be centered about 4 and for the second about 5,
in both cases with a standard deviation of 1.4, corresponding
to a variance of about 2.
Suppose further that for the parameters of the objective function
the prior mean for the density parameter is specified as $-1$,
all other prior means as $0$, and all prior between-group variances as $0.16$,
corresponding to prior between-group standard deviations of $0.4$.
Further assume that the prior uncertainty about $\mu$ is thought to be
2~times larger, on the parameter scale, than the prior between-group differences,
which means a ratio of 4 on the variance scale.
One then could use the following piece of code.
\begin{verbatim}
m7 <- c(4, 5, -1, 0, 0, 0, 0)
S7 <- matrix(0, 7, 7)
diag(S7) <- c(2, 2, 0.16, 0.16, 0.16, 0.16, 0.16)
ans <- sienaBayes(...., priorMu=m7, priorSigma=S7, priorDf=22, priorKappa=0.25,
                  priorRatesFromData = 0, ....)
\end{verbatim}
\texttt{priorDf} is the prior degrees of freedom for the
covariance matrix. It can be interpreted as the sample size on which,
hypothetically, the prior knowledge about the covariance matrix of the
parameters is based.
The influence of the prior on the results is larger when \texttt{priorDf}
is larger.
\medskip

\noindent
\emph{Parameters of the objective function}
\smallskip

\noindent
For parameters of the objective function, it will be usually be possible
to use some prior knowledge, together with neutrality with respect to
the sign of tested parameters (in order not to unduly bias results.)
In most cases the outdegree parameter is expected to be negative and
the reciprocity parameter positive. The researcher should consider
earlier studies of similar network dynamics; reasonable values for the
prior mean for the outdegree parameter might be --2 or --1, and for the
reciprocity parameter +1.5 or +2. For homophily parameters on important
attributes expressed by the \texttt{simX} effect (which is standardized),
as long as these are regarded as control effects, one might specify the
prior mean conservatively as 0.3 or 0.5.
Since many \SI parameters are defined in such a way that they have values
in the range between --1 and +1, a prior variance in the range from 0.02 to
0.5 would often be reasonable; but it will be good to consider earlier
studies to have a good grounding for this choice.

Continuing the example above, if the 5 varying non-rate parameters would
start with an outdegree and a reciprocity parameter, the prior means
and prior variances could be modified, e.g., to
\begin{verbatim}
m7 <- c(4, 5, -2, +1.5, 0, 0, 0)
S7 <- matrix(0, 7, 7)
diag(S7) <- c(2, 2, 1, 0.3, 0.2, 0.1, 0.1)
\end{verbatim}


\subsubsection{Operation of sienaBayes()}

In Section \ref{S_sienaBayesParameters} it was already suggested to
start with a run with very low values of the sample size settings for the
MCMC procedure.

When the procedure has made a good start but the MCMC sample seems too
short, you can make a prolonged analysis using the \texttt{prevBayes} option,
and then combine the earlier with the later results using \sfn{glueBayes()}.
This is illustrated in the example on the help page.

During operation of \sfn{sienaBayes()}, partial results of the function
are now and then stored
as objects named \texttt{z} in files with the name
\texttt{PartialBayesResult.RData}; see the help page.
This is for the case that the computer or \R stops inadvertently
during the long computations.
These are \sfn{sienaBayesFit} objects, and therefore can be used in the
\sfn{print} and \sfn{summary} functions; they also can be used for
the \texttt{prevBayes} option to continue estimation.

\subsubsection{Assessing convergence}

You can visually inspect convergence by looking at the tracelines of the
various parameters. These can be plotted by the functions in \texttt{BayesPlots.r}
(available from the Siena website). In many cases, the tracelines for
the rate parameters already tell the story about convergence.

The file \texttt{BayesPlots.r} contains a variety of plotting functions that
can be used to obtain trace plots and posterior density plots.

The parameters \texttt{nwarm} and \texttt{nmain} in the call of
\sfn{sienaBayes} only imply
that an extra \sfn{improveMH} step is made between the warming and the
main iterations; there are no other differences between the warming
and main iterations. It is possible that convergence has set in only
later; depending on the case, the traceplots may give information about this.
If you conclude that convergence has occurred later, then use this to
define the \texttt{nfirst} parameter in the \sfn{print} and
\sfn{summary} functions for
\sfn{sienaBayesFit} object (see \texttt{`?print.sienaBayesFit'}).

When the procedure seems to have diverged and this occurs right
from the start, it is
advisable to use smaller values of the parameters \texttt{initgainGlobal}
and \texttt{initgainGroupwise}.
If divergence sets in later and is most pronounced
for the rate parameters, it may be advisable to use a smaller value of
\texttt{reductionFactor}, e.g., 0.1.
If generally the tracelines are irregular, it may be good to increase
\texttt{nrunMHBatches} but another possibility is to increase
the \texttt{mult} parameter set in \sfn{sienaAlgorithmCreate()}.

\iffalse
A way to get estimates from overdispersed starting points and not
run the whole improveMH() over and over again is to use prevBayes,
with an object in which \$thetaMat is changed to new initial values.
Then the proposal covariance matrices etc. will be retained,
so the transition distribution of the MCMC process remains the same but
only the starting values are different.
\fi
\medskip

\noindent
\emph{Using other packages for convergence assessment}
\smallskip

\noindent
The advice of literature such as \citet{BDA3} is to use multiple
sequences produced independently, preferably from overdispersed
starting points, for assessing convergence.
For example, one may use 4 or 5 such sequences.
Function \sfn{extract.sienaBayes()} can be used to extract
from these sequences the draws from the posterior distributions
of the parameters of interest.
This function produces a three-dimensional array of
iterations by chains by parameters, which then can be used, e.g., in
function \sfn{monitor()} of package \sfn{rstan} or with the
help of package \sfn{coda}.

Currently there is no good way in \sfn{sienaBayes()} to use
overdispersed starting points. (The difficulty is to get overdispersion
while still retaining a reasonable convergence for each sequence.)
The best option currently is to use independent restarts of the whole
algorithm; or to use one starting point and several continuations
using \texttt{prevBayes}. In the latter option one uses a long chain
instead of parallel chains, which is too bad, but this is the best
we have currently on offer; and using \sfn{monitor()} on such parts of
a long chain still will give an acceptable impression of convergence.

Function \sfn{monitor()} gives information about the potential
scale reduction $\hat R$ of the posterior distribution if simulations
were continued indefinitely, and the effective sample size
$n_{\text{\scriptsize eff}}$ (i.e., the estimated equivalent
sample size under independent sampling).
Rules of thumb given in \citet[][p. 287]{BDA3} are that,
for all parameters of interest,
$\hat R \leq 1.1$ and $n_{\text{\scriptsize eff}} \geq 5m$,
where $m$ is the number of chains.

Note that what is given by \sfn{monitor()} as the
`\texttt{se\_mean}' is the standard error of the mean
of the posterior distribution as an estimator for
the global mean $\mu_i$: i.e., this expresses the uncertainty
due to the finite length of the MCMC chain, it is not
a measure of spread of the posterior distribution itself.


\subsubsection{Interpreting results of sienaBayes}
\label{S_sienaBayesInterpret}

The \sfn{print} and \sfn{summary} functions
give posterior means, posterior standard deviations, 95\% credibility intervals,
and one-sided posterior $p$-values
for testing whether the parameter is positive or negative.
These are the Bayesian versions of estimates, standard errors,
confidence intervals, and $p$-values.

The functions \sfn{simpleBayesTest()} and \sfn{multipleBayesTest()}
are available for testing parameters; see the help page for these functions.
To compute further properties of the sample of the posterior,
the components
\texttt{ThinParameters, ThinPosteriorMu, \\
ThinPosteriorEta}, and \texttt{ThinPosteriorSigma} of the
\sfn{sienaBayesFit} object, as mentioned in the help page, may be useful.

The function \sfn{extract.posteriorMeans()} can be used to obtain
posterior means and standard deviations of the groupwise estimated
parameters. These are like the `\emph{empirical Bayes}' estimates
known also from other statistical models.

The file \texttt{BayesPlots.r}, mentioned above, contains some plotting
functions that are useful for making posterior density plots.

It should be noted that the \texttt{.out} files produced by \sfn{sienaBayes()}
are produced somewhere in the initial phase of the project and not meant
to be informative for final results. They contain the results of the
initial estimate by the multiple groups method and may be disregarded.
\medskip

When comparing results for specifications that differ with respect
to specifying the effects as fixed or varying across groups,
it will be noted that posterior standard deviations for the means
are larger when specifying the effects as randomly varying, as compared
to specifying them as fixed. This is natural, and it is associated
with a difference in interpretation.
Specifying the effect as randomly varying implies that there also is
an important step of generalization from the observed groups to the population
of groups. The between-group variance then is a priori unknown and one is
estimating a mean parameter from a sample of $N$ groups; usually $N$ is not
very large and the uncertainty about the between-group differences
will contribute considerably to the uncertainty of the population mean.

\newpage
\section[Formulas for effects]{Mathematical definition of effects}
\label{S_math}

The list of all effects available for any data set is obtained by
the command
\begin{verbatim}
effectsDocumentation()
\end{verbatim}
which produces a html file.
For a given effects object, say with the name \texttt{myeff}, the command
\begin{verbatim}
effectsDocumentation(effects = myeff)
\end{verbatim}
will give a file with all effects implemented for this effects object.
See
\begin{verbatim}
?effectsDocumentation
\end{verbatim}
for further options.
\bigskip

This chapter present the mathematical formulae for the definition of the
effects. Further background to these formulae can be found
for network dynamics in \citet{Snijders01,Snijders05,SnijdersEA10b};
for network and behavior dynamics in the last reference and
\citet*{SteglichEA10}; and for co-evolution of multiple networks,
including two-mode networks, in \citet{SLT2013}.
The effects are grouped into effects for modelling network
evolution and effects for modelling behavioral evolution (i.e.,
the dynamics of dependent actor variables). Within each group of
effects, the effects are listed in the order in which they appear
in \si. The short name of the effect (\texttt{shortName}),
as it is specified in \RS is specified in brackets.


For two-mode (bipartite) networks, only a subset of the effects is
meaningful, since the first node set has only outgoing ties
and the second only incoming; for example, the reciprocity effect
is meaningless because there cannot be any reciprocal ties;
the out-degree popularity effect is meaningless because it refers to
incoming ties of actors with high out-degrees; and there are no direct
similarity effects of actor covariates. However, distance-two effects
such as \texttt{simEgoInDist2}, and the interaction of effects like
\texttt{altInDist2} with \texttt{egoX} can be used to represent
homophily-like tendencies.
There are some specific effects for two-mode networks, e.g.,
the four-cycle effect.

\hypertarget{T_effpar}{
Some of the effects contain a number which is denoted in this section
by $c$, and called in this manual an \emph{internal effect parameter}.
}
(These are totally different from the statistical parameters which are
the weights of the effects in the objective function.)
These are set or modified by the \texttt{setEffect} function, e.g.,
\begin{verbatim}
myeffects <- setEffect(myeffects, gwespFF, parameter=69)
\end{verbatim}
%These numbers can be determined by the user
%by changing the \textsf{{\em pname}.mo} file
%described in Section~\ref{S_mo3file}.

\subsection{Network evolution}
The model of network evolution consists of the model of actors'
decisions to establish new ties or dissolve existing ties
(according to {\it evaluation}, {\it creation},
and {\it endowment functions}) and the
model of the timing of these decisions (according to the {\it rate
function}).
The model, and the roles played by these three functions,
were briefly explained in Section~\ref{S_defmod}.

For some effects
the creation and endowment functions are
implemented not for estimation by the Method of Moments
but only by the Maximum Likelihood or Bayesian method;
this is indicated below by ``endowment effect only likelihood-based''.

(It may be noted that the network evaluation function
was called objective function,
and the creation and endowment functions were called gratification function,
in \citet{Snijders01}.)

\subsubsection{Network evaluation function}
\label{S_f}

The network evaluation function for actor $i$ is defined as
\begin{equation}
f^{\rm net}_i(x) \, = \,
              \sum_k \beta^{\rm net}_k s^{\rm net}_{ik}(x)   \label{f_net}
\end{equation}
where $\beta^{\rm net}_k$ are parameters and $s^{\rm net}_{ik}(x)$
are effects as defined below.
If the model also contains some elementary effects
(see Section~\ref{S_elementary}), the objective
function is the sum of this and
\begin{equation}
f^{\rm el}_i(x) \, = \,
              \sum_k \beta^{\rm el}_k s^{\rm el}_{ik}(x)  \ , \label{f_el_net}
\end{equation}
see Section~\ref{S_mathmod}.
Elementary effects are of the type $s^{\rm el}_{ijk}(x) = x_{ij}\,s^{\rm el0}_{ijk}(x)$,
where $s^{\rm el0}_{ijk}(x)$ does not depend on $x_{ij}$.


The potential effects in the \hypertarget{T_objective}{network
evaluation function}
are the following. Note that in all
effects where a constants $c$ occurs, this constant can be chosen
and changed by the user;
this is the internal effect parameter mentioned above,
which can be modified by the function \texttt{setEffect(..., parameter=..., ...)}.
\iffalse
Also note that the evaluation effects which
are a function only of the out-degree of actor $i$ are excluded for
Model Type 2.
\fi
For non-directed networks, the same formulae are used,
unless a different formula is given explicitly.
Some of the effects are dropped for non-directed networks, because
they are not meaningful; and some of the names differ in the
non-directed case.
Section~\ref{S_NonDirEff} gives some effects that are specific
to non-directed networks.
\medskip

\noindent
\textbf{\emph{Structural effects}}
\medskip

\noindent
Structural effects are the effects depending on the network only.
The following list also contains some elementary effects
(see Section~\ref{S_elementary}).
The type of the elementary effects in \RS still is \texttt{eval},
indicating that its parameter is applied both for creating new ties
and for maintaining existing ties.

\begin{enumerate}
 \item  \hypertarget{T_density}{{\em out-degree effect}} or
 \emph{density effect} \texttt{(density)},
 defined by the out-degree\\
 $s^{\rm net}_{i\vit}(x) = x_{i+} = \sum_j x_{ij}$,\\
 where $x_{ij}=1$ indicates presence of a tie from $i$ to $j$
 while $x_{ij}=0$ indicates absence of this tie;

 \item  \hypertarget{T_reci}{{\em reciprocity effect}} \texttt{(recip)},
 defined by the number of reciprocated ties\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\,x_{ji}$;

 \begin{minipage}[t]{.75\textwidth}
  \item \hypertarget{T_transtrip}{{\em transitive triplets effect}}
 \texttt{(transTrip)},
   defined by the number of transitive
 patterns in $i$'s relations (ordered pairs of actors
 $(j,h)$ to both of whom $i$ is tied, while also $j$ is tied to $h$),\\
 for directed networks,
  $s^{\rm net}_{i\vit}(x) =  \sum_{j, h} x_{ij}\, x_{ih}\, x_{hj}\,$;\\
 and for non-directed networks,
 $s^{\rm net}_{i\vit}(x) =  \sum_{j < h} x_{ij}\, x_{ih}\, x_{hj}\,$;\\
 there was an error here until version 3.313,
 which amounted to combining the transitive triplets and transitive
 mediated triplets effects;
\end{minipage}
\hfill
\begin{minipage}[t]{.13\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}\\

 \item {\em transitive triplets effect type 1}  \texttt{(transTrip1)},
  may also be called \emph{transitive closure effect};
  the elementary effect corresponding to creating or maintaining
  the tie  $i \rightarrow j$ in the figure above; this is transitive
  closure in the strict sense of the term. The effect is\\
  $s^{\rm el}_{i\vit}(x) =   x_{ij} \sum_{h} x_{ih}\, x_{hj}\,$;\\


 \begin{minipage}[t]{.75\textwidth}
 \item {\em transitive triplets effect type 2}  \texttt{(transTrip2)},
  may also be called \emph{two-out-star closure effect};
  the elementary effect corresponding to creating or maintaining
  the tie  $i \rightarrow j$  in the figure here; this could be
  called structural equivalence for outgoing ties \\(but
  note that there is also
  the \texttt{balance} effect which is another implementation
  of structural equivalence equivalence for outgoing ties).\\
  The effect is\\
  $s^{\rm el}_{i\vit}(x) =   x_{ij} \sum_{h} x_{ih}\, x_{jh}\,$;
\end{minipage}
\hfill
\begin{minipage}[t]{.13\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}\\


 \item {\em transitive mediated triplets effect} \texttt{(transMedTrip)},
 defined by the number of transitive patterns in $i$'s
 relations where $i$ has the mediating position
 (ordered pairs of actors
 $(j,h)$ for which $j$ is tied to $i$ and $i$ to $h$, while also $j$ is tied
 to $h$),  which is different from the transitive triplets effect
 only for directed networks,\\
  $s^{\rm net}_{i\vit}(x) =  \sum_{j, h} x_{ji}\, x_{ih}\, x_{jh}\,$;\\
 this cannot be used together with the transitive triplets effect in
 Method of Moments estimation, because of perfect collinearity
 of the fit statistics;


 \item
 {{\em transitive reciprocated triplets effect}}  \texttt{(transRecTrip)},
 which can be regarded as an interaction between the transitive triplets
 effect and reciprocity, where the reciprocated tie is the tie
 $i \leftrightarrow j$  that  closes the two-path
 $i \rightarrow h \rightarrow j$,\\
  $s^{\rm net}_{i\vit}(x) =  \sum_{j, h} x_{ij}\, x_{ji}\, x_{ih}\, x_{hj}\,$;

 \item
 {{\em transitive reciprocated triplets effect (type 2)}}  \texttt{(transRecTrip2)},
 another interaction between the transitive triplets
 effect and reciprocity, where the reciprocated tie is the tie
 $h \leftrightarrow j$   in the closed the two-path
 $\{i \rightarrow h \rightarrow j, i \rightarrow j\}$,\\
  $s^{\rm net}_{i\vit}(x) =  \sum_{j, h} x_{ij}\, x_{ih}\, x_{hj}\, x_{jh}\,$;\\
  this represents the tendency to send ties simultaneously to pairs of actors
  who are mutually linked; but when outdegree-activity is also included in the model,
  it represents as well the tendency to send ties simultaneously to pairs of actors
  who are not linked to each other;

 \item \hypertarget{T_cycle3}{{\em number of three-cycles}}
 \texttt{(cycle3)}, \\
 $s^{\rm net}_{i\vit}(x) =  \sum_{j, h} x_{ij}\, x_{jh}\, x_{hi}\,$;

 \item
\begin{minipage}[t]{.7\textwidth}
 {\em shared popularity} \texttt{sharedPop},\\
 $s^{\rm net}_{i\vit}(x) =
      \frac14   \sum_{j,k,h; \text{all different}} x_{ij}\, x_{hj} \, x_{ik}\, x_{hk}$;\\[0.3em]
 this is like a 4-cycle but in a special orientation, like the 2PU (`two-paths up')
 effect (for $k$=2) for directed ERGMs proposed in \citet{RPW2009}.
 Therefore the statistic is called the `number of 2-2PU' configurations;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 4.5
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.5
\put{\large$\bullet$} at  3 4.0
\put{$i$} at 2 0.4
\put{$h$} at 4 0.4
\put{$j$} at 3 2.0
\put{$k$} at 3 4.4
\arrow <2mm> [.2,.6]  from 2.1 1.1 to 2.9 2.4
\arrow <2mm> [.2,.6]  from 2.05 1.2 to 2.9 3.85
\arrow <2mm> [.2,.6]  from 3.9 1.1 to 3.1 2.4
\arrow <2mm> [.2,.6]  from 3.95 1.2 to 3.1 3.85
\endpicture
\end{center}
\vfill
\end{minipage}

\vspace{-4em} % I do not know why this is necessary
 \item \begin{minipage}[t]{.68\textwidth}
for two-mode networks and for non-directed networks: \\
the {\em number of four-cycles} with shortName \texttt{(cycle4)} \\
   for the two-mode and \texttt{(cycle4ND)} for the  non-directed case,\\[0.3em]
 $s^{\rm net}_{i\vit}(x) =  \frac14 \sum_{j,k,h; \text{all different}}
            x_{ij}\, x_{ik}\, x_{hj}\, x_{hk}\,$;\\[0.3em]
 for parameter $p=2$ the square root is taken;\\
 note that this is like the \texttt{sharedPop} effect above, \\
 but for the two-mode  and non-directed cases \\
 the directionality plays no role;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 0.5 to 4.5, y from 0 to 5
\put{\large$\bullet$} at  1 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  1 3
\put{\large$\bullet$} at  4 3
\put{$h$} at 0.5 1
\put{$i$} at 0.5 3
\put{$k$} at 4.5 1
\put{$j$} at 4.5 3
\arrow <2mm> [.2,.6]  from 1.2 3 to 3.8 3
\arrow <2mm> [.2,.6]  from 1.2 2.9 to 3.8 1.1
\arrow <2mm> [.2,.6]  from 1.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 1.2 1.1 to 3.8 2.9
\endpicture
\end{center}
\end{minipage}

 \item {\em transitive ties effect} \texttt{(transTies)}
 (earlier called \emph{(direct and indirect ties) effect}),
 defined by
 the number of actors to whom $i$ is directly as well as indirectly tied, \\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij} \, \max_h (x_{ih}\, x_{hj}) $;

 \item {\em betweenness count} \texttt{(between)},\\
 $s^{\rm net}_{i\vit}(x) =  \sum_{j, h} x_{hi}\, x_{ij}\, (1-x_{hj})\,$;\\
 note that this is one of the rare effects that depends on \underline{non-existence}
 of a tie (here, the tie $h \rightarrow j$); this makes it less attractive,
 use it only if you know what you are doing!

 \item {\em balance} \texttt{(balance)}, defined by the similarity between
 the outgoing ties of actor $i$ and the outgoing ties of the other actors
 $j$ to whom $i$ is tied,
 \[ s^{\rm net}_{i\vit}(x) = \sum_{j=1}^n x_{ij} \neqsum{h}{h}{i,j}
 \left( b_0 - \mid x_{ih} - x_{jh} \mid \right)\, , \]
 where $b_0$ is a constant included to reduce the correlation
 between this effect and the density effect,
 \hypertarget{T_meanbal}{defined by}
 \[ b_0 = \frac{1}{(M-1)n(n-1)(n-2)} \sum_{m=1}^{M-1}
 \sum_{i, j=1}^n \neqsum{h}{h}{i,j}
 \mid x_{ih}(t_m) - x_{jh}(t_m) \mid \,.\]
 This may also be regarded as \emph{structural equivalence
 with respect to outgoing ties}.
 (In \SI versions before 3.324, this was divided by $n-2$, which for larger
 networks tended to lead to quite large estimates and standard errors.
 Therefore in version 3.324, the division by $n-2$
 -- which had not always been there -- was dropped.)

\item {\em structural equivalence effect with respect to
      incoming ties} \texttt{(inStructEq)}, which is an analogue to the
      balance effect but now considering similarity with respect to incoming
      ties,
      \begin{subequations}
      \begin{equation}
      s^{\rm net}_{i\vit}(x) = \sum x_{ij} d_{ij}
      \end{equation}
      with
      \begin{equation}
       d_{ij} =  \neqsum{h}{h}{i,j} \big(b_0 - \mid x_{hi} - x_{hj}\mid \big) \ .
%       =  (n-2)b_0 - \big( x_{+i}+x_{+j} -x_{ij}-x_{ji}-2\sum_h x_{hi}x_{hj} \big)
      \end{equation}
      \end{subequations}
      This effect is not quite finalized yet, because provisionally
      $b_0 = 0$ instead of a mean of the subtracted values like in the balance effect.
      Subtraction of the mean will lead to better convergence properties.

 \item {\em Jaccard similarity for outgoing ties effect} \texttt{(Jout)},
 an elementary effect defined by
 the Jaccard similarity with respect to outgoing ties,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij} \, J_{\text{out}}(i,j)$, where
 \[
 J_{\text{out}}(i,j) \,=\, \frac{\sum_h x_{ih}\,x_{jh}}
                     {x_{i+} + x_{j+} - \sum_h x_{ih}\,x_{jh}}
 \]
 (where 0/0 is taken as 0).

 \noindent
 Since the Jaccard measure has smaller variability than a lot of other
 effects, the parameter estimates of this will often be larger,
 with correspondingly larger standard errors,
 than many other parameter estimates. The same holds for
 the other Jaccard similarity effects.

 \item {\em Jaccard similarity for incoming ties effect} \texttt{(Jin)},
 an elementary effect defined by
 the Jaccard similarity with respect to incoming ties,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij} \, J_{\text{in}}(i,j)$, where
 \[
 J_{\text{in}}(i,j) \,=\, \frac{\sum_h x_{hi}\,x_{hj}}
                     {x_{+i} + x_{+j} - \sum_h x_{hi}\,x_{hj}}
 \]
 (where again 0/0 is taken as 0).

 \item {\em number of distances two effect} \texttt{(nbrDist2)},
 \hypertarget{T_dist2}{defined by}
 the number of actors to whom $i$ is indirectly tied
 (through at least one intermediary, i.e., at sociometric distance 2),\\
 $s^{\rm net}_{i\vit}(x) =  \#\{j \mid x_{ij} = 0,\, \max_h (x_{ih}\, x_{hj}) > 0 \}$;\\
 endowment effect only likelihood-based because the Method of Moments
 estimators for endowment effects are based on the `loss' associated
 with terminated ties, and this cannot be straightforwardly applied
 for the number of distances two effect.\\
 This effect is difficult to interpret: actor $i$ can increase this effect by making a
 new tie to an actor $j$ at distance 2 but also by dropping a direct tie to an
 actor $j$ to whom $i$ is also connected via a two-path
 $i \rightarrow h \rightarrow j$.
 Instead of this effect it may be preferable to use one of the many other
 effects representing closure (\texttt{transTrip}, \texttt{transTies},
 the various gwesp effects, the various Jaccard effects, etc.).

 \item {\em number of doubly achieved distances two effect} \texttt{(nbrDist2twice)},
 defined by
 the number of actors to whom $i$
 is not directly tied, and tied through twopaths via at least two intermediaries,\\
 $s^{\rm net}_{i\vit}(x) =  \#\{j \mid x_{ij} = 0,\, \sum_h (x_{ih}\, x_{hj}) \geq 2 \}$;\\
 endowment effect only likelihood-based;


 \item {\em number of dense triads} \texttt{(denseTriads)},
 defined as triads containing at least $c$ ties,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_{j,h} x_{ij} \, I\{ x_{ij}\, + x_{ji}\, + x_{ih}\, + x_{hi}\,
 + x_{jh}\, + x_{hj}\,)\geq c \}\,$,\\
 where the `indicator function' $I\{A\}$ is 1 if the condition
 $A$ is fulfilled and 0 otherwise, and where $c$ is either 5 or 6;\\
  (this effect is superfluous and undefined for symmetric networks);

 \item five variations of the \emph{GWESP (geometrically weighted edgewise
  shared partners)} effects: \texttt{gwespFF, gwespBB, gwespFB, gwespBF, gwespRR},
  and for non-directed $W$ networks the sixth version \texttt{gwesp}. \\
  \emph{Note that there is a difference since version 1.1-251; see at the end
  of this item.}\\
  These are effects like those developed for exponential random graph models (`ERGMs')
  by \citet{SPRH06}, in the parametrisation of \citet{Hunter2007}.
  The \texttt{gwespFF} effect is an alternative expression for transitivity.
  This concept here is specified in an actor-based way,
  by counting configurations in the local neighbourhood of
  a given actor, rather than in the tie-oriented way of the
  models in the ERGM family, for which the GWESP statistic
  was first developed.
  The actor-based \texttt{gwespFF} effect is defined,
  in direct analogy to the corresponding global statistic
  of \citet{Hunter2007}, by
\begin{subequations}
\begin{equation}
  \text{GWESPFF}(i, \alpha) \,=\,
      \sum_{k=1}^{n-2}  e^{\alpha} \,\big\{1 \,-\, \big(1 - e^{-\alpha}\big)^k  \big\}
      \, \text{EPFF}_{ik}   \ ,
         \label{GWESP}
\end{equation}
where $\text{EPFF}_{ik}$ (for `edgewise partners') is the number of nodes $j$
such that $i \rightarrow j$ and there are exactly $k$ other
nodes $h$ for which there is the two-path $i \rightarrow h \rightarrow j$.


\begin{figure}[htb]
\begin{center}
\includegraphics[scale=0.8]{gwesp.png}
% from tikztry.tex
\\
\end{center}
\caption{Geometrically weighted edgewise shared partners; 
left, transitive (`gwespFF'); right, cyclical (`gwespBB');
for F=`forward', B=`backward'.}
\label{F_gwesp1}
\end{figure}

An equivalent way of writing this is
\begin{equation}
  \text{GWESPFF}(i, \alpha) \,=\,
       \sum_{j=1}^n x_{ij} \,
                        e^{\alpha} \,\Big\{1 \,-\, \big(1 -
                        e^{-\alpha}\big)^{\sum_{h=1}^n x_{ih}x_{hj} }  \Big\}
      \,   \ ,
         \label{GWESP2}
\end{equation}
\end{subequations}
where the convention is used that $x_{jj} = 0$ for all $j$.

\begin{figure}[htb]
\begin{center}
\includegraphics[scale=1]{gwespCurves.png}
\end{center}
\caption{ GWESP weight for a tie closing $s$ two-paths for
                    $\alpha = \infty, 1.2, 0.69, 0$.}
\label{F_gwesp2}
\end{figure}

The parameter $\alpha$ is a tuning parameter that may range from 0 to $\infty$.
The internal effect parameter is defined as $100 \times \alpha$.
For all $\alpha$, it holds that
$ \text{GWESP}(0, \alpha) = 0,\  \text{GWESP}(1, \alpha) = 1,$
and $\text{GWESP}(k, \alpha) $ increases with $k$ to a maximum
slightly less than $e^\alpha$.
For $\alpha = 0$ the coefficients
$e^{\alpha} \,\big\{1 \,-\, \big(1 - e^{-\alpha}\big)^k\big\} $
are equal to 1 for all $k \geq 1$,
and for $\alpha \rightarrow \infty$ they tend to $k$.
Since we can write
\[
  \sum_{j,h} x_{ih}x_{hj}x_{ij} \,=\, \sum_{k=1}^{n-2} k\, \text{EP}_{ik}   \ ,
\]
this implies that for $\alpha \rightarrow \infty$  the regular number
of transitive triplets is approached, while for smaller $\alpha$
the extra contribution of a high number of intermediaries $h$
is downweighted.
An often used value is $\alpha = \log(2) = 0.69$ \citep{SPRH06},
corresponding to an internal effect parameter of 69,
\begin{verbatim}
myeffects <- setEffect(myeffects, gwespFF, parameter=69)
\end{verbatim}
but it is worthwhile to try out different values of $\alpha$
to see which one gives the best fit.

Although the fit statistic of the GWESP effect is identical to that
for transitive ties for $\alpha=0$ and approximates the fit
statistic for transitive triplets
for large $\alpha$, the estimates are not the same because some other
calculations are done differently. The issue is that the GWESP effects are
not implemented as an evaluation effect, but as an elementary effect,
where for the change statistic only changes of the tie $i \rightarrow j$ in
(\ref{GWESP2}) are considered, and not of the tie $i \rightarrow h$.

Thus, the GWESP effects are defined in \RS as the elementary effects
\begin{equation}
 s^{\rm el}_{i\vit}(x) \,=\,
       x_{ij} \,
                        e^{\alpha} \,\Big\{1 \,-\, \big(1 -
                        e^{-\alpha}\big)^{\sum_{h=1}^n x_{ih}x_{hj} }  \Big\}
      \,   \ .
         \label{GWESP3}
\end{equation}

It should be noted that although the GWESP statistic is not triadic but
depends on higher-order configurations, still it is actor-oriented
in the sense that only those configurations are considered that are part of the
personal network, i.e., the set of actors immediately connected
to the focal actor $i$.

The other types of GWESP effect are analogous, with
different tie orientations. They are defined as follows:\\
\texttt{gwespBB}: uses $\text{EPBB}_{ik}$, counting the number of nodes $j$
with $i \rightarrow j$ and there are exactly $k$ other
nodes $h$ for which there is the two-path $i \leftarrow h \leftarrow j$;\\
\texttt{gwespFB}: uses $\text{EPFB}_{ik}$, counting the number of nodes $j$
with $i \rightarrow j$ and there are exactly $k$ other
nodes $h$ for which there is the two-out-star $i \rightarrow h \leftarrow j$;\\
\texttt{gwespBF}: uses $\text{EPBF}_{ik}$, counting the number of nodes $j$
with $i \rightarrow j$ and there are exactly $k$ other
nodes $h$ for which there is the two-in-star $i \leftarrow h \rightarrow j$;\\
(the last two were incorrect in the manual before 23/06/2017)\\
\texttt{gwespRR}: uses $\text{EPRR}_{ik}$, counting the number of nodes $j$
with $i \rightarrow j$ and there are exactly $k$ other
nodes $h$ for which there are the reciprocal ties $i \rightleftarrows h \rightleftarrows j$.

In version 1-1.251 the implementation was changed (thanks to Nynke Niezink),
because earlier versions were not quite according to what is described above.
The effect was until version 1-1.250 implemented as\\
$c_1 + c_2 \times \text{GWESPFF}(i, \alpha')$\\
for values $c_1(\alpha)$ and $c_2(\alpha)$ not dependent on $x$, and with
positive parameters $\alpha$, $\alpha'$ related according to
$\exp(-\alpha) + \exp(-\alpha') = 1$. Note that for the default value
$\alpha = \log(2)$ corresponding to the effect parameter 69 (see above), $\alpha = \alpha'$.

\item two variations of the
   \emph{GWDSP (geometrically weighted dyadwise shared partners)} effects:
   \texttt{gwdspFF} and \texttt{gwdspFB}.
   These are defined, respectively, by
\begin{equation}
  \text{GWDSPFF}(i, \alpha) \,=\,
       \sum_{h=1;\; h \neq i}^n \, e^{\alpha} \,\Big\{1 \,-\, \big(1 -
   e^{-\alpha}\big)^{\sum_{j=1}^n x_{ij}x_{jh} }  \Big\}    \,   \ ,
\end{equation}
and
\begin{equation}
  \text{GWDSPFB}(i, \alpha) \,=\,
       \sum_{h=1;\; h \neq i}^n \, e^{\alpha} \,\Big\{1 \,-\, \big(1 -
   e^{-\alpha}\big)^{\sum_{j=1}^n x_{ij}x_{hj} }  \Big\}    \,   \ .
\end{equation}
   It may be noted these are of a quite different nature than most other effects,
   with the outgoing tie variables from $i$ tucked far away in the formula.
   These effects are somewhat similar with respect to what they mean for the
   networks as \texttt{outPop} and \texttt{inPop}, respectively.\\
   Like the gwesp effects, these are similar to the effects developed for
   exponential random graph models (`ERGMs')
   by \citet{SPRH06}, in the parametrisation of \citet{Hunter2007}.
   They are motivated because they are natural companions to \texttt{gwespFF}
   and \texttt{gwespFB}, as the conditions for the transitive closure
   expressed by the latter two effects.\\
   These effects are implemented as regular effects, not as elementary effects.

 \item {\em number of (unilateral) peripheral relations to dense triads},\\
 $s^{\rm net}_{i\vit}(x) =  \sum_{j,h,k} x_{ij} (1-x_{ji})(1-x_{hi})(1-x_{ki})
 I\{ (x_{jh}\,  + x_{hj}\, + x_{jk}\, + x_{kj}\, + x_{hk}\, + x_{kh}\,)\geq c \} \,$,\\
 where $c$ is the same constant as in the {\it dense triads} effect;\\
 for symmetric networks, the `unilateral' condition is dropped, and the definition is\\
 $s^{\rm net}_{i\vit}(x) =  \sum_{j,h,k} x_{ij} (1-x_{hi})(1-x_{ki})
 I\{ (x_{jh}\,  + x_{hj}\, + x_{jk}\, + x_{kj}\, + x_{hk}\, + x_{kh}\,)\geq c \} \,$;



 \item {\em in-degree related popularity effect} \texttt{(inPop)}
 (earlier called {\em popularity} or {\em popularity of alter effect}), defined by
  the sum of
 the in-degrees of the others to whom $i$ is tied,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, x_{+j} =
 \sum_j x_{ij} \sum_h x_{hj} = \sum_j x_{ij} (\sum_{h \neq i} x_{hj} + 1)$;\\
 in \SI 3 until version 3.313, this effect was multiplied by a factor $1/n$;\\
 in \RS this effect has had a bug until version 1.1-219;\\
 in \RS the target statistic for this effect was multiplied by a factor $n$ until version 1.1-241;

 \item {\em in-degree related popularity (sqrt) effect} \texttt{(inPopSqrt)}
 (earlier called {\em popularity of alter (sqrt measure) effect}), defined by the sum of
 the square roots of the in-degrees of the others to whom $i$ is tied,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, \sqrt{x_{+j}} =
  \sum_j x_{ij} \sqrt{\sum_h x_{hj}} $;\\
 this often works better in practice than the raw popularity effect;
 also it is often reasonable to assume that differences between high in-degrees are
 relatively less important than the same differences between low
 in-degrees;

 \item {\em out-degree related popularity effect} \texttt{(outPop)}
 (earlier called {\em activity} or {\em activity of alter effect}), defined by
  the sum of the out-degrees
 of the others to whom $i$ is tied,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, x_{j+} =
  \sum_j x_{ij} \sum_h x_{jh} $; \\
 until version 3.313, this effect was multiplied by a factor $1/n$;


 \item {\em out-degree related popularity (sqrt) effect} \texttt{(outPopSqrt)}
 (earlier called {\em activity of alter (sqrt measure) effect}), defined by the sum of
 the square roots of the out-degrees of the others to whom $i$ is tied,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, \sqrt{x_{j+}} =
  \sum_j x_{ij} \sqrt{\sum_h x_{jh}} $;\\
 this often works better in practice than the raw activity effect
 for the same reasons as mentioned above for the sqrt measure of the popularity effect;

 \item {\em reciprocal degree-related popularity effect} \texttt{(reciPop)}
 defined by the sum of the reciprocal degrees
 of the others to whom $i$ is tied,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, x^{(r)}_{j} $, \\
 where the reciprocal degree is defined by\\
 $ x^{(r)}_{j} = \sum_h x_{jh}x_{hj} $.

 \item {\em reciprocal degree-related popularity (sqrt) effect } \texttt{(reciPopSqrt)}
 defined by the sum of the square roots of the reciprocal degrees
 of the others to whom $i$ is tied,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{x^{(r)}_{j}} $, \\
 where the reciprocal degree is defined as above;

 \item[{\hspace*{-1ex}$\bigodot$}] for non-directed networks, the popularity and activity
 effects are taken together as ``degree effects'',
 since in-degrees and out-degrees are the same in this case;

 \item {\em in-degree related activity effect}, \texttt{(inAct)}
 defined as  the cross-product  of the actor's in- and out-degrees,\\
 $s^{\rm net}_{i\vit}(x) = x_{i+}\, x_{+i}$;\\
 endowment effect only likelihood-based;

 \item {\em in-degree related activity (sqrt) effect}, \texttt{(inActSqrt)}
 defined by  \\
 $s^{\rm net}_{i\vit}(x) = x_{i+}\,\sqrt{x_{+i}}$ ;

\item \emph{in-isolate Outdegree effect}, (\texttt{inIsDegree}), the
      (additional) out-degree (or activity)
      effect for actors with in-degree zero, defined as the out-degree
      but only if the actor has in-degree zero,
 $s^{\rm net}_{i\vit}(x, z) =   I\{x_{+i} = 0 \}\, \sum_j x_{ij}   $ ;\\

 \item {\em out-degree related activity effect} \texttt{(outAct)},
 	 defined as the squared out-degree of the actor,
 $s^{\rm net}_{i\vit}(x) = x^2_{i+}$;\\
 endowment effect only likelihood-based;

 \item {\em out-degree related activity (sqrt) effect}  \texttt{(outActSqrt)}
 (earlier called {\em out-degree$\,\hat{\ }$(1.5)}), defined by  \\
 $s^{\rm net}_{i\vit}(x) = x^{1.5}_{i+} = x_{i+}\,\sqrt{x_{i+}}$ \\
 endowment effect only likelihood-based;

 \item {\em reciprocal degree-related activity effect} \texttt{(reciAct)}
 defined by the degree of $i$ multiplied by $i$'s reciprocal degree,\\
 $s^{\rm net}_{i\vit}(x) =   x_{i+}\, x^{(r)}_{i} $; \\
 where the reciprocal degree is defined as above;\\
 for internal effect parameter $c=2$, it is defined by\\
 $s^{\rm net}_{i\vit}(x) =   x_{i+}\, \sqrt{x^{(r)}_{i}} $; \\

 \item {\em out-degree up to $c$} (\emph{truncated out-degree}),
 where $c$ is some constant
 (internal effect parameter, see above),  there are two implementations here:
 \texttt{outTrunc} and \texttt{outTrunc2}, to allow the simultaneous use of this
 effect with 2 different internal effect parameters; the effect is
 defined by  \\
 $s^{\rm net}_{i\vit}(x) = \text{min}(x_{i+}\,,\, c)$;\\
 note that for $c=1$ this represents --inversely-- the tendency to be an isolate
 with respect to outgoing ties, i.e., have out-degree equal to 0:
 $ \text{min}(x_{i+}\,,\, 1) = 0$ if $x_{i+} = 0$, and
 $ \text{min}(x_{i+}\,,\, 1) = 1$ if $x_{i+} \geq 1$.\\
 Since the representation is inverse, a result like a negative coefficient
 $ -1.2$ for \texttt{outTrunc} (internal effect parameter $c=1$) is interpreted
 as a positive tendency $+1.2$ toward outdegrees equal to 0; the standard
 error is unchanged. In the case of $c=1$, an alternative and more directly
 comprehensible name is \emph{outdegree at least 1} effect.

 \item {\em square root out-degree}, defined by  \\
 $s^{\rm net}_{i\vit}(x) = \sqrt{x_{i+}}$;\\
 this is left out in later versions of \si;

 \item {\em squared (out-degree -- $c$)}, where $c$ is some constant,
 defined by  \\
 $s^{\rm net}_{i\vit}(x) = (x_{i+} - c)^2$,\\
 where $c$ is chosen to diminish the collinearity between this
 and the density effect;\\
 this is left out in later versions of \si;

 \item {\em sum of (1/(out-degree + $c$)} \texttt{(outInv)},
 where $c$ is some constant,  defined by  \\
 $s^{\rm net}_{i\vit}(x) = 1/(x_{i+} + c)$;\\
 endowment effect only likelihood-based;

 \item {\em sum of (1/(out-degree + $c$)(out-degree + $c+1$))} \texttt{(outSqInv)},
 where $c$ is some constant, defined by  \\
 $s^{\rm net}_{i\vit}(x) = 1/(x_{i+} + c)(x_{i+} + c + 1)$;\\
 endowment effect only likelihood-based.


 \item[{\hspace*{-1ex}$\bigodot$}] the following assortativity effects are,
 for $c=1$, various orientations of three-paths (plus a bit of two-paths):\\

 \item {\em out-out degree$\,\hat{\ }$(1/c) assortativity}
 \texttt{(outOutAss)},
 which represents the differential tendency for actors with high out-degrees
 to be tied to other actors who likewise have high out-degrees,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, {x_{i+}^{1/c}} {x_{j+}^{1/c}} $;\\
 $c$ can be 1 or 2 (the latter value is the default);

 \item {\em out-in degree$\,\hat{\ }$(1/c) assortativity}
 \texttt{(outInAss)},
 which represents the differential tendency for actors with high out-degrees
 to be tied to other actors who have high in-degrees,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, {x_{i+}^{1/c}} {x_{+j}^{1/c}} $;\\
 $c$ can be 1 or 2 (the latter value is the default);

 \item {\em in-out degree$\,\hat{\ }$(1/c) assortativity}
 \texttt{(inOutAss)},
 which represents the differential tendency for actors with high in-degrees
 to be tied to other actors who have high out-degrees,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, {x_{+i}^{1/c}} {x_{j+}^{1/c}} $;\\
 $c$ can be 1 or 2 (the latter value is the default);

 \item {\em in-in degree$\,\hat{\ }$(1/c) assortativity}
 \texttt{(inInAss)},
 which represents the differential tendency for actors with high in-degrees
 to be tied to other actors who likewise have high in-degrees,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, {x_{+i}^{1/c}} {x_{+j}^{1/c}} $;\\
 $c$ can be 1 or 2 (the latter value is the default);

\item \emph{network-isolate effect}, (\texttt{isolateNet}), the effect of ego having
      in-degree as well as out-degree zero, i.e., being a total isolate,\\
 $s^{\rm net}_{i\vit}(x, z) =   I\{x_{+i} = x_{i+} = 0 \}  $ ;

%\setcounter{savenumi}{\value{enumi}}
%\end{enumerate}

\iffalse
The next three effects, `anti isolates', `anti in-isolates',
and `anti in-near-isolates',
are not regular effects in the evaluation function tradition.
They are gratification effects as defined in \citet{Snijders01},
which can be defined as components of the function $u_i(x^0, x)$ in
(\ref{probab}) in Section~\ref{S_mathmod}.
In the operation of \rs, specifying the `endowment' or `creation'
types in the effects object will mean that these effects operate
only for maintaining existing or for creating new ties -- as usual.

For these three effects, the method implemented in \RS for dealing with
missing data will not work well if
(for the anti isolates and anti in-isolates effects),
for some actors $j$ with true indegree 1 or more, missing tie variables
might decrease the observed indegree to 0;
and (in the case of the anti in-near-isolates effect),
for some actors $j$ with true indegree 2 or more, missing tie variables
might decrease the observed indegree to 0 or 1.
\fi

%\begin{enumerate}
%\setcounter{enumi}{\value{savenumi}}
\item \emph{anti isolates effect}, (\texttt{antiIso}), the effect of
      wishing to connect to others who otherwise would
      be a total isolate, i.e., have no incoming or outgoing
      ties, and wishing not to sever connections to
      others who thereby would become a total isolate,\\
$s^{\rm net}_{i\vit}(x) = \sum_j I\{x_{+j} \geq 1, x_{j+} = 0\} $;\\

 %      This is defined not by an evaluation statistic but only by a
%      change statistic (contribution to the function (\ref{probab})
%      in Section~\ref{S_mathmod}).
%      The value of the change statistic is +1 when making a
%      new connection to an isolate,
%      and --1 when terminating a connection to an actor who subsequently
%      would be an isolate:\\
%$g^{\rm net}_{i\vit}(x^0, x) =  I\{x^0_{+j} = x^0_{j+} = 0,\, x_{ij} = 1 \} -
%                  I\{x^0_{+j}  = 1,\, x^0_{j+} = 0,\, x_{ij} = 0 \} $ .\\
%      The target statistic is the number of
%      actors with outdegrees 0 and indegrees of value at least 1,
%      multiplied by the number of actors.\\
%      Note: perhaps this effect is of limited use, as it would be
%      better to define the target statistic by posing the requirement
%      of an outdegree 0 at the starting rather than the end wave
%      of the period;
%      but this is not straightforward in the architecture of  \rs.\\
%      Note the remark above concerning missing data.

\item \emph{anti in-isolates effect}, (\texttt{antiInIso}), the effect of
      wishing to connect to others who otherwise would have
      no incoming ties, and wishing not to sever connections to
      others who thereby would lose their last incoming connection: \\
$s^{\rm net}_{i\vit}(x) = \sum_j I\{x_{+j} \geq 1 \} $;

\item \emph{anti in-near-isolates effect}
 = \emph{indegree at least 2 effect}, (\texttt{antiInIso2 = in2Plus}),
      the effect of
      wishing to make a new connection to others who currently have
      an indegree equal to 1, and wishing not to sever connections to
      others who currently have an indegree equal to 2:\\
$s^{\rm net}_{i\vit}(x) = \sum_j I\{x_{+j} \geq 2 \} $;

\item \emph{indegree at least 3 effect}, (\texttt{in3Plus}),
      the effect of
      wishing to make a new connection to others who currently have
      an indegree equal to 2, and wishing not to sever connections to
      others who currently have an indegree equal to 3:\\
$s^{\rm net}_{i\vit}(x) = \sum_j I\{x_{+j} \geq 3 \} $;

\item \emph{isolate popularity effect}, (\texttt{isolatePop}), the effect of
      being tied to actors who further are isolates
      (the fact that such a tie does exist will give the other actor
      an in-degree of 1),\\
$s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, I\{x_{+j} = 1, x_{j+} = 0 \} $ .\\
     Note that perhaps this effect is of limited use, as other (third) actors
     might increase the indegree of $j$ to more than 1, and then the ex-isolate
     does not contribute any more to $i$'s evaluation of the network;
     the three effects above ( `anti isolates', `anti in-isolates',
     and `anti in-near-isolates') may be more useful instead.
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}

      Note that the network-isolate effect expresses the tendency for ego
      to be an isolate (not sending ties if ego has indegree 0),
      whereas the in-isolate and
      isolate popularity effect express the tendency for ego
      to connect to others who, without this connection, would
      have an indegree of 0, or be total isolates, respectively.
      Thus, in modeling the number of isolates, for the network-isolate
      effect the agency is in the isolate (see the $i$ in the formula),
      whereas for the various anti isolates and the isolate popularity
      effects the agency is in others connecting (or not)
      to the isolate (see the $j$ in the formulae).

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
\item only in RSienaTest: \emph{Simmelian outdegree effect}, (\texttt{simmelian}), the effect of
      the Simmelian outdegree. The Simmelian transformation of the network is
      the network composed of all ties embedded in at least one complete triad:
\[
    x^{\rm{simm}}_{ij} \,=\, \left\{ \begin{array}{cl}
                               1 & x_{ij} = x_{ji} = 1 \text{ and} \\
                                  & \ \text{ there is at least one }
                                      h \text{ for which } x_{hi} = x_{ih} = x_{hj} = x_{jh} = 1 \\
                               0 & \text{else.}
                             \end{array} \right.
\]
      In other words, these ties must be reciprocal, and there must be at least one
      third actor to whom both have a mutual tie.
      The Simmelian outdegree of $i$ is  \\
$s^{\rm net}_{i\vit}(x ) = \sum_j  x^{\rm{simm}}_{ij} $ .\\

\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
\medskip

\noindent
\textbf{\emph{Dyadic covariate effects}}
\medskip

\noindent
The effects for a dyadic covariate $w_{ij}$ are
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}

 \item {\em covariate (centered) main effect} \texttt{(X)},\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \, (w_{ij} - \bar{w}) $\\
 where $\bar{w}$ is the mean value of $w_{ij}\,$;

 \item {\em covariate (centered) $\times$ reciprocity} \texttt{(XRecip)},\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} x_{ji} \, (w_{ij} - \bar{w}) $.

 \item[{\hspace*{-1ex}$\bigodot$}]
Various different ways can be modeled in which
 a triadic combination can be made between
 the dyadic covariate and the network.
 In the explanation, the dyadic covariate
 is regarded as a weighted network
 (which will be reduced to a non-weighted network if $w_{ij}$ only
 assumes the values 0 and 1).
 By way of exception, the dyadic covariate
 is not centered in these effects
 (to make it better interpretable as a network).
 In the text and the pictures, an arrow with the letter $W$
 represents a tie according to the weighted network $W$.

 \item
\begin{minipage}[t]{.7\textwidth}
 {\em $WW=>X$ closure of covariate} \texttt{(WWX)},\\
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{ih}\, w_{hj}\,$;\\
 this refers to the closure of $W-W$ two-paths;
 each $W-W$ two-path
 $i \stackrel{W}{\rightarrow} h \stackrel{W}{\rightarrow} j$
 is weighted by the product $w_{ih} w_{hj}$
 and the sum of these product weights measures the
 strength of the tendency toward closure of
 these $W-W$ twopaths by a tie.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

 Since the dyadic covariates are represented by square arrays
 and not by edgelists, this and the following effects will be relatively
 time-consuming if the number of nodes is large.

\item
\begin{minipage}[t]{.7\textwidth}
 {\em mixed cyclic $WW=>X$ closure}, ($X$: cyclic closure of $W$) \texttt{(cyWWX)}  \\
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{jh}\, w_{hi}\,$;\\
 this refers to the cyclic closure of $W-W$ two-paths (weighted if the
 dyadic covariate $W$ does not only have 0 and 1 values);
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of product of weights of $W-W$ two-paths
 $j \stackrel{W_{jh}}{\longrightarrow} h \stackrel{W_{hi}}{\longrightarrow} i$;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from  2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to  3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}

\item
\begin{minipage}[t]{.7\textwidth}
 {\em incoming shared $WWX$}, ($X$: incoming shared $W$) \texttt{(InWWX)}  \\
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{hi}\, w_{hj}\,$;\\
 this refers to shared incoming $W$ ties contributing
 to the tie $i \stackrel{X}{\rightarrow} j$;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from  2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from   3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}

\item
\begin{minipage}[t]{.7\textwidth}
 {\em incoming shared $WWX$}, ($X$: incoming shared $W$) \texttt{(OutWWX)}  \\
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{ih}\, w_{jh}\,$;\\
 this refers to shared outgoing $W$ ties contributing
 to the tie $i \stackrel{X}{\rightarrow} j$;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from  2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from  3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}

\begin{minipage}[t]{.7\textwidth}
 \item {\em $WX=>X$ closure of covariate} \texttt{(WXX)},\\
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{ih}\, x_{hj}\,$;\\
 this refers to the closure of mixed $W-X$ two-paths;
 each $W-X$ two-path $i \stackrel{W}{\rightarrow} h \rightarrow j$
 is weighted by $w_{ih} $
 and the sum of these  weights measures the
 strength of the tendency toward closure of
 these mixed $W-X$ twopaths by a tie;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 2.0
\put{{\small $X$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}

\begin{minipage}[t]{.7\textwidth}
 \item {\em $XW=>X$ closure of covariate} \texttt{(XWX)},\\
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, x_{ih}\, w_{hj}\,$;\\
 this refers to the closure of mixed $X-W$ two-paths;
 each $X-W$ two-path $i \rightarrow h \stackrel{W}{\rightarrow} j$
 is weighted by $w_{hj} $
 and the sum of these  weights measures the
 strength of the tendency toward closure of
 these mixed $X-W$ twopaths by a tie.\\
 The covariate $W$ here always is used non-centered.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 3.9 2.0
\put{{\small $X$}} at 2.1 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
\smallskip
There are two partial variants of this effect; they can be
distinguished not by the Method of Moments, but only
by Maximum Likelihood and Bayesian estimation.
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
 \item
 {\em  $XW => X$ closure-1 of covariate} \texttt{(XWX1)}, \\
 This is an elementary effect, not an evaluation effect,
 comprising of the  `$XW => X$ closure of covariate' effect
 only the contribution of the
 the number of weighted $X-W$ two-paths
 $i \stackrel{X}{\rightarrow} h \stackrel{W}{\rightarrow} j$.
 In other words, only the $i \rightarrow j$ tie in the figure
 is the dependent variable here. The effect is defined as\\
 $s^{\rm el}_{i\vit}(x) = x_{ij} \sum_{h; h \neq j}  x_{ih}\, w_{hj}\,$;\\
 The covariate $W$ here always is used non-centered.


\begin{minipage}[t]{.7\textwidth}
\item
 {\em  $XW => X$ closure-2 of covariate} \texttt{(XWX2)}, \\
 This is an elementary effect, not an evaluation effect,
 comprising of the  `$XW => X $ closure of covariate' effect
 only the contribution of the number of weighted $X-W$ two-in-stars
 $i \stackrel{X}{\rightarrow} h $,
 $j \stackrel{W}{\rightarrow} h $.
 In other words, only the $i \rightarrow j$ tie in the figure here
 is the dependent variable. The effect is defined as\\
 $s^{\rm el}_{i\vit}(x) = x_{ij} \sum_{h; h \neq j}  x_{ih}\, w_{jh}\,$.\\
 The covariate $W$ here always is used non-centered.
\end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 3.9 2.0
\put{{\small $X$}} at 2.1 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
\medskip

\noindent
\textbf{\emph{Monadic covariate effects}}
\medskip

\noindent
For actor-dependent covariates $v_j$ (recall that these are
centered internally by \si, unless they are constructed with
\texttt{centered=FALSE}), as well as for dependent behavior
variables (for notational simplicity here also denoted $v_j$;
these variables also are centered),
the following effects are available:
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}

 \item {\em covariate-alter} or {\em covariate-related popularity}
 \texttt{(altX)},
 defined by the sum of the covariate over all actors to whom $i$ has a tie,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, v_j$;

 \item {\em covariate squared - alter} or {\em squared covariate-related popularity} \texttt{(altSqX)},
 defined by the sum of the squared centered covariate over all actors to whom $i$ has a tie,
 (not included if the variable has range less than 2)\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, v_j^2$;

 \item {\em right threshold covariate alter}
 \texttt{(altRThresholdX)},
 defined by the number of actors to whom $i$ has a tie
 and whose covariate value
 is greater than (to the right of)  or equal to a threshold $c$,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, I\{v_j \geq c\} $;\\
 for an actor covariate this (and the following effect)
 can also be obtained as \texttt{altX} for a transformed
 covariate, but this would be impossible for a behavioral dependent variable $V$;\\
 note that behavioral dependent variables always are centered!

 \item {\em left threshold covariate alter}
 \texttt{(altLThresholdX)},
 defined by the number of actors to whom $i$ has a tie
 and whose covariate value
 is smaller than (to the left of)  or equal to a threshold $c$,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, I\{v_j \geq c\} $;\\
 note that behavioral dependent variables always are centered;
 i.e., the overall mean is subtracted!

 \item {\em covariate-ego} or {\em covariate-related activity}
 \texttt{(egoX)},
 defined by $i$'s out-degree weighted by his covariate value,\\
 $s^{\rm net}_{i\vit}(x) = v_i \, x_{i+} $;

 \item {\em covariate squared - ego} or {\em squared covariate-related activity}
 \texttt{(egoSqX)},
 defined by $i$'s out-degree weighted by his covariate value,\\
 $s^{\rm net}_{i\vit}(x) = v_i^2 \, x_{i+} $;

 \item {\em right threshold covariate ego}
 \texttt{(egoRThresholdX)},
 defined by $i$'s out-degree when $i$'s covariate value
 is greater than (to the right of)  or equal to a threshold $c$,\\
 $s^{\rm net}_{i\vit}(x) = I\{v_i \geq c\} \, x_{i+} $;\\
 for an actor covariate this (and the following effect)
 can also be obtained by transforming
 the covariate, but this would be impossible for a behavioral dependent
 variable $V$;\\
 note that behavioral dependent variables always are centered!

 \item {\em left threshold covariate ego}
 \texttt{(egoLThresholdX)},
 defined by $i$'s out-degree when $i$'s covariate value
 is less than (to the right of) or equal to a threshold $c$,\\
 $s^{\rm net}_{i\vit}(x) = I\{v_i \leq c\} \, x_{i+} $;\\
 note that behavioral dependent variables always are centered!

 \item {\em absolute difference outdegree -- covariate}
 \texttt{(degAbsDiffX)},
 defined by the absolute difference between $i$'s out-degree and his covariate value,\\
 $s^{\rm net}_{i\vit}(x) = \ \mid x_{i+} \,-\, \lfloor v_i \rfloor \mid $;\\
 here $\lfloor v_i \rfloor $ is $v_i$ truncated to the largest integer
 not larger than $v_i$;
 working with a non-centered covariate may be advisable for this effect;

 \item {\em positive difference outdegree -- covariate}
 \texttt{(degPosDiffX)},
 defined by the positive part of the difference between $i$'s out-degree
 and her covariate value,\\
 $s^{\rm net}_{i\vit}(x) = \max \{ x_{i+} \,-\, \lfloor v_i \rfloor  ,\, 0 \} $;\\
 here $\lfloor v_i \rfloor $ is $v_i$ truncated to the largest integer
 not larger than $v_i$;
 working with a non-centered covariate may be advisable for this effect;

 \item {\em negative difference outdegree -- covariate}
 \texttt{(degNegDiffX)},
 defined by the negative part of the difference between $i$'s out-degree
 and her covariate value,\\
 $s^{\rm net}_{i\vit}(x) =  - \, \min \{ x_{i+} \,-\, \lfloor v_i \rfloor  ,\, 0 \}
 \,=\, \max \{ \lfloor v_i \rfloor \,-\, x_{i+} ,\, 0 \}  $;\\
 here $\lfloor v_i \rfloor $ is $v_i$ truncated to the largest integer
 not larger than $v_i$;
 working with a non-centered covariate may be advisable for this effect;

 \item \hypertarget{T_simx}{{\em covariate-related similarity}} \texttt{(simX)},
 \label{simx}
 defined by the sum of centered similarity scores ${\rm sim}^v_{ij}$
 between $i$  and the other actors $j$ to whom he is tied,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} ({\rm sim}^v_{ij} - \widehat{{\rm sim}^v}) $,\\
 where $\widehat{{\rm sim}^v}$ is the mean of all similarity scores, which are defined as
 ${\rm sim}^v_{ij}=\frac{\Delta-\vert v_i - v_j \vert}{\Delta}$ with
 $\Delta=\max_{ij}\vert v_i - v_j \vert$ being the observed range of the covariate $v$
 (this mean is given in the output file just before the
 ``initial data description''; it is also given, e..g., for data set \texttt{mydata}
 and constant covariate \texttt{mycov}, by
 \texttt{attr(mydata\$cCovars\$mycov, "simMean")});\\
 the definition of ${\rm sim}^v_{ij}$ is discussed in
 section~\ref{S_internal}, see (\ref{simV});

 \item {\em covariate-difference} or {\em covariate-related difference}
 \texttt{(diffX)},
 defined by the alter-minus-ego difference of the covariate over all actors
 to whom $i$ has a tie,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, (v_j - v_i)$;

 \item {\em absolute covariate-difference} or {\em covariate-related absolute difference}
 \texttt{(absDiffX)},
 defined by the absolute value of the alter-ego difference of the covariate over all actors
 to whom $i$ has a tie,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, |\,v_j - v_i\,|$;

 \item {\em covariate-squared-difference} or {\em covariate-related squared difference}
 \texttt{(diffSqX)},
 defined by the squared alter-minus-ego difference of the covariate over all actors
 to whom $i$ has a tie,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, (v_j - v_i)^2$;

 \item {\em covariate-ego $\times$ difference} or {\em covariate-related ego-difference interaction}
 \texttt{(egoDiffX)},
 defined by ego's value times the alter-minus-ego difference of the covariate over all actors
 to whom $i$ has a tie,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, v_i \, (v_j - v_i)$;


 \item {\em covariate-ego $\times$ alter} \texttt{(egoXaltX)},
 defined by the product of $i$'s covariate and the sum of those of his alters,\\
 $s^{\rm net}_{i\vit}(x) = v_i \, \sum_j x_{ij}\, v_j $;

 \item {\em covariate-ego $\times$ alter $\times$ reciprocity}
 \texttt{(egoXaltXRecip)},
 defined by the product of $i$'s covariate and the sum of those
 of his reciprocated alters,\\
 $s^{\rm net}_{i\vit}(x) = v_i \, \sum_j x_{ij}\,x_{ji}\, v_j $;

 \item {\em covariate-related similarity $\times$ reciprocity}
 \texttt{(simRecipX)}, defined by
 the sum of centered similarity scores for all
 reciprocal dyads in which $i$ is situated,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}x_{ji} ({\rm sim}^v_{ij} - \widehat{{\rm sim}^v}) $;

 \item \emph{same covariate}, which can also be called {\em covariate-related identity} \texttt{(sameX)},
 defined by the
 number of ties of $i$ to all other actors $j$ who have
 exactly the same value on the covariate,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, I\{v_i = v_j \} $,\\
 where the indicator function $I\{v_i = v_j \} $ is 1 if the condition $\{v_i = v_j \} $
 is satisfied, and 0 if it is not;\\

 \item {\em same covariate $\times$ reciprocity}
\texttt{(sameXRecip)} defined by the
 number of reciprocated ties between $i$ and all other actors $j$ who have
 exactly the same value on the covariate,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} x_{ji}\, I\{v_i = v_j \} $;

 \item {\em in-degree popularity weighted by sender's V }
  \texttt{(inPopX)}\\
 defined by the sum of values of $V$ for actors $h$
 for which there are ties  $ i \rightarrow j \leftarrow h$,
 i.e., an in-two-star;
 the value $\sum_h x_{hj}\,v_h$ can be regarded as a $V$-weighted
 version of the indegree of $j$:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h x_{hj}\,v_h  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h x_{hj}\,v_h}   $;\\
 note that to use this effect for $p=2$ the variable $V$ must be nonnegative,
 which implies that it must be non-centered;

 \item {\em in-degree activity weighted by sender's V } \texttt{(inActX)}\\
 defined by the sum of values of $V$ for actors $h$
 for which there are ties  $h \rightarrow i \rightarrow j$,
 i.e., a two-path with $i$ in the middle;
 the value $\sum_h x_{hi}\,v_h$ can be regarded as a $V$-weighted
 version of the indegree of $i$:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h x_{hi}\,v_h  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h x_{hi}\,v_h}   $;\\
 note that to use this effect for $p=2$ the variable $V$ must be nonnegative,
 which implies that it must be non-centered;


 \item {\em out-degree popularity weighted by receiver's V }  \texttt{(outPopX)}\\
 defined by the sum of values of $V$ for actors $h$
 for which there are ties  $ i \rightarrow j \rightarrow h$,
 i.e., at out-distance 2;
 the value $\sum_h x_{jh}\,v_h$ can be regarded as a $V$-weighted
 version of the outdegree of $j$:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h x_{jh}\,v_h  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h x_{jh}\,v_h}   $;\\
 note that to use this effect for $p=2$ the variable $V$ must be nonnegative,
 which implies that it must be non-centered;

 \item {\em out-degree activity weighted by receiver's V }   \texttt{(outActX)}\\
 defined by the sum of values of $V$ for actors $h$
 for which there are ties  $h \leftarrow i \rightarrow j$,
 i.e., an out-two-star;
 the value $\sum_h x_{ih}\,v_h$ can be regarded as a $V$-weighted
 version of the outdegree of $i$:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h x_{ih}\,v_h  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h x_{ih}\,v_h}   $;\\
 note that to use this effect for $p=2$ the variable $V$ must be nonnegative,
 which implies that it must be non-centered.

 \item {\em indegree popularity from same covariate}
\texttt{(sameXInPop)} defined by the
 number of incoming ties received by those to whom $i$ is tied
 and sent by others who have the same covariate value as $i$,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \sum_h x_{hj}\, I\{v_i = v_h \} $;

 \item {\em indegree popularity from different covariate}
\texttt{(diffXInPop)} defined by the
 number of incoming ties received by those to whom $i$ is tied
 and sent by others who have a different covariate value than $i$,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \sum_h x_{hj}\, I\{v_i \neq v_h \} $;

 \item {\em outdegree activity to same covariate}
\texttt{(sameXOutAct)} defined by the
 squared number of ties to those
 others who have the same covariate value as $i$,\\
 $s^{\rm net}_{i\vit}(x) = \big(\sum_j x_{ij} \,I\{v_i = v_j \}\big)^2 $;

 \item {\em outdegree activity to different covariate}
\texttt{(diffXOutAct)} defined by the
 squared number of ties to those
 others who have a different covariate value than $i$,\\
 $s^{\rm net}_{i\vit}(x) = \big(\sum_j x_{ij} \,I\{v_i \neq v_j \}\big)^2 $;


 \item {\em outdegree activity to homogeneous covariate}
\texttt{(homXOutAct)} defined by the
 sum of outgoing ties weighted by the number of outgoing
 ties to those with the same covariate value (as alter),\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \sum_h x_{ih} \,I\{v_j = v_h \} $;

 \item {\em outdegree activity weighted by alter's covariate}
  \texttt{(altXOutAct)} defined by the
 squared sum of ties weighted by alter's covariate values,\\
 $s^{\rm net}_{i\vit}(x) = \big(\sum_j x_{ij} \,v_j \big)^2 $;\\
 since the covariate here is used as a weight, this probably
 makes sense especially for non-centered covariates;


\item only in RSienaTest:  \emph{Simmelian alter X effect}, (\texttt{simmelianAltX}), the effect of
      Simmelian ties weighted by alter's value of $X$. The Simmelian transformation of the network is
      the network composed of all ties embedded in at least one complete triad:
\[
    x^{\rm{simm}}_{ij} \,=\, \left\{ \begin{array}{cl}
                               1 & x_{ij} = x_{ji} = 1 \text{ and} \\
                                  & \ \text{ there is at least one }
                                      h \text{ for which } x_{hi} = x_{ih} = x_{hj} = x_{jh} = 1 \\
                               0 & \text{else.}
                             \end{array} \right.
\]
      In other words, these ties must be reciprocal, and there must be at least one
      third actor to whom both have a mutual tie.
      The Simmelian alter $V$ effect  is  \\
$s^{\rm net}_{i\vit}(x ) = \sum_j  x^{\rm{simm}}_{ij}\,v_j $ .


 \item {\em same covariate $\times$ transitive triplets}
 \texttt{(sameXTransTrip)}, defined by the number of transitive triplets
 $i \rightarrow h \rightarrow j \leftarrow i$
 that have the same covariate value for $i$ and $j$,\\
 $s^{\rm net}_{i\vit}(x) =
 \sum_j x_{ij}\, x_{ih} \, x_{hj} \, I\{v_i = v_j\}$;

 \item {\em different covariate $\times$ transitive triplets}
 \texttt{(diffXTransTrip)}, defined by the number of transitive triplets
 $i \rightarrow h \rightarrow j \leftarrow i$
 that have different covariate values for $i$ and $j$,\\
 $s^{\rm net}_{i\vit}(x) =
 \sum_j x_{ij}\, x_{ih} \, x_{hj} \, I\{v_i \neq v_j\}$;


 \item {\em covariate-related similarity $\times$ transitive triplets}
 \texttt{(simXTransTrip)}, defined by the sum of transitive triplets
 $i \rightarrow h \rightarrow j \leftarrow i$
 weighted by the centered similarity scores between $i$ and $j$,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, x_{ih} \, x_{hj}
         ({\rm sim}^v_{ij} - \widehat{{\rm sim}^v}) $;

 \item {\em homogeneous covariate $\times$ transitive triplets}
 \texttt{(homXTransTrip)}, defined by the number of transitive triplets
 $i \rightarrow h \rightarrow j \leftarrow i$
 that have the same covariate value for $i$, $j$, and $h$,\\
 $s^{\rm net}_{i\vit}(x) =
 \sum_j x_{ij}\, x_{ih} \, x_{hj} \, I\{v_i = v_j = v_h\}$;

\item
\begin{minipage}[t]{.7\textwidth}
 {\em transitive triplets jumping to different V}
  \texttt{(jumpXTransTrip)}, \\
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            x_{ih}\, x_{hj}\,I\{v_i = v_h \neq v_j\}$;\\
 this refers to transitive closure, restricted to ``jump outside
 of $V$-groups'' in the sense that the focal actor and the mediating
 actor have the same value of $V$, but the target actor has a
 different value;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\diamond$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}


 \item {\em same covariate $\times$ transitive reciprocated triplets}
 \texttt{(sameXTransRecTrip)}, defined by the number of transitive
 reciprocated triplets
 $i \rightarrow h \rightarrow j \leftrightarrow i$
 that have the same covariate value for $i$ and $j$,\\
 $s^{\rm net}_{i\vit}(x) =
 \sum_j x_{ij}\, x_{ji}\, x_{ih} \, x_{hj} \, I\{v_i = v_j\}$;

 \item {\em different covariate $\times$ transitive reciprocated triplets}
 \texttt{(diffXTransRecTrip)}, defined by the number of transitive
 reciprocated triplets
 $i \rightarrow h \rightarrow j \leftrightarrow i$
 that have different covariate values for $i$ and $j$,\\
 $s^{\rm net}_{i\vit}(x) =
 \sum_j x_{ij}\, x_{ji}\, x_{ih} \, x_{hj} \, I\{v_i \neq v_j\}$;


\iffalse
 \item {\em covariate-related similarity $\times$ popularity alter}, defined by
 the sum of centered similarity scores between $i$ and the
 other actors $j$ to whom he is tied, weighted by the indegree of
 these other actors,\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}x_{+j}
       ({\rm sim}^v_{ij} - \widehat{{\rm sim}^v}) $.
\fi

 \item {\em ego $>$ alter for covariate} \texttt{(higher)} ,
 defined by the number of ties where $i$'s covariate
 is larger than alter's, while equality counts for half,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \text{dsign}(v_i - v_j) $,\\
 where $\text{dsign}(d) = 0$ for $d < 0$, 0.5 for $d = 0$,
 and 1 for $d > 0$.

 \item {\em covariate of indirect ties}
 \texttt{(IndTies)}, % \texttt{(IndTiesX)},
 defined by
 the sum of the covariate over the actors
 to whom $i$ is tied indirectly (at a geodesic distance of 2),\\
 $s^{\rm net}_{i\vit}(x) = \sum_j (1 -x_{ij})
                      \big( \max_h x_{ih}x_{hj} \big) v_j $;

 \item \begin{minipage}[t]{.68\textwidth}
for two-mode networks and for non-directed networks: \\
the {\em number of four-cycles from same covariate} \\
with shortName \texttt{(sameXCycle4)}, \\[0.3em]
 $s^{\rm net}_{i\vit}(x) =  \frac14 \sum_{j,k,h; \text{all different}}
            x_{ij}\, x_{ik}\, x_{hj}\, x_{hk}\,I\{v_i = v_h\} $;\\[0.3em]
 for parameter $p=2$ the square root is taken.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 0.5 to 4.5, y from 0 to 5
\put{\large$\bullet$} at  1 1
\put{\large$\circ$} at  4 1
\put{\large$\bullet$} at  1 3
\put{\large$\circ$} at  4 3
\put{$h$} at 0.5 1
\put{$i$} at 0.5 3
\put{$k$} at 4.5 1
\put{$j$} at 4.5 3
\arrow <2mm> [.2,.6]  from 1.2 3 to 3.8 3
\arrow <2mm> [.2,.6]  from 1.2 2.9 to 3.8 1.1
\arrow <2mm> [.2,.6]  from 1.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 1.2 1.1 to 3.8 2.9
\endpicture
\end{center}
\end{minipage}

\setcounter{savenumi}{\value{enumi}}
\end{enumerate}

\noindent
The following group of effects uses an auxiliary variable $\breve v_j$ which
can be called ``alters' $v$-average''.
It is described as the average value of $v_h$ for those $h$
to whom $j$ is tied, and defined mathematically by
\begin{equation}
  \breve v_j = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_h x_{jh}v_h}{x_{j+}}  &  \text{ if } x_{j+} > 0     \\
         0                                &  \text{ if } x_{j+} = 0  .
  \end{array}   \right.            \label{alt_av}
\end{equation}
(If $v$ is centered ---the default---, the value of 0 in case $x_{j+} = 0$
is also the mean value of the original variable.)\\
(It may be noted that this constructed variable $\breve v_j$
will not itself have exactly a zero mean generally.)

Note that this value is being updated during the simulations.
Network changes will change $\breve v_j$; if $v_j$ is a dependent behavior
variable, then behaviour changes will also change $\breve v_j$.

In the following list, there is no ego effect, because the ego effect
of $\breve v_j$ would be the same as the alter effect of $v_j$.

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}

\item \emph{covariate - alter at distance 2} \texttt{(altDist2)}.
      This effect is associated with an effect parameter
      which can have values 1 or 2.
      For parameter 1, it is
      defined as the sum of alters' covariate-average over all actors
      to whom $i$ has a tie,
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \breve v_j \hfill
            (\text{parameter 1}) \hfill
\]
      For parameter 2, it is defined similarly,
      but for an alters' covariate-average excluding
      ego:
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \breve v_j^{(-i)} \hfill
                          (\text{parameter 2}) \hfill
\]
      where
\begin{equation}
  \breve v_j^{(-i)} = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_{h \neq i} x_{jh}v_h}{x_{j+} - x_{ji}}  &
                                       \text{ if } x_{j+} - x_{ji} > 0     \\
         0                                &  \text{ if } x_{j+}- x_{ji} = 0  .
  \end{array}   \right.            \label{alt_av2}
\end{equation}
      To compute the contribution for this effect, note that
\[
 \sum_j x_{ij} \breve v_j^{(-i)} = \sum_j x_{ij} \,
                      \frac{x_{j+} \breve v_j - x_{ji}v_i}{x_{j+}-x_{ji}}
\]
      This shows that, given that $\breve v_j$ is being updated for all $j$,
      the contribution for this effect for parameter 2 can be computed as
      \[
       \frac{x_{j+} \breve v_j - x_{ji}v_i}{x_{j+}-x_{ji}}
      \]
      (where 0/0 is interpreted as 0).


\item \emph{total covariate - alter at distance 2} \texttt{(totDist2)}.
      This is like the previous effect, but using the total
      instead of the average value of alter's covariate.
      For parameter 1, it is  defined as
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \, x_{j+}\breve v_j \hfill
            (\text{parameter 1}) \hfill
\]
      and for parameter 2, as
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} (x_{j+} - x_{ji}) \breve v_j^{(-i)} \hfill
                          (\text{parameter 2}) \hfill
\]
      where $\breve v_j$ and $\breve v_j^{(-i)}$ are as above.

\item \emph{ego-(alter-distance-2) covariate - similarity} \texttt{(simEgoDist2)},
      defined as the sum of centered similarity  between $i$
      and alters' covariate-average, for all actors
      $j$ to whom $i$ has a tie,
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, \Big({\rm sim}(\grave v)_{ij}
  - \widehat{{\rm sim}^v}\Big) \ ,
\]
 where the similarity scores ${\rm sim}(\grave v)_{ij}$ are defined as
\[
{\rm sim}(\grave v)_{ij}=
 \frac{\Delta-\vert  v_i - \breve v_j^{(-i)} \vert}{\Delta} \ ,
\]
  where
 $\Delta=\max_{ij}\vert v_i - v_j \vert$ is the observed range of the
 \emph{original} covariate $v$,
 $\breve v_j^{(-i)}$ is as above in effect \texttt{(altDist2)}
 and $\widehat{{\rm sim}^v}$ is the mean of all similarity scores as used also
 for the \texttt{simX} effect; this centering is applied since version 1.1-285.
 For a constant covariate \texttt{mycov}, this mean is given by
 \texttt{attr(mydata\$cCovars\$mycov, "simMean")}.

\item \emph{covariate - similarity at distance 2} \texttt{(simDist2)} ,
      defined as the sum of centered similarity
      values for alters' covariate-average between $i$ and all actors
      $j$ to whom $i$ has a tie,
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \,\Big({\rm sim}(\breve v)_{ij}
  - \widehat{{\rm sim}^v}\Big) \ ,
\]
 where the similarity scores ${\rm sim}(\breve v)_{ij}$ are defined as
\[
{\rm sim}(\breve v)_{ij}=
 \frac{\Delta-\vert \breve v_i - \breve v_j \vert}{\Delta} \ ,
\]
 while
 $\Delta=\max_{ij}\vert v_i - v_j \vert$ is the observed range of the
 \emph{original} covariate $v$
 and $\widehat{{\rm sim}^v}$ is the mean of all similarity scores as used also
 for the \texttt{simX} effect; this centering is applied since version 1.1-285.
 For a constant covariate \texttt{mycov}, this mean is given by
 \texttt{attr(mydata\$cCovars\$mycov, "simMean")}.\\
\iffalse  until version 1.1-283:
 , and\\
 $\widehat{{\rm sim}(\breve v)}$ is the
 \emph{observed} mean of all these similarity scores;
 this observed mean is defined by calculating the $\breve v_i$ values
 for each of the observations $t_1$ to $t_{M-1}$, and averaging
 these
 $(M-1)n(n-1)$ (or $(M-1)n(n-1)/2$) similarity values.
% checking revealed that no centering is applied.
\fi
  Note that for both ego ($i$) and alter ($j$) their alters' covariate-average
  is used, so that this effect is about a comparison between the
  out-neighbourhoods of $i$ and $j$.

\item \emph{covariate - in - alter at distance 2} \texttt{(altInDist2)}.
     This is defined as the sum of alters' values for
     the average of the covariate values of all their
     incoming ties, except for the possibly incoming tie from ego:
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \check v_j^{(-i)}
\]
      where
\begin{equation}
  \check v_j^{(-i)} = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_{h \neq i} x_{hj}\,v_h}{x_{+j} - x_{ij}}  &
                                       \text{ if } x_{+j} - x_{ij} > 0     \\
         0                                &  \text{ if } x_{+j}- x_{ij} = 0  .
  \end{array}   \right.            \label{alt_inav2}
\end{equation}


\item \emph{total covariate - in - alter at distance 2} \texttt{(totInDist2)}.
     This is defined as the sum of alters' values for
     the total of the covariate values of all their incoming ties,
     except for the possibly incoming tie from ego:
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} (x_{+j} - x_{ij}) \check v_j^{(-i)} \ .
% for centered V this is   \,=\, \sum_j x_{ij} \sum_{h \neq i} x_{hj}\,v_h   \ .
\]

\item \emph{ego-(in-alter-distance-2) covariate - similarity} \texttt{(simEgoInDist2)},
      defined as the sum of centered similarity  between $i$
      and alters' covariate-in-average, for all actors
      $j$ to whom $i$ has a tie,
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, \Big({\rm sim}(\acute v)_{ij}
  - \widehat{{\rm sim}^v} \Big) \ ,
\]
 where the similarity scores ${\rm sim}(\acute v)_{ij}$ are defined as
\[
{\rm sim}(\acute v)_{ij}=
 \frac{\Delta-\vert  v_i - \check v_j^{(-i)} \vert}{\Delta} \ ,
\]
 while
 $ \check v_j^{(-i)}$ is as in the definition of \texttt{altInDist2},
 $\Delta=\max_{ij}\vert v_i - v_j \vert$ is the observed range of the
 \emph{original} covariate $v$, and $\widehat{{\rm sim}^v}$ is as above
 (see \texttt{simDist2}).\\
  Note that for ego ($i$) the own value is used and for alter ($j$) the alters' covariate-average
  (these are alter's in-alters!), so that this effect is about a comparison between $i$
   and the in-neighbourhoods of the $j$'s.

\setcounter{savenumi}{\value{enumi}}
\end{enumerate}



\iffalse
If there are multiple networks, their roles can be crossed here --
the alters' covariate average is calculated
in turn, respectively, for each dependent network variable;
and this is then used as an effect respectively for each of the
dependent network variables -- giving a total of $2 R_N^2$ effects
if $R_N$ is the number of dependent network variables. At this moment
I do not care for all this generality, but I guess the request
could come up at a later stage, so perhaps it is efficient to include
the generality already now.
\fi



\iffalse
 \item {\em user-defined interaction effects}
 as described in Section~\ref{S_int_eff}. The internal effect parameter
 is decomposed by \SI into its two or three constituents, see
 in the mentioned section. The interaction is defined on a tie basis:
 if two interacting effects are defined by
 $s^{\rm net}_{ia}(x) = \sum_j s^a_{ij}(x)$ and
 $s^{\rm net}_{ib}(x) = \sum_j s^b_{ij}(x)$
 (where $a$ and $b$ are calculated from the internal effect parameter $c$),
 then the interaction is defined by\\
 $s^{\rm net}_{i\vit}(x) = \sum_j s^a_{ij}(x) s^b_{ij}(x)$ .
\fi


\subsubsection{Special effects for non-directed networks}
\label{S_NonDirEff}

For non-directed networks
\citep[see Section~\ref{S_modeltype_nd} and][]{SnijdersPickup16},
in principle the same effects are used as above; you may search
in this manual for 'non-directed' to see the cases where the definition of
an effect for non-directed networks deviates from the
definition for directed networks.
Here we present a few effects that are defined specifically for
non-directed networks. The reason is that non-directed data will not allow
to differentiate between senders and receivers of ties, and instead
of working hypothetically with either ego or alter effects,
it may be preferable to utilize effects where ego and alter are
assumed to have equal contributions.

\begin{enumerate}
\item \emph{degree activity plus popularity effect} \texttt{(degPlus)}.
     This is defined as the sum of the in=outdegree popularity
     and in=outdegree activity effects; equivalently, this effect
     operates as the degree popularity combined with the degree activity effect
     under the assumption that the parameters for both are the same:
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} (x_{j+} + x_{i+}) \ .
\]
    For internal effect parameter equal to 2, the square roots are taken:
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} (\sqrt{x_{j+}} + \sqrt{x_{i+}}) \ .
\]
\item \emph{covariate effect} \texttt{(egoPlusAltX)}.
     This is defined as the sum of the covariate-ego and
     covariate-alter effects; equivalently, this effect
     operates as the covariate-ego combined with the covariate-alter effect
     under the assumption that the parameters for both are the same:
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} (v_i + v_j) \ .
\]
\item \emph{covariate-squared effect} \texttt{(egoPlusAltSqX)}.
     This is defined as the sum of the covariate-squared ego and
     covariate-squared alter effects; equivalently, this effect
     operates as the covariate-squared ego combined with the
     covariate-squared alter effect
     under the assumption that the parameters for both are the same:
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} (v_i^2 + v_j^2) \ .
\]
\end{enumerate}
For non-directed networks there is only one degree assortativity effect,
the degree assortativity effect which is the outdegree-indegree version
with short name \texttt{outInAss}.

\subsubsection{Multiple network effects}
\label{S_MultiNet}

An introduction to the analysis of multiple (multivariate) networks,
with a discussion of the basic effects, is given in \citet{SLT2013}.

See Section~\ref{S_constraints} for the possibility that two networks
have a deterministic constraint by being mutually exclusive,
or by one being implied by the other, or (rarely used, if ever)
by the union of them being the complete graph.

If there are multiple dependent networks, the definition of
cross-network effects is such that always, one network has the
role of the dependent variable, while the other network, or
networks, have the role of explanatory variable(s).
In the following list the network in the role of dependent variable
is denoted by the tie variables $x_{ij}$, while the
tie variables $w_{ij}$ denote the network that is the
explanatory variable.

Various of these effects are applicable only if the networks $X$
and $W$ satisfy certain conditions of conformability; for example,
the first effect of $W$ on $X$ is meaningful only if $W$ and $X$
have the same dimensions, i.e., either both are one-mode networks,
or both are two-mode networks with the same actor set for the second mode;
as another example, the second effect, of incoming $W$ on $X$,
is applicable only if $W$ and $X$ are one-mode networks.
These conditions are hopefully clear from logical considerations,
and drawing a little diagram of the involved nodes and arrows
will be helpful in cases of doubt.

In the \SI output for projects with multiple networks,
the dependent network in each given effect is indicated by
the first part of the effect name.
In the list below, a more or less normally formulated name is given first,
then the name used in \SI between parentheses,
using $X$ as the name for the dependent network and $W$
as the name for the explanatory network,
then between parentheses in \texttt{typewriter font} the \texttt{shortName}
as used by \rs.
Since this is a co-evolution model, \SI will include also the effects
where the roles of $X$ and $W$ are reversed.

The first three effects are dyadic. The first can be regarded
as a main effect; the reciprocity and mutuality effects
will require rather big data sets to be empirically distinguished
from each other.
\begin{enumerate}
 \item {\em Effect of W on X} ($X$: $W$)  \texttt{(crprod)},\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \, w_{ij}  $ ;\\
 $i \stackrel{W}{\rightarrow} j$ leads to  $i \stackrel{X}{\rightarrow} j$;
 this is also called the dyadic entrainment effect;\\
 if one of the contraints of Section~\ref{S_constraints} is in use,
 this effect should not be included because its role is taken over by the
 constraint;

 \item {\em Effect of incoming W on X} ($X$: reciprocity with $W$)  \texttt{(crprodRecip)},\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \, w_{ji}  $ ;\\
 this can be regarded as generalized exchange:
 $j \stackrel{W}{\rightarrow} i$ leads to  $i \stackrel{X}{\rightarrow} j$;

 \item {\em Effect of mutual ties in W on X} ($X$: mutuality with $W$)  \texttt{(crprodMutual)},\\
 $s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \, w_{ij} \, w_{ji}  $ ;\\
 $j \stackrel{W}{\leftrightarrow} i$ leads to  $i \stackrel{X}{\rightarrow} j$.
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
\smallskip
The following seven are degree-related effects, where nodal degrees
in the $W$ network have effects on popularity or activity in the
$X$  network. They use an internal effect parameter $p$, which
mostly will be 1 or 2.

To decrease correlation with other effects, the
$W$-degrees are centered by subtracting the value $\bar w$,
which is the average degree of $W$ across all observations.

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
 \item {\em Effect of in-degree in W on X-popularity } ($X$: indegree$^{1/p}$ $W$ popularity)   \texttt{(inPopIntn)}\\
 defined by   the sum of  the $W$-in-degrees of the others to whom $i$ is tied,
 for parameter $p = 2$ the square roots of the $W$-in-degrees:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, ({w_{+j}} - {\bar w})  $ or\\
for $p=2$ \  $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, (\sqrt{w_{+j}} - \sqrt{\bar w})  $;\\

 \item {\em Effect of in-degree in W on X-activity } ($X$: indegree$^{1/p}$ $W$ activity)  \texttt{(inActIntn)}\\
 defined by the $W$-in-degrees of $i$ (for $p = 2$ its square root)
 times $i$'s $X$-out-degree:\\[0.2em]
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, ({w_{+i}} - {\bar w})
                 =  x_{i+}\, ({w_{+i}} - {\bar w}) $ or\\[0.2em]
for $p=2$ \  $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, (\sqrt{w_{+i}} - \sqrt{\bar w})
                 =  x_{i+}\, (\sqrt{w_{+i}} - \sqrt{\bar w}) $;\\[0.2em]

 \item {\em Effect of out-degree in W on X-popularity } ($X$: outdegree$^{1/p}$ $W$ popularity) \texttt{(outPopIntn)}\\
 defined by   the sum of  the $W$-out-degrees of the others to whom $i$ is tied,
 for parameter $p = 2$ the square roots of the $W$-out-degrees:\\[0.2em]
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, ({w_{j+}} - {\bar w})$ or\\[0.2em]
for $p=2$ \  $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, (\sqrt{w_{j+}} - \sqrt{\bar w})$;\\[0.2em]

 \item {\em Effect of out-degree  in W on X-activity } ($X$: outdegree$^{1/p}$ $W$ activity) \texttt{(outActIntn)}\\
 defined by the $W$-out-degrees of $i$ (for $p = 2$ its square root)
 times $i$'s $X$-out-degree:\\[0.2em]
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, ({w_{i+}} - {\bar w}) =
                           x_{i+}\, ({w_{i+}} - {\bar w}) $ or\\[0.2em]
for $p=2$ \  $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, (\sqrt{w_{i+}} - \sqrt{\bar w}) =
                           x_{i+}\, (\sqrt{w_{i+}} - \sqrt{\bar w}) $;\\[0.2em]

 \item {\em Effect of both in-degrees in W on X-popularity } ($X$: both indegrees$^{1/p}$ $W$ ) \texttt{(both)}\\
 defined by   the sum of  the $W$-in-degrees of the others to whom $i$ is tied
 multiplied by the centered $W$-in-degree of $i$,
 for parameter $p = 2$ the square roots of the $W$-in-degrees:\\[0.2em]
 $s^{\rm net}_{i\vit}(x) =
   \sum_j x_{ij}\, ({w_{+i}} - {\bar w}) \, ({w_{+j}} - {\bar w})  $ or\\[0.2em]
for $p=2$ \  $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\,
 (\sqrt{w_{+i}} - \sqrt{\bar w}) \, (\sqrt{w_{+j}} - \sqrt{\bar w})  $;\\[0.2em]
 this can be regarded as an interaction between the effect of $W$-in-degree on $X$-popularity
 and the effect of $W$-in-degree on $X$-activity.

 \item {\em Duplex XW out-degree activity effect } ($X$: duplex $W$ outdegree$^{1/p}$ activity)\\
    \texttt{(doubleOutAct)}\\
  which is like the out-degree activity effect, but now for the degrees in the
  joined $X$ \underline{and} $W$ network;
 for parameter $p = 2$ the square root of the out-degrees is taken:\\[0.4em]
 $s^{\rm net}_{i\vit}(x) =  \big(\sum_j x_{ij}\,w_{ij} \big)^2  $ or\\[0.4em]
for $p=2$ \  $s^{\rm net}_{i\vit}(x) =
        \sum_j x_{ij}\,w_{ij} \sqrt{\sum_h x_{ih}\,w_{ih}^{\phantom{0}} }  $\ ;\\

 \item {\em Duplex XW in-degree popularity effect } ($X$: duplex $W$ indegree$^{1/p}$ popularity)\\
    \texttt{(doubleInPop)}\\
  which is like the in-degree popularity effect, but now for the degrees in the
  joined $X$ \underline{and} $W$ network;
 for parameter $p = 2$ the square root of the out-degrees is taken:\\[0.4em]
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\,w_{ij}\sum_h x_{hj}\,w_{hj}   $ or\\[0.4em]
for $p=2$ \  $s^{\rm net}_{i\vit}(x) =
        \sum_j x_{ij}\,w_{ij} \sqrt{\sum_h x_{hj}\,w_{hj}^{\phantom{0}} }  $\ .\\

\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
\smallskip
The betweenness effect is another positional effect:
a positional characteristic in the $W$ network affects the
ties in the $X$ network, but now the position is the betweenness count,
defined as the number of pairs of nodes that are not directly connected:
 $j \stackrel{W}{\nrightarrow} h$ ,
but that are connected through $i$:
 $j \stackrel{W}{\rightarrow} i  \stackrel{X}{\rightarrow} h$ .
 Again there is an internal effect parameter $p$, usually
1 or 2.
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
 \item
{\em Effect of W-betweenness on X-popularity } ($X$: betweenness$^{1/p}$ $W$ popularity)  \\
 \texttt{(betweenPop)}
 defined by   the sum of  the $W$-betweenness counts of the others to whom $i$ is tied:\\[0.2em]
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\,
        \left(\sum_{h,k; h \neq k}w_{hj}\,w_{jk}\,(1-w_{hk})\right)^{1/p}  $;\\

\item
\begin{minipage}[t]{.70\textwidth}
  mixed twopath activity effect ($X$: twopath$^{1/p}$ $W$ activity)  \texttt{(outOutActIntn)}
   defined by the outdegree of $i$
   multiplied by sum of $X$-outdegrees of those to whom $i$ has an $X$-tie:\\
   for $p=1$, this is\\[0.4em]
 $s^{\rm net}_{i\vit}(x) =   x_{i+}\, \sum_h w_{ih} \big(x_{h+} - \bar x\big)$\\[0.4em]
 and for $p=2$, there is a square root transformation:\\[0.4em]
 $s^{\rm net}_{i\vit}(x) =  x_{i+},\ \sum_h w_{ih} \big(\sqrt{x_{h+}} - \sqrt{\bar x}\big)$\\[0.4em]
 where $\bar x$ is the average degree over all waves.
\setcounter{savenumi}{\value{enumi}}
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $X$}} at 3.7 2.4
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from  3.2 2.8 to 4.5 2.8
\endpicture
\end{center}
\vfill
\end{minipage}
\end{enumerate}
\smallskip
Further there are a number of mixed triadic effects.

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
\item
\begin{minipage}[t]{.7\textwidth}
 {\em agreement along W leading to X}, ($X$: from $W$ agreement)  \texttt{(from)} \\[0.2em] % \texttt{(fromWAgree)}\\
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{ih}\, w_{jh}\,$;\\[0.2em]
 this refers to agreement of actors with respect to their $W$-choices
 (structural equivalence with respect to outgoing $W$-choices);
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of joint $W$ choices of others,
 $i \stackrel{W}{\rightarrow} h \stackrel{W}{\leftarrow} j$.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from  3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip
\item
\begin{minipage}[t]{.7\textwidth}
 {\em agreement along mutual W-ties leading to X}, ($X$: from $W$ mutual agreement) \texttt{(fromMutual)}
           \\[0.2em] % \texttt{(fromWMutualAgree)}\\
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{ih}\,  w_{hi}\, w_{jh}\, w_{hj}\,$;\\[0.2em]
 this refers to agreement of actors with respect to their mutual $W$-choices
 (structural equivalence with respect to mutual $W$-choices);
 the contribution  of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of joint mutual $W$ choices of others,
 $i \stackrel{W}{\leftrightarrow} h \stackrel{W}{\leftrightarrow} j$.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from  3.9 1.1732 to 3.1 2.559
\arrow <2mm> [.2,.6]  from 2.9 2.559 to  2.1 1.1732
\arrow <2mm> [.2,.6]  from  3.1 2.559 to  3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip
 \item
\begin{minipage}[t]{.7\textwidth}
 {\em  W leading to agreement along X}, ($X$: $W$ to agreement) \texttt{(to)} \\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{ih}\, x_{hj}\,$;\\[0.2em]
 this refers to the closure of mixed $W-X$ two-paths;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of mixed $W-X$ two-paths
 $i \stackrel{W}{\rightarrow} h \stackrel{X}{\rightarrow} j$.\\
 This is an elementary effect for actor $i$:
 only the $x_{ij}$ tie indicator in the formula,
 corresponding to  the tie $i \stackrel{X}{\rightarrow} j$,
 is the dependent variable here.\\
 The interpretation is that actors have the tendency to make the same
 outgoing $X$-choices as those to whom they have a $W$-tie.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $X$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
 \item
\begin{minipage}[t]{.7\textwidth}
 {\em  XWX closure of $W$}, \texttt{(cl.XWX)} \\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, x_{ih}\, w_{hj}\,$;\\[0.2em]
 this refers to the closure of mixed $X-W$ two-paths;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of mixed $X-W$ two-paths
 $i \stackrel{X}{\rightarrow} h \stackrel{W}{\rightarrow} j$
 plus the number of mixed $X-W$ two-in-stars
 $i \stackrel{X}{\rightarrow} h $,
 $j \stackrel{W}{\rightarrow} h $.\\
 The interpretation is the closure of $X \rightarrow W$ paths:
 if there is a tie $h \stackrel{W}{\rightarrow} j$, then ties
  $i \stackrel{X}{\rightarrow} j $ and  $i \stackrel{X}{\rightarrow} h $
  will tend to entrain each other.\\
  (The reported target statistic is multiplied by 2.)
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $X$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
\smallskip
There are two partial variants of this effect; they can be
distinguished not by the Method of Moments, but only
by Maximum Likelihood and Bayesian estimation.
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}

 \item
 {\em  XWX closure-1 of $W$}, \texttt{(cl.XWX1)} \\
 This is an elementary effect, not an evaluation effect,
 comprising of the  `XWX closure of $W$' effect
 only the contribution of the
 the number of mixed $X-W$ two-paths
 $i \stackrel{X}{\rightarrow} h \stackrel{W}{\rightarrow} j$.\\
 So the dependent variable here is only the tie variable
 $i \rightarrow j$ in the figure above. The effect is defined as\\[0.2em]
 $s^{\rm el}_{i\vit}(x) = x_{ij} \sum_{h; h \neq j}  x_{ih}\, w_{hj}\,$;\\


\begin{minipage}[t]{.7\textwidth}
\item
 {\em  XWX closure-2 of $W$}, \texttt{(cl.XWX2)} \\
 This is an elementary effect, not an evaluation effect,
 comprising of the  `XWX closure of $W$' effect
 only the contribution of the number of mixed $X-W$ two-in-stars
 $i \stackrel{X}{\rightarrow} h $,
 $j \stackrel{W}{\rightarrow} h $.\\
 In other words, only the $i \rightarrow j$ tie in the figure here
 is the dependent variable. The effect is defined as\\[0.2em]
 $s^{\rm el}_{i\vit}(x) = x_{ij} \sum_{h; h \neq j}  x_{ih}\, w_{jh}\,$.
\end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 3.9 2.0
\put{{\small $X$}} at 2.1 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

 \item
\begin{minipage}[t]{.7\textwidth}
 {\em  shared mixed incoming X and W }, ($X$: mixed incoming with $W$) \texttt{(mixedInXW)} \\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, x_{hi}\, w_{hj}\,$;\\[0.2em]
 this refers to the closure of mixed incoming $X$ and $W$ ties;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of mixed $X-W$ out-two-stars
 $h \stackrel{X}{\rightarrow} i,  h \stackrel{W}{\rightarrow} j$.\\
 This is an elementary effect for actor $i$:
 only the $x_{ij}$ tie indicator in the formula,
 corresponding to  the tie $i \stackrel{X}{\rightarrow} j$,
 is the dependent variable here.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $X$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip
 \item
\begin{minipage}[t]{.7\textwidth}
 {\em  shared mixed incoming W and X}, ($X$: mixed incoming from $W$) \texttt{(mixedInWX)} \\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{hi}\, x_{hj}\,$;\\[0.2em]
 this refers to the closure of mixed incoming $W$ and $X$ ties;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of mixed $W-X$ out-two-stars
 $h \stackrel{W}{\rightarrow} i,  h \stackrel{X}{\rightarrow} j$.\\
 This is an elementary effect for actor $i$:
 only the $x_{ij}$ tie indicator in the formula,
 corresponding to  the tie $i \stackrel{X}{\rightarrow} j$,
 is the dependent variable here.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $X$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip
 \item
\begin{minipage}[t]{.7\textwidth}
 {\em mixed $WW=>X$ closure}, ($X$: closure of $W$) \texttt{(closure)}  \\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{ih}\, w_{hj}\,$;\\[0.2em]
 this refers to the closure of $W-W$ two-paths;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of $W-W$ two-paths
 $i \stackrel{W}{\rightarrow} h \stackrel{W}{\rightarrow} j$.\\
 The interpretation is that actors have the tendency to make
 and maintain $X$-ties to those to whom they have an indirect
 (distance 2) $W$-tie: `$W$-ties of $W$-ties tend to become $X$-ties';
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}

\item
\begin{minipage}[t]{.7\textwidth}
 {\em mixed cyclic $WW=>X$ closure}, ($X$: cyclic closure of $W$) \texttt{(cyClosure)}  \\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{jh}\, w_{hi}\,$;\\[0.2em]
 this refers to the cyclic closure of $W-W$ two-paths;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of $W-W$ two-paths
 $j \stackrel{W}{\rightarrow} h \stackrel{W}{\rightarrow} i$.\\
 The interpretation is that actors have the tendency to make
 and maintain $X$-ties to those from whom they receive an indirect
 (distance 2) $W$-tie: `$W$-ties of $W$-ties tend to become
 reciprocated by $X$-ties'.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from  2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to  3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}

\item
\begin{minipage}[t]{.7\textwidth}
 {\em closure of shared incoming $WW=>X$}, \\
 ($X$: shared incoming $W$) \texttt{(sharedIn)}  \\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\, w_{hi}\, w_{hj}\,$;\\[0.2em]
 this refers to shared incoming $W$ ties contributing
 to the tie $i \stackrel{X}{\rightarrow} j$.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from  2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from   3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}

\noindent The following two Jaccard similarity effects also are triadic,
 but not expressed as sums over triads.

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
 \item {\em Jaccard similarity with respect to outgoing $W$ ties effect} \texttt{(JoutMix)},
 the Jaccard similarity with respect to outgoing $W$-ties,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij} \, J_{W,\, \text{out}}(i,j)$, where
 \[
 J_{W,\, \text{out}}(i,j) \,=\, \frac{\sum_h w_{ih}\,x_{jh}}
                     {w_{i+} + w_{j+} - \sum_h w_{ih}\,w_{jh}}
 \]
 (where 0/0 is taken as 0).

 \item {\em Jaccard similarity with respect to incoming $W$ ties effect} \texttt{(JinMix)},\\
 defined by
 the Jaccard similarity with respect to incoming $W$-ties,\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij} \, J_{W,\, \text{in}}(i,j)$, where
 \[
 J_{W,\, \text{in}}(i,j) \,=\, \frac{\sum_h w_{hi}\,w_{hj}}
                     {w_{+i} + w_{+j} - \sum_h w_{hi}\,w_{hj}}
 \]
 (where again 0/0 is taken as 0).

 \item Five variations of mixed \emph{GWESP (geometrically weighted edgewise
  shared partners)} effects: \texttt{gwespFFMix, gwespBBMix,
  gwespFBMix, gwespBFMix, gwespRRMix}, and for non-directed
  and two-mode networks the sixth version \texttt{gwespMix}. \\
  See above for the GWESP effects for one-mode networks for their
  further background.
  These are geometrically downweighted analogues:
   \texttt{gwespFFMix} of \texttt{closure},
   \texttt{gwespBBMix} of \texttt{cyClosure},
  \texttt{gwespFBMix} of \texttt{from}, \texttt{gwespBFMix} of \texttt{sharedIn},
  and \texttt{gwespRRMix} of \texttt{fromMutual}.
  The \texttt{gwespFFMix} effect is defined by
\[
  \text{GWESPFF}(i, \alpha) \,=\,
       \sum_{j=1}^n x_{ij} \,
                        e^{\alpha} \,\Big\{1 \,-\, \big(1 -
                        e^{-\alpha}\big)^{\sum_{h=1}^n w_{ih}w_{hj} }  \Big\}
      \,   \ ,
\]
where the convention is used that $w_{jj} = 0$ for all $j$.
See the figures above in the presentation of the \texttt{gwespFF}
effect.

The parameter $\alpha$ is a tuning parameter that may range from 0 to $\infty$.
The internal effect parameter is defined as $100 \times \alpha$.
An often used value is $\alpha = \log(2) = 0.69$ \citep{SPRH06},
corresponding to an internal effect parameter of 69,
but it is worthwhile to try out different values of $\alpha$
to see which one gives the best fit.
For large $\alpha$ the  \texttt{gwespFFMix} effect will
approximate the \texttt{closure} effect, and similarly for the
other correspondences mentioned above.

The other types of mixed GWESP effect are analogous, with
different tie orientations. They are defined as follows:\\
\texttt{gwespBBMix}: ${\sum_{h=1}^n w_{ih}w_{hj} }$
is replaced by ${\sum_{h=1}^n w_{hi}w_{jh} }$;\\[0.3em]
\texttt{gwespFBMix}: ${\sum_{h=1}^n w_{ih}w_{hj} }$
is replaced by ${\sum_{h=1}^n w_{ih}w_{jh} }$;\\[0.3em]
\texttt{gwespBFMix}: ${\sum_{h=1}^n w_{ih}w_{hj} }$
is replaced by ${\sum_{h=1}^n w_{hi}w_{hj} }$;\\[0.3em]
\texttt{gwespRRMix}: ${\sum_{h=1}^n w_{ih}w_{hj} }$
is replaced by ${\sum_{h=1}^n w_{ih}w_{hi}w_{jh}w_{hj} }$;\\[0.3em]
\texttt{gwespMix} for two-mode $W$:\ ${\sum_{h=1}^n w_{ih}w_{hj} }$
is replaced by ${\sum_{h=1}^m w_{ih}w_{jh} }$.
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}

\noindent
Then there are effects using mixed configurations on four nodes
(cf.\ \texttt{sharedPop}).
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
 \item
\begin{minipage}[t]{.7\textwidth}
 {\em shared W leading to agreement along X}, ($X$: shared $W$ to agreement) \texttt{(sharedTo)} \\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j,h,k; k \neq i} x_{ij}\, x_{kj}\,
                  \big( w_{ih}\, w_{kh} - c\big ) \,$;\\[0.2em]
 this refers to the closure of mixed $W-X$ three-paths;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of mixed $W-X$ three-paths
 $i \stackrel{W}{\rightarrow} h  \stackrel{W}{\leftarrow} k  \stackrel{X}{\rightarrow} j$.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  2 3
\put{\large$\bullet$} at  4 3
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 2 3.6
\put{$k$} at 4 3.6
\put{{\small $W$}} at 1.6 2
\put{{\small $W$}} at 3   3.3
\put{{\small $X$}} at 4.4 2
\put{{\small $X$}} at 3 0.6
\arrow <2mm> [.2,.6]  from 2.25 1 to 3.75 1
\arrow <2mm> [.2,.6]  from 2 1.25 to 2 2.75
\arrow <2mm> [.2,.6]  from 3.75 3 to 2.25 3
\arrow <2mm> [.2,.6]  from 4 2.75 to 4 1.25
\endpicture
\end{center}
\vfill
\end{minipage}


 The effect parameter $p$ can take the values 1, 2, 3 and 4.
  The value $c$, a constant for centering,
   is the average of the observed values $w_{ih}\, w_{kh}$:\\[0.5em]
 $ c \,=\, \left\{ \begin{array}{ll} \big(1/Mn(n-1)\big)
               \sum_{m,h} \big( w_{+h}^2(t_m) - w_{+h}(t_m)\big) & (p \geq 3) \\[0.3em]
                            0  & (p < 3) \ .
    \end{array} \right. $\\[0.5em]
 Note that since this is the evaluation function for actor $i$ with
 respect to network $X$, only the $x_{ij}$ tie indicator in the formula,
 corresponding to  the tie $i \stackrel{X}{\rightarrow} j$,
 is the dependent variable here.\\
 The interpretation is that actors have the tendency to make the same
 outgoing $X$-choices as those ($k$) with whom they share many outgoing $W$-ties.\\
 For $p=2$ and $p=4$, the square root is taken: \\[0.3em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j,k; k \neq i} x_{ij}\, x_{kj}\,
 \Big( \sqrt{\sum_{h} w_{ih}\, w_{kh} } \,-\, \sqrt{c} \Big)\,$.\\

 This can be regarded as a higher-order effect related to indegree-popularity.
 The differences between the centered and non-centered versions amount to
 a multiple of the indegree-popularity (without $\sqrt{}$) \texttt{inPop} effect.
 Therefore, when the \texttt{sharedTo} effect is used, it is advisable
 also to include the \texttt{inPop} effect, so as to avoid misinterpretations.
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}

\noindent
The mixed degree-related effects can be weighted with monadic covariates $V$,
as implemented by the following four effects.
(For two-mode networks, these effects are meaningful only in special cases;
however, this is not checked when creating the effects object, so errors
can lead here to meaningless results or to crashes.)
Note that, unlike the unweighted effects
\texttt{inPopIntn, inActIntn, outPopIntn, outActIntn}, the $W$-degrees
here are not centered (well, they are also not really degrees).

Weights at the other side of the $W$-tie can be obtained by interactions of
\texttt{inPopIntn, inActIntn, outPopIntn, outActIntn} with the ego or
alter effects of $V$.
Different types of weighting are available through the distance-two
effects \texttt{altDist2W} and \texttt{totDist2W}, see below.

For these effects the other network $W$ is given as \texttt{interaction1},
and the covariate $V$ as \texttt{interaction2}.

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
 \item {\em Effect of in-degree in W, weighted by sender's V, on X-popularity }
 ($X$: indegree$^{1/p}$ $W$ weighted by $V$ popularity)   \texttt{(inPopIntnX)}\\
 defined by the sum of values of $V$ for actors $h$
 for which there are ties  $ i \stackrel{X}{\rightarrow} j \stackrel{W}{\leftarrow} h$,
 i.e., at mixed $X - W$ out-in  distance 2;
 the value $\sum_h w_{hj}\,v_h$ can be regarded as a $V$-weighted
 version of the $W$-indegree of $j$:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h w_{hj}\,v_h  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h w_{hj}\,v_h}   $;\\
 note that to use this effect for $p=2$ the variable $V$ must be nonnegative,
 which implies that it must be non-centered;

 \item {\em Effect of in-degree in W, weighted by sender's V, on X-activity }
 ($X$: indegree$^{1/p}$ $W$ weighted by $V$ activity)   \texttt{(inActIntnX)}\\
 defined by the sum of values of $V$ for actors $h$
 for which there are ties  $h \stackrel{W}{\rightarrow} i \stackrel{X}{\rightarrow} j$,
 i.e., a mixed $W - X$ two-path with $i$ in the middle;
 the value $\sum_h w_{hi}\,v_h$ can be regarded as a $V$-weighted
 version of the $W$-indegree of $i$:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h w_{hi}\,v_h  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h w_{hi}\,v_h}   $;\\
 note that to use this effect for $p=2$ the variable $V$ must be nonnegative,
 which implies that it must be non-centered;


 \item {\em Effect of out-degree in W, weighted by receiver's V, on X-popularity }
 ($X$: outdegree$^{1/p}$ $W$ weighted by $V$ popularity)   \texttt{(outPopIntnX)}\\
 defined by the sum of values of $V$ for actors $h$
 for which there are ties  $ i \stackrel{X}{\rightarrow} j \stackrel{W}{\rightarrow} h$,
 i.e., at mixed $X - W$ outgoing  distance 2;
 the value $\sum_h w_{jh}\,v_h$ can be regarded as a $V$-weighted
 version of the $W$-outdegree of $j$:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h w_{jh}\,v_h  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h w_{jh}\,v_h}   $;\\
 note that to use this effect for $p=2$ the variable $V$ must be nonnegative,
 which implies that it must be non-centered;

 \item {\em Effect of out-degree in W, weighted by receiver's V, on X-activity }
 ($X$: outdegree$^{1/p}$ $W$ weighted by $V$ activity)   \texttt{(outActIntnX)}\\
 defined by the sum of values of $V$ for actors $h$
 for which there are ties  $h \stackrel{W}{\leftarrow} i \stackrel{X}{\rightarrow} j$,
 i.e., a mixed $W - X$ two-star;
 the value $\sum_h w_{ih}\,v_h$ can be regarded as a $V$-weighted
 version of the $W$-outdegree of $i$:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h w_{ih}\,v_h  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h w_{ih}\,v_h}   $;\\
 note that to use this effect for $p=2$ the variable $V$ must be nonnegative,
 which implies that it must be non-centered.
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}

Similarly, there are some mixed degree effects restricting the summation
to third actors $h$ with the same covariate value as $i$.
Here again, the other network $W$ is given as \texttt{interaction1},
and the covariate $V$ as \texttt{interaction2}.

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
 \item {\em Effect of in-degree in W, restricted to same $V$, on X-popularity }
 ($X$: indegree$^{1/p}$ $W$ from same $V$ - popularity)   \texttt{(sameXinPopIntn)}\\
 defined by the number of incoming $W$ ties to alter from other actors $h$
 having the same value of $V$ as ego:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h w_{hj}\,I\{v_i = v_h\}  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h w_{hj}\,I\{v_i = v_h\}}   $;

 \item {\em Effect of in-degree in W, restricted to same $V$, on X-activity }
 ($X$: indegree$^{1/p}$ $W$ from same $V$ - activity) \texttt{(sameXinActIntn)}\\
 defined by the number of incoming $W$ ties to ego from other actors $h$
 having the same value of $V$ as ego:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h w_{hi}\,I\{v_i = v_h\}  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h w_{hi}\,I\{v_i = v_h\}}   $;

 \item {\em Effect of out-degree in W, restricted to same $V$, on X-popularity }
 ($X$: outdegree$^{1/p}$ $W$ to same $V$ - popularity)   \texttt{(sameXoutPopIntn)}\\
 defined by the number of outgoing $W$ ties from alter to other actors $h$
 having the same value of $V$ as ego:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h w_{jh}\,I\{v_i = v_h\}  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h w_{jh}\,I\{v_i = v_h\}}   $;

 \item {\em Effect of out-degree in W, restricted to same $V$, on X-activity }
 ($X$: outdegree$^{1/p}$ $W$ to same $V$ - activity) \texttt{(sameXoutActIntn)}\\
 defined by the number of outgoing $W$ ties from ego to other actors $h$
 having the same value of $V$ as ego:\\
 $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sum_h w_{ih}\,I\{v_i = v_h\}  $ \\
 or for $p=2$ \\
   $s^{\rm net}_{i\vit}(x) =  \sum_j x_{ij}\, \sqrt{\sum_h w_{ih}\,I\{v_i = v_h\}}   $.
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}

\noindent
Then there are some  mixed triadic effects
restricted to triples with the same or different values on a monadic
covariate $V$.
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
\item
\begin{minipage}[t]{.7\textwidth}
 {\em agreement along W leading to X, for same V}, \\
($X$: from $W$ agr.\ $\times$ same $V$)  \texttt{(covNetNet)},\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h}
                     x_{ij}\, w_{ih}\, w_{jh}\,I\{v_i = v_j\}$;\\[0.2em]
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 this refers to agreement of actors with respect to their $W$-choices
 (structural equivalence with respect to outgoing $W$-choices), but only
 for actors sharing the same value of a covariate $V$;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of joint $W$ choices of others,
 $i \stackrel{W}{\rightarrow} h \stackrel{W}{\leftarrow} j$,
 counting only those for which $v_i = v_j$.
      \end{minipage}
% Until 05/05/16, this stated "for which v_i=v_j=v_h", which was false.
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\circ$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from  3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\item
\begin{minipage}[t]{.7\textwidth}
 {\em agreement along W leading to X, for homogeneous V}, \\
($X$: from $W$ agr.\ $\times$ hom.\ $V$)  \texttt{(homCovNetNet)},\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h}
                     x_{ij}\, w_{ih}\, w_{jh}\,I\{v_i = v_j = v_h\}$;\\[0.2em]
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 this refers to agreement of actors with respect to their $W$-choices
 (structural equivalence with respect to outgoing $W$-choices), but only
 for actors and choices sharing the same value of a covariate $V$;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of joint $W$ choices of others,
 $i \stackrel{W}{\rightarrow} h \stackrel{W}{\leftarrow} j$,
 counting only those for which $v_i = v_j= v_h$.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from  3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\item
\begin{minipage}[t]{.7\textwidth}
 {\em mixed WW $\Rightarrow$ X closure, same-V path jumping to different V}
($X$: $W$ closure jumping $V$),   \texttt{(jumpWWClosure)}\\
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            w_{ih}\, w_{hj}\,I\{v_i = v_h \neq v_j\}$;\\[0.2em]
 this refers to the closure of $W-W$ paths, restricted to ``jump outside
 of $V$-groups'' in the sense that the focal actor and the mediating
 actor have the same value of $V$, but the target actor has a
 different value.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\diamond$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\item
\begin{minipage}[t]{.7\textwidth}
 {\em agreement along W, same-V, leading to X for different V}
($X$: from $W$ agreement jumping $V$),   \texttt{(jumpFrom)}\\
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            w_{ih}\, w_{jh}\,I\{v_i = v_h \neq v_j\}$;\\[0.2em]
 this refers to agreement about $W$ ties, restricted to ``jump outside
 of $V$-groups'' in the sense that the focal actor and the agreed
 actor have the same value of $V$, but the target actor has a
 different value.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\diamond$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\item
\begin{minipage}[t]{.7\textwidth}
 {\em agreement along W, same-V about contrasting V, leading to X}
($X$: from $W$ agreement contrasting $V$),   \texttt{(contrastCovNetNet)}\\
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            w_{ih}\, w_{jh}\,I\{v_i = v_j \neq v_h\}$;\\[0.2em]
 this refers to agreement ``outside of $V$-groups'' about $W$ ties,
 in the sense that the focal actor and the target
 actor have the same value of $V$, but the agreed actor has a different value;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\diamond$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\item
\begin{minipage}[t]{.7\textwidth}
 {\em agreement along W, all different V, leading to X}
($X$: from $W$ agreement all diff. $V$),   \texttt{(allDifCovNetNet)}\\
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            w_{ih}\, w_{jh}\,I\{v_i, v_j, v_h \text{ all different} \}$;\\[0.2em]
 this refers to agreement  about $W$ ties between actors who have
 all three a different value for $V$;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\footnotesize$\triangle$} at  4 1
\put{\large$\diamond$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.9 1.1732 to 3.1 2.559
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\item
\begin{minipage}[t]{.7\textwidth}
 {\em mixed WX $\Rightarrow$ X closure, same-V path}
($X$: mixed $W$ closure same $V$),
  \texttt{(sameWXClosure)}   \\
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            w_{ih}\, x_{hj}\,I\{v_i = v_h \}$;\\[0.2em]
 this refers to the closure of $W-X$ two-paths, restricted to
 two-paths  $i \stackrel{W}{\rightarrow} h \stackrel{X}{\rightarrow} j $
 in which the focal actor and the mediating actor have the same value of $V$.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\circ$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $X$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\item
\begin{minipage}[t]{.7\textwidth}
 {\em mixed WX $\Rightarrow$ X closure, same-V path jumping to different V}
($X$: mixed $W$ closure jumping $V$),
  \texttt{(jumpWXClosure)}   \\
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            w_{ih}\, x_{hj}\,I\{v_i = v_h \neq v_j\}$;\\[0.2em]
 this refers to the closure of $W-X$ paths, restricted to ``jump outside
 of $V$-groups'' in the sense that the focal actor and the mediating
 actor have the same value of $V$, but the target actor has a
 different value.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\diamond$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $X$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip


\item
\begin{minipage}[t]{.7\textwidth}
 {\em closure of shared incoming $WW=>X$ same-V, leading to X for different V}, \\
 ($X$: shared incoming $W$ jumping $V$) \texttt{(jumpSharedIn)}  \\[0.2em]
 $s^{\rm net}_{i\vit}(x) =
    \sum_{j \neq h} x_{ij}\, w_{hi}\, w_{hj}\,I\{v_i = v_h \neq v_j\}\,$;\\[0.2em]
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 this refers to shared incoming $W$ ties contributing
 to the tie $i \stackrel{X}{\rightarrow} j$, restricted to ``jump outside
 of $V$-groups'' in the sense that the focal actor and the count of shared incoming
 actors is for those having the same value of $V$, but the target actor has a
 different value.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\diamond$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from  2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from   3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}

\item
\begin{minipage}[t]{.7\textwidth}
 {\em shared incoming W leading to X, for same V}, \\
($X$: shared incoming $W$ same $V$)  \texttt{(covNetNetIn)},\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h}
                     x_{ij}\, w_{hi}\, w_{hj}\,I\{v_i = v_j\}$;\\[0.2em]
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 this refers to shared incoming $W$-choices
 (structural equivalence with respect to incoming $W$-choices), but only
 for actors sharing the same value of a covariate $V$;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of joint $W$ choices of others,
 $i \stackrel{W}{\leftarrow} h \stackrel{W}{\rightarrow} j$,
 counting only those for which $v_i = v_j$.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\circ$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\item
\begin{minipage}[t]{.7\textwidth}
 {\em shared incoming W leading to X, for homogeneous V}, \\
($X$: shared incoming $W$ hom.\ $V$)  \texttt{(homCovNetNetIn)},\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h}
                     x_{ij}\, w_{hi}\, w_{hj}\,I\{v_i = v_j = v_h\}$;\\[0.2em]
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 this refers to shared incoming $W$-choices
 (structural equivalence with respect to incoming $W$-choices), but only
 for actors and choices sharing the same value of a covariate $V$;
 the contribution of the tie $i \stackrel{X}{\rightarrow} j$
 is proportional to
 the number of joint incoming $W$ choices of others,
 $i \stackrel{W}{\leftarrow} h \stackrel{W}{\rightarrow} j$,
 counting only those for which $v_i = v_j= v_h$.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from  2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip


\item
\begin{minipage}[t]{.75\textwidth}
 {\em shared incoming W, same-V about contrasting V, leading to X}\\
($X$: shared incoming $W$ contrasting $V$),   \texttt{(contrastCovNetNetIn)}\\
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            w_{hi}\, w_{hj}\,I\{v_i = v_j \neq v_h\}$;\\[0.2em]
 this refers to shared incoming $W$-choices
 (structural equivalence with respect to incoming $W$-choices),
 restricted in the sense that the focal actor and the target
 actor have the same value of $V$, but the actors
 making the shared incoming choices have a different value;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\diamond$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\item
\begin{minipage}[t]{.75\textwidth}
 {\em shared incoming W, all different V, leading to X}\\
($X$: shared incoming $W$ all different $V$),   \texttt{(allDifCovNetNetIn)}\\
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            w_{hi}\, w_{hj}\,I\{v_i, v_j, v_h \text{ all different} \}$;\\[0.2em]
 this refers to shared incoming $W$-choices
 (structural equivalence with respect to incoming $W$-choices),
 restricted in the sense that the focal actor, the target
 actor, and the actors
 making the shared incoming choices all have a different value of $V$;
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\footnotesize$\triangle$} at  4 1
\put{\large$\diamond$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $W$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.9 2.559 to 2.1 1.1732
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip


\item
\begin{minipage}[t]{.75\textwidth}
 {\em mixed WX $\Rightarrow$ X closure, homogeneous on V}\\
($X$: mixed $W$ closure homog. $V$),
  \texttt{(homWXClosure)}   \\
  (specified with \texttt{interaction1} = $W$, \texttt{interaction2} = $V$)\\[0.2em]
 $s^{\rm net}_{i\vit}(x) = \sum_{j \neq h} x_{ij}\,
            w_{ih}\, x_{hj}\,I\{v_i = v_j = v_h\}$;\\[0.2em]
 this refers to the closure of $W-X$ paths, restricted to
 triples that are homogeneous with respect to $V$.
      \end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\linethickness{0.3pt}
\vfill
\begin{center}
\beginpicture
\setcoordinatesystem units <0.8cm,0.8cm> point at 4 3
\setplotarea x from 2 to 4, y from 0 to 3
\put{\large$\bullet$} at  2 1
\put{\large$\bullet$} at  4 1
\put{\large$\bullet$} at  3 2.732
\put{$i$} at 2 0.4
\put{$j$} at 4 0.4
\put{$h$} at 3 3.4
\put{{\small $W$}} at 2.1 1.9
\put{{\small $X$}} at 3.9 1.9
\put{{\small $X$}} at 3   0.6
\arrow <2mm> [.2,.6]  from 2.2 1 to 3.8 1
\arrow <2mm> [.2,.6]  from 2.1 1.1732 to 2.9 2.559
\arrow <2mm> [.2,.6]  from 3.1 2.559 to 3.9 1.1732
\endpicture
\end{center}
\vfill
\end{minipage}
\smallskip

\setcounter{savenumi}{\value{enumi}}
\end{enumerate}


\noindent
There are two effects similar to the effects described above
depending on the auxiliary variable $\breve v_i$,
``alters' $v$-average''.
Now the `alter' is defined, however, by the other network $W$.
Thus, \emph{$W$-alters' $v$-average} $\breve v_i^W$ is defined by
\begin{equation}
  \breve v_i^W = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_j w_{ij}v_j}{w_{i+}}  &  \text{ if } w_{i+} > 0     \\
         0                                &  \text{ if } w_{i+} = 0  .
  \end{array}   \right.            \label{alt_av_w}
\end{equation}

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}

\item \emph{covariate - alter at W-distance 2} \texttt{(altDist2W)} \\ % \texttt{(altXDist2W)}.
      This effect is associated with an effect parameter
      which can have values 1 or 2.
      For parameter 1, it is
      defined as the sum of $W$-alters' covariate-average over all actors
      to whom $i$ has a tie,
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \breve v_j^W \hfill (\text{parameter 1}). \hfill
\]
      For parameter 2, it is defined similarly,
      but for an alters' covariate-average excluding
      ego:
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \breve v_j^{W(-i)} \hfill (\text{parameter 2}) \hfill
\]
      where
\begin{equation}
  \breve v_j^{W(-i)} = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_{h \neq j} w_{jh}v_h}{w_{j+} - w_{ji}}  &  \text{ if } w_{j+} - w_{ji} > 0     \\
         0                                &  \text{ if } w_{j+}- w_{ji} = 0  .
  \end{array}   \right.
\end{equation}

\item \emph{total covariate - alter at W-distance 2} \texttt{(totDist2W)} \\
      This effect is like the previous effect, but now defined
      defined as the sum of $W$-alters' covariate-total over all actors
      to whom $i$ has a tie. For parameter 1 it is
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, x_{j+} \, \breve v_j^W \hfill (\text{parameter 1}). \hfill
\]
      For parameter 2, it is defined similarly,
      but for an alters' covariate-total excluding
      ego:
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij} \, (x_{j+}  - x_{ji}) \,
               \breve v_j^{W(-i)} \hfill (\text{parameter 2}) \hfill
\]
      where $ \breve v_j$ and $ \breve v_j^{W(-i)}$ are as above.

\item \emph{ego-(alter-W-distance-2) covariate - similarity} \texttt{(simEgoDist2W)},
      defined as the sum of centered similarity  between $i$
      and alters' covariate-average, for all actors
      $j$ to whom $i$ has a tie,
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, \Big({\rm sim}(\grave v^W)_{ij}
  - \widehat{{\rm sim}^v}\Big) \ ,
\]
 where the similarity scores ${\rm sim}(\grave v^W)_{ij}$ are defined as
\[
{\rm sim}(\grave v^W)_{ij}=
 \frac{\Delta-\vert  v^W_i - \breve (v^W_j)^{(-i)} \vert}{\Delta} \ ,
\]
 while
 $\Delta=\max_{ij}\vert v_i - v_j \vert$ is the observed range of the
 \emph{original} covariate $v$,
 $\breve v_j^{(-i)}$ is as above in effect \texttt{(altDist2)},

 and $\widehat{{\rm sim}^v}$ is the mean of all similarity scores as used also
 for the \texttt{simX} effect; this centering is applied since version 1.1-285.
 For a constant covariate \texttt{mycov}, this mean is given by
 \texttt{attr(mydata\$cCovars\$mycov, "simMean")}.\\

 \item \emph{covariate - similarity at W-distance 2} \texttt{(simDist2W)}, % \texttt{(simXDist2W)},
      defined as the sum of centered similarity
      values for alters' covariate-average between $i$ and all actors
      $j$ to whom $i$ has a tie,
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, \Big({\rm sim}(\breve v^W)_{ij}
  -  \widehat{{\rm sim}^v}\Big) \ ,
\]
 where the similarity scores ${\rm sim}(\breve v^W)_{ij}$ are defined as
\[
{\rm sim}(\breve v^W)_{ij}=
 \frac{\Delta-\vert \breve v_i^W - \breve v_j^W \vert}{\Delta} \ ,
\]
 while
 $\Delta=\max_{ij}\vert v_i - v_j \vert$ is the observed range of the
 \emph{original} covariate $v$, and\\
  $\widehat{{\rm sim}^v}$ is as above.

\item \emph{ego-(in-alter-W-distance-2) covariate - similarity} \texttt{(simEgoInDist2W)},
      defined as the sum of centered similarity  between $i$
      and alters' covariate-in-average, for all actors
      $j$ to whom $i$ has a tie,
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\, \Big({\rm sim}(\acute v^W)_{ij}
  - \widehat{{\rm sim}^v}\Big) \ ,
\]
 where the similarity scores ${\rm sim}(\acute v^W)_{ij}$ are defined as
\[
{\rm sim}(\acute v)_{ij}=
 \frac{\Delta-\vert  v_i - \check v_j^{(-i)} \vert}{\Delta} \ ,
\]
 while
 $ \check v_j^{(-i)}$ is as in the definition of \texttt{altInDist2W},
 $\Delta=\max_{ij}\vert v_i - v_j \vert$ is the observed range of the
 \emph{original} covariate $v$, and\\
 $\widehat{{\rm sim}^v}$ is as above.

\setcounter{savenumi}{\value{enumi}}
\end{enumerate}

\noindent
The following is an effect for three networks:
the dependent network is $X$, the two explanatory networks are $W$ and $Z$.

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
\item \emph{from $W$ agreement weighted by $Z$ indegrees} \texttt{(from.w.ind)},
      defined as the sum of $Z$-indegrees of all
      actors who have incoming $W$-ties from $i$ and from those actors
      $j$ to whom $i$ has a tie,
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\,
        \Big( \sum_{h} w_{ih}\,w_{jh} \, z_{+h} \Big) \ .
\]
     For internal effect parameter $p=2$, the effect is
\[
 s^{\rm net}_{i\vit}(x) = \sum_j x_{ij}\,
        \Big( \sum_{h} w_{ih}\,w_{jh} \, \sqrt{ z_{+h}} \Big) \ .
\]
    $W$ is given as \texttt{interaction1}, $Z$ as \texttt{interaction2}.

    This effect also is available if all or some of $X$, $W$, and $Z$ are the same.
    If $X$ and $W$ are the same, this effect is defined as an elementary effect
    (see Section~\ref{S_elementary}).
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}

\subsubsection{Network creation and endowment functions}
\label{S_c}
\label{S_e}

The \emph{network creation function}
is one way of modeling effects which operate in
different strengths for the creation and the dissolution of
relations.
The network creation function is zero for dissolution of ties,
and is given by
\begin{equation}
c^{\rm net}_i(x) \, = \, \sum_k \zeta_k^{\rm net} \, s^{\rm net}_{ik}(x)
                             \label{c_net}
\end{equation}
for creation of ties.
In this formula, the $\zeta_k^{\rm net}$
are the parameters for the creation function.
The potential effects $s^{\rm net}_{ik}(x) $ in this function, and their
formulae, are the same as in the evaluation function;
except that not all are available, as indicated in the preceding subsection.
For further explication, consult \citet{Snijders01, Snijders05};
(here, the `gratification function' is used rather than the creation function),
\citet*{SnijdersEA07}, and \citet*{SteglichEA10}
(here only the endowment function is treated and not the creation function,
but they are similar in an opposite way).

The \emph{network endowment function}
is another way of modeling effects which operate in
different strengths for the creation and the dissolution of
relations.
The network endowment function is zero for creation of ties,
and is given by
\begin{equation}
e^{\rm net}(x) \, = \, \sum_k \gamma^{\rm net}_k \, s^{\rm net}_{ik}(x)
                                                           \label{e_net}
\end{equation}
for dissolution of ties.
In this formula, the $\gamma_k^{\rm net}$
are the parameters for the endowment function.
The potential effects $s^{\rm net}_{ik}(x) $ in this function, and their
formulae, are the same as in the evaluation function;
except that not all are available, as indicated in the preceding subsection.
For further explication, consult \citet{Snijders01, Snijders05};
(here, the `gratification function' is used rather than the endowment function),
\citet*{SnijdersEA07}, and \citet*{SteglichEA10}.

A better term than endowment is perhaps \emph{maintenance}.


These functions are combined in the following way.
For the creation of ties, the objective function used is
\begin{equation}
f_i^{\rm net}(x) \,+\, c_i^{\rm net}(x)     \ ,             \label{fc_net}
\end{equation}
in other words, the parameters for the evaluation and creation effects are
added.
For the dissolution of ties, on the other hand, the objective function is
\begin{equation}
f_i^{\rm net}(x) \,+\, e_i^{\rm net}(x)      \ ,            \label{fe_net}
\end{equation}
in other words, the parameters for the evaluation and endowment effects are
added.
Therefore, a model with a parameter with some value $\beta_k$
for a given evaluation effect,
and for which there are no separate creation and endowment effects,
has exactly the same consequences as a model for which this
evaluation effect is excluded, and that includes a creation as well as
an endowment effect, both with the same parameter value
$\zeta_k = \beta_k$ and $\gamma_k = \beta_k$.

Of the three types of effect --- evaluation, creation, and endowment ---,
one therefore should use one or two, not all three, because this leads to collinearity.


\subsubsection{Network rate function} \label{S_r}

To define rate effects by the function \sfn{includeEffects} or \sfn{setEffect},
note that in the call of these functions the specification
\texttt{type='rate'} should be included.
\medskip

The network rate function $\lambda^{\rm net}$
(lambda) is defined for Model Type~1 (which is the default Model
Type) as a product \[ \lambda^{\rm net}_i(\rho, \alpha, x, m) =
\lambda^{\rm net}_{i1} \lambda^{\rm net}_{i2} \lambda^{\rm net}_{i3}
\] of factors depending, respectively, on period $m$, actor
covariates, and actor position \citep[see][p.\ 383]{Snijders01}. The
corresponding factors in the rate function are the following:
\begin{enumerate}
 \item The dependence on the period \texttt{(Rate)}
 can be represented by a simple factor
 \[ \lambda^{\rm net}_{i1} = \rho^{\rm net}_m \]
 for $m = 1, ..., M-1$.\\
 This basic rate parameter is always period-dependent (i.e.,
 it may and will be different for
 different values of $m$); this is in contrast to all other parameters.

 \item The effect of actor covariates \texttt{(RateX)} with values
 $v_{hi}$ can be represented by the factor
 \[ \lambda^{\rm net}_{i2} = \exp(\sum_h \alpha_h \, v_{hi})\,. \]

 \item The dependence on the position of the actor can be modeled
 as a function of the actor's out-degree \texttt{(outRate)},
 in-degree \texttt{(inRate)}, and number
 of reciprocated relations \texttt{(recipRate)}, the `reciprocated degrees'.
 Define these by
 \[ x_{i+} \,=\, \sum_j x_{ij}, \phantom{abcde} x_{+i} \,=\, \sum_j x_{ji},
                \phantom{abcde} x_{i(r)} \,=\, \sum_j x_{ij}x_{ji} \]
 (recalling that $x_{ii} = 0$ for all $i$).\\

 \iffalse
 Denoting the corresponding parameter by $\alpha_1$, the dependence
 on the out-degree is represented by
 \[ \lambda^{\rm net}_{i3} = \frac{x_{i+}}{n-1} \exp(\alpha_1) \+
 \left(1 - \frac{x_{i+}}{n-1}\right) \exp(- \alpha_1). \]
 This formula is motivated in \citet{SnijdersDuijn97}.
 This defines a linear function of the out-degree,
 parametrized in such a way that it is necessarily positive.\\
 For a general dependence on the out-degree, in-degree, and number
 of reciprocated relations, one can use an average of such terms, the
 second and third one depending in the analogous way on
 $x_{+i}$ and $x_{i(r)}$, respectively.\\
 \fi

The contribution of the out-degrees to $\lambda^{\rm net}_{i3}$
is a factor
 \[ \exp( \alpha_h \, x_{i+})\,, \]
if the associated parameter is denoted $\alpha_h$ for some $h$,
and similarly for the contributions of the in-degrees and the
reciprocated degrees.

 Nonlinear dependence of the exponent on out-degrees
 can also be specified;
 \begin{itemize}
 \item inverse outdegree effect  \texttt{(outRateInv)} \\
 Denoting again the corresponding parameter by $\alpha_h$
 (but always for different index numbers $h$),
 this effect multiplies the factor $\lambda^{\rm net}_{i3}$ by
 \[ \exp\big( \alpha_h / (x_{i+} +1)\big) \ . \]
 \item logarithmic outdegree effect  \texttt{(outRateLog)} \\
 This effect multiplies the factor $\lambda^{\rm net}_{i3}$ by
 \[ \exp\Big( \ln\big(\alpha_h (x_{i+} +1)\big)\Big) \,=\,
                 \big(x_{i+} +1\big)^{\alpha_h} \ . \]
 \emph{This effect works properly only for non-conditional estimation
    (set \texttt{cond = FALSE} in \sfn{sienaAlgorithmCreate()}).  }


 The exponential link function and logarithmic transformation collaborate
 to produce direct proportionality to (outdegree + 1), in case
 the parameter is $\alpha_h=1$.
 \end{itemize}
 For the two latter effects, the addition of 1 to the outdegrees avoids
 problems (division by 0, logarithm of 0) that otherwise would occur
 when $ x_{i+} = 0$.

 For making the rates dependent on the outdegree,
 the \texttt{outRateLog} effect often gives the best fit.
\end{enumerate}

When rate effects are included, sometimes it can be helpful to specify
a smaller value for the initial gain parameter in \sfn{sienaAlgorithmCreate()};
e.g., \texttt{initg=0.01} or even  \texttt{initg=0.001}.
When the estimation algorithm diverges and any rate effects are in the model,
this option should be considered.

\iffalse
\subsubsection{Network rate function for Model Type 2}

For Model Type 2 (see Section~\ref{S_modeltype}), the network rate
function is defined according to \citet{Snijders03} by
\begin{align*}
  \rho_m\, \lambda_{i+}(s) & =
               \rho_m\,\frac{\nu(s)\, \xi(s)}{1 \,+\, \xi(s)}\, , \\
  \rho_m\, \lambda_{i-}(s) & =   \rho_m\, \frac{\nu(s-1)}{1 \,+\, \xi(s-1)} \ ,
\end{align*}
where $ \rho_m\,\lambda_{i+}(s)$ and $ \rho_m\,\lambda_{i-}(s)$
represent, respectively, the rate at which an actor of current
out-degree $s$ increases, or decreases, his out-degree by 1. The
parameter $\rho_m$ is a multiplicative effect of the observation
period.

Function $\xi$ (\emph{xi}) is called the distributional tendency
function and is represented according to \citet[formula (17)]{Snijders03} by
\[ \xi(s) \,=\, \exp\left(\alpha_1 \,-\, \alpha_2 \log(s+1) - \frac{\alpha_3}{s+1}\right)  \ . \]
where the names given in \SI are
\begin{itemize}
 \item $\alpha_1$ : out-degrees effect;
 \item $\alpha_2$ : logarithmic out-degree effect;
 \item $\alpha_3$ : factorial out-degree effect.
\end{itemize}
The reasons for these names and interpretation of the effects
can be found in \citet{Snijders03}.
To the exponent also effects of actor covariates can be added.

The so-called volatility function $\nu$ (\emph{nu}) is defined as
\[ \nu(s) \,=\, \left( 1 \,+\, \alpha_4 \, \frac{1}{s+1} \right) \ . \]
Also to this exponent effects of actor covariates can be added.
\fi

\subsection{Behavioral evolution}
\label{S_ff_b}

The model of the dynamics of a dependent actor variable
consists of a model of actors' decisions (according to {\it
evaluation}, {\it creation}, and {\it endowment functions})
and a model of the timing
of these decisions (according to a {\it rate function}),
just like the model for the network dynamics. The
decisions now do not concern the creation or dissolution of
network ties, but whether an actor increases or decreases his
score on the dependent actor variable by one, or keeps it as it
is.

\subsubsection{Behavioral evaluation function}
\label{S_f_b}

The behavior evaluation function for actor $i$ is defined as
\begin{equation}
f^{\rm beh}_i(x, z) \, = \, \sum_k \beta^{\rm beh}_k s^{\rm beh}_{ik}(x, z)
                                             \label{f_beh}
\end{equation}
where $\beta^{\rm beh}_k$ are parameters and $s^{\rm beh}_{ik}(x, z)$
are effects as defined below.
The behavioral dependent variable is denoted by $z$ and the
dependent network variable by $x$.
Here the dependent variable is transformed
to have an overall average value of 0;
in other words, $z$ denotes the original input variable
minus the overall mean\footnote{More precisely: \label{meandef}
this is the mean of the means per wave, and the
means per wave are means of the non-missing observations
for that wave.}, which is given in the
output file produced by \sfn{print01Report()} under the heading
\emph{Reading dependent actor variables}.

First there are effects that have to do only
with the behavioral variable itself.

\begin{startenum}
 \item {\em behavioral shape effect} \texttt{(linear)},\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \,$,\\
 where $z_{i}$ denotes the value of the dependent behavior variable
 of actor $i$;

 \item {\em quadratic shape effect, or effect of the behavior upon itself}
                                                             \texttt{(quad)},
 where the attractiveness of further steps up the behavior `ladder'
 depends on where the actor is on the ladder:\\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i^2$.

 \item {\em threshold shape effect}    \texttt{(threshold)},
  \texttt{(threshold2)},  \texttt{(threshold3)},  \texttt{(threshold4)},
 where the attractiveness of the behavior depends on
 whether it is larger than the internal effect parameter $p$:\\
 $s^{\rm beh}_{i\vit}(x, z) =  I\{ z_i \geq p\}  $ ;\\
 note that $z_i$ is the
 \underline{centered} dependent behavioral variable!\\
 Multiple versions of this effect are available to allow the use
 of more than one threshold.
\end{startenum}
Next there is a list of effects that have to do with the influence of
the network on the behavior.
To specify such effects in \RS using, e.g., function \sfn{includeEffects},
it is necessary\footnote{If this behavior variable is the only dependent
variable, then this is not necessary. But this seldom happens.}
to specify the dependent behavior variable
in the keyword \sfn{name}
as well as the network in the keyword \sfn{interaction1}.
For example,
{\small
\begin{verbatim}
  myCoEvolutionEff <- includeEffects( myCoEvolutionEff, name = "drinkingbeh",
                                      avSim, indeg, outdeg,
                                      interaction1 = "friendship" )
\end{verbatim}
}
The list of these effects is the following.
\begin{followenum}
 \item {\em average similarity effect} \texttt{(avSim)}, defined by the
 average of centered similarity scores ${\rm sim}^z_{ij}$ between $i$
 and the other actors $j$ to whom he is tied,\\
 $s^{\rm beh}_{i\vit}(x, z) = x_{i+}^{-1} \,
           \sum_j x_{ij} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;\\
 (and 0 if $x_{i+} = 0$) ;\\
 the definition of ${\rm sim}^z_{ij}$ is discussed in
 section~\ref{S_internal}, see (\ref{simV});

 \item {\em total similarity effect} \texttt{(totSim)}, defined by the
 sum of centered similarity scores ${\rm sim}^z_{ij}$ between $i$
 and the other actors $j$ to whom he is tied,\\
 $s^{\rm beh}_{i\vit}(x, z) =
            \sum_j x_{ij} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;

 \item {\em indegree effect} \texttt{(indeg)}, \\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{ji} $;

 \item {\em outdegree effect} \texttt{(outdeg)}, \\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{ij} $;

\item {\em reciprocated degree effect} \texttt{(recipDeg)}, \\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{ij}\,x_{ji} $;


% \item {\em indegree up to $c$ effect}, where $c$ is a constant between 1 and $n-1$,\\
% $s^{\rm beh}_{i\vit}(x, z) = z_i I\{x_{+i} \leq c\}$,\\
% where again $I\{A\}$ denotes the indicator function of the condition $A$;

 \item {\em isolate effect} \texttt{(isolate)},
  the differential attractiveness of the behavior for isolates, \\
 $s^{\rm beh}_{i\vit}(x, z) = z_i I\{x_{+i} = 0 \}$,\\
 where again $I\{A\}$ denotes the indicator function of the condition $A$;

 \item
 {\em average similarity $\times$ reciprocity effect} \texttt{(avSimRecip)},
 defined by the sum of centered similarity scores
 ${\rm sim}^z_{ij}$ between $i$
 and the other actors $j$ to whom he is reciprocally tied,\\
 $s^{\rm beh}_{i\vit}(x, z) = x_{i(r)}^{-1} \,
            \sum_j x_{ij} x_{ji} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;\\
 (and 0 if $x_{i(r)} = 0$) ;

 \item {\em total similarity $\times$ reciprocity effect}
 \texttt{(totSimRecip)}, defined by the
 sum of centered similarity scores ${\rm sim}^z_{ij}$ between $i$
 and the other actors $j$ to whom he is reciprocally tied,\\
 $s^{\rm beh}_{i\vit}(x, z) =
         \sum_j x_{ij} x_{ji} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;

 \item {\em average similarity $\times$ popularity alter effect}
 \texttt{(avSimPopAlt)}, defined by the
 average of centered similarity scores ${\rm sim}^z_{ij}$ between $i$
 and the other actors $j$ to whom he is  tied, multiplied by their indegrees, \\
 $s^{\rm beh}_{i\vit}(x, z) = x_{i+}^{-1} \,
        \sum_j x_{ij}  x_{+j} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;\\
 (and 0 if $x_{i+} = 0$) ;


 \item
 {\em popularity alter effect} \texttt{(popAlt)}, defined by the
 average in-degrees of the other actors $j$ to whom $i$ is tied,\\
 $s^{\rm beh}_{i\vit}(x, z) =   z_i\,x_{i+}^{-1} \, \sum_j x_{ij} x_{+j}  $;\\
 (and 0 if $x_{i+} = 0$) ;\\
 this effect may be useful, e.g., as a control effect for the average
 similarity $\times$ popularity alter effect;

 \item
 {\em total similarity  $\times$ popularity alter effect}
 \texttt{(totSimPopAlt)}, defined by the
 sum of centered similarity scores ${\rm sim}^z_{ij}$ between $i$
 and the other actors $j$ to whom he is tied, multiplied by their indegrees,\\
 $s^{\rm beh}_{i\vit}(x, z) =  \sum_j x_{ij} x_{+j} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;

 \item {\em average similarity $\times$ reciprocity $\times$ popularity alter effect} \texttt{(avSimRecPop)}, defined by the
 sum of centered similarity scores ${\rm sim}^z_{ij}$ between $i$
 and the other actors $j$ to whom he is reciprocally tied, multiplied by their indegrees, \\
 $s^{\rm beh}_{i\vit}(x, z) = x_{i(r)}^{-1} \, \sum_j x_{ij} x_{ji} x_{+j} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;\\
 (and 0 if $x_{i(r)} = 0$) ;

 \item {\em total similarity $\times$ reciprocity $\times$ popularity alter effect} \texttt{(totSimRecPop)}, defined by the
 sum of centered similarity scores ${\rm sim}^z_{ij}$ between $i$
 and the other actors $j$ to whom he is reciprocally tied, multiplied by their indegrees,\\
 $s^{\rm beh}_{i\vit}(x, z) =  \sum_j x_{ij} x_{ji} x_{+j} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;

 \item {\em average alter effect} \texttt{(avAlt)},
 defined by  $i$'s
 behavior multiplied by the average behavior of his alters (a kind
 of ego-alter behavior covariance), \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, z_j \big)
                                / \big (\sum_j x_{ij}\big)  $\\
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;

 \item {\em total alter effect} \texttt{(totAlt)},
 defined by  $i$'s
 behavior multiplied by the sum of behavior of his alters, \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, z_j \big) ;  $\\

 \item {\em average in-alter effect} \texttt{(avInAlt)},
 defined by  $i$'s
 behavior multiplied by the average behavior of his in-alters (a kind
 of ego-alter behavior covariance), \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ji}\, z_j \big)
                                / \big (\sum_j x_{ji}\big)  $\\
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;

 \item {\em total alter effect} \texttt{(totInAlt)},
 defined by  $i$'s
 behavior multiplied by the sum of behavior of his in-alters, \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ji}\, z_j \big) ;  $\\

 \item {\em average reciprocated alter effect} \texttt{(avRecAlt)},
 defined by  $i$'s
 behavior multiplied by the average behavior of his reciprocated alters, \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, x_{ji}\, z_j \big)
                                / \big (\sum_j x_{ij}\, x_{ji} \big)  $\\
 (and 0 if the ratio is 0/0) ;

 \item {\em total reciprocated alter effect} \texttt{(totRecAlt)},
 defined by  $i$'s
 behavior multiplied by the sum of behavior of his reciprocated alters, \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, x_{ji}\, z_j \big);  $\\


 \item {\em average alter $\times$ popularity effect}
 \texttt{(avAltPop)}, defined by the
 behavior multiplied by the average behavior of his alters,
 multiplied by their indegrees, \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i\, x_{i+}^{-1} \,
        \big( \sum_j x_{ij}\, x_{+j}\,z_j  \big) $;\\
 (and 0 if $x_{i+} = 0$) ;

 \item {\em total alter $\times$ popularity effect}
 \texttt{(totAltPop)}, defined by the
 behavior multiplied by the sum of the behavior of his alters,
 multiplied by their indegrees, \\
 $s^{\rm beh}_{i\vit}(x, z) =
        z_i\,  \big( \sum_j x_{ij}\, x_{+j} \,z_j \big) $;

\item only in RSienaTest:  \emph{average Simmelian alter effect}, (\texttt{avSimmelianAlt}), the effect of
      the average behavior for the Simmelian alters. The Simmelian transformation of the network is
      the network composed of all ties embedded in at least one complete triad:
\[
    x^{\rm{simm}}_{ij} \,=\, \left\{ \begin{array}{cl}
                               1 & x_{ij} = x_{ji} = 1 \text{ and} \\
                                  & \ \text{ there is at least one }
                                      h \text{ for which } x_{hi} = x_{ih} = x_{hj} = x_{jh} = 1 \\
                               0 & \text{else.}
                             \end{array} \right.
\]
      In other words, these ties must be reciprocal, and there must be at least one
      third actor to whom both have a mutual tie.
      The average Simmelian alter effect is  \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x^{\rm{simm}}_{ij}\, z_j \big)
                                / \big (\sum_j x^{\rm{simm}}_{ij}\big)  $\\
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;

\item only in RSienaTest: \emph{total Simmelian alter effect}, (\texttt{totSimmelianAlt}), the effect of
      the sum of behavior for the Simmelian alters, defined by\\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x^{\rm{simm}}_{ij}\, z_j \big)  $;

 \item {\em average alter effect at distance 2} \texttt{(avAltDist2)},
 defined by  $i$'s
 behavior multiplied by the average of the alter-averages $\breve z_j^{(-i)}$ of his alters,
 excluding the contribution from a tie $j \rightarrow i$ (if any),
 defined by
\begin{equation}
  \breve z_j^{(-i)} = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_{h \neq i} x_{jh}\,z_h}{x_{j+} - x_{ji}}  &
                                       \text{ if } x_{j+} - x_{ji} > 0     \\
         0                                &  \text{ if } x_{j+}- x_{ji} = 0  .
  \end{array}   \right.            \label{alt_av3}
\end{equation}
(also see (\ref{alt_av2})), \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, \breve z_j^{(-i)} \big)
                                / \big (\sum_j x_{ij}\big)  $\\[0.5ex]
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;


 \item {\em total alter effect at distance 2} \texttt{(totAltDist2)},
 defined by  $i$'s
 behavior multiplied by the total of the alter-totals  of his alters,
 excluding the contribution from a tie $j \rightarrow i$ (if any),\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{ij}\, \sum_{h \neq i} x_{jh}\,z_h =
         z_i \sum_j x_{ij}\, (x_{j+}- x_{ji}) \, \breve z_j^{(-i)}  $;

 \item {\em average total alter effect at distance 2} \texttt{(avTAltDist2)},
 defined by  $i$'s
 behavior multiplied by the average of the alter-totals of his alters,
 excluding the contribution from a tie $j \rightarrow i$ (if any),\\[0.3ex]
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\,(x_{j+}- x_{ji}) \, \breve z_j^{(-i)} \big)
                                / \big (\sum_j x_{ij}\big)
 =  z_i
     \big( \sum_j x_{ij} \sum_{h \neq i} x_{jh}\,z_h \big) / \big( \sum_j x_{ij} \big)
                                $\\[0.5ex]
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;

 \item {\em total average alter effect at distance 2} \texttt{(totAAltDist2)},
 defined by  $i$'s
 behavior multiplied by the total of the alter-averages $ z_j^{(-i)}$ of his alters,
 excluding the contribution from a tie $j \rightarrow i$ (if any), \\[0.3ex]
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, \breve z_j^{(-i)} \big) $;

 \item {\em average incoming alter effect at distance 2} \texttt{(avInAltDist2)},
 defined by  $i$'s
 behavior multiplied by the average of the incoming alter
 averages $\check z_j^{(-i)}$ of his alters,
 excluding the contribution from a tie $i \rightarrow j$ (if any),
 defined by
\begin{equation}
  \check z_j^{(-i)} = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_{h \neq i} x_{hj}\,z_h}{x_{+j} - x_{ij}}  &
                                       \text{ if } x_{+j} - x_{ij} > 0     \\
         0                                &  \text{ if } x_{+j}- x_{ij} = 0  .
  \end{array}   \right.            \label{inalt_av3}
\end{equation}
(cf.\ (\ref{alt_av3})), \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, \check z_j^{(-i)} \big)
                                / \big (\sum_j x_{ij}\big)  $\\[0.5ex]
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;

 \item {\em total incoming alter effect at distance 2} \texttt{(totInAltDist2)},
 defined by  $i$'s
 behavior multiplied by the total of the incoming alter-totals  of his alters,
 excluding the contribution from a tie $i \rightarrow j$ (if any),\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{ij}\, \sum_{h \neq i} x_{hj}\,z_h =
         z_i \sum_j x_{ij}\, (x_{+j}- x_{ij}) \, \check z_j^{(-i)}  $;

 \item {\em average total incoming alter effect at distance 2} \texttt{(avTInAltDist2)},
 defined by  $i$'s
 behavior multiplied by the average of the incoming alter-totals of his alters,
 excluding the contribution from a tie $i \rightarrow j$ (if any),\\[0.3ex]
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\,(x_{+j}- x_{ij}) \, \check z_j^{(-i)} \big)
                                / \big (\sum_j x_{ij}\big)  $\\[0.5ex]
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;

 \item {\em total average incoming alter effect at distance 2} \texttt{(totAInAltDist2)},
 defined by  $i$'s
 behavior multiplied by the total of the incoming alter-averages $ z_j^{(-i)}$ of his alters,
 excluding the contribution from a tie $i \rightarrow j$ (if any), \\[0.3ex]
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, \check z_j^{(-i)} \big) $;

 \item {\em maximum alter effect} \texttt{(maxAlt)},
 defined by  $i$'s
 behavior multiplied by the maximum behavior of his alters, \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \text{max}_j \, x_{ij}\, z_j \big) $\\
 (and the mean behavior, i.e. $0$, if $\sum_j x_{ij} = 0$) ;

 \item {\em minimum alter effect} \texttt{(minAlt)},
 defined by  $i$'s
 behavior multiplied by the minimum behavior of his alters, \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \text{min}_j \, x_{ij}\, z_j \big) $\\
 (and the mean behavior, i.e. $0$, if $\sum_j x_{ij} = 0$) ;


 \item {\em dense triads effect} \texttt{(behDenseTriads)},
 defined by  $i$'s
 behavior multiplied by the number of dense triads in which actor $i$ is
 located, \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \sum_{j,h} I\{ x_{ij}\, + x_{ji}\, + x_{ih}\, + x_{hi}\,
 + x_{jh}\, + x_{hj}\,\geq p \}\,$,\\
 where the internal effect parameter $p$ is either 5 or 6; \\

 \item {\em similarity in dense triads effect} \texttt{(simDenseTriads)},
 defined by  the total sum of $i$'s behavior similarity to others
 in the dense triads in which actor $i$ is located, \\
 $s^{\rm beh}_{i\vit}(x, z) =  \sum_{j,h} ({\rm sim}(v_i, v_j) + {\rm sim}(v_i, v_h))\,
  I\{ x_{ij}\, + x_{ji}\, + x_{ih}\, + x_{hi}\,
 + x_{jh}\, + x_{hj}\,\geq c \}\,$,\\
 where $c$ is either 5 or 6; \\

 \item {\em peripheral effect}, defined by  $i$'s
 behavior multiplied by the number of dense triads to which actor $i$ stands
 in a unilateral-peripheral relation,\\
 $s^{\rm beh}_{i\vit}(x, z) =  \\[0.4ex]
 \phantom{abcdef} z_i \sum_{j,h,k} x_{ij} (1-x_{ji})(1-x_{hi})(1-x_{ki})
 I\{ x_{ij}\,  + x_{ji}\, + x_{ih}\, + x_{hi}\, + x_{jh}\, + x_{hj}\,)\geq c \} \,$,\\[0.4ex]
 where $c$ is the same constant as in the {\it dense triads} effect;\\
 for symmetric networks, the unilateral condition is dropped, and the effect is\\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \sum_{j,h,k} x_{ij} (1-x_{hi})(1-x_{ki})
 I\{ x_{ij}\,  + x_{ji}\, + x_{ih}\, + x_{hi}\, + x_{jh}\, + x_{hj}\,)\geq c \} \,$;\\

 \item {\em average similarity $\times$ popularity ego effect}
 \texttt{(avSimPopEgo)}, defined by the
 sum of centered similarity scores ${\rm sim}^z_{ij}$ between $i$
 and the other actors $j$ to whom he is  tied, multiplied by ego's indegree, \\
 $s^{\rm beh}_{i\vit}(x, z) =  x_{+i} \, x_{i+}^{-1} \sum_j x_{ij} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;\\
 (and 0 if $x_{i+} = 0$) ;\\
 because of collinearity, under the Method of Moments this cannot be estimated together with the
  average similarity $\times$ popularity alter effect;

 \item {\em group average} \texttt{(avGroup)}, defined by ego's value multiplied by the
 average of \underline{all} values $z_h$ for this period,  \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_{i} \,( \overline {z} - c_p) $;\\
 here $\overline {z}$ is the mean of the values $z_h$ for all actors $h$
 in the group, and $c_p$ is a centering constant depending on the internal effect parameter $p$.
 Denote the overall mean used for centering the observed $Z$ values by
 $m_Z$ (see the footnote on p.~\pageref{meandef}).
 If $p \leq 0$, centering is no different than for the $z_i$ values generally,
 so $c_p = 0$; if $p \geq 1$, centering is by $c_p = p - m_Z$.
 For the original non-centered values of $Z$, this means that the mean
 is centered around the value $p$.\\
 This effect is useful especially for multigroup data sets, where the average value
 varies between groups. For multigroup data sets, centering by the groupwise
 mean may be less desirable, and it will be better to center by a value $p$
 close to the median of $Z$.
 (Note that the centering in a multi-group data set
 will affect the linear shape parameter.)

\end{followenum}
\medskip


\noindent
\textbf{\emph{Effects of multiple networks}}
\medskip

\noindent
If there are more than one dependent network variables,
denoted $X_1$ and £$X_2$,
they can operate jointly on the behavioural dependent variable using
the following effects.
$X_1$ is given as \texttt{interaction1}, $X_2$ as \texttt{interaction2}.

For the combined degree-effects, mentioned first, \texttt{F} means `Forward',
\texttt{B} means `Backward', and \texttt{R} means `Reciprocal'.

\begin{followenum}
 \item {\em double outdegree effect} \texttt{(FFDeg)},\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{1ij}\,x_{2ij} \,$;\\[0.2em]
 if the internal effect parameter $p$ is at least~2, the outdegree
 for $X_1$ is subtracted:\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \Big( \sum_j x_{1ij}\,x_{2ij} \,-\,
  \sum_j x_{1ij} \Big)  \,$;\\
  note that in this case, the factor between $\Big( \ldots \Big)$
  is non-positive;

 \item {\em double indegree effect} \texttt{(BBDeg)},\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{1ji}\,x_{2ji} \,$;\\[0.2em]
 if the internal effect parameter $p$ is at least~2, the indegree
 for $X_1$ is subtracted:\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \Big( \sum_j x_{1ji}\,x_{2ji} \,-\,
  \sum_j x_{1ji} \Big)  \,$;\\
  note that also in this case, the factor between $\Big( \ldots \Big)$
  is non-positive;

 \item {\em combined out-indegree effect} \texttt{(FBDeg)},\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{1ij}\,x_{2ji} \,$;\\[0.2em]
 if the internal effect parameter $p$ is at least~2, the outdegree
 for $X_1$ is subtracted:\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \Big( \sum_j x_{1ij}\,x_{2ji} \,-\,
  \sum_j x_{1ij} \Big)  \,$;\\
  note that also in this case, the factor between $\Big( \ldots \Big)$
  is non-positive;

 \item {\em combined out-reciprocated degree effect} \texttt{(FRDeg)},\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{1ij}\,x_{2ij}\,x_{2ji}\, $;
 \\[0.2em]
 if the internal effect parameter $p$ is at least~2, the outdegree
 for $X_1$ is subtracted:\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \Big( \sum_j x_{1ij}\,x_{2ij}\,x_{2ji}\,-\,
  \sum_j x_{1ij} \Big)  \,$;\\
  note that also in this case, the factor between $\Big( \ldots \Big)$
  is non-positive;

 \item {\em combined in-reciprocated degree effect} \texttt{(BRDeg)},\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{1ji}\,x_{2ij}\,x_{2ji}\, $;
 \\[0.2em]
 if the internal effect parameter $p$ is at least~2, the indegree
 for $X_1$ is subtracted:\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i
 \Big( \sum_j x_{1ji}\,x_{2ij}\,x_{2ji} \,-\,  \sum_j x_{1ji} \Big)  \,$;\\
  note that also in this case, the factor between $\Big( \ldots \Big)$
  is non-positive.

% \item {\em double reciprocated degree effect} \texttt{(RRDeg)},\\
% $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{1ij}\,x_{1ji}\,x_{2ij}\,x_{2ji} \,$.
\end{followenum}

\noindent
\textbf{\emph{Monadic covariate effects}}
\medskip

\noindent
For each actor-dependent covariate $v_j$ (recall that by default these are
centered internally by \si) as well as for each of the other
dependent behavior variables (for notational simplicity here also
denoted $v_j$), there are the following effects.
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
 \item {\em main covariate effect} \texttt{(effFrom)},\\
 $s^{\rm beh}_{i\vit}(x, z) = z_{i} v_{i}\,$;\\
 here too, the other dependent behavioral variables are centered so that they
 have overall mean 0;

\item \emph{alter's covariate average } effect on behavior $z$
 \texttt{(avXAlt)}, formerly called \texttt{(AltsAvAlt)},\\
      defined as the product of $i$'s behavior $z_i$ and
      $i$'s alters' covariate-average $\breve v_i$ as defined
      in (\ref{alt_av}),\\
       $s^{\rm beh}_{i\vit}(x, z) = z_i \, \breve v_i $.\\
      This is similar to the `average alter' effect; for
      $v_i = z_i$ it would reduce to the latter effect.

\item \emph{alter's covariate total } effect on behavior $z$
 \texttt{(totXAlt)},\\
      defined as the product of $i$'s behavior $z_i$ and
      $i$'s alters' covariate sum $x_{i+}\,\breve v_i$ as defined
      in (\ref{alt_av}),\\
       $s^{\rm beh}_{i\vit}(x, z) = z_i \, x_{i+}\, \breve v_i $.\\
      This is similar to the `total alter' effect; for
      $v_i = z_i$ it would reduce to the latter effect.


\item {\em absolute contrast outdegree -- covariate}
 \texttt{(degAbsContrX)},
 defined as the product of $i$'s behavior $z_i$ and
 the absolute difference between $i$'s out-degree and his covariate value,\\
 $s^{\rm beh}_{i\vit}(x, z) = \ z_i \, \mid x_{i+} \,-\, v_i  \mid $;\\
 working with a non-centered covariate may be advisable for this effect;

\item {\em positive contrast outdegree -- covariate}
 \texttt{(degPosContrX)},
 defined as the product of $i$'s behavior $z_i$ and
 the positive part of the difference between $i$'s out-degree
 and her covariate value,\\
 $s^{\rm net}_{i\vit}(x) = \ z_i \, \max \{ x_{i+} \,-\,  v_i   ,\, 0 \} $;\\
 working with a non-centered covariate may be advisable for this effect;

\item {\em negative contrast outdegree -- covariate}
 \texttt{(degNegContrX)},
 defined as the product of $i$'s behavior $z_i$ and
 the negative part of the difference between $i$'s out-degree
 and her covariate value,\\
 $s^{\rm net}_{i\vit}(x) =  - \, z_i \, \min \{ x_{i+} \,-\, v_i   ,\, 0 \}
 \,=\, z_i \, \max \{  v_i  \,-\, x_{i+} ,\, 0 \}  $;\\
 working with a non-centered covariate may be advisable for this effect;


\item \emph{alter's covariate total } effect on behavior $z$
 \texttt{(totXAlt)},\\
      defined as the product of $i$'s behavior $z_i$ and
      $i$'s alters' covariate sum $x_{i+}\,\breve v_i$ as defined
      in (\ref{alt_avwa}),\\
       $s^{\rm beh}_{i\vit}(x, z) = z_i \, x_{i+}\, \breve v_i $.\\
      This is similar to the `total alter' effect; for
      $v_i = z_i$ it would reduce to the latter effect.

\item \emph{in-alter's covariate average } effect on behavior $z$
 \texttt{(avXInAlt)},\\
      defined as the product of $i$'s behavior $z_i$ and
      $i$'s in-alters' covariate-average $\breve v_i$ as defined
      in
\begin{equation}
  \check v_i = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_j x_{ji}v_j}{x_{+i}}  &  \text{ if } x_{+i} > 0     \\
         0                                &  \text{ if } x_{+i} = 0  ,
  \end{array}   \right.            \label{inalt_av}
\end{equation}
      the effect being \\
       $s^{\rm beh}_{i\vit}(x, z) = z_i \, \check v_i $.\\
      This is similar to the `average in-alter' effect; for
      $v_i = z_i$ it would reduce to the latter effect.

\item \emph{in-alter's covariate total } effect on behavior $z$
 \texttt{(totXInAlt)},\\
      defined as the product of $i$'s behavior $z_i$ and
      $i$'s alters' covariate sum $x_{i+}\,\check v_i$ as defined
      in (\ref{inalt_av}),\\
       $s^{\rm beh}_{i\vit}(x, z) = z_i \, x_{i+}\, \check v_i $.\\
      This is similar to the `total in-alter' effect; for
      $v_i = z_i$ it would reduce to the latter effect.

 \item {\em alter's distance-two covariate average} effect on behavior $z$ \texttt{(avXAltDist2)},
 defined by  $i$'s
 behavior multiplied by the average of the alter-averages $\breve v_j^{(-i)}$ of his alters,
 excluding the contribution from a tie $j \rightarrow i$ (if any),
 defined by
\begin{equation}
  \breve v_j^{(-i)} = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_{h \neq i} x_{jh}\,v_h}{x_{j+} - x_{ji}}  &
                                       \text{ if } x_{j+} - x_{ji} > 0     \\
         0                                &  \text{ if } x_{j+}- x_{ji} = 0  .
  \end{array}   \right.            \label{alt_av4}
\end{equation}
(also see (\ref{alt_av2}) and (\ref{alt_av3})), \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, \breve v_j^{(-i)} \big)
                                / \big (\sum_j x_{ij}\big)  $\\[0.5ex]
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;\\
 this is similar to \texttt{avAltDist2}, but now for covariate $V$
 instead of the behavior $Z$;

 \item {\em alter's distance-two covariate total} effect on behavior $z$ \texttt{(totXAltDist2)},
 defined by  $i$'s
 behavior multiplied by the total of the alter-totals on $V$ of his alters,
 excluding the contribution from a tie $j \rightarrow i$ (if any),\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{ij}\, \sum_{h \neq i} x_{jh}\,v_h =
         z_i \sum_j x_{ij}\, (x_{j+}- x_{ji}) \, \breve v_j^{(-i)}  $;\\[0.5ex]
 this is similar to \texttt{totAltDist2}, but now for covariate $V$
 instead of the behavior $Z$;

 \item {\em average total covariate alter effect at distance 2} \texttt{(avTXAltDist2)},
 defined by  $i$'s
 behavior multiplied by the average of the alter-totals on $V$ of his alters,
 excluding the contribution from a tie $j \rightarrow i$ (if any),\\[0.3ex]
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\,(x_{j+}- x_{ji}) \, \breve v_j^{(-i)} \big)
                                / \big (\sum_j x_{ij}\big)  $\\[0.5ex]
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;\\
 this is similar to \texttt{avTAltDist2}, but now for covariate $V$
 instead of the behavior $Z$;

 \item {\em total average covariate alter effect at distance 2} \texttt{(totAXAltDist2)},
 defined by  $i$'s
 behavior multiplied by the total of the alter-averages on $V$ of his alters,
 excluding the contribution from a tie $j \rightarrow i$ (if any), \\[0.3ex]
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, \breve v_j^{(-i)} \big) $;\\[0.5ex]
 this is similar to \texttt{totAAltDist2}, but now for covariate $V$
 instead of the behavior $Z$;

 \item {\em alter's distance-two incoming covariate average} effect on behavior $z$ \texttt{(avXInAltDist2)},
 defined by  $i$'s
 behavior multiplied by the average of the incoming alter-averages $\check v_j^{(-i)}$ of his alters,
 excluding the contribution from a tie $j \rightarrow i$ (if any),
 defined by
\begin{equation}
  \check v_j^{(-i)} = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_{h \neq i} x_{hj}\,v_h}{x_{+j} - x_{ij}}  &
                                       \text{ if } x_{+j} - x_{ij} > 0     \\
         0                                &  \text{ if } x_{+j}- x_{ij} = 0  .
  \end{array}   \right.            \label{inalt_av4}
\end{equation}
(also see (\ref{inalt_av3})), \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, \check v_j^{(-i)} \big)
                                / \big (\sum_j x_{ij}\big)  $\\[0.5ex]
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;\\
 this is similar to \texttt{avInAltDist2}, but now for covariate $V$
 instead of the behavior $Z$;

 \item {\em alter's distance-two incoming covariate total} effect on behavior $z$ \texttt{(totXInAltDist2)},
 defined by  $i$'s
 behavior multiplied by the total of the incoming alter-totals on $V$ of his alters,
 excluding the contribution from a tie $i \rightarrow j$ (if any),\\
 $s^{\rm beh}_{i\vit}(x, z) = z_i \sum_j x_{ij}\, \sum_{h \neq i} x_{hj}\,v_h =
         z_i \sum_j x_{ij}\, (x_{+j}- x_{ij}) \, \check v_j^{(-i)}  $;\\[0.5ex]
 this is similar to \texttt{totInAltDist2}, but now for covariate $V$
 instead of the behavior $Z$;

 \item {\em average total incoming covariate alter effect at distance 2} \texttt{(avTXInAltDist2)},
 defined by  $i$'s
 behavior multiplied by the average of the incoming alter-totals on $V$ of his alters,
 excluding the contribution from a tie $i \rightarrow j$ (if any),\\[0.3ex]
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\,(x_{+j}- x_{ij}) \, \check v_j^{(-i)} \big)
                                / \big (\sum_j x_{ij}\big)  $\\[0.5ex]
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;\\
 this is similar to \texttt{avTInAltDist2}, but now for covariate $V$
 instead of the behavior $Z$;

 \item {\em total average incoming covariate alter effect at distance 2} \texttt{(totAXInAltDist2)},
 defined by  $i$'s
 behavior multiplied by the total of the incoming alter-averages on $V$ of his alters,
 excluding the contribution from a tie $i \rightarrow j$ (if any), \\[0.3ex]
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij}\, \check v_j^{(-i)} \big) $;\\[0.5ex]
 this is similar to \texttt{totAInAltDist2}, but now for covariate $V$
 instead of the behavior $Z$;

\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
There are also a number of interaction effects between actor covariates
(which includes other dependent behavior variables) and influence effects.
These have to be specified using \texttt{interaction1} for the covariate
and \texttt{interaction2} for the network, e.g.,
\begin{verbatim}
myCoevolutionEff <- includeEffects(myCoevolutionEff, avAltEgoX,
        name="smoking",  interaction1 = "sex", interaction2="friendship")
\end{verbatim}
Between parentheses: the functionality of the `ego'-variant of these effects is duplicated by
interaction effects created, for example, as follows:
\begin{verbatim}
myCoevolutionEff <- includeInteraction(myCoevolutionEff, effFrom, avAlt,
        name="smoking", interaction1 = c("sex", "friendship"))
\end{verbatim}
For the `alter'-variant, this way of construction will not work because the
effect statistic cannot be decomposed into a product of two ego-level statistics.
The available effects of this type are the following.
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
\item {\em interaction of ego (tie sender) variable with average similarity},
                       \texttt{(avSimEgoX)} \\
 $s^{\rm beh}_{i\vit}(x, z) = (v_i / x_{i+}) \,
         \sum_j x_{ij} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;\\
 (and the mean behavior, i.e. $0$, if $x_{i+} = 0$) ;
\item {\em interaction of ego (tie sender) variable with total similarity},
                       \texttt{(totSimEgoX)} \\
 $s^{\rm beh}_{i\vit}(x, z) = v_i \,
         \sum_j x_{ij} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;
\item {\em interaction of ego (tie sender) variable with average alter},
                       \texttt{(avAltEgoX)} \\
 $s^{\rm beh}_{i\vit}(x, z) =  v_i \, z_i \big( \sum_j x_{ij}\, z_j \big)
                                / \big (\sum_j x_{ij}\big)  $\\
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;
\item {\em interaction of ego (tie sender) variable with total alter},
                       \texttt{(totAltEgoX)} \\
 $s^{\rm beh}_{i\vit}(x, z) =  v_i \, z_i \big( \sum_j x_{ij}\, z_j \big)   $ ;
\item {\em interaction of alter (tie receiver) variable with average similarity},
                       \texttt{(avSimAltX)} \\
 $s^{\rm beh}_{i\vit}(x, z) = (1 / x_{i+}) \,
         \sum_j x_{ij} \, v_j ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;\\
 (and the mean behavior, i.e. $0$, if $x_{i+} = 0$) ;
\item {\em interaction of alter (tie receiver) variable with total similarity},
                       \texttt{(totSimAltX)} \\
 $s^{\rm beh}_{i\vit}(x, z) =
         \sum_j x_{ij} \, v_j ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;
\item {\em interaction of alter (tie receiver) variable with average alter},
                       \texttt{(avAltAltX)} \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij} \, v_j \, z_j \big)
                                / \big (\sum_j x_{ij}\big)  $\\
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;
\item {\em interaction of alter (tie receiver) variable with total alter},
                       \texttt{(totAltAltX)} \\
 $s^{\rm beh}_{i\vit}(x, z) =  z_i \big( \sum_j x_{ij} \, v_j \, z_j \big) $ ;
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
\iffalse
% the following would be the non publicized inflIntX :
the latter of which is a choice among three, dependent on the
\hyperlink{T_effpar}{internal parameter} for this effect:
\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}
 \item depending on the parameter value (1, 2, or 3):
\begin{enumerate}
   \item[value 1:] {\em interaction of actor variable with average similarity},\\
 $s^{\rm beh}_{i\vit}(x, z) = (v_i / x_{i+}) \,
         \sum_j x_{ij} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;\\
    (and 0 if $x_{i+} = 0$) ;
   \item[value 2:] {\em interaction of actor variable with total similarity},\\
 $s^{\rm beh}_{i\vit}(x, z) = v_i \,
         \sum_j x_{ij} ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) $;\\
   \item[value 3:] {\em interaction of actor variable with average alter},\\
 $s^{\rm beh}_{i\vit}(x, z) =  v_i \, z_i \big( \sum_j x_{ij}\, z_j \big)
                                / \big (\sum_j x_{ij}\big)  $\\
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;
  \end{enumerate}
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}
\fi



\noindent
\textbf{\emph{Dyadic covariate effects}}
\medskip

For each dyadic covariate $W$ there are the following effects.
Recall that the default is to center dyadic covariates; however, it often
will be preferable here to use non-centered covariates.
It is then important how to define the zero point of the covariate!

\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}


\item \emph{alter's  average of dyadic covariate } effect on behavior $z$
 \texttt{(avWAlt)},\\
      defined as the product of $i$'s behavior $z_i$ and
      $i$'s alters' dyadic covariate-average $\breve w_i$ as defined by
\begin{equation}
  \breve w_i = \left\{\begin{array}{ll} \displaystyle
         \frac{\sum_h x_{ih}w_{ih}}{x_{i+}}  &  \text{ if } x_{i+} > 0     \\
         0                                &  \text{ if } x_{i+} = 0  .
  \end{array}   \right.            \label{alt_avwa}
\end{equation}
      leading to the effect \\
       $s^{\rm beh}_{i\vit}(x, z) = z_i \, \breve w_i $.\\

\item \emph{alter's  total of dyadic covariate W } effect on behavior $z$
 \texttt{(totWAlt)},\\
      defined as the product of $i$'s behavior $z_i$ and
      the sum of $i$'s alters' values of the dyadic covariate, \\
       $s^{\rm beh}_{i\vit}(x, z) = z_i \, \sum_h x_{ih}w_{ih}  $.\\

 \item {\em average alter weighted by dyadic covariate $W$}
                       \texttt{(avAltW)},
                       a weighted version of  \texttt{avAlt};\\
                       depending on the parameter value (1 or 2):\\
  parameter = 1 : \ $s^{\rm beh}_{i\vit}(x, z) =
                     z_i \big( \sum_j x_{ij} \, w_{ij} \, z_j \big)  /
                                        \big (\sum_j x_{ij}\big)$\\
   parameter = 2 : \  $s^{\rm beh}_{i\vit}(x, z) =
                    z_i \big( \sum_j x_{ij} \, w_{ij} \, z_j \big)  /
                                \big (\sum_j w_{ij} \,x_{ij}\big) ;$\\
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;
 \item {\em total alter weighted by dyadic covariate $W$}
                       \texttt{(totAltW)},
                       a weighted version of  \texttt{totAlt};\\
   $s^{\rm beh}_{i\vit}(x, z) =  z_i \, \sum_j x_{ij} \, w_{ij} \, z_j  ;$

 \item {\em average similarity weighted by dyadic covariate $W$}
                       \texttt{(avSimW)},
                       a weighted version of  \texttt{avSim};\\
                       depending on the parameter value (1 or 2):\\
  parameter = 1 : \ $s^{\rm beh}_{i\vit}(x, z) =
                      \sum_j x_{ij} \, w_{ij} \,({\rm sim}^z_{ij} - \widehat{{\rm sim}^z})  /
                                        \big (\sum_j x_{ij}\big)$\\
   parameter = 2 : \  $s^{\rm beh}_{i\vit}(x, z) =
                  \sum_j x_{ij} \, w_{ij} \,({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}) /
                                \big (\sum_j w_{ij} \,x_{ij}\big) ;$\\
 (and the mean behavior, i.e. $0$, if the ratio is 0/0) ;\\
   as usual, ${\rm sim}^z_{ij}$ denotes the similarity between $i$ and $j$
   on the behavior $Z$;
 \item {\em total similarity weighted by dyadic covariate $W$}
                       \texttt{(totSimW)} ,
                       a weighted version of  \texttt{totSim}; \\
   $s^{\rm beh}_{i\vit}(x, z) =  z_i \, \sum_j x_{ij} \, w_{ij} \, ({\rm sim}^z_{ij} - \widehat{{\rm sim}^z})  .$
\setcounter{savenumi}{\value{enumi}}
\end{enumerate}



\medskip

\noindent
\textbf{\emph{User-defined interaction effects}}
\medskip

\noindent

The \emph{user-defined interaction effects} of Section~\ref{S_beh_infl}
are defined as follows.
Suppose we consider two effects $s^{\rm beh}_{ia}(x, z)$ and
$s^{\rm beh}_{ib}(x, z)$. Then their interaction effect is defined by
\begin{equation}
    s^{\rm beh}_{i [a\ast b] }(x, z) \,=\,
      \frac{1}{z_i} \, s^{\rm beh}_{ia}(x, z) \, s^{\rm beh}_{ib}(x, z) \ .
\end{equation}
For three effects $s^{\rm beh}_{ia}(x, z)$,
$s^{\rm beh}_{ib}(x, z)$ and $s^{\rm beh}_{ic}(x, z)$,
the interaction effect is defined by
\begin{equation}
    s^{\rm beh}_{i [a\ast b \ast c] }(x, z) \,=\,
      \frac{1}{z_i^2} \, s^{\rm beh}_{ia}(x, z) \,
                      s^{\rm beh}_{ib}(x, z) \, s^{\rm beh}_{ic}(x, z)\ .
\end{equation}
The division by $z_i$ or $z_i^2$, respectively, is necessary to offset the
fact that all behavior effects of \texttt{interactionType = OK} contain
a factor $z_i$, and further do not depend on $z_i$.
For example, the interaction between two main effects (\texttt{effFrom})
of actor covariates $v_{1i}$ and $v_{2i}$, is the same as
the main effect of the product variable $v_{1i}\times v_{2i}$,
with the proviso that the user-defined interaction does not center
the product variable;  the user-defined interaction
then is defined by
\begin{equation}
    s^{\rm beh}_{i [v_1\ast v_2] }(x, z) \,=\,
              \frac{1}{z_i}\, ( z_i \, v_{1i})  \, ( z_i \, v_{2i}) \,=\,
                      z_i \, v_{1i}\,v_{2i}  \ ,
\end{equation}
where both component variables $v_{1i}$ and $v_{2i}$
are internally centered, but the product variable will generally not have
mean 0.


\subsubsection{Behavioral creation function}
Also the behavioral model knows the distinction between evaluation,
creation, and
endowment effects. The formulae of the effects that can be included
in the behavioral creation function $c^{\rm beh}$ are the same as
those given for the behavioral evaluation function. However, they enter
calculation of the creation function only when the actor considers
increasing his behavioral score by one unit (downward steps), not
when downward steps (or no change) are considered. For more details,
consult
\citet*{SnijdersEA07} and \citet*{SteglichEA10}
and replace `going down' by `going up'.

The statistics reported as \emph{inc.\ beh.} (increase in behavior)
are the sums of the changes in actor-dependent values
for only those actors who increased in behavior.
More precisely, it is
\begin{equation}
\sum_{m=1}^{M-1} \sum_{i=1}^n I\{z_{i}(t_{m+1}) > z_{i}(t_m) \}\,
     \big( s^{\rm beh}_{ik}(x(t_{m+1})) -  s^{\rm beh}_{ik}(x(t_m))   \big) ,
\end{equation}
where $M$ is the number of observations, $x(t_m)$ is the observed situation
at observation $m$, and the indicator function
$I\{A\}$ is 0 if event $A$ is true
and 0 if it is untrue.

\subsubsection{Behavioral endowment function}
Also the behavioral model knows the distinction between evaluation and
endowment effects. The formulae of the effects that can be included
in the behavioral endowment function $e^{\rm beh}$ are the same as
those given for the behavioral evaluation function. However, they enter
calculation of the endowment function only when the actor considers
decreasing his behavioral score by one unit (downward steps), not
when upward steps (or no change) are considered. For more details,
consult
\citet*{SnijdersEA07} and
\citet*{SteglichEA10}.

The statistics reported as \emph{dec.\ beh.} (decrease in behavior)
are the sums of the changes in actor-dependent values
for only those actors who decreased in behavior.
More precisely, it is
\begin{equation}
\sum_{m=1}^{M-1} \sum_{i=1}^n I\{z_{i}(t_{m+1}) < z_{i}(t_m) \}\,
     \big( s^{\rm beh}_{ik}(x(t_{m})) -  s^{\rm beh}_{ik}(x(t_{m+1}))   \big) ,
\end{equation}
where $M$ is the number of observations, $x(t_m)$ is the observed situation
at observation $m$, and the indicator function
$I\{A\}$ is 0 if event $A$ is true
and 0 if it is untrue.

\subsubsection{Behavioral rate function}
\label{S_behRate}

The behavioral rate function $\lambda^{\rm beh}$ consists of a
constant term per period, \[ \lambda^{\rm beh}_{i} = \rho^{\rm
beh}_m \] for $m = 1, ..., M-1$, which can be called the basic rate;
multiplied potentially by the following further effects.
\begin{enumerate}
 \item The dependence on the position of the actor can be modeled
 as a function of the actor's out-degree \texttt{(outRate)},
 in-degree \texttt{(inRate)}, and number
 of reciprocated relations \texttt{(recipRate)}, the `reciprocated degrees'.
 These can be defined by
 \[ x_{i+} \,=\, \sum_j x_{ij}, \phantom{abcde} x_{+i} \,=\, \sum_j x_{ji},
                \phantom{abcde} x_{i(r)} \,=\, \sum_j x_{ij}x_{ji} \]
 (recalling that $x_{ii} = 0$ for all $i$).

The contribution of the out-degrees to the rate function
is a factor
 \[ \exp( \alpha_h \, x_{i+})\,, \]
if the associated parameter is denoted $\alpha_h$ for some $h$,
and similarly for the contributions of the in-degrees and the
reciprocated degrees.

 \item[{\hspace*{-1ex}$\bigodot$}]
 For the analysis of diffusion of innovations,
  which is applicable if the behavior variable
  is a non-decreasing variable with values 0 and 1,
  there are various contagion effects that render a model that
  would reduce to a proportional hazards model if the network
  were constant; see \citet{Greenan15}.
  This holds if they are part of the rate function,
  but not if they are included in the evaluation function.
  This also holds for effects depending on actor covariates.
  For all these effects, the rate function is multiplied by
 \[ \exp\big( \alpha_h \, a_{ih}(x)\big)\,, \]
 if the associated parameter is denoted $\alpha_h$ for some $h$,
 and the effect is $a_i(x)$.



\item \emph{average exposure effect} (\verb|avExposure|),
  defined as the proportion of $i$'s alters who have adopted the innovation,
\[
a_{i\vit}(y) = \frac{\sum_{j=1}^n z_j\, x_{ij} }{\sum_{j=1}^n x_{ij}};
\]

\item \emph{total exposure effect} (\verb|totExposure|), defined as the
 number of $i$'s alters who have adopted the innovation,
\[
a_{i\vit}(y) = \sum_{j=1}^n z_j\, x_{ij} ;
\]
\item \emph{infection by indegree effect} (\verb|infectIn|),
  defined as the sum of indegrees of $i$'s alters who are also adopters of the innovation,
\[
a_{i\vit}(y)=\sum_{j=1}^n z_j \,x_{ij}\, x_{+j};
\]
  for non-directed networks this is called the
   \emph{infection by degree effect} (\verb|infectDeg|);
\item \emph{infection by outdegree effect} (\verb|infectOut|),
 defined as the sum of outdegrees of $i$'s alters who are also adopters of the innovation,
\[
a_{i\vit}(y)=\sum_{j=1}^n z_j\, x_{ij}\, x_{j+};
\]
\item \emph{infection by covariate effect} (\verb|infectCovar|),
 defined as the sum of covariate values of $i$'s alters who are also adopters of the innovation,
\[
a_{i\vit}(y)=\sum_{j=1}^n z_j\, x_{ij}\, v_j;
\]
\item \emph{susceptibility to average exposure by indegree effect} (\verb|susceptAvIn|),
 defined as the interaction between $i$'s indegree and $i$'s average exposure,
\[
a_{i\vit}(y)=x_{+i} \frac{\sum_{j=1}^n z_j\, x_{ij}}{\sum_{j=1}^n x_{ij}};
\]
  for non-directed networks the equivalent effect is \verb|totExposure|;

\item \emph{susceptibility to average exposure by covariate effect} (\verb|susceptAvCovar|),
  defined as the interaction between $i$'s covariate value and $i$'s  average exposure,
\[
a_{i\vit}(y)=v_{i} \frac{\sum_{j=1}^n z_j\, x_{ij}}{\sum_{j=1}^n x_{ij}}.
\]

\end{enumerate}

\subsection{Effects for estimation by Generalized Method of Moments}

A variety of effects can be specified in \rst\ with \texttt{type='gmm'},
as shown in \textsf{effectsDocumentation()}.
These are not effects for the definition of the probability model,
but for the estimation by the Generalized Method of Moments
(Section~\ref{S_GMoM}).
This is still in full development, and will be documented later.

\newpage
\section{Parameter interpretation}
\label{S_interpret}

The main `driving force' of the actor-oriented model
is the evaluation function
(extended with the creation and/or endowment function, if these are
part of the model specification).
For the network, this is given in formula (\ref{f_net}) as
\[
f^{\rm net}_i(x) \, = \, \sum_k \beta^{\rm net}_k \, s^{\rm net}_{ik}(x)   \ .
\]
The evaluation function can be regarded as the ``attractiveness"
of the network (or behavior, respectively) for a given actor.
For getting a feeling of what are small and large values,
is is helpful to note that the evaluation functions are
used to compare how attractive various different tie changes are,
and for this purpose random disturbances are added
to the values of the evaluation function with standard deviations
equal\footnote{More exactly, the value is $\sqrt{\pi^2/6}$,
the standard deviation of the Gumbel
distribution; see \citet{Snijders01}.} to 1.28.

An alternative interpretation is that when actor $i$ is making
a `ministep', i.e., a single change in his outgoing ties
(where no change also is an option), and
$x_a$ and $x_b$ are two possible results of this ministep,
then $f^{\rm net}_i(x_b) - f^{\rm net}_i(x_a)$ is the log odds ratio
for choosing between these two alternatives -- so that the ratio
of the probability of $x_b$ and $x_a$ as next states is
\[
  \exp\big(f^{\rm net}_i(x_b) - f^{\rm net}_i(x_a)\big) \ .
\]
Note that, when the current state is $x$, the possibilities
for $x_a$ and $x_b$ are $x$ itself (no change), or $x$ with one extra
outgoing tie from $i$, or $x$ with one fewer outgoing tie from $i$.
Explanations about log odds ratios can be found
in texts about logistic regression and loglinear models.
For dependent behavior variables, the interpretation is similar,
keeping in mind that permitted changes in the behavior variable are
--1, 0, and +1 (as far as these changes do not lead beyond the
permitted range).

If one wishes an extremely short description of what the parameters
of the objective function stand for, one could write
`non-standardized contributions to log-probabilities'
as a shorthand for
`contributions to log-probabilities of increasing the
dependent variable by 1~unit when the effect is increased by 1~unit'.
Here the dependent variable is either the tie variable $X_{ij}$
or the behavior variable $Z_i$; the effect is $s_{ik}(x)$.



\subsection{Networks}

The evaluation function is a weighted sum of `effects'
$s^{\rm net}_{ik}(x)$.
Their formulae can be found in Section~\ref{S_f}.
These formulae, however, are defined as a function of the whole
network $x$, and in most cases the contribution of a single tie
variable $x_{ij}$ is just a simple component of this formula.
The contribution to $s^{\rm net}_{ik}(x)$
of adding the tie $i \rightarrow h$ minus the
contribution of adding the tie $i \rightarrow j$ is the log odds ratio
comparing the probabilities of $i$ sending a new tie to $h$ versus
sending the tie to $j$, if all other effects $s^{\rm net}_{ik}(x)$
yields the same values for these two hypothetical new configurations.

For example, suppose that actors $j$ and $h$,
actual or potential relation partners of actor $i$,
have exactly the same network
position and the same values on all variables included in the model,
except that for some actor variable $V$ for which only the
popularity (alter) effect is included in the model,
actor $h$ is one unit higher than actor $j$: $v_h = v_j + 1$.
It can be seen in Section~\ref{S_f} that
the popularity (alter) effect is defined as
\[
s^{\rm net}_{ik}(x) \, = \,  \sum_j x_{ij}\, v_j \ .
\]
The contribution to this formula made by a single tie variable,
i.e., the difference made by filling in $x_{ij} = 1$ or $x_{ij} = 0$
in this formula, is just $v_j$.
Let us denote the weight of the $V$-alter effect by $\beta_k$.
Then, the difference between extending a tie to $h$ or to $j$
that follows from the $V$-alter effect is
$\beta_k \times (v_h - v_j) = \beta_k \times 1 = \beta_k$.

Thus, in this situation, $\beta_k$ is the log odds ratio of the probability
that $h$ is chosen compared to the probability that $j$ is chosen.
E.g., if $i$ currently has a tie neither to $j$ nor to $h$,
and supposing that $\beta_k = 0.3$, the probability for $i$ to
extend a new tie to $h$ is $e^{0.3} = 1.35$ times as high
as the probability for $i$ to extend a new tie to $j$.

\subsection{Behavior}

The evaluation function for behavior is given by
\[
f^{\rm beh}_i(x, z) \, = \, \sum_k \beta^{\rm beh}_k s^{\rm beh}_{ik}(x, z) \ ,
\]
see (\ref{f_beh}).
In many cases\footnote{For effects satisfying this condition,
the \texttt{interactionType} is defined as \texttt{OK}.}
the effect has the form of a product
\begin{equation}
s^{\rm beh}_{ik}(x, z) \,=\, z_i \,s^{0}_{ik}(x, z) \ ,  \label{beh_generic}
\end{equation}
where $s^{0}_{ik}(x, z)$ is not dependent on $z_i$
(although it might depend on $z_j$ for other actors $j$), and therefore
would not be affected by the outcome of a behavior ministep of actor $i$.
Examples are the main effect of an actor attribute, but also the
average alter effect.
For such effects,
when a ministep in behavior occurs, the contribution
on the probability distribution of the change is as follows:
a change of $z_i $ by --1 will decrease the evaluation function by
$\beta^{\rm beh}_k s^{0}_{ik}(x, z)$,
and a change by +1 will increase it by the same amount.
(Note that this amount does not depend on the value of $z_i$
because of the mentioned condition.)
Therefore, the log-odds-ratio of an increase in behavior compared to
staying constant that can be attributed to a difference of +1 in the
value of the predictor function $s^{0}_{ik}(x, z)$, is equal to
$\beta^{\rm beh}_k$. The odds ratio is $\exp(\beta^{\rm beh}_k)$.

For example, later in this section results are presented where,
for an analysis of drinking behavior, the
estimated parameter for average alter is 1.1414.
This means that when comparing two individuals who are equal in all respects
except that the friends of the first on average are  1 higher
on the drinking scale than those of the second individual,
the odds of increasing drinking behavior compared to no change
(in the event of a ministep with respect to drinking behavior)
are $\exp(1.1414) = 3.1$ times higher for the first individual
than for the second.
\medskip

The average similarity effect is defined by
\[ s^{\rm beh}_{i\vit}(x, z) = x_{i+}^{-1} \,
           \sum_j x_{ij} \big({\rm sim}^z_{ij} - \widehat{{\rm sim}^z}\big)
\]
(see Section~\ref{S_f_b}), where ${\rm sim}^z_{ij}$ is given in (\ref{simV})
in Section~\ref{S_internal}.
(If the ratio is 0/0, the effect is defined as 0.)
Subtracting $\widehat{{\rm sim}^z}$ is done just for the purpose
of centering.
Since the underlying measure ${\rm sim}^z_{ij}$ ranges from 0
(if $z_i$ and $z_j$ are the two different extreme values of $Z$)
to 1 (if $z_i = z_j$), this effect has a range of 1 independently
of the scaling of $Z$.
Therefore the average similarity effect, and also the total
similarity effect, differ from the total and average
alter effects by the fact that the latter are dependent on the scaling
of $Z$, whereas the former are not directly dependent on this scaling.
This means that parameters for average similarity effects can be regarded
as being on the same scale for different variables, but parameters
for average alter are not.
\medskip

The interpretations of total and average similarity are more laborious
to explain than the interpretation of the average alter effect.
This is because total and average similarity are not of the form
(\ref{beh_generic}). To explain the log-odds or odds ratios due to these
effects, it has to be understood how a change in the behavior $z_i$
will affect the values of these effects.
Examining their formulae leads to the following.

For a given actor $i$, the out-degree (number of friends) is denoted $x_{i+}$.
Let the number of friends whose values $z_j$ are less than, equal to,
or greater than the value $z_i $ of $i$, be denoted by $a$, $b$, and $c$.
Denote the range (maximum minus minimum value) of the behavior by $r$.
Then, in the event of a ministep with respect to behavior,
the contributions of the total similarity effect to the log-probabilities
of changes --1, 0, or +1, are given by $\beta^{\rm beh}_k(a-b-c)/r$,
0, and $\beta^{\rm beh}_k(c-a-b)/r$, respectively.
The contributions for the average similarity effect are
$\beta^{\rm beh}_k(a-b-c)/(rx_{i+})$,
0, and $\beta^{\rm beh}_k(c-a-b)/(rx_{i+})$.
This shows that the influence of the friends in the similarity effects
depends only on whether they have larger or smaller values than the focal actor,
not on how much larger the values are.
It also shows that for the similarity effects the dispersion of the
friends' values matters and not only their average,
whereas for the average alter effect only the average matters.

To have a compact formulation, without all this detail, one could
say the following. We use the example on one of the following
pages, where an average similarity effect on drinking is reported of
$\hat\beta^{\rm beh}_k = 3.9689$, where drinking has a range of $r = 5-1 = 4$.
For an individual all of whose friends drink more than this individual does,
the contribution of friends' influence to the odds of an increase in drinking
as compared to no change is a factor $\exp(3.9689/4) = 2.7$.
(In this formulation, the condition ``in the event of a ministep
with respect to drinking behavior" is left implicit.)

In the same situation, if hypothetically a total average similarity
effect were found of 0.82, then one could say that having \emph{one} additional
friend who drinks more than oneself increases the odds of an increase in drinking
as compared to no change by a factor $\exp(0.82/4) = 1.23$.
In general, parameters for the total similarity effect will tend to be
smaller than those for the average similarity effect, because the former
refer to comparisons about a single friend, and the latter to comparisons
about all friends.

\subsection{Ego -- alter selection tables}

When some variable $V$ occurs in several effects in the model,
then its effects can best be understood
by considering all these effects simultaneously.
This section treats this issue for the case that $V$ is an
actor variable with more than two values (for dichotomous
variables the situation is simpler).

As an example, consider the
Glasgow data set from the Teenage Friends and Lifestyle Study of
West et al.\ \citep{MichellWest1996,PearsonWest03,SteglichEA10}.
We refer to any of these papers for a further description of the data.
The data is used for the 129 students who were present at all three measurement
times; this data set is available from the \SI website.
We treat friendship as the dependent network, drinking as the
dependent behaviour variable, and cannabis use (`drugs') as an
actor covariate.
Drinking has categories 1--5, coded as
1 (none), 2 (once or twice a year), 3 (once a month), 4 (once a week),
and 5 (more than once a week);
cannabis use is coded 1 (none), 2 (tried once), 3 (occasional) and 4 (regular).
The frequencies (over the three waves combined) of these substance
use variables are given in Figure~\ref{F_DD}.

\begin{figure}
  \centering
  \includegraphics[width=0.4\textwidth]{TableDrinking.png}
  \hspace{1em}
  \includegraphics[width=0.4\textwidth]{TableDrugs.png}
  \caption{Frequencies of drinking and drug use over 3 waves combined.}\label{F_DD}
\end{figure}

For both actor variables, in the network part we use the
four-parameter specification of \citet{SL2018}, which is
a combination of the ego minus alter squared, alter squared,
ego, and alter effects.

The formulae in Section~\ref{S_f} imply that the
components in the network evaluation function corresponding to the effects
of variable $V$ are
\begin{equation}
\beta_{\rm sq.\ diff}  \sum_j x_{ij}\, (v_j - v_i)^2  \, + \,
 \beta_{\rm ego}\, (v_i - \bar v) \, x_{i+}
           \, + \, \beta_{\rm alter}  \sum_j x_{ij}\, (v_j - \bar v)
 \, + \, \beta_{\rm sq.\ alter}  \sum_j x_{ij}\, (v_j - \bar v)^2  \ .
          \label{eq_4par_V}
\end{equation}
The contribution to this formula of the single tie variable $x_{ij}$  ---
i.e., the difference between the values of~(\ref{eq_4par_V}) for $x_{ij}=1$
and $x_{ij}=0$  ---  is equal to
\begin{equation}
\beta_{\rm sq.\ diff}   (v_j - v_i)^2 \, + \,
  \beta_{\rm ego}\, (v_i - \bar v)
         \, + \, \beta_{\rm alter}\,  (v_j - \bar v) \, + \,
      \beta_{\rm sq.\ alter}  \, (v_j - \bar v)^2   \ .
                 \label{eq_4par}
\end{equation}

\iffalse
For example, if in a network dynamics model the
ego, alter, and similarity effects of a variable $V$ are specified,
then the formulae for their contribution
to the evaluation function can be obtained
from the components listed in Section~\ref{S_f} as
\begin{equation}
 \beta_{\rm ego}\, v_i \, x_{i+}
           \, + \, \beta_{\rm alter}  \sum_j x_{ij}\, v_j \, + \,
        \beta_{\rm sim}  \sum_j x_{ij}
                          ({\rm sim}^v_{ij} - \widehat{{\rm sim}^v}) \ ,
        \label{eq_contr_V}
\end{equation}
where the similarity score is
\[
{\rm sim}^v_{ij}= 1 - \frac{\vert v_i - v_j \vert}{\Delta_V} \ ,
\]
with
$\Delta_V=\max_{ij}\vert v_i - v_j \vert$ being
the observed range of the covariate $v$
and where $\widehat{{\rm sim}^v}$ is the mean of all similarity scores.

The superscript $^{\rm net}$ is left out of the notation for the parameters
in order not to clutter the notation.

The contribution of variable $V$ to the
network evaluation function of actor $i$ is given by
\begin{align}
  &  \beta_{\rm ego}\, (v_i - \bar v)
                \, + \, \beta_{\rm alter}\,  (v_j - \bar v) \, + \,
   \beta_{\rm sim} \, ({\rm sim}^v_{ij} - \widehat{{\rm sim}^v} ) \nonumber \\
 & \hspace{3em} = \, \beta_{\rm ego}\, (v_i - \bar v)
              \, + \, \beta_{\rm alter}\,  (v_j - \bar v) \, + \,
        \beta_{\rm sim} \,  \Big( 1 - \frac{\vert v_i - v_j \vert}{\Delta_V}
                     - \widehat{{\rm sim}^v} \Big) \ .
                 \label{eq_sel}
\end{align}
\fi

It should be noted that by default all variables are internally centered by \si.
The mean values used for the centering
are given near the beginning of the file produced by
\sfn{print01Report()} and are given by the \textsf{"mean"}
attributes of the covariates, as explained in
Section~\ref{S_center}.
This is made explicit in the formulae by the subtraction
of the mean $\bar v$.
From this equation (\ref{eq_4par}) a table, or a plot, can be made
that gives these contributions for some values of $v_i$ and $v_j$.

From the output of \sfn{print01Report()} for these data it can be seen that
the alcohol use variable assumes values from 1 to 5, with overall
mean\footnote{The mean of the three means per wave.}
equal to $\bar v = 2.99$.
%, and mean of the similarity variable $\widehat{{\rm sim}^v} = 0.6983$.
Drug use is a changing actor variable, with
range 1--4, and mean $\bar v = 1.5$.
% and average dyadic similarity $\widehat{{\rm sim}^v} = 0.7533$.

Suppose that we fit a model of network-behavior co-evolution to this data set
with for the network evolution the effects of outdegree, reciprocity,
geometrically weighted edgewise shared partners (`gwesp', in the
\texttt{gwespFF} version, representing transitivity),
indegree popularity, outdegree activity, outdegree popularity,
and reciprocal degree activity; ego, alter, and same effect of sex;
for drinking and drug use the four effects in (\ref{eq_4par_V});
and for the  behavior (i.e., alcohol drinking) dynamics the
effects linear shape, quadratic shape (effect of drinking on itself),
and average alter.

The results obtained are as follows.\\

{\small
% Table based on sienaFit object ans5 , Sat Feb 03 18:03:20 2018
\begin{center}
\begin{tabular}{l | r@{.}l r@{.}l   }
\hline
\rule{0pt}{2ex}\relax
Effect &\multicolumn{2}{c}{par.}&\multicolumn{2}{c  }{(s.e.)}  \\[0.5ex]
\hline
\multicolumn{4}{l}{\rule{0pt}{2.5ex}\relax \emph{Network Dynamics}}&\\
\hline
\rule{0pt}{2ex}\relax
constant friendship rate (period 1) &   12 & 643 & (1 & 595)\\
constant friendship rate (period 2) &   10 & 201 & (1 & 024)\\
\hline
\rule{0pt}{2ex}\relax
outdegree (density)                 &  --2 & 723 & (0 & 304)\\
reciprocity                         &    3 & 387 & (0 & 244)\\
gwesp (transitivity)                &    1 & 847 & (0 & 088)\\
indegree -- popularity              &  --0 & 030 & (0 & 025)\\
outdegree -- popularity             &  --0 & 107 & (0 & 048)\\
outdegree -- activity               &    0 & 075 & (0 & 037)\\
reciprocal degree -- activity       &  --0 & 287 & (0 & 051)\\
sex alter                           &  --0 & 120 & (0 & 096)\\
sex ego                             &    0 & 054 & (0 & 108)\\
same sex                            &    0 & 664 & (0 & 089)\\
drinking alter                      &    0 & 024 & (0 & 082)\\
drinking squared alter              &  --0 & 113 & (0 & 091)\\
drinking ego                        &    0 & 104 & (0 & 088)\\
drinking (alter-ego) squared        &  --0 & 117 & (0 & 056)\\
drugs alter                         &  --0 & 137 & (0 & 091)\\
drugs squared alter                 &    0 & 164 & (0 & 067)\\
drugs ego                           &  --0 & 123 & (0 & 068)\\
drugs  (alter-ego) squared          &  --0 & 051 & (0 & 025)\\
\hline
\multicolumn{4}{l}{\rule{0pt}{2.5ex}\relax \emph{Behaviour Dynamics}}&\\
\hline
\rule{0pt}{2ex}\relax
rate drinking (period 1)            &    1 & 598 & (0 & 302)\\
rate drinking (period 2)            &    2 & 431 & (0 & 508)\\
\hline
\rule{0pt}{2ex}\relax
drinking linear shape               &    0 & 452 & (0 & 138)\\
drinking quadratic shape            &  --0 & 609 & (0 & 181)\\
drinking average alter              &    1 & 281 & (0 & 488)\\
\hline
\multicolumn{5}{l}
   {\footnotesize{convergence $t$ ratios all $<$ 0.04.}}\\
\multicolumn{5}{l}{\footnotesize{Overall maximum convergence ratio 0.15.}}
\end{tabular}
\end{center}
}

\noindent
We interpret here the parameter estimates for the effects of drinking behavior
and drug use without being concerned with the significance, or lack thereof.
For the drinking behavior, formula (\ref{eq_4par}) yields
\[
  -0.117\, (v_j - v_i)^2 \, + \,
  0.104 \, (v_i - \bar v)
         \, + \, 0.024 \,  (v_j - \bar v) \, - \,
      0.113  \, (v_j - \bar v)^2   \ .
\]

These values can be calculated for $v_i$ and $v_j$ ranging
from 1 to 5, with $\bar v = 2.99$.
This is called the \emph{selection table}.
On the \SI website the script \texttt{SelectionTables.r} is available,
which contains several functions that can be helpful for doing this.


Given that this script is available in the working directory,
the data set is called \texttt{G129\_Data}, the answer
(\sfn{sienaFit}) object is called \texttt{ans}, the network \texttt{"friendship"},
and the actor variable \texttt{"drinking"}, the following script
can be used.

\begin{verbatim}
source("SelectionTables.r") # needs to be done only once in the session
sm.drink <- selectionMatrix(ans, G129_Data, "friendship", "drinking", 1:5)
# It can be displayed
sm.drink
# and if package xtable is loaded, also be written
# to a latex or html file. For example,
tab.drink <- xtable(sm.drink)
print(tab.drink,file="tab_drink.htm", type="html",
             html.table.attributes = "rules = none")
# The html.table.attributes option gives the <table> tag
# used in the html file.
# and optional
xtable(sm.drink) # for a LaTeX table
\end{verbatim}

This will produce the following table.

\begin{table}[h]
\centering
\begin{tabular}{l  r@{.}l  r@{.}l  r@{.}l  r@{.}l  r@{.}l}
  \hline
$ v_i \ \  \backslash  \ \ v_j $
    & \mcc{2}{1}  & \mcc{2}{2} & \mcc{2}{3} & \mcc{2}{4} & \mcc{2}{5} \\
  \hline
  1 & --0&70 & --0&46 & --0&68 & --1&35 & --2&49 \\
  2 & --0&72 & --0&24 & --0&22 & --0&66 & --1&57 \\
  3 & --0&96 & --0&25 &   0&00 & --0&21 & --0&88 \\
  4 & --1&45 & --0&50 & --0&01 &   0&01 & --0&42 \\
  5 & --2&17 & --0&98 & --0&26 &   0&00 & --0&20 \\
   \hline
\end{tabular}
\caption{Selection table for friendship with respect to drinking.}
\label{T_sel_fd}
\end{table}

It is instructive to make a plot of this table. This can be
done, e.g., using package \sfn{ggplot2} \citep{ggplot2}.
The following script will produce a \texttt{png} plot in the
current working directory.
Of course all elements of this script can be changed to accommodate the wishes
given the purpose of the figure.

\begin{verbatim}
library(ggplot2)
vname <- "drinking"
name <- "friendship"
levls <- 1:5
vselect <- selectionTable(ans, G129_Data, name, vname, levls)
sp <- ggplot(vselect, aes(valter, select, group=ego, colour=ego))
png(filename=paste("selectionTable_",vname,".png",sep=""),
        width=1000,height=800)
sp  +geom_point() + geom_smooth(size=1.2, span=3) +
        scale_colour_hue() +
        scale_x_continuous(breaks=levls) +
        theme(legend.key=element_blank())+
        labs(x=paste(vname),
                y=paste("selection function"),
                title=paste("Effect",vname,"on",name),
                colour=paste(vname)) +
        theme_grey(base_size=26, base_family="") +
        theme(legend.key.width=unit(1, "cm")) +
        theme(plot.title=element_text(hjust=0.5))
graphics.off()
\end{verbatim}

In this case, what was produced can be seen in Figure~\ref{F_sel_dk}.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.7\textwidth]{selectionTable_drinking.png}
  \caption{Plot of selection table  for friendship with respect to drinking.}
  \label{F_sel_dk}
\end{figure}

From the table it can be concluded that there is a significant tendency
toward homophily (negative effect of ego minus alter squared).
\iffalse % to be added when SL2018 is out
Interpreting the results along the lines of  \citet{SL2018},
 there is a significant tendency
to homophily (negative effect of ego minus alter squared), and
a non-significant tendency to conformity (negative effect
of alter squared), where the estimated social norm is
$\bar v + \hat\beta_{\rm{altX}}/(2 \,  \hat\beta_{\rm{altSqX}}) =
2.99 + 0.024/(2 \times 0.113) = 3.1$.
\fi
We see that the maximum of the curves increases with
ego's value $v_i$, but for low $v_i$ the maximum is larger than $v_i$,
and for high $v_i$ it is less than $v_i$:
homophily is combined with a kind of `regression to the mean'.
\medskip

For drug use,  formula (\ref{eq_4par}) yields
\[
  -0.051\, (v_j - v_i)^2 \, + \,
  -0.123 \, (v_i - \bar v)
         \, - \, 0.137 \,  (v_j - \bar v) \, + \,
      0.164  \, (v_j - \bar v)^2   \ ,
\]
which leads to the following table.
\bigskip

\begin{table}[h]
\centering
\begin{tabular}{l  r@{.}l  r@{.}l  r@{.}l  r@{.}l }
  \hline
$ v_i \ \  \backslash  \ \ v_j $
    & \mcc{2}{1}  & \mcc{2}{2} & \mcc{2}{3} & \mcc{2}{4}  \\
  \hline
1 & 0&16 & --0&02 & 0&03 & 0&30 \\
  2 & --0&02 & --0&09 & 0&06 & 0&43 \\
  3 & --0&30 & --0&27 & --0&01 & 0&47 \\
  4 & --0&68 & --0&54 & --0&19 & 0&39 \\
   \hline
\end{tabular}
\caption{Selection table for friendship with respect to drug use.}
\label{T_sel_fdg}
\end{table}


The corresponding figure is in Figure~\ref{F_sel_dg}.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.7\textwidth]{selectionTable_drugs.png}
  \caption{Plot of selection table  for friendship with respect to drug use.}
  \label{F_sel_dg}
\end{figure}

Here we see a totally different pattern.
Since the sum of the alter squared and the difference squared effects
is positive, the parabolas have a minimum rather than a maximum.
Pay attention to the vertical scale: in Figure~\ref{F_sel_dk} the
difference between the highest and lowest values is about 2.5,
in Figure~\ref{F_sel_dg} it is about 1.2, half as much.
This signifies that overall, drug use has smaller effects on friendship
than smoking. For ego's who do not use cannabis ($v_i = 1$),
drug use of alters hardly matters;
egos who use cannabis regularly ($v_i = 4$) have a somewhat lower
attraction to alters with lower cannabis use.
For this actor variable, the specification with the effects of ego, alter,
and the product interaction ego $\times$ alter might fit just as well,
or perhaps better.

\clearpage

\subsection{Ego -- alter influence tables}

In quite a similar way as in the preceding section,
from the parameter estimates as presented in the
output tables, combined with the formulae for the effects,
we can construct tables indicating how likely are changes to
various different values of the behavior,
depending on the behavior of the actor's friends.
The functions used to define the effects can be found
in Section~\ref{S_f_b}, and it must not be forgotten that all variables
are internally centered in \rs, and the subtracted means are reported
in the initial output produced by \sfn{print01Report},
but for the covariates they also can be obtained by requesting the
\textsf{"mean"} attributes of the covariates, see Section~\ref{S_center}.

\subsubsection{Average alter}

In the model from the preceding section, the estimated coefficients in the
behavior evaluation function are as follows.
\medskip

{\small
% Table based on sienaFit object ans5 , Sat Feb 03 18:03:20 2018
\begin{center}
\begin{tabular}{l | r@{.}l r@{.}l   }
\hline
\rule{0pt}{2ex}\relax
Effect &\multicolumn{2}{c}{par.}&\multicolumn{2}{c  }{(s.e.)}  \\[0.5ex]
\hline
\multicolumn{4}{l}{\rule{0pt}{2.5ex}\relax \emph{Behaviour Dynamics}}&\\
\hline
\rule{0pt}{2ex}\relax
rate drinking (period 1)            &    1 & 598 & (0 & 302)\\
rate drinking (period 2)            &    2 & 431 & (0 & 508)\\
\hline
\rule{0pt}{2ex}\relax
drinking linear shape               &    0 & 452 & (0 & 138)\\
drinking quadratic shape            &  --0 & 609 & (0 & 181)\\
drinking average alter              &    1 & 281 & (0 & 488)\\
\hline
\end{tabular}
\end{center}
}

The dependent behavior variable now is indicated $Z$. (In the preceding
section the letter $V$ was used, but this referred to any actor variable
predicting network dynamics,
irrespective of whether it was also a dependent behavior variable.)

The formulae in Section \ref{S_f_b} show that the evaluation function
for this model specification is
\begin{equation}
   f^{\rm beh}_i \,=\, \beta_{\rm linear} \, (z_i - \bar z)
           \,+\, \beta_{\rm quad} \, (z_i - \bar z)^2 \,+\,
          \beta_{\rm avAlt}\,  (z_i - \bar z)(\bar z_{(i)} - \bar z)  \ ,
                    \label{eq_f_b2}
\end{equation}
where $\bar z_{(i)} $ is the average $Z$ value of $i$'s
friends,
\[
  \bar z_{(i)}  =\frac{1}{x_{i+}} \, \sum_j x_{ij}\, z_j   \ ,
\]
and 0 if this formula would be 0/0.

The \emph{Influence Table} presents a matrix with in the rows
the average of $Z$ for $i$'s friends,
in the columns the possible values of $z_i$,
and in the cells the evaluation function (\ref{eq_f_b2}).
For the table above, the evaluation function is
\[
   {\hat f}^{\rm beh}_i \,=\, 0.452 \, (z_i - \bar z)
           \,-\, 0.609 \, (z_i - \bar z)^2 \,+\,
         1.281\,  (z_i - \bar z)(\bar z_{(i)} - \bar z)  \ .
\]
At the \SI website there is a script \texttt{InfluenceTables.r}
which can be used to produce the table and the corresponding plot.

Given that this script is available in the working directory,
the data set is called \texttt{G129\_Data}, the answer
(\sfn{sienaFit}) object is called \texttt{ans}, the network \texttt{"friendship"},
and the actor variable \texttt{"drinking"}, the following script
can be used.

\begin{verbatim}
source("InfluenceTables.r") # needs to be done only once in the session
im.drink <- influenceMatrix(ans, G129_Data, 'friendship', 'drinking', 1:5)
# It can be displayed
im.drink
# and if package xtable is loaded, also be written
# to a latex or html file. For example,
tbl.drink <- xtable(im.drink)
print(tbl.drink,file="tbl_drink.htm", type="html",
             html.table.attributes = "rules = none")
# The html.table.attributes option gives the <table> tag
# used in the html file.
# and optional
xtable(tbl.drink) # for a LaTeX table
\end{verbatim}

The influence table is as follows.
\begin{center}
\begin{tabular}{l r@{.}l  r@{.}l  r@{.}l  r@{.}l  r@{.}l }
 $\bar z_{(i)}$ \ \ $ \backslash $ \ \ $z_i $   &  \mcc{2}{ 1}
               & \mcc{2}{ 2} & \mcc{2}{ 3} & \mcc{2}{ 4} &  \mcc{2}{ 5}
\separationb
  1 &   1&76 &   1&48 & --0&02 & --2&74 & --6&67 \\
  2 & --0&79 &   0&21 & --0&01 & --1&44 & --4&10 \\
  3 & --3&34 & --1&06 &   0&00 & --0&15 & --1&53 \\
  4 & --5&89 & --2&33 &   0&02 &   1&14 &   1&05 \\
  5 & --8&44 & --3&59 &   0&03 &   2&43 &   3&62 \\
   \hline
\end{tabular}
\end{center}
The interpretation\footnote{The interpretation is given here
in terms of attraction and preferences;
this is for the sake of having a straightforward and easy way of expressing
the interpretation, which strictly should be only about probabilities.}
is that each row corresponds to a given average behavior
of the focal actor's friends; comparing the different values in the row
shows the relative `attractiveness' of the different potential values
of ego's own behavior.
The maximum in each row is assumed at the diagonal. This means that
for each value for the average friends' behavior $\bar z_{(i)}$,
the focal actor `prefers' to have the same behavior as all these friends.
The differences in the bottom rows are larger than in the top rows,
indicating that in the case where the friends who do not drink at all,
the `preference' (or social pressure) toward imitating their behavior is
less strong than in the case where all the friends drink a lot.

A figure of this table can be produced, e.g., by the following script.
\begin{verbatim}
library(ggplot2)
name <- 'drinking'
zname <- 'friendship'
levls <- 1:5
png(filename=paste("influenceTable_",name,".png",sep=""), width=1000,height=800)
zselect <- influenceTable(ans, G129_Data, zname, name, levls)
sp <- ggplot(zselect, aes(zego, select, group=alter, colour=alter))
sp + geom_point() + geom_smooth(size=1.2, span=3) +
   scale_colour_hue() +
   scale_x_continuous(breaks=levls) +
   theme(legend.key=element_blank())+
   labs(x=paste(name),
      y=paste('evaluation function'),
      title=paste('Influence effect',zname,'on',name),
      colour=paste(name,'\nalter')) +
   theme_grey(base_size=26, base_family="") +
   theme(legend.key.width=unit(1, "cm")) +
   theme(plot.title=element_text(hjust=0.5))
graphics.off()
\end{verbatim}

The corresponding figure is in Figure~\ref{F_infl_dk}.

\begin{figure}[hb]
  \centering
  \includegraphics[width=0.7\textwidth]{influenceTable_drinking.png}
  \caption{Plot of influence table  for friendship with respect to drinking.}
  \label{F_infl_dk}
\end{figure}

\noindent
The five plotted curves intersect at the same point. This is indeed implied
by  formula (\ref{eq_f_b2}), which is 0 if $z_i = \bar z = 2.99$.


Another way to look at the behavior evaluation function is to consider
mathematically the location of its maximum.
This function here can be written also as
\[
   f^{\rm beh}_i \,=\, \big( 0.452 +
                1.281( \bar z_{(i)} - \bar z) \big) \, (z_i - \bar z)
       \,-\, 0.609 \, (z_i - \bar z)^2   \ .
\]
Differentiating with respect to $z_i$ shows that
this function is maximal for
\[
   z_i = \bar z \,+\, \frac{0.452 +
               1.281( \bar z_{(i)} - \bar z)}{2 \times  0.609 }
    \,=\,  0.22 \,+\, 1.05 \,  \bar z_{(i)}  \ ,
\]
just a little bit larger than $ \bar z_{(i)}$.
Indeed in the table and in the plot we see that, if $ \bar z_{(i)}$
has integer values 1, 2, 3, 4, or 5,
the highest values are obtained exactly
for  $z_i = \bar z_{(i)}$.


\subsubsection{Average similarity}

The formulae in Section \ref{S_f_b} show that when average similarity is used
as the specification of social influence, the evaluation function is given by
\begin{equation}
   f^{\rm beh}_i(z_i) \,=\, \beta_{\rm trend} \, (z_i - \bar z)
               \,+\, \beta_{\rm drink} \, (z_i - \bar z)^2 \,+\,
                 \beta_{\rm av.\ sim}\,  \frac{1}{x_{i+}} \,
          \sum_j x_{ij} \big({\rm sim}(z_i, z_j) - \widehat{{\rm sim}^z}\big)
                    \label{eq_f_b10}
\end{equation}
where the similarity score is
\[
 {\rm sim}(z_i, z_j) \,=\, 1 \,-\, \frac{ \vert z_i - z_j \vert}{\Delta}
\]
in which $\Delta$ is the range (maximum minus minimum) of $Z$,
while $\widehat{{\rm sim}^z}$ is the mean of the similarity scores.
The latter is just a constant that does not have any influence on
the change probabilities of the behavior. Therefore we
use the equivalent form
\begin{equation}
   f^{\rm beh}_i(z_i) \,=\, \beta_{\rm trend} \, (z_i - \bar z)
               \,+\, \beta_{\rm drink} \, (z_i - \bar z)^2 \,+\,
                 \beta_{\rm av.\ sim}\,  \frac{1}{x_{i+}} \,
          \sum_j x_{ij} \bigg(
          \frac{ \vert \bar z - z_j \vert \,-\, \vert z_i - z_j \vert}{\Delta}
          \bigg) \ ,                    \label{eq_f_b1}
\end{equation}
which has the advantage that it is zero for $z_i = \bar z$,
and therefore comparable across $i$.

With this specification for the effect of drinking
(and a modified specification of the effect of drug use), the estimation
results are as follows.
\medskip

{\small
\begin{center}
% Table based on sienaFit object ans.s , Sun Feb 04 20:09:27 2018
\begin{tabular}{l | r@{.}l r@{.}l  | }
\hline
\rule{0pt}{2ex}\relax
Effect &\multicolumn{2}{c}{par.}&\multicolumn{2}{c | }{(s.e.)}  \\[0.5ex]
\hline
\multicolumn{4}{l}{\rule{0pt}{2.5ex}\relax \emph{Network Dynamics}}&\\
\hline
\rule{0pt}{2ex}\relax
constant friendship rate (period 1) &   12 & 769 & (1 & 331)\\
constant friendship rate (period 2) &   10 & 262 & (0 & 987)\\
\hline
\rule{0pt}{2ex}\relax
outdegree (density)                 &  --2 & 708 & (0 & 320)\\
reciprocity                         &    3 & 376 & (0 & 247)\\
gwesp (transitivity)                &    1 & 837 & (0 & 084)\\
indegree -- popularity              &  --0 & 028 & (0 & 027)\\
outdegree -- popularity             &  --0 & 108 & (0 & 053)\\
outdegree -- activity               &    0 & 075 & (0 & 037)\\
reciprocal degree -- activity       &  --0 & 285 & (0 & 052)\\
sex alter                           &  --0 & 123 & (0 & 092)\\
sex ego                             &    0 & 051 & (0 & 107)\\
same sex                            &    0 & 661 & (0 & 087)\\
drinking alter                      &    0 & 037 & (0 & 075)\\
drinking squared alter              &  --0 & 108 & (0 & 095)\\
drinking ego                        &    0 & 097 & (0 & 091)\\
drinking squared ego                &    0 & 010 & (0 & 098)\\
drinking (ego -- alter) squared     &  --0 & 108 & (0 & 052)\\
drugs alter                         &  --0 & 020 & (0 & 054)\\
drugs ego                           &  --0 & 183 & (0 & 066)\\
drugs ego $\times$ drugs alter      &    0 & 126 & (0 & 052)\\
\hline
\multicolumn{4}{l}{\rule{0pt}{2.5ex}\relax \emph{Behaviour Dynamics}}&\\
\hline
\rule{0pt}{2ex}\relax
rate drinking (period 1)            &    1 & 696 & (0 & 326)\\
rate drinking (period 2)            &    2 & 659 & (0 & 565)\\
\hline
\rule{0pt}{2ex}\relax
drinking linear shape               &    0 & 461 & (0 & 136)\\
drinking quadratic shape            &  --0 & 003 & (0 & 088)\\
drinking average similarity         &    6 & 190 & (1 & 810)\\
\hline
\multicolumn{5}{l}
   {\footnotesize{convergence $t$ ratios all $<$ 0.08.}}\\
\multicolumn{5}{l}{\footnotesize{Overall maximum convergence ratio 0.17.}}
\end{tabular}
\end{center}
}

Equation (\ref{eq_f_b1}) is less simple than equation (\ref{eq_f_b2}), because
(\ref{eq_f_b2}) is a quadratic function of $z_i$, with coefficients depending
on the $Z$ values of $i$'s friends as a function of their average,
whereas (\ref{eq_f_b1}) depends on the entire distribution
of the $Z$ values of $i$'s friends.

Suppose that, in model (\ref{eq_f_b1}),
the similarity coefficient $\beta_{\rm av.\ sim}$ is positive,
and compare two focal actors,
$i_1$  all of whose friends have $z_j = 3$
and $i_2$ who has four friends, two of whom with
$z_j = 2$ and the other two with $z_j = 4$.
Both actors are then drawn toward the preferred value
of 3; but the difference between drinking behavior 3 on one hand
and 2 and 4 on the other hand will be larger for $i_1$
than for $i_2$.
In model (\ref{eq_f_b2}), on the other hand,
since the average is the same,
both actors would be drawn equally strongly toward
the average value of~3.

Since the objective function for model (\ref{eq_f_b1}) depends
on all behavior values of the actor's friends, not just on their average,
here we present a table only for the special case of actors
all whose friends have the same behavior $z_{j}$.
For the parameters given above, the behavior
evaluation function then reads
\[
   f^{\rm beh}_i(z_i) \,=\, 0.461 \, (z_i - \bar z)
              \,-\, 0.003 \, (z_i - \bar z)^2 \,+\,
             6.190 \, \bigg(
          \frac{ \vert \bar z - z_j \vert \,-\, \vert z_i - z_j \vert}{\Delta}\bigg)  \ .
\]

The same script used above for average alter, \texttt{InfluenceTables.r},
will for this model specification produce the following table and plot.

\begin{center}
\begin{tabular}{l r@{.}l  r@{.}l  r@{.}l  r@{.}l  r@{.}l }
 $z_j$ \ \ $ \backslash $ \ \ $z_i $   &  \mcc{2}{ 1}
               & \mcc{2}{ 2} & \mcc{2}{ 3} & \mcc{2}{ 4} &  \mcc{2}{ 5}
\separationb
  1 &   2&15 &   1&07 & --0&01 & --1&10 & --2&19 \\
  2 & --0&94 &   1&07 & --0&01 & --1&10 & --2&19 \\
  3 & --4&01 & --1&99 &   0&02 & --1&07 & --2&17 \\
  4 & --4&01 & --1&99 &   0&02 &   2&02 &   0&93 \\
  5 & --4&01 & --1&99 &   0&02 &   2&02 &   4&02 \\
\hline
\end{tabular}
\end{center}
The interpretation of this table is that each row corresponds to a
given common behavior
of the focal actor's friends; comparing the different values in the row
shows the relative `attractiveness' of the different potential values
of ego's own behavior.
The maximum in each row is assumed at the diagonal. This means that
for each value for the common friends' behavior $z_j$,
the focal actor prefers to have the same behavior as these friends.
The differences in the bottom rows are larger than in the top rows,
indicating that in the case where the friends who do not drink at all,
the preference (or social pressure) toward imitating their behavior is
less strong than in the case where all the friends drink a lot.


The values far away from the maximum contrast in this case less
strongly than in the case of the model with the average alter
effect, which is a consequence of the use of the absolute rather than
squared deviation.
However, neither of these models fits clearly better than the other.
The fact that the $t$-ratio for testing the social influence effect
is larger for average similarity (6.190/1.810 vs.\ 1.281/0.488)
suggest that this specification has a slightly better fit.

These tables present only the contribution of some of the terms of the
objective function, and the behavior dynamics will of course
be compounded if the objective function contains more effects.

Figure~\ref{F_infl_dk_avsim} gives the same information as the table.


\begin{figure}[hb]
  \centering
  \includegraphics[width=0.8\textwidth]{influenceTable_s_drinking.png}
  \caption{Plot of influence table  for friendship with respect to drinking,\protect\newline
  for specification by average similarity.
  \protect\newline Small vertical displacements
  were added to make the curves visually distinguishable.}
  \label{F_infl_dk_avsim}
\end{figure}

\clearpage

\subsection{Effect sizes and measures of fit}

For linear regression models we are used to the coefficient of determination,
usually denoted $R^2$, defined as the proportion of variance
that is explained by the model.
Such a measure is not easily available for most other statistical models;
linear regression is special in allowing such a well-interpretable
measure of `fit'.
The following measures that have something of the same purpose
are available in \RS through function  \sfn{sienaRI()}.

\subsubsection{Relative importance of effects}

The measure for \emph{relative importance of effects} in {\saom}s,
proposed by \citet{IndlekoferBrandes2013},
together with a measure for the (non-relative) \emph{importance of effects},
can be calculated by \sfn{sienaRI()}.

Ministeps in the {\saom} are random events with $n$ possible outcomes.
Let us denote the probabilities with which
actor $i$ in a ministep may change one of the outgoing ties by
$p_{i}(\beta, x) = \big(p_{i1}(\beta, x), \ldots, p_{in}(\beta, x)\big)$.
The Indlekofer-Brandes measures are numerical answers to the question,
`How strongly do these probabilities depend on each of the effects?'.
In their paper, measures are proposed for expressing this per actor
per wave; these measures can be relative (so that the total importance
for each actor always is 1), or raw.
The relative importances are calculated by  \sfn{sienaRI()} as \texttt{RIActors},
the raw importances as \texttt{IActors} (see the help page).
The  relative importances can be averaged over actors to give
\texttt{expectedRI}, which is printed by the print method for \sfn{sienaRI()}.

\subsubsection{Entropy / relative certainty}

The uncertainty in a random categorical variable
can be measured by the \emph{entropy} \citep{Shannon1948}. For a probability
distribution with probabilities $p = (p_1, \ldots, p_K)$ for
an outcome with categories $1, \ldots, K$, it is defined as
\begin{equation}\label{entropy}
  H(p) \,=\, - \sum_{k=1}^K p_k {}\,^2 \log(p_k) \ .
\end{equation}
This is 0 if the variable is deterministic, i.e., one of the categories
has probability~1; the maximum value is ${}^2 \log(K)$, attained if all
categories have the same probability $1/K$ (maximum uncertainty).

Using a minus sign, the degree of certainty (as opposed to uncertainty)
in the outcome of the ministep with probabilities
$p_{i}(\beta, x) = \big(p_{i1}(\beta, x), \ldots, p_{in}(\beta, x)\big)$
can be expressed by
\begin{equation}\label{uncertainty}
  R_H(i,\beta, x) \,=\,  1 - \frac{H(p_{i}(\beta, x))}{{}^2 \log(n)} \ .
\end{equation}
For models with a constant rate function, this can be averaged over
actors to obtain a measure for a ministep taken by a random actor:
\begin{equation}\label{explained}
  R_H(\beta, x) \,=\, \frac1n \sum_i R_H(i,\beta, x) \ .
\end{equation}
This is a measure between 0 and 1.
It was proposed in \citet{Snijders04}, where further discussion may be found.

The values of the degree of certainty will generally be low, because
which tie to create or to drop normally will have a very large
degree of `chance variability'.
They are calculated by  \sfn{sienaRI()} as \texttt{RHActors}
(see the help page). The mean over actors is printed by the print method
for \sfn{sienaRI()}.

Note that the values given by \sfn{sienaRI()} refer to each of the waves,
including the first wave; for this purpose, $x$ in (\ref{explained})
is taken as the observed network (and behaviour...) at each wave.


\subsubsection{Standard deviation of change statistics}

The  \emph{change statistics} $\delta_{ijk}(x)$
for an effect $s_{ik}(x)$ are the changes in the
value of this effect, for a given actor $i$, a given current state
of the network $x$, and a given alter $j$, when the
tie variable $x_{ij}$ would be toggled.
These are the basic `variables' in the conditional multinomial
logistic regression model that is at the heart of the \saom.
Their \emph{within-actor} standard deviations $\sigma_k(x)$
can be used to turn the parameters $\beta_k$ into
comparable quantities,
\begin{equation}
    \sigma_k(x) \, \beta_k  \ .   \label{standardized.beta}
\end{equation}
These express the parameters $\beta_k$, for different $k$ and a common $x$,
on a common scale.

These standard deviations are computed by \sfn{sienaRI()} as \texttt{sigma}
and  printed by the print method for \sfn{sienaRI()} if \texttt{printSigma=TRUE}.
The change statistics themselves are potentially a lot of numbers
($n^2 \times M \times K$, where $M$ is the number of waves and $K$
the number of effects in the model), and are only retained in the object
produced by \sfn{sienaRI()} if \texttt{getChangeStats=TRUE}; see the help page.

\newpage
\section{Error messages}


This chapter contains some error messages with their explanations.
Currently it is not very  extensive; new error messages will be added
as answerable questions about them arise.
For understanding errors, general advice is to read in this manual,
read the help pages for functions, and look at the News page of the
Siena website.
\medskip

For diagnosing errors in R in general, a useful function is
\begin{verbatim}
traceback()
\end{verbatim}
This is to be called after an error was generated. It will give information,
usually very helpful, about where exactly the error was caused.
For example, it will give you the function generating the error message,
with recursive information.
\medskip

Note that it is not difficult to find the source of error messages in the code.
The easiest way is searching for the text of the error message
by some search machine such as google.
You will probably find it points to R-Forge or another repository of the code.
There you can see what led to the error message, if you can understand some R.
An alternative, if you know the function generating the error message
(which you can find out by \texttt{traceback()}, see above)
is to search directly in the code for this function.
If the function is called, e.g., \textsf{siena07}, you can write
the code to a file called \texttt{listing.txt} by the commands
\begin{verbatim}
sink("listing.txt")
siena07
sink()
\end{verbatim}
Note that you should give the function name without parentheses.
When the function is not an exported function, e.g., \texttt{robmon},
you can request it via
\begin{verbatim}
sink("listing_robmon.txt")
RSiena:::robmon
sink()
\end{verbatim}


\subsubsection*{After updating}

\noindent
Updates of \RS and \textsf{RSienaTest} are not always completely backward
compatible. When updating the version, you may have to create
effects objects and algorithm objects again. If there is
incomplete backward compatibility with respect to
useability of scripts, this will be mentioned at the \emph{News page}
of the \SI website.



\subsection{During estimation}

\emph{Unlikely to terminate this epoch: more than 1000000 steps}.
\medskip

\begin{indentation}{0.04\textwidth}{0pt}
\noindent
This can happen in function \sfn{siena07};
in conditional estimation (\texttt{COND=FALSE} in\\
 \sfn{sienaAlgorithmCreate}),
when the rate parameter provisionally has hit a value such that the
desired number of changes will probably never be reached;
or in non-conditional estimation when the number of ministeps has become
too large before arriving at the time for the next wave.
See Section~\ref{S_cond}.

\medskip

\noindent
\emph{Potential solutions.}
\begin{enumerate}
\item Check whether your model specification is reasonable;
    for example, there might be doubts about the specification of the
    rate function.
\item  Use non-conditional estimation (Section~\ref{S_cond}) if you were not
   already doing so.
\item If the model includes the \texttt{outRate} effect, consider
    replacing it by the \texttt{outRateLog} effect;
    but note that this works properly only for non-conditional estimation
    (\texttt{cond = FALSE} in \sfn{sienaAlgorithmCreate()}).
\item If you are working with a data set with more than two waves, there might
   be unmodeled heterogeneity between the periods. Try modeling the periods
   separately.
\item Set the parameter \texttt{firstg} in \sfn{sienaAlgorithmCreate} to a
   lower value than the default 0.2.
   This will make the algorithm move more slowly, hopefully avoiding the problematic region
   in the parameter space.

   The advice would be to set  \texttt{firstg}  to 0.02
   and expect the necessity to do a second estimation using the \texttt{prevAns}
   parameter in \sfn{siena07}. If the problem still occurs for \texttt{firstg}=0.02,
   use a smaller value (but less than 0.001 probably makes no sense).
   \texttt{firstg} determines the step sizes in the stochastic approximation
   algorithm; it is mentioned in some places earlier in this manual.
   Especially for models with additional rate effects the default value of 0.2
   might be too large.
    \texttt{firstg}  is the initial value of parameter $a_N$ mentioned
    on p.\ 393 of \citet{Snijders01}.
\item Use multiple processes (\texttt{useCluster=TRUE, nbrNodes=...}).
\item In combination with trying out a lower value for \texttt{firstg},
    you might try setting a higher value for  \texttt{doubleAveraging}
    in \sfn{sienaAlgorithmCreate}. Double averaging is a different definition
    of the Robbins-Monro update step; see Section~\ref{S_contconv}.
    You could try setting  \texttt{doubleAveraging} to 1 or 2, which uses
    single averaging in the first 1 or 2 subphases; or you could set it to
    4, avoiding double averaging altogether (if you have 4 subphases).
\end{enumerate}
\end{indentation}
%\end{minipage}
\bigskip

\iffalse
Error in initialEstimates[i, use] <- startup1$theta :
  number of items to replace is not a multiple of replacement length
Calls: sienaBayes -> initializeBayes
In addition: Warning message:
In effects0$initialValue[effects0$include] <- startupGlobal$theta[use] :
  number of items to replace is not a multiple of replacement length
Execution halted

This requires allowOnly=FALSE in startup1Model

\fi

\noindent
\emph{Error in solve.default(z\$dfra) : \\
system is computationally singular: reciprocal condition number = 2.34809e--35
}\\
(or some other very small number -- note that `\textit{e--35}' means 10 to the power
--35.)
\smallskip

or
\smallskip

\noindent
\emph{Error for inversion of d11}
\smallskip

\begin{indentation}{0.04\textwidth}{0pt}
\noindent
This can happen at the end of estimation in function \sfn{siena07},
when the covariance matrix is singular.
It means that some effects in the model are linearly related,
or are always 0.
\smallskip

\noindent
\emph{Solutions.}\\
Check your data (look at the description of the variables
given as the output of \sfn{print01Report}).\\
Check your model specification.\\
Find out which effect might be especially correlated
with some other effects, and treat it by a score-type
test without estimating (i.e., specify it with
\texttt{fix=TRUE, test=TRUE}).
(Also see the discussion of the Hauck-Donner phenomenon
in Section~\ref{S_fixingparameters}; this issue might
be relevant here.)
\end{indentation}
\bigskip

\noindent\emph{Error in initializeFRAN(z, x, initC = FALSE, ...) :\\
  Unexpected effect name: someShortName}\\
(where \emph{someShortName} is a short name you supplied in the
model specification).
\smallskip

\begin{indentation}{0.04\textwidth}{0pt}
\noindent
Probably your effects object was made by an earlier version
of {\rs} than the version you are using now.
\smallskip

\noindent
\emph{Solution.} \\
First check that the short name was correctly spelled and
is available in your version of {\rs}, by requesting
\begin{verbatim}
effectsDocumentation(myeff)
\end{verbatim}
(where of course you should substitute the name of your effects object
for \texttt{myeff}).
If this is all right, the recreate the effects object.
\end{indentation}
\bigskip


\noindent\emph{Endowment effect not supported}\\
(for a specified endowment or creation effect).
\smallskip

\begin{indentation}{0.04\textwidth}{0pt}
\noindent
This endowment or creation effect was not implemented.
\smallskip

\noindent
\emph{Solution.} \\
First check that the short name was correctly spelled and
is available in your version of {\rs}, by requesting
\begin{verbatim}
effectsDocumentation(myeff)
\end{verbatim}
(where of course you should substitute the name of your effects object
for \texttt{myeff}).
If this is all right, the recreate the effects object.
\end{indentation}
\bigskip




\subsection{As the result of a score-type test (including time test)}

\emph{Error in solve.default(v9) :
   Lapack routine dgesv: system is exactly singular\\
Error in if (cvalue $<$ 0) cvalue $<-$ 0 :
   missing value where TRUE/FALSE needed.}
\smallskip

\begin{indentation}{0.04\textwidth}{0pt}
\noindent
This can happen as the result of a score test requested in function
\sfn{siena07}; or the score test requested in function
\sfn{sienaTimeTest}.
In the first case it indicates that there are linear dependencies in the
list of effects (estimated and fixed)
that are used for \sfn{siena07}.
If this error message occurs for \sfn{sienaTimeTest}, it indicates
linear dependencies in the list of effects estimated
in the \sfn{siena07} run analyzed by this \sfn{sienaTimeTest},
together with the interactions with time dummies tested by
\sfn{sienaTimeTest}.
See Sections~\ref{S_timetest1} and~\ref{S_Scoretest}.
\smallskip

\noindent
\emph{Solutions.} \\
For \sfn{siena07}: drop some of the requested score-type test,
retaining only a set of tested effects between which there are no
linear dependencies.\\
For \sfn{sienaTimeTest}: exclude some of the requested
time heterogeneity tests by the \sfn{excludeEffects} parameter.
\end{indentation}

\subsection{In sienaGOF}


\emph{Error in if (attr(obsData[[groupName]]\$depvars[[varName]], "sparse")) \{ :\\
  argument is of length zero }
\smallskip

\begin{indentation}{0.04\textwidth}{0pt}
\noindent
This can happen directly when calling \sfn{sienaGOF}.
It indicates that you used a wrong name for \sfn{groupName} or \sfn{varName}.
See the help file for \sfn{sienaGOF}.
\smallskip

\noindent
\emph{Solutions.} \\
Use a correct \sfn{groupName} and \sfn{varName}.
\end{indentation}
\bigskip

\noindent
\emph{Error in if (isbipartite) \{ : argument is of length zero }
\smallskip

\begin{indentation}{0.04\textwidth}{0pt}
\noindent
This can happen directly when calling \sfn{sienaGOF}.
It indicates that you used a wrong name for \sfn{groupName} or \sfn{varName}.
See the help file for \sfn{sienaGOF}.
\smallskip

\noindent
\emph{Solutions.} \\
Use a correct \sfn{groupName} and \sfn{varName}.
\end{indentation}

\newpage

\section{For programmers: Get the source code}

To do something with the source code,
first you must get access to it.
In the first place, it is good to know that for any \R function
that can be called,
the source code is listed by writing the function name.
Thus, if \RS is loaded, the command
\begin{verbatim}
sienaAlgorithmCreate
\end{verbatim}
will list the code for the function with this name.

To get insight into a package, and certainly to modify
or personalize it, it is necessary, however,
to get the source code of the whole package.
This can be done by downloading, from CRAN or (preferably) R-Forge,
the `tarball' with extension \sfn{.tar.gz}.
This file can be extracted by compression/decompression
programs (perhaps you need to do a double extraction).
If you do not succeed in extracting the tar ball, see below
for the use of \texttt{RTools} for this purpose.
This will lead to a directory structure where at some place
there is a directory called \texttt{RSiena} and/or a directory
called \texttt{RSienaTest}, which includes the source code
of the package.

In the file structure for \texttt{RSienaTest} there is a directory
\texttt{doc} which contains a lot of programmers' documentation.
These are in the form of \LaTeX \ files, which can be compiled
to produce .pdf files.
The file \texttt{Siena\_Algorithms.tex} contains a lot of details
about algorithms used.
For code developers, important files are
\texttt{HowToCommit.tex} and \texttt{RSienaDeveloper.tex}.
The latter file will guide you to the further documentation.

The file
\href{http://www.stats.ox.ac.uk/~snijders/siena/Siena_algorithms.pdf}{\texttt{Siena\_algorithms.pdf}}
can also be downloaded from the
\SI website.

\section{For programmers: Other tools you need}
\begin{description}
\item[Windows]
\begin{enumerate}
\item Download and install the appropriate (version number
  depending on which \R you are using)
\textsf{Rtools.exe} from
  \url{http://www.murdoch-sutherland.com/Rtools/}.
  (I think this is not the right place any more - should be downloaded from CRAN.)
\item Make sure you check the box to amend your path during installation.
\item Beware: if you later install
  other programs containing utilities such as tar (delphi is one offender),
  you may need to uninstall and reinstall Rtools, as you need Rtools
  at the start of your path.
\item Add the path-to-the file
 R.exe to your path. Right-click on My Computer icon,
  select Properties/Advanced/Environment variables\ldots   \\
 Restart your computer to put the new path into effect.
\end{enumerate}
\item[Mac]
\begin{enumerate}
\item Make sure the Xcode tools are installed.
\item Add the path-to-the-file R.exe to your path.
\end{enumerate}
\item[linux]
 Add the path-to-the-file R.exe to your path.
\end{description}

\section{For programmers: Building, installing and checking the package}
In a command prompt or terminal window, navigate to the directory
immediately above the
siena source tree. Here we assume the source tree is in a directory
called \sfn{RSiena}. (You may have minor
difficulties if it is not the same as the name of the package you are trying to
build or install: you can do all these things with \sfn{RSienaTest} also.)

For Windows computers, the following `type' instructions are Dos commands.
A convenient way to apply them are by including them in a batch
file (extension name \texttt{.bat}) followed by a name with \verb|pause|
so that the Dos window -- that will contain the error messages
if there are any -- will still be there when all is over.

\begin{description}
\item[Install] Installing will recreate the binary and install in your normal R
  library path. Type\\
\verb|R CMD INSTALL RSiena|
\item[Build] Building will create a tar ball. Type\\
\verb|R CMD build RSiena|\\
This may give warning messages about the line endings if you run it on
Windows. Do not worry, unless you have created any new source files, when it
might remind you to set the property of \textsf{eol-style} on them when you add
them to the repository.
\item [Check] Checking is a process designed to ensure that packages are likely
  to work correctly when installed. Type\\
\verb|R CMD check RSiena_1.0.n.tar.gz|\\
(where \verb|n| is adjusted to match the tar ball name.)
\item[zip file] To make a zip file that can be used in Windows for
`installing from a local zip file', and therefore is easy for distribution
to others, type\\
\verb|R CMD INSTALL --build RSiena_1.0.n.tar.gz| \\
(where again \verb|n| is adjusted to match the tar ball name.)
\end{description}

If you make a change you need to \textsf{INSTALL} the new version in order to
test it, and before you commit any changes to a repository you should
\textsf{check} your new version. Make sure you get \emph{no} warnings or
errors from the check.

You can also \textsf{INSTALL} from a tar ball, and \textsf{check} a source
tree.

If you have permission problems on Linux or Mac, you may need to do the first
install from within \textsf{R}, so that the necessary personal library
directories will be created. Use\\
\verb|install.packages(tarballname, repos=NULL)| \\after creating a tar
ball. (Or possibly just try to install some other package within R which will
create the directories for you.)

You can unpack a tar ball by using

\verb|tar xf tar-ball-name|

\section{For programmers: Understanding and adding an effect}

If you wish to check the definition of an effect,
you can locate it in the source code and study it.
You may also add
effects to your personalized version of \rs.
If you think the effect could be useful for others, too,
it will be appreciated if you propose it for inclusion through
one of the discussion lists or directly to the maintainer
of the package.
This section gives the outline of the procedure for adding an effect, and then presents
an elaborate example.

If you only wish to understand an effect without creating
a new one, then you may
follow the appropriate steps of this section.
The main things then are to go to the \textsf{Effectfactory.cpp}
file, find the name of the effect you are interested in and
from there the function that implements it
and read the code of this function.

The explanations here are not yet given for generic effects, which allow
a more streamlined construction of effects. Looking at the code,
starting with the file \sfn{EffectFactory.cpp}, may be helpful for understanding
this construction of generic effects.
For example, compare the construction of \texttt{sameXTransTrip} to that of
\texttt{sameXInPop}.

\begin{enumerate}

\item Work out the definition of the effect and the contribution or
      change statistic.
      For network effects, the change statistic is
      \begin{equation}
      \Delta_{kij} (x) =  s_{ki}(x^{+ij}) -     s_{ki}(x^{-ij})  \label{changestat}
      \end{equation}
      where $x^{+ij}$ is the network with the tie $i \rightarrow j$
      and $x^{-ij}$ is the network without this tie.
\item The list of all defined effects can be obtained from \textsf{effectsDocumentation()},
      which produces a file \textsf{effects.html} or \textsf{effects.pdf}.
      All effects are also listed, with their definitions, in the manual (Section~\ref{S_math}). \\
      Determine an existing effect that is most similar
      to this effect (or perhaps more than one).
      In the file \textsf{effects.html} or \textsf{effects.pdf} the effects are grouped
      by \sfn{effectGroup}.
\item Open the file \textsf{allEffects.csv} located in
       \textsf{"RSiena\textbackslash data"}. The default program for opening a .csv file
       usually is Excel, but other editors may be more helpful
       for opening this particular file; e.g., NotePad or NotePad++.
       It must \underline{not} be saved as a Excel file!
	   \begin{itemize}
		\item You will see that the first column is called \sfn{effectGroup}.
              These groups define combinations of dependent variable, effect type,
              and covariates (if any)
              (e.g. nonSymmetricObjective,  bipartiteSymmetricObjective).
              Identify the effectGroup where this effect belongs.
              Determine which is which by considering some examples
              in this file or in the result of \sfn{effectsDocumentation()}.

              For covariate-related effects for two-mode networks, see
              extra remarks in Section~\ref{S_notestwomode}.
    	\item Insert a new row in this group.
              Copy a row that corresponds best to your new effect
              and modify effectName, functionName, shortName,
              and more if this seems necessary.
              Perhaps your new effect is suitable in more than one group;
              then a new row can be made for all these groups, differing only
              in the name of the effect group; e.g., check that there are
              three versions of \texttt{inPop}, for directed, non-directed,
              and bipartite (two-mode) networks.
              Assume our new effect has shortName \textit{newEf}.

              In some cases, the new function will have extra parameters,
              as you can see from other examples;
              this is mostly the case, if one function is being used to define
              more than one effect.

              For how to deal with internal effect parameters, look up
              a function defining an effect that has such
              a parameter.

		\item Build the package and install it.  Check from R that
              the new effect (which has only been created nominally)
              appears now in the effects object in RSiena.\\
              If this is not the case, there may be further changes necessary
              in the file \sfn{effects.r}; also see
              Section~\ref{S_notestwomode}.
		\end{itemize}
\item Open the folder
      \textsf{"RSiena\textbackslash src\textbackslash
         model\textbackslash effects"}.
         In an editor open the files \textsf{AllEffects.h}
         and  \textsf{EffectFactory.cpp}.\\
         These are C++ files; using a C++ editor is convenient
         but not necessary. Note however that you must save the files
         as ASCII (raw text) files without changing their names.
        Let us use the name \textit{NewEffect} as the function name
        to be used (replace this by whatever is appropriate).
		\begin{itemize}
			\item In the file AllEffects.h you need to add the line\\
                \texttt{ \#include "NewEffect.h" }\\
                 where it is alphabetically appropriate.
            \item In the file \textsf{EffectFactory.cpp}, at the appropriate place,
                  add the lines
                \begin{verbatim}
    else if (effectName == "newEf")
	{
		pEffect = new NewEffect(pEffectInfo);
	}
                \end{verbatim}
			\item Now you will need to create two files (namely header
                  and source files for
                   C++) that should be called \textsf{NewEffect.h} and
                   \textsf{NewEffect.cpp}.
                   If there is a similar effect to the one you want to add
                   it is usually easier to use it as a template.

                  We recommend opening any effect file to see
                  how the syntax works, but creating a new effect will be hard
                   without knowing at least a bit of C++.
            \item Add the name \textsf{NewEffect.cpp} to the file \textsf{sources.list}.
                  This is a long file without any hard returns. It does not matter where

		\end{itemize}

		\item Once you are done editing you should build
the package again and install it (from the command prompt)
and then go to R to see if it is available to you.

It is a good idea to check the target statistics computed for a simple
two-wave data set such as \sfn{s50}.
\end{enumerate}

As examples, start with simple effects.
For example, a network effect depending on a nonlinear transformation
of outdegree, or a behavior effect depending nonlinearly
on the behavior and nothing else.
After having obtained experience with such a simple effect,
continue with the effect that you are interested in.

Note that if your new effect could usefully be used as part of a multiple
network effect you should use the generic effect approach and not the following.


\subsection{Example: adding the truncated out-degree effect}

As an example, we show how the truncated out-degree effect
(short name \texttt{outTrunc}) was added. It is
 defined by
 \begin{equation}
  s^{\rm net}_{i}(x) = \text{min}(x_{i+}\,,\, c)   \label{outTrunc}
 \end{equation}
where $c$ is an \hyperlink{T_effpar}{internal effect parameter}.

\begin{enumerate}
\item The change statistic (\ref{changestat}) is
      \begin{equation}
       \Delta_{ij}(x) \,=\, \left\{ \begin{array}{ll}
                   1 & \text{  if } \{x_{i+} < c,  x_{ij} = 0 \}
                     \text{ or } \{x_{i+} \leq c,  x_{ij} = 1 \} \\
                   0 & \text{  else. }
                   \end{array}         \right.  \label{outTrunc_cs}
      \end{equation}
      Note that for this effect the case for going up ($x_{ij} = 0$)
      must be distinguished from the case
      for going down ($x_{ij} = 1$).
\item In the file \textsf{allEffects.csv} the name of the
      effect group \textsf{nonSymmetricObjective} seems to cover the
      type of effect we are considering, and also contains other effects
      such as out-degree activity which are very similar to this
      effect.\\
      The row for the out-degree activity (sqrt) effect was copied
      and inserted below this row. The ``effectName" was changed to
      \texttt{outdegree-trunc(\#)}, the ``functionName" to
      \texttt{Sum of outdegrees trunc(\#)},
      and the ``shortname" to \texttt{outTrunc}.
      The hash sign (\texttt{\#}) in these names will be replaced
      by the value of the
      internal effect parameter in the written output.
      The ``parm" column, which defines
      the default value of the internal effect parameter, was set to 5.
      \\
      The package was built. Loading it in \R and creating an
      \RS data set showed that indeed the effect was there.
\item The name \sfn{TruncatedOutdegreeEffect} was chosen for the new function.\\
      In the file \textsf{AllEffects.h} the line
      \begin{verbatim}
    #include "TruncatedOutdegreeEffect.h"
      \end{verbatim}
      was included at the appropriate alphabetic place.

      In the file \textsf{EffectFactory.cpp}, after the piece referring
      to \texttt{effectName == "outActSqrt"}, the lines
\begin{verbatim}
    else if (effectName == "outTrunc")
    {
         pEffect = new TruncatedOutdegreeEffect(pEffectInfo);
    }
\end{verbatim}
      were inserted.  This refers the program, when it encounters short name
      \sfn{outTrunc}, to the function \sfn{TruncatedOutdegreeEffect}.  The next
      step was to construct this function.
\item To choose a template for \sfn{TruncatedOutdegreeEffect},
      we could make various
      different choices; here it is important to have a look at the various
      effects defined in Chapter~\ref{S_math} that depend only on the
      outdegree. Consider the effects Outdegree activity - sqrt
      (short name \texttt{outActSqrt})
      and sum of (1/(out-degree + $c$) (short name \texttt{outInv})
      as possible examples.
      A look in  \textsf{EffectFactory.cpp} shows that these are implemented
      using the functions
      \textsf{OutdegreeActivitySqrtEffect}
      and \textsf{InverseOutdegreeEffect}, respectively.
      Therefore look at the files \textsf{OutdegreeActivitySqrtEffect.cpp}
      and \textsf{InverseOutdegreeEffect.cpp} where these functions
      are defined.\\
      The former defines the effect through a
      `\sfn{calculateContribution}' function, which defines the
      tie flip contribution
      (the function called $\Delta_{ij}(x)$ above)
      and \sfn{tieStatistic}, which is the function $r_{ij}(x)$
      when the effect can be defined as
      \begin{equation}
       s^{\rm net}_{i}(x) = \sum_j x_{ij}\,r_{ij}(x) \ .  \label{tiestat}
      \end{equation}
      The latter defines the effect through  a
      \sfn{calculateContribution} function and an\\
      \sfn{egoStatistic} function, which is the effect
      as defined in (\ref{outTrunc}). It should be noted that
      generally effects can be defined either by the one or the other
      combination.


      Since our new effect cannot be expressed in a straightforward way
      by an equation of the type (\ref{tiestat}), we chose to use
      the files \textsf{InverseOutdegreeEffect.h} and\\
      \textsf{InverseOutdegreeEffect.cpp} as templates.
      This has a second advantage: the  \texttt{outInv} effect has an
      \hyperlink{T_effpar}{effect parameter}, which we also need
      to represent the parameter $c$ in  (\ref{outTrunc}).

      As a first step,   the files \textsf{InverseOutdegreeEffect.h} and
      \textsf{InverseOutdegreeEffect.cpp} were saved under the new names
      \textsf{TruncatedOutdegreeEffect.h} and
      \textsf{TruncatedOutdegreeEffect.cpp}.
      \\
      For the header file \textsf{TruncatedOutdegreeEffect.h}, all strings
      `inverseoutdegreeeffect'
      were changed into `truncatedoutdegreeeffect' while retaining the original
      use of upper and lower case.
      The explanation also was adapted.
      The header file now implies that for the function
      \texttt{TruncatedOutdegreeEffect}
      functions are needed of the types \sfn{calculateContribution},\\
      \sfn{endowmentStatistic} and \sfn{egoStatistic}.
      \\
      This was implemented in the file \textsf{TruncatedOutdegreeEffect.cpp},
      which just was created by renaming \textsf{InverseOutdegreeEffect.cpp}.
      First  all strings `outdegreeactivitysqrteffect'
      were changed into `truncatedoutdegreeeffect', again retaining the original
      use of upper and lower case.\\
      To understand the C++ syntax, keep into account
      the object-oriented nature of C++.
      The keyword \sfn{this} is a pointer referring to the object
      in which the current function is defined, and the arrow \texttt{->}
      indicates a further pointer; thus, the variable\\
      \texttt{this->pNetwork()->outDegree(this->ego())}\\
      refers to the outdegree of ego (denoted in our mathematical
      formulae by $i$) in the current network -- in other words,
      $x_{i+}$.\\
      The variable \texttt{this->lc} refers to the
      internal effect parameter, denoted in our formulae by $c$.
      The \sfn{return} statement defines the function value that is returned
      when the function is called.
      \\
      Armed with this knowledge, we specified the change statistic,
      implementing (\ref{outTrunc_cs}), as follows.

{\small
\begin{verbatim}
double TruncatedOutdegreeEffect::calculateContribution(int alter) const
{
    double change = 0;

    // Current out-degree
    int d =	this->pNetwork()->outDegree(this->ego());
    if (this->outTieExists(alter))
    {
        // After a tie withdrawal, the new out-degree would be d-1, and
        // the new effect value would have decreased by 1 if d <= this->lc

        if (d <= this->lc)
        {
             change = 1;
        }
    }
    else
    {
        // When introducing a new tie, the new out-degree would be d+1, and
        // the new effect value would have increased by 1 if d < this->lc

        if (d < this->lc)
        {
             change = 1;
        }
    }

    return change;
}
\end{verbatim}
}

      The effect statistic, implementing (\ref{outTrunc_cs}),
      was specified as follows.

{\small
\begin{verbatim}
double TruncatedOutdegreeEffect::egoStatistic(int ego,
    const Network * pNetwork)
{
    // Current out-degree
    int d =	this->pNetwork()->outDegree(this->ego());

    if (d <= this->lc)
    {
         return d;
    }
    else
    {
         return this->lc;
    }
}
\end{verbatim}
}

\item To the file \textsf{src{\textbackslash}sources.list}, the item
      \texttt{model/effects/TruncatedOutdegreeEffect.cpp} was added.
\item Having done this, the package was built and installed again.
      (To be honest, there first were some errors; but the error messages
       from the compiler are quite clear and easily led to solving
       the errors.)\\
      Upon starting \R and loading \rs, indeed the new effect  was
      available. For an easy check, the following commands
      were used.
{\small
\begin{verbatim}
mynet       <- sienaDependent(array(c(s501, s502), dim=c(50, 50, 2)))
mydata      <- sienaDataCreate(mynet)
myalgorithm <- sienaAlgorithmCreate(projname="s50_12")
myeff       <- getEffects(mydata)
myeff       <- setEffect(myeff, outTrunc, parameter = 3)
ans         <- siena07(myalgorithm, data=mydata, effects=myeff)
summary(ans)
\end{verbatim}
}
      The parameter was set at 3, because the maxima of the
      observed out-degrees
      in the two data sets \sfn{s501} as well as \sfn{502} were 5,
      so the `outdegree-trunc(\#)' effect would be highly collinear with the
      outdegree effect if the default parameter of 5 were used.
      This led to good convergence. To check the calculation of the
      statistics, it was noted that the output file
      mentioned the target values
{\small
\begin{verbatim}
Observed values of target statistics are
  1. Number of ties                                           116.0000
  2. Number of reciprocated ties                               70.0000
  3. Sum of outdegrees trunc(3)                               105.0000
\end{verbatim}
}
      The value of the target statistic for the new effect should be
      \[
       \sum_i s^{\rm net}_{i}(x(t_2)) \,=\,
                         \sum_i \text{min}(x_{i+}(t_2), 3) \ .
      \]
      This can be directly calculated in \R by requesting
\begin{verbatim}
sum(pmin(rowSums(s502),3))
\end{verbatim}
      which indeed returns the value 105, confirming that the calculation
      of the ego statistic seems correct.
\item To complete the extension of the package by this effect,
      it also was added to the set of effects for symmetric
      and bipartite networks.
      This was done by inserting, at appropriate places in the file
      \sfn{allEffects.csv},
      the same line but now with \sfn{effectGroup}
      changed to \sfn{bipartiteObjective} and \sfn{symmetricObjective},
      respectively.
\end{enumerate}

\subsection{Notes on effectGroups and two-mode networks}
\label{S_notestwomode}

For two-mode networks the difference between the two node sets implies
some peculiarities.
Recall that effectGroups are used in the file \texttt{allEffects.csv}
and in function \sfn{effects.r}.

In the function \sfn{getEffects} in file \sfn{effects.r}, some additional
measures are taken for effects in effectGroup \sfn{covarBipartiteEff}.
This implies that for adding such effects, it will be necessary to see whether
this function also must be modified; this will have to be done
in function \sfn{covarBipartiteEff()}.
(Note: it would be preferable perhaps to have separate effect classes
for covariates on the first and on the second mode, as done for the effect
groups in the following paragraphs.)

A different approach was taken for effectGroups
\sfn{covarABehaviorBipartiteObjective} and \sfn{covarBBehaviorBipartiteObjective}:
the former is for covariates on the first node set, the second for
covariates on the second node set.

For effects defined for two dependent networks and one actor covariate,
the following effectGroups are defined:
\begin{itemize}
\item \sfn{covarNetNetObjective} is for effects where the second network is one-mode;
\item \sfn{covarABNetNetObjective} is without restriction on the modes;
\item \sfn{covarANetNetObjective}  is for effects where, if the second network is two-mode,
     the covariate is defined for the first node set;
\item \sfn{covarBNetNetObjective} is for effects where, if the second network is two-mode,
     the covariate is defined for the second node set.
\end{itemize}
\medskip

For effects defined for a two-mode dependent network, another dependent
network (in the role of explanatory; whether one- or two-mode), and one actor covariate,
the following effectGroup is defined:
\begin{itemize}
\item \sfn{covarABipNetObjective} for covariates defined for the first node set.
\end{itemize}
\medskip

Further some of the complex effectGroups are the following:
\begin{itemize}
\item \sfn{tripleNetworkObjective} is for combinations
    of three networks where for the two in the role of explanatory networks,
    either both should be one-mode, or both should be bipartite with the same second node sets.
\item \sfn{behaviorOneOneModeObjective} is for dependent behavioral variables and
    two explanatory one-mode directed networks.
\item \sfn{behaviorSymSymObjective} is for dependent behavioral variables and
    two explanatory one-mode non-directed networks.
\item \sfn{behaviorOneModeSymObjective} is for dependent behavioral variables and
    two explanatory one-mode networks, the first directed, the second non-directed.
\item \sfn{behaviorBipBipObjective} is for dependent behavioral variables and
    two explanatory two-mode networks with identical actor sets.
\item \sfn{dyadBehaviorNetObjective} is for dependent behavioral variables,
   an explanatory one-mode network and an explanatory dyadic covariate.
\end{itemize}

If you wish to add an effect with a combination of variables that is not yet implemented,
you have also to treat it in \sfn{effects.r}.


\appendix
\newpage
\section{List of Functions in Order of Execution}

    This appendix
    provides a description of the functions that constitute the
    \RS package. This is intended as a quick reference or catalogue for the
    user to employ Stochastic Actor Oriented Models (SAOM) to analyze network
    dynamics in \Rn.

    The functions are presented in execution order (more or less as
    they would be used in practice). A list of useful \R
    functions to read and prepare the data set is also included at the
    beginning. In all cases examples on how to use these functions are provided.
    In the `syntax' column,
    when arguments of functions are followed by = and a single option,
    this is the default option.

    The descriptions provided are suitable for beginner and intermediate \R and
    Siena users. For the advanced specifications of the functions the user
    should refer to the help by typing ``?funName'' in the \R console, where
    ``funName'' is the name of the function.

    We consider that the model estimation is composed by 6 stages:
\begin{enumerate}
    \item Getting started
    \item Get the data the right format or check that it is in the correct
      format
    \item Data specification
    \item Model specification
    \item   Model estimation
    \item   Working with the results
\end{enumerate}

Tables \ref{tab:FuncExR} and \ref{tab:ListSienaExec} present the list of useful
\R functions and the list of \RS functions in execution order, respectively.
%\begin{footnotesize}
\begin{sidewaystable}
\begin{threeparttable}
\begin{small}
\centering
        \begin{tabular}{c | l | p{3cm} | p{3cm} | p{12cm} }
        \multicolumn{1}{c}{\textbf{Stage}} & \multicolumn{1}{c}{\textbf{Name}}
 &                          \multicolumn{1}{c}{\textbf{Syntax}} &
 \multicolumn{1}{c}{\textbf{Examples}} &
\multicolumn{1}{c}{\textbf{Description}} \\
        \hline
        1   &getwd  &getwd()        & &
Returns the name of the current working directory.
                Does not require arguments\\
                \hline
        1 & list.files &    list.files(dir) &
list.files (``C:/User/ \newline MyDocuments/
\newline
MySiena'') &    Returns a character vector
with the names of the files in the directory ``dir''. If no argument is
provided, ``dir'' is the current working directory.\\
\hline 1   &setwd\tnote{*} &setwd(dir) &setwd( ``C:/MyDocuments/ MySiena'') &
    Sets the working directory to ``dir''. In this context the working
 directory should be where the data is saved\\
\hline 1   &install.packages\tnote{*} &    install.packages() & &It is used to
install packages. If no arguments are provided it opens a GUI
 to select a mirror site and the packages that we want to download and
 install. This is not necessary if the package has already been installed.\\
\hline 1   &library\tnote{*} & library(package) &  library(RSiena) &
Loads the library named ``package''. \\
\hline 1   &read.table &   read.table(file, header=FALSE, \newline sep=``'',
\newline
quote=``{\''}'',...) &  net1 $<$-- read.table(
\newline
`network1.dat', header=F) & Reads
a file in table format and creates a data frame from it. The argument ``file''
is the file containing the data. In the case of adjacency matrices, the file
should have the same number of columns and rows. ``header'' is a logical
argument indicating whether the first row of the data contains the column
names. ``sep'' is the field separator character
 (such as space, comma, etc.). See the help on the function to specify
other arguments\\
\hline 2 &  as.matrix   &as.matrix(x,...)   &net1 $<$-- \newline as.matrix(net1) &
Transforms an object ``x'' into a matrix. Siena works with matrices and
not with data frames\\
\hline 2&  class &   class(x)  & class(net1)  & Returns the type of object that
``x'' is\\
\hline
2&   dim  & dim(x)  & dim(net1) &  Returns the dimension of object ``x''\\
\hline 4 &   fix\tnote{*}  & fix(x) &  fix(effects) &  Allows editing the
object ``x''
 by opening a window and it replaces the old object by the edited ``x''\\
\hline
\end{tabular}
\caption[Functions from \R in order of execution] {Useful functions from \R in
execution order} \label{tab:FuncExR}
\begin{tablenotes}
\item [*] Also available via a menu option
\end{tablenotes}
\end{small}
\end{threeparttable}
\end{sidewaystable}
%\end{footnotesize}


\begin{landscape}
\begin{small}
%\begin{longtable}{c | p{3cm} | p{5.2cm} | p{4.2cm} | p{8.5cm} }
\begin{longtable}{c | p{2.4cm} | p{4.5cm} | p{4.0cm} | p{9.0cm} }
\caption[List of \RS Functions: Execution] {List of \RS Functions in order of
Execution}
\label{tab:ListSienaExec} \\
\hline

\multicolumn{1}{c}{\textbf{Stage}} & \multicolumn{1}{c}{\textbf{Name}} &
\multicolumn{1}{c}{\textbf{Syntax}} & \multicolumn{1}{c}{\textbf{Examples}} &
\multicolumn{1}{c}{\textbf{Description}} \\
\hline
\endfirsthead

\multicolumn{5}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline \multicolumn{1}{c}{\textbf{Stage}} & \multicolumn{1}{c}{\textbf{Name}} &
\multicolumn{1}{c}{\textbf{Syntax}} & \multicolumn{1}{c}{\textbf{Examples}} &
\multicolumn{1}{c}{\textbf{Description}} \\
\hline
\endhead

\hline \multicolumn{5}{|r|}{{\tiny{Continued...}}} \\
\hline
\endfoot

\hline \hline
\endlastfoot

1 & installGui &    installGui()    &
    &Starts the installer for the standalone version of \rs.
Only for Windows. Does not require arguments\\
\hline

3   &sienaNodeSet   &sienaNodeSet (n, \newline
nodeSetName= ``Actors'', \newline
names=NULL) & &
Creates a Siena node set which can be used as the nodes
 in a siena network. ``n'' is the number of actors or nodes; ``nodeSetName''
 is a character string to name the node set (defaults to ``Actors'') and
```names'' is a string vector with length n with the names of each node
(optional)\\
\hline

3 & sienaDependent & sienaDependent (netarray, type= \newline
c(``oneMode'', ``bipartite'',\newline
``behavior''), \newline
nodeSet=``Actors'', \newline
sparse=is.list (netarray)) & sienaDependent(array(
c(net1,net2,net3), dim=c(dim(net1),3))) & Creates a Siena network object by
forming an array of network observations represented as matrices, arrays or
sparse matrices. ``netarray'' is a matrix (type=``behavior'' only) or array of
values or list of sparse matrices of type ``dgTMatrix'';``type'' is either
``one mode'' (default), ``bipartite'' or ``behaviour''; ``nodeSet'' is the name
of the node set.  It is a vector with two strings for a bipartite network;
``sparse'' is logical and it is set to TRUE if the data is in sparse matrix
format,  FALSE otherwise\\
\hline

3 &coCovar & coCovar(val, \newline
nodeSet =`Actors') & cons $<$-- \newline
as.matrix( read.table \newline
('cons.DAT')) \newline cons1 $<$--\newline
 coCovar (cons[,1]) & Creates a constant
covariate object, where val is the vector of covariate values and nodeSet is
the name of the actors' set.  The dimension of val should be (1, \#
Actors)\\
\hline

3 & varCovar & varCovar(val, \newline
nodeSet =`Actors') & chan $<$-- as.matrix \newline
(read.table ('chan.DAT')) \newline chan $<$-- \newline
varCovar (chan[,1]) & Creates a
changing covariate object where ``val'' is a matrix with the covariate values
with one row for each actor and one column for each period; ``nodeSet'' is the
name of the set of actors \\
\hline

3& coDyadCovar &coDyadCovar(val, \newline
nodeSets= \newline
c(``Actors'', ``Actors'')) & &
Creates a constant dyadic covariate object where ``val'' is a matrix of the
same dimension as the network observations and nodeSets are the sets of actors
with
which the constant covariate is associated\\
\hline

3 &varDyadCovar & varDyadCovar(val, \newline
nodeSets= \newline
c(``Actors'', ``Actors'')) &
&Creates a changing dyadic covariate object where ``val'' is an array of
matrices. Each matrix has the same dimension of the actor set and ``val'' has
one less matrices than observations of the network; ``nodeSets'' are the sets
of actors to which the varying covariate object is associated\\
\hline

3 & sienaCompositionChange & \newline
sienaCompositionChange( changelist,\newline
nodeSet="Actors", \newline
option=1) & & Creates a list of events describing the moments
in which each actor is present in the network: ``changelist'' is a list with an
entry for each actor in the node set. Each entry is a vector indicating
intervals in which an actor is present in the network. ``nodeSet'' is the name
of the set of actors corresponding to these composition changes and ``option''
(defaults to 1) is an integer controlling the processing of the network entries
for the actors not currently present. See help(sienaCompositionChange) for
details on this\\
\hline

%3 & sienaCompositionChangeFromFile & \newline
%sienaCompositionChangeFromFile ( filename, \newline
%nodeSet="Actors", \newline
%fileobj=NULL, option=1) & & Creates a list of events
%describing the changes over time in the actor set from a file. ``filename'' %is
%the name of the file containing change information (one line per actor) each
%line is a series of space delimited numbers indicating intervals. ``fileobj''
%is the result of readLines on ``filename''. ``nodeSet'' is the name of the %set
%of actors. ``option'' (defaults to 1) has the same
%description that in  sienaCompositionChange\\
%\hline

3 & sienaDataCreate & sienaDataCreate(...,\newline nodeSets=NULL, \newline
getDocumentation=FALSE) &
MyData $<$-- \newline
sienaDataCreate (net, \newline cons1, cons2, cons3, \newline
chan, dyad) & Creates a siena object from networks, covariates,
composition and behaviour objects: .``...''  represents the objects of class
``sienaDependent'', ``coCovar'', ``varCovar'', ``coDyadCovar'', ``varDyadCovar'',
``compositionChange''. ``nodeSets'' is a list of Siena node sets. Default is a
single set named ``Actors'' with length equal to the number of rows in the
first object of class ``SienaNet'', it has to match the nodeSet supplied when
the arguments are created; ``getDocumentation'' is a flag to allow
documentation for internal functions,  not for use by users\\
\hline

%3 & sienaDataCreateFromSession & \newline
%sienaDataCreateFromSession( \newline
%filename=NULL, \newline
%session=NULL, \newline
%modelName=``Siena'', ...) & myobj $<$-- \newline
%sienaDataCreateFromSession  \newline
%(`Session.csv') & Reads a SIENA session from a file and creates a
%Siena Data object or group. ``file'' is the session file; ``session'' is the
%input session if the function is called from siena01Gui(); ``modelName'' is %the
%project's name; ``...'' refers to other
%arguments used by siena01Gui()\\
%\hline

3 & sienaGroupCreate & sienaGroupCreate (objlist, \newline
singleOK=FALSE, \newline
getDocumentation=FALSE) & sienaGroupCreate (list( \newline
MyData1, MyData2)) & Creates
an object of class ``sienaGroup'' from a list of Siena data objects:
``objlist'' is a list of objects of class ``siena''; ``singleOK'' is a boolean
variable to indicate if it is OK to have just one object; ``getDocumentation''
is a flag to  allow documentation of internal functions, not for use by users\\
\hline

4 & effectsDocumentation & \newline
effectsDocumentation() & & Prints a html or
\LaTeX\ table with the  effects details\\
\hline

4 & getEffects& getEffects(x, nintn=10, \newline
behNintn=4, \newline
getDocumentation=FALSE) &
MyEff $<$-- getEffects (\newline
MyData, nint=2, \newline
behNint=1) & Creates a siena effects
objects (a data frame) that contains a list of the effects that can be included
in the model.  Type fix(MyEff) to edit the effects through a GUI (e.g.
Including them or excluding them, changing their names, initial values, fixing
them, etc.) The arguments are a siena or a siena group object ``x'', the number
of lines for user defined network interactions ``nint'' and the number of lines
for user defined behaviour interactions ``behNintn''. ``getDocumentation'' is a
flag to allow documentation for
internal functions, not to  be used by users\\
\hline

4 & includeEffects & includeEffects(myeff, ..., \newline include=TRUE, \newline
name=myeff{\,\$}name[1], type=``eval'', \newline
interaction1=``'',\newline
interaction2=``'') & {MyEff$<$--includeEffects(MyEff, transTrip, balance)
\flushleft MyEff$<$--includeEffects(MyEff, sameX, \newline
sameXRecip, \newline
interaction1="gender")}
 &The function is a
way to select the effects to be included. ``myeff'' is an effects object, as
created by getEffects. It is necessary to indicate the short names to identify
the effects to be included (argument ...).
Use myeff{\,\$\,}shortName to get a list
of the short names of possible effects to include and myeff{\,\$}effectName to get
the full name of the effects. This information can also be found in the
documentation created by effectsDocumentation(). The ``include=TRUE'' indicates
that we want to include the ``...'' effects in the model, it can be set to
FALSE to exclude effects from the model. ``name'' is the name of the network
for which effects are being included. ``type'' is to include ``eval''
(evaluation function effects) or ``endow'' (endowment function effects).
``interaction1'' and ``interaction2'' are names of siena objects (where needed)
to completely identify the effects e.g. covariate name or behavior variable
name. Use myeff{\,\$}effectName[myeff{\,\$}include]
to get the names of the included
effects. It returns a new effects object, so it is important to assign it to a
name\\
\hline

4   & includeInteraction &  includeInteraction(myeff, ..., include=TRUE,
\newline
name=myeff{\,\$}name[1], \newline
type =``eval'', \newline
interaction1=rep(``'', 3),\newline
interaction2=rep(``'', 3)) &  MyEff$<$--includeInteraction( MyEff, \newline
transTrip, egoX, \newline
interaction1= c(``'',``beh''))     &This function provides an interface to
allow easy update of  an unspecified interaction row in a Siena effects object.
``myeff'' is  a Siena  effects object as created by getEffects. To specify the
effects to interact,  list their short names instead of ``...''; ``include'' is
a boolean variable,  default TRUE to include the interaction, it can be
switched to FALSE to turn off  an interaction. ``name'' is the name of network
for which interactions are being  defined. Defaults to the first in the effects
object. ``type'' is the type of  effects to be interacted: currently only
``eval'' or ``endow''. ``interaction1''  is a vector of siena objects where
needed to completely identify the effect e.g.  covariate name or behavior
variable name. Trailing blanks may be omitted.  ``interaction2''  is a vector
of siena objects where needed to completely  identify the effect e.g. covariate
name or behavior variable name.  Trailing blanks may be omitted. \\
\hline

4 & setEffect &setEffect(myeff, shortName, \newline
parameter=0, fix=FALSE, \newline
test=FALSE, \newline
initialValue=0, \newline
include=TRUE, name=myeff{\,\$}name[1], \newline
type=``eval'', \newline
interaction1 = ``'', \newline
interaction2 = ``'') & MyEff $<$-- \newline
setEffect(MyEff, transTrip,
initialValue=3, \newline
include=T) & Interface to change the attributes of a particular
effect. The required arguments are an effect object (``myeff''), the short name
of the effect to modify (``shortName'') and a required integer value that
defaults to zero (``parameter''). Depending on what it is desired to be
modified we can supply: ``fix=TRUE'', if we wish to fix that parameter; ``test
= TRUE'' if we wish to test that parameter; ``initialValue=2'' (or any desired
number) to modify the effect's initial value (Defaults to zero); ``include=TRUE
or FALSE'' depending on whether we want to include/exclude the effect (defaults
to TRUE). The arguments ``name'', ``type'' and ``interaction1'' and
``interaction2'' are defined as in includeInteraction  and includeEffects.\\
\hline

5 & print01Report & print01Report(data, modelname=``Siena'',\newline
session=NULL, \newline
getDocumentation=FALSE) & print01Report(MyData) & Prints a
report of a Siena data object and its default effects. We need to supply a
Siena data object (``data'') a siena effects object (``myeff'') and a model
name (``modelname'') that defaults to ``Siena''. It creates and saves a file
named ``modelname.out'' (Siena.out) that contains preliminary information
on the data.\\
\hline

5 & sienaAlgorithmCreate & sienaAlgorithmCreate(\newline
fn=simstats0c,\newline
%usesimstats0c = \newline deparse(substitute(fn)) == \newline "simstats0c",
% \newline
projname=``Siena'', \newline
MaxDegree=0, \newline
useStdInits=FALSE, n3=1000, \newline
nsub=4, maxlike=FALSE, \newline
diag=!maxlike, \newline
condvarno=0, \newline
condname=``'', firstg=0.2, \newline
cond=NA, findiff=FALSE, \newline
seed=NULL) &
\newline
MyAlgorithm $<$-- sienaAlgorithmCreate \newline
(projname = \newline
``MyProject'') & Creates a siena algorithm
object that can be used to call siena07. ``fn'' is function to do one
simulation in the Robbins-Monro algorithm.
%``usesimstats0c'' is boolean, if true the standard algorithm
% is being used which can be used with multiple processes.
% Just used for validation.
``projname'' is character string name of
project. No embedded spaces. ``MaxDegree'' is a named vector of maximum degree
values for corresponding networks. ``useStdInits'' is a boolean variable, if
TRUE, the initial values in the effects object will be ignored and default
values used instead. ``n3'' is the number of iterations in phase 3 (defaults to
1000). ``nsub'' is the number of subphases in phase 2 (defaults to 4).
``maxlike'', boolean to indicate whether to use maximum likelihood method or
straightforward simulation (defaults to false). ``diag'' is boolean to indicate
if the complete estimated derivative matrix should be used; ``condvarno'', if
conditional estimation is used the parameter is the sequential number of the
network or behaviour variable on which to condition. ``condname'' is the name
of the dependent variable on which to condition (only use condname or condvar,
not both). ``firstg'' initial value of gain parameter in the Robbins-Monro
procedure. ``cond'' is boolean, If TRUE, use conditional simulation. If
missing, decision is deferred until siena07 is called, when it is set to TRUE
if there is only one dependent variable, FALSE otherwise. ``findiff'' is
boolean, if TRUE, estimate derivatives using finite differences and if FALSE,
use scores. ``seed'' is an integer referring to the starting value of random
seed. Not used if parallel
testing.\\
\hline

5 & siena07 & siena07(x, batch=FALSE, \newline
verbose=FALSE, silent=FALSE,\newline
useCluster=FALSE, \newline
nbrNodes=2, \newline
initC=FALSE, \newline
clusterString= \newline
rep(``localhost'', nbrNodes), \newline
tt=NULL, \newline
parallelTesting=FALSE, ...) & ans $<$-- \newline
siena07(MyModel,
data=MyData, effects=MyEff, batch=FALSE, \newline
verbose=TRUE, \newline
useCluster=TRUE,\newline
nbrNodes=2
% , \newline initC=TRUE
)
& Estimates parameters using Robbins-Monro algorithm.
 Note that the particular
model to be used is passed on as the algorithm object, and data for the model
must be passed by using named arguments. ``x'' is a model object; ``batch'' is
a boolean variable to indicate if it is desired to open the GUI of Siena
simulation; ``verbose'' is a boolean variable to produce output on the console;
``silent'' is also a boolean variable, if true, no output is printed to the
console; ``useCluster'' is a boolean variable to indicate if it is desired to
use a cluster of processes; ``nbrNodes'' is the number of processes to use if
useCluster is TRUE; `
%`initC'' is boolean: set to TRUE if the simulation will
%use C routines (currently always needed). Only relevant if using multiple
%processes, to ensure all copies are initialised correctly.
``clusterString''
is the definition of clusters, default set up to use the local machine only;
%``tt'' is a tcltk toplevel window used if called from the model options screen;
%``parallelTesting'' is boolean, if TRUE, sets up random numbers to parallel
%those in Siena 3. ``...''  Arguments for the simulation function, such as the
%data, effects, etc.
\newline
siena07 returns an object of class sienaFit (let's say ans). The
main attributes are ans{\,\$}theta, which are the estimated coefficients;
ans{\,\$}covtheta is the estimated covariance matrix of theta;
ans{\,\$}dfra is the
matrix of estimated derivatives; ans{\,\$}targets and ans{\,\$} targets2 are the
observed statistics and the observed statistic by wave, respectively;
ans{\,\$}ssc are the score function contributions for each wave for each simulation
in phase 3: ans{\,\$}sims is the simulated networks as edgelists.
Use names(ans) to
obtain more characteristics; only recommended if you are
proficient in \rs.\\
\hline

6 & print.sienaFit & print(x, tstat=TRUE, ...) & print(ans) & The function
prints a table containing the estimated parameter values, standard errors and
(optionally) t-statistics for convergence. If ``x '' is a summary(sienaFit) it
prints on the console all the summary elements. ``tstat'' is a boolean
argument, set to TRUE if it is desired for the t-statistics for convergence to
be added to the report\\
\hline

6 & summary.sienaFit & summary(x,...) & summary(ans) & Prints a table
containing the estimated parameter values, standard errors and t-statistics for
convergence together with the covariance matrix of the estimates, the
derivative matrix of expected statistics D by parameters, and the covariance
matrix of the expected statistics D.  The only required argument is a
``sienaFit'' object ``x'', as produced by  siena07.\\
\hline

6 & xtable.sienaFit & xtable(x, caption=NULL, \newline
label=NULL, align=NULL, \newline
digits=NULL,\newline
 display=NULL, ...) & sienaxtab $<$-- \newline
 xtable(ans, \newline
caption=``My
Table'', \newline
digits=2).  &Creates an object of class xtable.sienaFit which inherits
from class xtable and passes an extra arguments to the print.xtable.
The argument is a sienaFit object ``x''. \\
\hline


\end{longtable}
\end{small}
\end{landscape}

%\section{List of Functions in Alphabetical Order}

%\input{ListFunctionsCleanrr}



\section{Changes compared to earlier versions}

This presents the main changes, especially those directly visible to the user,
in reverse time order from the current version until
version 1.0.6 of end October 2009.
For more complete information about changes,
consult the \sfn{ChangeLog} file in the source code on CRAN or in
the R-Forge repository, which contains a more complete listing.

\begin{small}
\begin{itemize} % Also update version number in abstract

\item 2018-10-30 R-Forge Revision 336, packages version 1.2-13.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item Correct error in \textsf{sienaGroupCreate} for non-centered actor covariates.
   \item Correct error in \textsf{print01Report} that occurred for changing dyadic covariates
     given as lists of sparse matrices.
   \item Also get simulated dependent behavior variables for
     \texttt{siena07(,,, returnDeps=TRUE, ...)} for ML estimation (see help page).
   \item \textsf{siena.table} corrected for data sets with several dependent variables.
   \item For \textsf{siena08}: new parameters \texttt{which} and \texttt{useBound}
   in \textsf{plot.sienaMeta};
     new parameter \texttt{reportEstimates}, allowing to reduce
     the output produced.
   \item \textsf{updateSpecification}: also update \texttt{randomEffects} column.
   \item More explanation of sparse matrix input in the help page for \textsf{sienaDependent}.
\end{itemize}

Changes in RSienaTest:
\begin{itemize}
   \item \textsf{sienaBayes}: new parameters \texttt{proposalFromPrev}, which allows
     taking proposal distributions from \texttt{prevBayes} object;\\
     \texttt{incidentalBasicRates} resuscitated;\\
     allow fixed rate parameters, with \texttt{priorRatesFromData=-1};\\
     changed initial values of scale factors for proposal distributions;\\
     new parameters target and \texttt{usePrevOnly};\\
     in case \texttt{prevBayes} is used, parameters \texttt{nrunMHBatches, nSampVarying, nSampConst},
     and \texttt{nSampRates} in the function call of \textsf{sienaBayes} supersede those
     in the \texttt{prevBayes} object;\\
     correct bug for three-effect interactions;\\
     copy parameters \texttt{modelType, behModelType, MaxDegree, Offset, initML},
     from parameter \texttt{algo} to the algorithms created within \textsf{sienaBayes};\\
     more extensive checking of smallest eigenvalue of covariance matrix;\\
     for \texttt{priorRatesFromData = 1} or 2, the resulting prior Covariance
     matrix for \texttt{priorKappa != 1}
     was incorrect; this was corrected;\\
     reported timing changed to elapsed system time.
\end{itemize}

\item 2018-05-13 CRAN, RSiena version 1.2-12.

\item 2018-05-06 R-Forge Revision 335, packages version 1.2-11.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item New effects \texttt{gwdspFF} and \texttt{gwdspFB}.
   \item Effects \texttt{simEgoInDist2} and \texttt{simEgoInDist2W}
   for two-mode networks were corrected.
     Perhaps \texttt{simEgoDist2} and \texttt{simEgoDist2W} were broken
     in a previous version; if so, that was now corrected.
   \item Added \texttt{sqrt} version for \texttt{reciAct}, obtained for parameter = 2.
   \item Allowed the value \texttt{parameter=NULL} for \textsf{setEffect} and
   \textsf{includeInteraction},
     meaning that no change is made for the internal effect parameter.
     For \textsf{setEffect} this is the new default,
     implying that when starting the
     default values from \texttt{allEffects.csv} are used, just like in
     \textsf{includeEffects}
     (where no parameter can be given).
   \item New auxiliary functions for \textsf{sienaGOF}:
   \textsf{Triad Census} and \textsf{mixedTriadCensus}
     (contribution by Christoph Stadtfeld).
   \item triad census from \texttt{igraph} added to help page of
   \textsf{sienaGOF-auxiliary}.
   \item improved \textsf{sienatable} output for \texttt{type="html"}:
   added \texttt{rules=none, frame = void} to
     general options; changed minus to \texttt{\&ndash;}~;
     added column for asterisks to have better alignment for estimates.
   \item Stop cluster also for a user interrupt in  \textsf{siena07}.
   \item Extension of help page for \textsf{siena07} by
   mentioning functions for accessing simulated networks for ML.
\end{itemize}

Change in RSienaTest:
\begin{itemize}
   \item \textsf{extract.sienaBayes}:
   error corrected that occurred if called with
     \texttt{extracted="all"} but there are no varying,
     or no non-varying parameters.
\end{itemize}

\item 2018-03-24 R-Forge Revision 334, packages version 1.2-10.

Change in RSiena and RSienaTest:
\begin{itemize}
   \item Example in help file \textsf{siena07} for accessing generated networks
   in case of ML estimation/simulation.
   \end{itemize}

\item 2018-03-21 R-Forge Revision 332, packages version 1.2-9.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item Added effects \texttt{avExposure, totExposure, infectDeg,
     susceptAvCovar, infectCovar} for symmetric networks, in
     new effect group \texttt{covarBehaviorSymmetricRate}.
   \item New effects \texttt{degAbsDiffX, degPosDiffX, degNegDiffX, degAbsContrX,
     degPosContrX, degNegContrX}.
   \item Effects \texttt{XWX, XWX1}, and \texttt{XWX2} enabled for
   bipartite networks, in
    new effect group \texttt{dyadBipartiteObjective}.
   \item Added parameter=2 for \texttt{FFDeg, BBDeg, FBDeg, FRDeg, BRDeg}.
   \item Corrected \texttt{altInDist2, totInDist2} for two-mode networks.
   \item Dropped some duplications in \sfn{effectsDocumentation}.
   \item Modification of effect \texttt{outTrunc2}.
     Perhaps this was superfluous.
   \item Export of last simulated state from ML simulations if
     \texttt{returnDeps}.
   \item Added endowment and creation effects for \texttt{maxAlt} and \texttt{minAlt}.
   \item Error messages for non-character \texttt{nodeSets} in functions
    \sfn{sienaDependent, coCovar,\\ varCovar}.
   \item Improved way of handling missings for distance-2 network effects.
   \item Added components \texttt{requestedEffects}, \texttt{theta}, and
    \texttt{se} to \texttt{siena08}
     (\texttt{theta} and \texttt{se} are the ML estimates).
   \item Error in summary of \sfn{sienaMeta} object corrected:
     for the estimated mean parameter the two-sided $p$ was announced but a
     one-sided $p$ was given. Also the ML results under normality assumptions
     were copied from \sfn{print.sienaMeta} to \sfn{print.summary.sienaMeta}.
   \item For non-directed networks, the initial model now contains
    only basic rates and degree effect.
   \item Added reference to \texttt{DESCRIPTION} and citation info in
    \texttt{{\textbackslash}inst},
   so \texttt{citation("RSiena")} now gives useful information.
   \item The dropping of the exclusion of effects if the variance of a
     covariate is 0, or a covariate has only two values, of version 1.1-306,
     was  taken further (was incomplete).
   \item Message if attributes \texttt{higher, disjoint},
   or \texttt{atLeastOne} are \texttt{TRUE}      at the end of \\
     \sfn{sienaDataCreate}.
   \end{itemize}
Changes in RSienaTest:
\begin{itemize}
   \item new function \sfn{extract.posteriorMeans} for \sfn{sienaBayes} results.
   \item Restrict check of maximum
     estimated parameter value after initialization to non-fixed effects.
   \item Correct construction of groupwise effects object in \sfn{sienaBayes}
    so that this
     will work also when evaluation effects for density and/or reciprocity are
     not included; and when there are interaction effects for which the main
     effects are not included.
   \item Corrections for \sfn{print} and \sfn{summary} of \sfn{sienaBayes} objects.
     In \sfn{print.sienaBayesFit}, include fixed parameters and
     give credibility intervals for rate parameters; include variance parameters;
     allow shorter \texttt{ThinParameters};
     print objects returned through \texttt{partialBayesResult.RData}
     (by adding \texttt{na.rm=TRUE} to quantile).
   \item \sfn{multipleBayesTest} corrected (there was an error for testing
      2 or more linear combinations simultaneously)
       and adapted for cases with fixed  parameters;
     adapted help file text.
   \item All remaining parts of \sfn{rsiena01gui} removed.
   \item As a compensation of this, \sfn{sienaDataCreateFromSession} exported,
   and a more informative help page written.
\end{itemize}

\item 2017-09-09 R-Forge Revision 318, packages version 1.2-4.
Changes in RSiena and RSienaTest:
\begin{itemize}
   \item Longer Description field in \texttt{DESCRIPTION}, as per CRAN suggestions.
   \item Correction of \sfn{print.sienaFit}, repairing the option
        \texttt{include=FALSE}  in \sfn{setEffect} and \\
        \sfn{includeEffects}.
\end{itemize}
Changes in RSienaTest:
\begin{itemize}
   \item Extra line in example for \texttt{sienaBayes.Rd}.
\end{itemize}

\item 2017-09-08 R-Forge Revision 316, CRAN package version 1.2-3.

Changes in RSiena and RSienaTest:
\begin{itemize}
 \item totAlt also for non-directed networks.
 \item Further corrections to make RSiena acceptable for CRAN.
\end{itemize}

\item 2017-09-04 R-Forge Revision 312.

Changes in RSiena and RSienaTest:
\begin{itemize}
 \item Score test and \sfn{sienaGOF} corrected for the case that some parameters
      are fixed and not tested.
 \item New function \sfn{score.Test}. This allows, for a \sfn{sienaFit}
     object in which some effects were tested with \texttt{test=TRUE}, to get the
     results of the score-type test for some or all of the parameters tested.
     When some effects are tested with \texttt{test=TRUE}, the
     results of the score test are also presented when printing the estimation
     result.
 \item Argument \texttt{varName} added to \sfn{updateTheta}.
     This allows the update to be restricted to one or more of the
     dependent variables.
 \item Operation of option `\texttt{absorb}' (\texttt{behModelType}=2) corrected.
 \item In \sfn{sienaAlgorithmCreate}, for parameters
     \texttt{Offset, MaxDegree, modelType},
     and \texttt{behModelType}, require that these are named vectors with the names
     of the dependent variables, or NULL; this is checked in \sfn{initializeFRAN}.\\
     The use of non-named vectors for these, in the case of using multiple processes
     may have led to errors in earlier versions.\\
     Note that the default for \texttt{MaxDegree} now is not \texttt{MaxDegree=0}
     but \texttt{MaxDegree=NULL}.
 \item New effects \texttt{sameXInPopIntn, sameXOutPopIntn, sameXInActIntn,
     sameXOutActIntn}.
 \item For \texttt{networkModelType} 3 (Initiative, \texttt{AAGREE}),
     an offset is added to the
     confirmation model; this is taken from \texttt{Offset} in the algorithm object.
 \item For effects \texttt{inPopX, outPopX, inActX, outActX, sameXInPop, sameXOutAct,
     diffXInPop, diffXOutAct, homXInPop, homXOutAct, altXOutAct, diffXOutAct},
     changed \texttt{interaction2} to \texttt{''} (was \texttt{'1'}, erroneously)
     and default parameter to 1 (\sfn{AllEffects.csv}).
 \item Additional parameter \texttt{dropRates} in \sfn{print.sienaEffects}
    (useful for \sfn{sienaBayes} with many groups).
 \item In \sfn{print.sienaEffects}, omit last remark about random effects if only
     one line is printed.
 \item Corrected use of \texttt{modeltype} (\sfn{initializeFRAN.r, CInterface.r}),
 \item Change in \sfn{print.sienaAlgorithm} for \texttt{modelType}.
 \item Added an example for multiple processes in \sfn{sienaGOF.Rd}, and
      took out verbose reporting from \sfn{sienaGOF} in case of multiple processes.
\end{itemize}
Changes in RSiena:
\begin{itemize}
 \item New parameter \texttt{OffSet} in \sfn{sienaAlgorithmCreate}.
 \item Registration of native routines (requirement for CRAN).
\end{itemize}
Changes in RSienaTest:
\begin{itemize}
 \item Parameter \texttt{UniversalOffset} of \sfn{sienaAlgorithmCreate}
       renamed to \texttt{Offset}.
 \item Added posterior variances to \sfn{print.sienaBayesFit}.
 \item Correction of error in \sfn{sienaBayes} that could lead to errors
       in results of estimations with data sets for multiple dependent
       variables (networks and/or behavior) with model specifications that
       contain an interaction effect for a dependent variable that is not
       the last of the dependent variables.
 \item Various changes in \sfn{sienaBayes} for less memory use and
       avoiding crashes in some situations.
\end{itemize}

\item 2017-05-08 Revision 306.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item New function \sfn{updateSpecification} to includes in an
   effects object a set of effects that are included in another effects object.
   \item New effects \texttt{inPopX, outPopX, inActX, outActX, sameWXClosure, degPlus,\\
     absDiffX, avAltPop, totAltPop, egoPlusAltX, egoPlusAltSqX,
     egoRThresholdX, \\ egoLThresholdX, altRThresholdX, altLThresholdX}.
   \item \texttt{outOutAss} dropped for symmetric networks;
   only \texttt{outInAss} remains.
   \item \texttt{egoX} effect has \texttt{interactionType='ego'}
   also for symmetric networks.
   \item The exclusion of effects if the variance of a covariate is 0,
     or a covariate has only two values, is dropped (these effects have no meaning,
     but their exclusion was a potential nuisance for meta-analyses).
   \item Description of \texttt{gwespFB} and \texttt{gwespBF} corrected.
   \item \sfn{includeInteraction} has an additional parameter \texttt{random}.
   \item \sfn{siena08} now also accepts a list for ...
   \item Argument \texttt{behModelType} added to \sfn{sienaAlgorithmCreate}.
       For \texttt{behModelType=2}, the `absorbing option' is chosen
     in the model for behavioral dependent variables;
     see Section~\ref{S_modeltype_beh} of this manual.
   \item Indication of effect parameters dropped in names for
     \texttt{altInDist2} and \texttt{totInDist2} (they have no effect parameters).
   \item \texttt{ModelType} now is specific to the dependent variable:
     given as a named integer vector in \sfn{sienaAlgorithmCreate}.
   \item \sfn{sienaAlgorithmCreate, siena07}: new option \texttt{lessMem},
      reducing storage in \sfn{siena07} by leaving out
      \texttt{z\$ssc} and \texttt{z\$sf2} from the object produced;
      but these are used by
     \sfn{sienaTimeTest} and \sfn{sienaGOF}, so running those functions will be impossible
     for \sfn{sienaFit} object obtained with \texttt{lessMem=TRUE}.
   \item extended information in \sfn{print.sienaAlgorithm}.
   \item Modified check for singular covariance matrix after Phase 3.
   \item Warning if \sfn{includeEffects} is used with parameter \texttt{random}.
   \item Warning for impossible or zero changes if maximum likelihood
     (see Section ~\ref{S_ML}, and News page of Siena website).
   \item Some parts dropped from the object produced by \sfn{siena07}
     to reduce memory use.
\end{itemize}
Changes in RSienaTest:
\begin{itemize}
\item sienaBayes:
        various changes to save memory (thanks to Ruth Ripley);
        improved reporting of groups with no changes;
        warning for impossible changes, see Section~\ref{S_sBData};
        if \texttt{priorRatesFromData=2}, change to different robust covariance matrix
          estimator when this is necessary (i.e., for small number of groups);
        in \sfn{print.summary}, also report \texttt{nImproveMH};
        a few lines added to help file.
   \item \sfn{print.sienaEffects} gives dimensions of \texttt{priorMu}
     and \texttt{priorSigma} if \texttt{includeRandoms}.
\end{itemize}


\item 2016-10-13, 14 Revision 303, 304.

Changes in RSiena and RSienaTest (George Vega Yon):
\begin{itemize}
   \item New parallellization option -cl- for \sfn{siena07}.
\end{itemize}

\item 2016-10-09 Revision 301.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item New effects: \texttt{sameXCycle4, homCovNetNet, contrastCovNetNet,
     covNetNetIn, \\
     homCovNetNetIn, contrastCovNetNetIn, inPopIntnX, inActIntnX, outPopIntnX, \\
     outActIntnX}.
   \item Changes permitting the 4-cycles effects for larger and denser networks.
   \item Dropped \texttt{cl.XWX} effect from two-mode -- one-mode coevolution
     (did not belong).
   \item \texttt{egoSqX} is an ego effect.
   \item Added \texttt{cycle4} for one-mode networks.
   \item Added \texttt{outAct, outInAss} for symmetric networks.
   \item \sfn{SienaRI}: Structural zeros and ones are excluded from the calculations;
     added option \texttt{getChangeStats};
     row names given to matrices that have rows corresponding to effects;
     adapted so that it runs for models with only 1 parameter;
     adapted so that for a bipartite dependent variable it does not crash.
   \item Warning if \sfn{includeEffects} is used with parameter \texttt{parameter}.
   \item Small additions to \sfn{print.sienaAlgorithm}.
   \item Clearer output for \texttt{MaxDegree} in \sfn{print.sienaFit}.
   \item Correction of how effect parameter for \texttt{outInAss}
     for 2-mode networks is reported.
\end{itemize}


\item 2016-08-17 Revision 296.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item Warning if \sfn{includeInteraction} is used for more interactions
     than available given parameters \texttt{nintn} and \texttt{behNintn}.
   \item Deleted session parameter from \sfn{print01Report}.
   \item Corrected \texttt{cycle4} effect for parameter=2 (sqrt version).
   \item Additional auxiliary function \sfn{CliqueCensus} in help page \sfn{sienaGOF-auxiliary}.
   \item Error corrected in \texttt{DyadicCovariateAvAltEffect.cpp}.
\end{itemize}


\item 2016-05-28 Revision 294.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item The manual was taken out of the installation;
   it still is in the source code distribution as
   RSienatest{$\backslash$}doc{$\backslash$}RSiena\_Manual.tex. It still is publicly
   it can be downloaded from \\
%\href{http://www.stats.ox.ac.uk/~snijders/siena/RSiena_Manual.pdf}
{\texttt{http://www.stats.ox.ac.uk/$\tilde{\ }$snijders/siena/RSiena\_Manual.pdf}}.
   \item New effects  \texttt{totAltEgoX}, \texttt{totAltAltX}, \texttt{egoSqX},
     \texttt{diffX}, \texttt{diffSqX}, \texttt{egoDiffX},
     \texttt{avAltW}, \texttt{totAltW}, \texttt{avSimW},
     \texttt{totSimW}, \texttt{jumpFrom}, \texttt{jumpSharedIn},
     \texttt{mixedInXW}, \texttt{mixedInWX},
     \texttt{avWalt},  \texttt{totWAlt}.
   \item \texttt{inActIntn} also implemented for two-mode dependent networks.
   \item Endowment and creation effects were added for
       \texttt{inAct}, \texttt{inActSqrt}, \texttt{outAct}, \texttt{outActSqrt}.
\end{itemize}
Changes in RSiena:
\begin{itemize}
   \item \sfn{(siena01Gui)} and \sfn{sienaDataCreateFromSession()} dropped.
\end{itemize}
Changes in RSienaTest:
\begin{itemize}
 \item Change in endowment effect estimation for \texttt{avAlt} effect.
   \item New effects
     \texttt{simmelian}, \texttt{simmelianAltX}, \texttt{avSimmelianAlt},
      \texttt{totSimmelianAlt}.
\end{itemize}

\item 2016-02-03 Revision 291.

Identical to 290, but now there is a Mac version.

\item 2016-02-01 Revision 290.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item New effects \texttt{FBDeg}, \texttt{FRDeg}, \texttt{BRDeg}
     (\texttt{RFDeg} was mentioned earlier
     but was not implemented; its place is now taken by \texttt{FRDeg}),
	 \texttt{gwespFFMix}, \texttt{gwespBBMix}, \texttt{gwespBFMix},
     \texttt{gwespFBMix}, \texttt{gwespRRMix}, \texttt{gwespMix}.
   \item Corrected the omission of the check for positive derivative matrix
      at the end of phase 1 for effects with fixed parameters.
   \item Added parameters \texttt{fix}, \texttt{test}, \texttt{parameter} to
   \sfn{includeInteraction()}.
   \item More helpful error message for incorrect nodesets in
    \sfn{sienaDataCreate()};
     extended help pages for  \sfn{sienaDataCreate()}
     and  \sfn{sienaDependent()}.
   \item Correction  to allow estimation for a one-dimensional parameter.
   \item \texttt{fromBayes} bug corrected.
\end{itemize}

Changes in RSienaTest:
\begin{itemize}
   \item \sfn{sienacpr()} added (programmed by Felix Sch\"{o}nenberger); this includes
     gmm estimation (Amati - Snijders).
   \item \sfn{sienaBayes()}: option \texttt{initML} added; check for zero distances;
     corrected function \texttt{improveMH()} in initialization.
   \item \sfn{print.multipleBayesTest()}: option \texttt{descriptives} added.
   \item \sfn{glueBayes()}: added \texttt{p1} and \texttt{p2} to created object.
\end{itemize}

\item 2015-09-10 Revision 289.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item New defaults for \sfn{siena07()} in \sfn{sienaAlgorithmCreate()}:
     doubleAveraging=0, diagonalize=0.2 (for MoM).
   \item Improved one-step approximations to expected Mahalanobis
     distances in \sfn{sienaGOF()} (control variates for score function).
   \item Permit 3-way interactions with one ego and two dyadic effects
     (\texttt{initializeFRAN.r}) (this was erroneously not allowed).
   \item New effects \texttt{Jin, Jout, JinMix, JoutMix, altXOutAct,
     doubleInPop, doubleOutAct}.
   \item \sfn{print01Report()} now reports in-degrees also for two-mode networks.
   \item Better error handling for \sfn{sienaTimeTest} and \sfn{scoreTest}.
   \item \texttt{inOutAss} is dyadic.
   \item Corrected \texttt{effectName} and \texttt{functionName} of \texttt{inPopIntn, outPopIntn,
     inActIntn}, and \texttt{outActIntn} (`\texttt{in}' and `\texttt{out}' were missing).
  \item Check for positive derivative matrix at the end of phase 1 (non-positive
     estimated derivatives lead to repeating a prolonged phase 1)
     omitted for effects with fixed parameters.
\end{itemize}

Changes in RSiena:
\begin{itemize}
   \item New effects \texttt{homXOutAct, FFDeg, BBDeg, RFDeg, diffXTransTrip}
     (ported from RSienaTest).
   \item \texttt{sameXInPop} and \texttt{diffXInPop} also added for two-mode networks;
     but they are not dyadic!
   \item In names of behavior effects and statistics dropped the
     (redundant) parts "behavior" and "beh.".
\end{itemize}

Changes in RSienaTest:
\begin{itemize}
   \item New function \sfn{extract.sienaBayes()}.
   \item \sfn{sienaBayes()}: options diagonalize=0.2, doubleAveraging=0 for estimation
     of initial models in initialization phase; save initial results in case of
     divergence during initialization phase;
     check for large initialEstimates done only for non-rate parameters.
\end{itemize}

\item 2015-07-18 Revision 288.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item \sfn{plot.sienaRI}: new parameter \texttt{actors}; proportions with
     piechart improved (hopefully); effect of parameter \texttt{radius} changed.
   \item \sfn{siena.table} does no more produce the double minus sign in html output.
\end{itemize}

Changes in RSiena:
\begin{itemize}
\item Correction of error for two-mode networks in \sfn{sienaGOF()}.
\end{itemize}

Changes in RSienaTest:
\begin{itemize}
\item New effects \texttt{homXOutAct}, \texttt{FFDeg}, \texttt{BBDeg},
   \texttt{RFDeg}, \texttt{diffXTransTrip}.
   \item \texttt{sameXInPop} and \texttt{diffXInPop} also added for two-mode networks;
     but they are not dyadic!
   \item In names of behavior effects and statistics dropped the
     (redundant) parts \texttt{behavior} and \texttt{beh.}.
   \item \sfn{sienaBayes}: new parameter \texttt{nSampRates};
     correction in use of \texttt{prevBayes};
	 more efficient calculation of multivariate normal density.
   \item Small changes in \sfn{HowToCommit.tex}.
\end{itemize}

\item 2015-05-21 and 2015-06-02 Revision 286.

Changes in RSiena and RSienaTest:
\begin{itemize}
\item \sfn{SienaRIDynamics} dropped from \rs, it still has an error
      (retained in \rst).
\end{itemize}

Changes in RSienaTest:
\begin{itemize}
\item Correction of error for two-mode networks in \sfn{sienaGOF()}.
\end{itemize}

\item 2015-05-20 Revision 285.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item \texttt{tmax} added to \sfn{sienaFit} objects and
     \texttt{tconv.max} mentioned in \sfn{print.sienaFit()}.
   \item \sfn{sienaAlgorithmCreate()} has new arguments \texttt{n2start},
     \texttt{truncation}, \texttt{doubleAveraging}, \texttt{standardizeVar};
     this leads to various changes in \texttt{phase2.r}.
   \item Diagonalization corrected (matrix transpose) (\texttt{phase2.r}).
   \item When there are missings in constant or changing monadic covariates,
     and \\centered=FALSE for their creation by \sfn{coCovar()} or
	 \sfn{varCovar()}, the mean will be imputed (used to be 0, which was an error).
	 For changing covariates, this is the global mean.
   \item In \sfn{coCovar()} and \sfn{varCovar()} there is a new argument \texttt{imputationValues},
     which are used (if given) for imputation of missing values.
	 Like all missings, they are not used for the calculation
	 of the target statistics in the Method of Moments.
   \item New effects: \texttt{outOutActIntn, toDist2, from.w.ind}.
   \item In the target statistic for the \texttt{higher} effect, contributions for
     value(ego)=value(alter) are now set appropriately at 0.5 (was 0).
   \item New effectGroup \sfn{tripleNetworkObjective} (\sfn{allEffects.csv, effects.r})
     (see earlier in this manual for its characteristics).
   \item Decent error message when there are (almost) all NA in the dependent
     behavioural variable (\sfn{effects.r}, function \sfn{getBehaviorStartingVals()}).
   \item The centering within effects for similarity variables at distance 2
     now is done by the same similarity means as for the \texttt{simX} effect
	  (\texttt{attr(mydata\$cCovars\$mycov, "simMean")}, etc.).
\end{itemize}

\item 2015-04-02 Revision 284.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item New effects: \texttt{simEgoDist2, simEgoInDist2, simEgoDist2W, simEgoInDist2W,\\
         sameXOutAct, diffXInPop, diffXOutAct}. The centering for the similarity
         measure in effects such as simEgoDist2 and simDist2 is not yet clear
         (this affects only the outdegree parameter).
   \item  Relevant for creating new effects:
        New effect groups  \sfn{covarABNetNetObjective},
         \sfn{covarANetNetObjective}, and \sfn{covarBNetNetObjective}.
    	See \sfn{SienaSpec.tex/pdf}, section 4.9: \sfn{covarNetNet}.
   \item Bug corrected that occurred in \sfn{print01Report} for a \sfn{sienaGroup} object
     where the component objects have constant dyadic covariates.
   \item When a statistic is not plotted in \sfn{plot.sienaGOF()} because
     its variance is 0, a note about this is printed to the screen.
   \item Minimum and maximum of plotted region in \sfn{plot.sienaGOF()}
     is calculated without taking into account non-plotted statistics.
   \item Bug corrected with includeTimeDummy for \texttt{timeDummy} greater than
     or equal to 10 (\sfn{sienaTimeTest.r}).
   \item In case of collinear parameter estimates, standard errors
     are reported as NA.
   \item Arguments \texttt{main} and \texttt{ylab} dropped from
     \sfn{plot.sienaGOF()}; they did
     not work, and their functionality now is covered by the ...
     argument (so using \texttt{main} and \texttt{ylab} as arguments now should work).
     (Thanks to David Kavaler.)
\end{itemize}
Changes in RSienaTest:
\begin{itemize}
   \item \sfn{sienaBayes}: correction in initialization of truncation rate parameters
     based on prior; error corrected for sampling constant parameters.
\end{itemize}
Changes in RSiena:
\begin{itemize}
   \item Parameter \texttt{reduceg} added in \textsf{sienaAlgorithmCreate()}
   for use in \textsf{siena07()}, like in RSienaTest.
\end{itemize}


\item 2014-12-11 R-Forge Revision 282.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item Effects \texttt{cl.XWX} and \texttt{cl2.XWX} corrected (thanks to Christoph Stadtfeld).
   \item \texttt{interactionType} of \texttt{gwesp..} effects was made \texttt{dyadic}.
   \item Some layout changes in warning message in \sfn{siena07()}.
   \item New effects \texttt{reciPop, reciAct, in3Plus, maxAlt, minAlt, transTrip1, transTrip2}.
   \item Effect \texttt{antiInIsolate2} got alias \texttt{in2Plus}.
   \item \texttt{inPop} is dyadic effect (except for non-directed networks)
     (it is $\sum_j x_{ij} \{\sum_{h \neq i} x_{hj} + 1\}$).
   \item \texttt{egoX} added as effect for non-directed networks
     (can be important for representing effects of group-level covariates
     in multi-group analyses).
   \item Components \texttt{IActors} and \texttt{expectedI} added to \sfn{sienaRI()}
     and \sfn{print.sienaRI()}.
   \item The check for \texttt{MaxDegree} when running \sfn{siena07()} now works properly also
     for \sfn{sienaGroup} objects.
   \item Manual introduces the term \emph{elementary effects}.
\end{itemize}
Changes in RSienaTest:
\begin{itemize}
   \item \sfn{sienaBayes}: the stop caused by singularity of the precision
     matrix after the multi-group estimation now is circumvented;
	 still a warning is printed to the screen.
  \item \sfn{sienaBayes:} option \texttt{priorRatesFromData} changed to values 0-1-2,
     with 0 = former \texttt{FALSE}, 1 = former \texttt{TRUE}, 2 = robust estimation of prior
     for rate parameters from estimates at the end of initialization phase.
  \item Correction of \sfn{print.summary.sienaBayesFit} for models
     with more than one dependent variable.
\end{itemize}

\item 2014-11-19   R-Forge Revision 280.
Changes in RSienaTest:
\begin{itemize}
\item Small changes in help pages for \sfn{sienaGOF()} and for \sfn{sienaCompositionChange()}.
\item New parameters \texttt{nSampVarying} and \texttt{nSampConst} in \sfn{sienaBayes()}.
\end{itemize}

\item 2014-11-13  R-Forge Revision 279.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item Effect \texttt{AltsAvAlt} renamed to \texttt{avXAlt}.
   \item Effects object no longer used as argument for \sfn{print01Report}.
   \item A lot of new effects: \texttt{sameXInPop, transRecTrip2, totAlt, avInAlt, totInAlt,
     totRecAlt, totXAlt, avXInAlt, totXInAlt,
	 avAltDist2, totAltDist2, avTAltDist2, totAAltDist2,
	 avXAltDist, totXAltDist2, avTXAltDist2, totAXAltDist2,
	 avInAltDist2, totInAltDist2, avTInAltDist2, totAInAltDist2,
	 avXInAltDist2, totXInAltDist2, avTXInAltDist2, totAXInAltDist2,
     XWX1, XWX2, cl.XWX1, cl.XWX2}.
   \item Endowment and creation effects added for \texttt{gwesp...} effects.
   \item Some meaningless effects for two-mode networks dropped.
   \item For non-invertible covariance matrices at the end of \sfn{siena07},
         give diagnostic for the linear combination that gives trouble.
   \item Correction of \sfn{igraphNetworkExtraction()} in the help page
       for \sfn{sienaGOF-auxiliary}
     (the earlier version dropped isolated nodes from simulated networks).
   \item In the help page for \sfn{sienaGOF-auxiliary.Rd},
     the example of constraint is replaced
     by the example of eigenvector centrality (because constraint
	 is undefined for isolated nodes, leading to computational problems).
   \item Set diagonal of observed networks to 0 in \sfn{sparseMatrixExtraction()}.
   \item \sfn{sienaRIDynamics()} restored, after corrections.
   \item ``file" parameter of \sfn{sienaRI()} dropped (implied platform dependence).
   \item Section in manual about user-defined interaction effects updated.
   \item Parameter \texttt{showAll} added to \sfn{descriptives.sienaGOF()}.
   \item Small correction of \sfn{print.siena()} (reporting uponly/downonly).
   \item Some changes in \sfn{print.sienaAlgorithm()}.
   \item Check in \sfn{siena07()} for incorrect \texttt{MaxDegree} specification.
   \item Correction of printing errors arising when result of score-type test is \texttt{NA}.
   \item \texttt{maxRatio} checked for \texttt{NA} or \texttt{NaN} in \sfn{phase2.r}.
   \item \texttt{Siena\_algorithms4.tex} renamed \texttt{Siena\_algorithms.tex};
         this document now is made available as a pdf file at the \SI website.
   \item Some improvement of error messages for \sfn{sienaTimeTest()}.
   \item $p$-value for goodness of fit (\sfn{sienaGOF()}) rounded to 3 decimal places.
   \item File \sfn{effects.pdf} dropped from \texttt{{$\backslash$}inst{$\backslash$}doc}
          (it can be created by \sfn{effectsDocumentation()}).
\end{itemize}
Changes in RSienaTest:
\begin{itemize}
   \item \sfn{sienaBayes()}: new parameters \texttt{nImproveMH} and \texttt{priorRatesFromData};
      these give the possibility to truncate initial rate parameters depending on prior.
   \item \sfn{glueBayes()} corrected so that it can be applied sequentially.
   \item \sfn{multipleBayesTest()} now allows matrix parameter to test
     linear combinations.
   \item Improved \sfn{plot.multipleBayesTest} (to show truncation at 0).
\end{itemize}

\item 2014-07-08  Revision 278.

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item Added \texttt{s50s} to data set.
   \item Corrected \texttt{se} component of \sfn{sienaFit} objects
     (should be standard error, was its square).
   \item new effects \texttt{totDist2, altInDist2, totInDist2,
     totDist2W, altInDist2W,\\
      totInDist2W}.
   \item Some warnings for calculations of \texttt{z\$regrCor}
   and \texttt{z\$regrCoef} avoided in \sfn{siena07()}.
   \item \sfn{print01Report()} errors corrected, and slightly improved,
    for descriptives for changing dyadic covariates
    and for upOnly / downOnly cases.
\end{itemize}

Changes in RSienaTest:
\begin{itemize}
\item  \sfn{sienaBayes()}:
    Internally multiplied the data-dependent choice of
     \texttt{priorSigma} for rate parameters by \texttt{priorKappa};
     changed \texttt{z\$nwarm} to 0 if \texttt{prevBayes} is used;
     dropped \texttt{plotit} functionality.
\item  \sfn{sienaBayes()}, \sfn{glueBayes()}, and
     \sfn{print.sienaBayes()}:
      adapted to allow inclusion of interaction effects without the corresponding
     main effects.
\item Added parameter \texttt{nwarm2} to \sfn{glueBayes()}.
      Checks of identical prior parameters in this function
      restricted to non-rate parameters.
\end{itemize}


\item 2014-06-22 R-Forge Revision 277.
Changes in RSiena and RSienaTest:
\begin{itemize}
\item Higher write-to-screen frequency for batch operation of \sfn{siena07()}.
\item Function \sfn{includeEffects()} now includes parameters \texttt{fix} and \texttt{test}.
\item Various small bug corrections (see the \sfn{ChangeLog}, 1.1-275).
\end{itemize}

Changes in RSienaTest:
\begin{itemize}
\item Changes in \sfn{sienaBayes()} and its print and summary methods.
\item Corrected starting printing \sfn{sienaBayesFit} at \texttt{nfirst}.
\item New function \sfn{glueBayes()} for combining \sfn{sienaBayesFit()} objects.
\item Added functions \sfn{simpleBayesTest()} and \sfn{multipleBayesTest()}.
\end{itemize}

\item 2014-04-26 R-Forge Revision 274.
Changes in RSiena and RSienaTest:
\begin{itemize}
\item Correction of effect \texttt{homWXClosure}.
\item Small change in \sfn{print01Report} to improve reporting
     two files of composition change.
\item \sfn{sienaRI}: require that \texttt{file} argument is not NULL for non-Windows
     operating systems.
\end{itemize}

\item 2014-04-13 R-Forge Revisions 267-271.

Changes in RSienaTest:
\begin{itemize}
 \item Updates to let \sfn{sienaBayes()} accept
     a wider range of data and models (e.g., user-defined interactions);
     and various corrections to \sfn{sienaBayes()}.
\end{itemize}

Changes in RSiena and RSienaTest:
\begin{itemize}
\item Added function \sfn{sienaRI()} for assessment of relative importance of effects,
      with print and plot methods.
\item In \sfn{coDyadCovar()} and \sfn{varDyadCovar()}, centering now also is
      optional by the new option \texttt{centered} (like it was done for
      \sfn{coCovar()} and \sfn{varCovar()} in revision 1.1-251).
\item Corrected bug when printing siena object with a symmetric network;
     and in \sfn{varDyadCovar()} corrected a bug occurring when calling it
     with a named list.
\item Added standard errors as component \texttt{se} to \texttt{sienaFit}
     objects.
\end{itemize}


\item Internal changes in the code version 1.1-255 to 1.1-267 (see \sfn{ChangeLog}).

\item No noticeable changes from version 1.1-251 to 1.1-254.

\item 2014-02-13 R-Forge Revision 251

It should be noted that two changes were made that potentially
have an influence on some results obtained.

First, the effects \texttt{gwespFF, gwespBB, gwespFB, gwespBF, gwespRR}
were modified in RSienaTest to bring them in accordance with the literature.
This means that the `old' parameter $\alpha'$ was effectively replaced by
$\alpha = -\log\big(1-\exp(\alpha')\big)$; here $\alpha$ is the internal
effect parameter divided by 100. For the default $\alpha = \log(2)$
this means no difference.

Second, in the help page for \sfn{sienaGOF-auxiliary}, geodesic distances
were changed to non-directed. This makes more sense usually and was done to
avoid runtime errors that occurred very rarely.

Changes in RSiena and RSienaTest:
\begin{itemize}
\item New effects \texttt{cl.XWX}, \texttt{homXTransTrip},
    \texttt{homWXClosure}, and \texttt{sharedPop}.
 \item Effect \texttt{cycle4} extended to non-directed one-mode networks
    (for directed one-mode networks this is \texttt{sharedPop}).
 \item Effect \texttt{jumpXTransTrip} ported to non-directed networks.
 \item \texttt{gwesp..}  effects modified and ported to nondirected networks.
 \item Also take account of behavior user-specified interactions in
     \sfn{includeInteraction} and \sfn{setEffect}.
 \item Correction: Effect \texttt{to} is not a dyadic effect.
 \item Manual: added paragraph about how to import results from
     \sfn{xtable()} and \sfn{siena.table()} into MS-Word.
 \item \sfn{sienaGOF}: added the name of the \sfn{sienaFit} object
     as attribute \sfn{sienaFitName} to each of the \sfn{sienaGofTest} objects.
 \item Correction in \sfn{sparseNetworkExtraction()} to avoid errors occurring
     when the extracted network has no edges.
 \item In the help page for \sfn{sienaGOF-auxiliary}, geodesic distances
     changed to non-directed; which avoids a further error
     when the extracted network has no edges.
 \item Correction of an error in \sfn{print.siena} for data sets including
     other types than \texttt{oneMode}.
 \item Changed bandwidth selector for violin plots in \sfn{plot.sienaGOF} to ``nrd",
     to avoid long violins in cases where all simulations have the same outcome.
\end{itemize}

Changes in RSienaTest:
\begin{itemize}
\item Further work on \sfn{SienaBayes()}.
\end{itemize}

Changes in RSiena:
\begin{itemize}
  \item Ported effects \texttt{outRateLog} and \texttt{outTrunc2} from RSienaTest.
\end{itemize}

\item 2013-12-04 R-Forge Revision 250

Changes in RSiena and RSienaTest:
\begin{itemize}
\item New option \texttt{centered} in \sfn{coCovar()} and \sfn{varCovar()}.
\item \sfn{setEffect()}, \sfn{updateTheta()}, and \sfn{prevAns} in \sfn{siena07()}
     now also work properly for user-specified interactions.
\item Tests \sfn{Wald.RSiena} and \sfn{Multipar.RSiena} added.
\item Error occurrence with message about \texttt{cvalue} in
      \sfn{EvaluateTestStatistic()} corrected.
\item Divergent parameters in \sfn{siena07()} get \texttt{NA} for their rows and columns
     in the resulting covariance matrix.
\end{itemize}
The following changes in revision 244 were ported from RSienaTest to RSiena:
\begin{itemize}
\item In \sfn{siena08()}, also report Bonferroni combination
     of the two Fisher combinations.
\item In \sfn{siena07()}, rolled back change in truncation from version 1.1-227
     to the earlier procedure.
\item \sfn{descriptives.sienaGOF()} added.
\item Minor changes of output in \sfn{siena.table}, \sfn{print.siena},
    \sfn{siena07}, and in error message for \sfn{includeEffects}.
\item Change artificial results from 999 to NA in \sfn{siena07()}.
\item For ML estimation: added autocorrelations during phase 3
     to \sfn{print.summary.sienaFit}.
\end{itemize}

\item 2013-10-31 R-Forge Revision 246

Changes in RSiena and RSienaTest:
\begin{itemize}
   \item New behavior objective function effects \sfn{avSimAltX}, \sfn{totSimAltX} and
    \sfn{avAltAltX} to differentiate sources of peer influence in directed networks.
   \item Added effect class \sfn{covarBehaviorNetObjective} to \sfn{effectsDocumentation.R}.
   \item Fix of a bug that occurred in the case of on average decreasing behavior variables.
  \end{itemize}

\item 2013-16-09 R-Forge Revision 245

Changes in RSienaTest:
\begin{itemize}
   \item New structural rate effect \sfn{outRateLog}.
   \item Duplication of \sfn{outTrunc} effect: \sfn{outTrunc2}, allowing use
    with two different parameters.
   \item In \sfn{siena08()}, also report Bonferroni combination
     of the two Fisher combinations.
   \item In phase2 of \sfn{siena07()}, rolled back change in truncation
     from version 1.1-227 to the earlier procedure.
   \item Added function \sfn{descriptives.sienaGOF()} with numerical results
   of \sfn{plot.sienaGOF()}.
   \item Minor changes of output in \sfn{siena.table()} and various reports,
    and in error message for \sfn{includeEffects()}.
   \item  Change artificial (`missing') results of \sfn{siena07()} from 999
    to NA.
   \item Added autocorrelations during phase 3 to \sfn{print.summary.sienaFit}
   for ML estimation.
   \item Start of the manual reorganized and partially rewritten (with help from
     Zs\'{o}fia Boda and Andr\'{a}s V\"{o}r\"{o}s); instructions for
     \sfn{siena01Gui()} separated in siena01gui.pdf.
  \end{itemize}

\item 2013-10-09 R-Forge Revision 244

Changes in RSienaTest:

\begin{itemize}
\item Repair bug that prevented compilation for Mac.
\end{itemize}

\item 2013-09-17 R-forge revision 243

Changes in RSiena and RSienaTest:
  \begin{itemize}
   \item Correct bug in \sfn{EffectFactory} for \texttt{isolatePop} effect.
   \item Improved plotting of \sfn{sienaGOF} objects so that observed values
     outside of the range of simulated values don't run off the chart.
   \item Improve treatment of structural values in \sfn{sienaGOF}.
  \end{itemize}
Changes in RSiena:
  \begin{itemize}
   \item Add functions \sfn{AntiIsolateEffect.h} and \sfn{AntiIsolateEffect.cpp}
     which were forgotten to include in revision 242.
  \end{itemize}

\item 2013-08-27 R-forge revision 242

Changes in RSiena as well as RSienaTest:
  \begin{itemize}
  \item Correction to Dolby option for the case of more than 2 waves:
     in \sfn{phase1.r} and \sfn{phase3.r}, scores are added
     (instead of averaged) over waves.
     (Averaging was wrong, because in phase 2 they are added.)
  \item New effects: \texttt{anti isolates}, \texttt{anti in-isolates},
   and \texttt{anti in-near-isolates}.
  \item Effect \texttt{inIsolatePop} dropped (it was shortlived).
  \item Improved printing of results of \sfn{siena07()} in the case
    \sfn{simOnly}.
  \item Prettier response printed to console for \sfn{includeEffects()} and
        \sfn{setEffect()}.
  \item \sfn{z\$estMeans} added to sienaFit objects \sfn{z}:
     vector of estimated expected values of statistics;
	 this is \sfn{colMeans(z\$sf) + z\$targets}  but if dolby,
	 the regression on the scores is subtracted.
  \end{itemize}


\item 2013-08-23 R-forge revision 241

Changes in RSiena as well as RSienaTest:
  \begin{itemize}
  \item Corrected bug (leading to error message)
     that occurred if there was only one option
     for choice of alter. It appeared mainly in cases where all changes
     were upward only (or downward only); in practice, it only was observed
     yet for two-mode networks with upward changes only.
  \item  Drop the unintended multiplication of the target statistic
     for the \texttt{inPop} effect by $n$.
  \item Trapped some execution errors (mainly associated with inversion of
    singular matrices) and allowed the functions to end properly
    with a warning message.
  \item Added various degree-related effects to bipartite networks.
  \item New effect \texttt{inIsolatePop}.
  \end{itemize}

\item 2013-08-08 R-forge revision 240

Changes in RSienaTest:
  \begin{itemize}
  \item Added the parameter reduceg to siena07.
  \end{itemize}

Changes in RSiena and RSienaTest:
  \begin{itemize}
  \item Added effects crprod and inPopIntn for two-mode networks.
  \end{itemize}

\item 2013-06-18 R-forge revision 232

Changes in RSiena:
  \begin{itemize}
  \item The possibility to use the obsolete packages \sfn{snow} and
     \sfn{rlecuyer} for R versions older than 2.14.0 was dropped;
     their functionality was replaced by package \sfn{parallel}.
   \item The DESCRIPTION file was corrected to satisfy CRAN requirements.
  \end{itemize}

\item 2013-06-15 R-forge revision 231

Changes in RSiena as well as RSienaTest:
  \begin{itemize}
  \item
   Make the "cumulative" option operational in \sfn{BehaviorDistribution()}
   for \sfn{sienaGOF()}.
  \item
   Correct bug in treatment of missing values in  \sfn{sparseMatrixExtraction()}
   for  \sfn{sienaGOF()}.
  \item
    Allow sparse observed data matrices, and structural zeros and ones, in
      \sfn{sparseMatrixExtraction()} and  \sfn{networkExtraction()},
     and bipartite networks in  \sfn{networkExtraction()} for  \sfn{sienaGOF()}.
  \item
   Report correct centering (by overall means) of individual
     covariates for multi-group objects in  \sfn{print01Report()}.
  \item
   If there is a composition change object, MoM estimation is forced
     to be non-conditional. This is reported in the help file
     for  \sfn{sienaCompositionChange()}.
  \end{itemize}
\item 2013-05-10 R-forge revision 230

Changes in RSiena as well as RSienaTest:
  \begin{itemize}
   \item Check whether the maximum observed degree is not higher than
     \sfn{maxDegree}.
	\item Fix error in implementation of \sfn{maxDegree}.
	\item Fix bug in \sfn{print.siena} and extend \sfn{print.siena}.
	\item Make print method for class \sfn{sienaDependent}.
  \end{itemize}
\item 2013-04-19 R-forge revision 227

  Changes in RSiena as well as RSienaTest;
  both now are very similar; \sfn{sienaBayes}, \sfn{algorithms}, and
  \sfn{profileLikelihoods}
  are the only functions in RSienaTest not in RSiena.
  Available effects now are the same in both packages.

  Main changes visible to users:

For Siena only:
  \begin{itemize}
	\item function \sfn{bayes()} was removed (still under development in
        RSienaTest).
	\item Attributes \sfn{allowOnly} and \sfn{simOnly} ported from
        RSienaTest.
	\item Improved error messages in  \sfn{includeEffects} ported from
        RSienaTest.
	\item \sfn{sienaGOF()} ported from RSienaTest.
	\item \sfn{siena.table()} ported from RSienaTest.
  \end{itemize}

For RSienaTest only:
  \begin{itemize}
	\item \sfn{bayes()} renamed to \sfn{sienaBayes()} and considerably changed,
         with print option.
  \end{itemize}

For RSiena and RSienaTest:
  \begin{itemize}
	\item Changes to \sfn{sienaGOF}: new use structure with extraction functions
		\sfn{sparseMatrixExtraction}, \sfn{networkExtraction},
        \sfn{behaviorExtraction},
		allowing the testing of any dependent variable;
		commented out some superfluous lines.
	\item The function \sfn{sienaModelCreate()} is now called
        \sfn{sienaAlgorithmCreate()},
		but the earlier name is still retained as an alias;
		the class name of the object created by this function is now called
		\sfn{sienaAlgorithm}.
	\item The function \sfn{sienaNet()} is now called \sfn{sienaDependent()},
		but the earlier name is still retained as an alias;
		the class name of the object created by this function is now
		\sfn{sienaDependent}.
	\item The function \sfn{effectsDocumentation()} now has an extra argument
        \sfn{effects};
		if this points to an effects object, all available effects
		in this effects object are listed with \sfn{shortName},
		with a variety of other often used characteristics.
	\item Added effects (some existed already in \sfn{RSienaTest}):

		average exposure effect on rate xxxxxx, \sfn{avExposure}

		susceptibility to av. exp. by indegree effect on rate xxxxxx,
			\sfn{susceptAvIn}

		total exposure effect on rate xxxxxx, \sfn{totExposure},

		infection by indegree effect on rate xxxxxx, \sfn{infectIn},

		infection by outdegree effect on rate xxxxxx, \sfn{infectOut},

		susceptibility to av. exp. by zzzzzz effect on rate xxxxxx,
			\sfn{susceptAvCovar}

		infection by zzzzzz effect on rate xxxxxx, \sfn{infectCovar,}

		WW$=>$X cyclic closure of xxxxxx, \sfn{cyWWX}

		WW$=>$X shared incoming xxxxxx, \sfn{InWWX}

		WW$=>$X shared outgoing xxxxxx, \sfn{OutWWX}

		xxxxxx alter at distance 2 (\#), \sfn{altDist2}

		xxxxxx similarity at distance 2, \sfn{simDist2}

		transitive triplets xxxxxx similarity, \sfn{simXTransTrip}

		transitive triplets same xxxxxx, \sfn{sameXTransTrip}

		transitive triplets jumping xxxxxx, \sfn{jumpXTransTrip}

		transitive reciprocated triplets, \sfn{transRecTrip}

		GWESP I $->$ K $->$ J (\#), \sfn{gwespFF}

		GWESP I $<-$ K $<-$ J (\#), \sfn{gwespBB}

		GWESP I $<-$ K $->$ J (\#), \sfn{gwespFB}

		GWESP I $->$ K $<-$ J (\#), \sfn{gwespBF}

		GWESP I $<>$ K $<>$ J (\#), \sfn{gwespRR}

		isolate - popularity, \sfn{isolatePop}

		in-isolate Outdegree, \sfn{inIsDegree}

		network-isolate, \sfn{isolateNet}

		outdegree$\wedge$(1/\#) xxxxxx popularity, \sfn{outPopIntn}

		closure jumping yyyyyy, \sfn{jumpWWClosure}

		mixed xxxxxx closure jumping yyyyyy, \sfn{jumpWXClosure}

		cyclic closure of xxxxxx, \sfn{cyClosure}

		shared incoming xxxxxx, \sfn{sharedIn}
	\item Outdegree-popularity effect: multiplication by $n$ dropped.
	\item GWESP effects: default parameter changed from 25 to 69
		(corresponding to $\alpha = \log(2)$.) See earlier in this manual.
	\item Added to \sfn{siena07} (defined by \sfn{sienaAlgorithmCreate}):
		option \sfn{Dolby} for variance reduction.
		Correlations between scores and statistics are reported in output file;
		this is a measure for the amount of variance reduction.
	\item Added to \sfn{siena07}:
		option \sfn{diagonalize} for having more possibilities for
		tuning the algorithm
		(extent of diagonalization of matrix $D$ in Robbins-Monro update).
	\item \sfn{sienaTimeTest()} updated; now also contains effect-wise tests,
		groupwise tests (for group objects), automatic exclusion of
		collinear effects, and has prettier output and improved	summary.
	\item Overall maximum convergence ratio, \sfn{x\$tconv.max}
		(maximum value of $t$-ratio for convergence, for any linear combination)
		added to result of \sfn{siena07}.\\
        This is a very severe convergence criterion, and not meant as a default
        criterion to judge convergence in practical cases.
	\item The \sfn{print} method for objects of class \sfn{siena} (created by
        \sfn{sienaDataCreate})
		has been extended with printing \sfn{uponly} and \sfn{downly} attributes,
		if these are \texttt{TRUE}.
	\item A bug in the starting values for two-mode networks was corrected.
	\item Small bug fixed in \sfn{print01Report()} for reporting of \sfn{uponly}
        and \sfn{downonly},
		in the case where this does not affect all periods.
	\item Changed almost all \sfn{.Rd} documentation files: sometimes to make them
		better understandable or complete, sometimes to make more appropriate
		examples, sometimes only minor prettifications.
	\item Updated scripts:\\
		Rscript01DataFormat.R, Rscript02VariableFormat.R,
 	 	Rscript03SienaRunModel.R,\\
 	 	Rscript04SienaBehaviour.R.
		(of RSienaDescriptives only the date was changed.)
  \end{itemize}

\item 2012-12-24 R-forge revision 222
\begin{itemize}
\item Changed example on \sfn{sienaNet} help page to stop it masking data files
  in the package.
\item Example on \sfn{sienaGOF} page now runs. (RSienaTest only)
\item \sfn{profileLikelihood} (RSienaTest only) returns its object invisibly
  (i.e.\  it does not print when not assigned but can be assigned).
\end{itemize}
\item 2012-12-23 R-forge revision 221, RSiena and RSienaTest:

  changed version check to cope with R version 3.0.0.
\item 2012-07-05 R-forge revision 219, for RSienaTest only:
\begin{itemize}
  \item Further changes to bayes().
  \item Additional effects connected with triadic closure interacting with
    covariates.
  \item Some networks from Chris Baerveldt's data set added
        as data objects (N34* and HN34*).
\end{itemize}
\item 2012-06-11 R-forge revision 217, for RSienaTest only:
\begin{itemize}
  \item Preliminary updates to sienaGOF to put more power in the hands of the
  user.
  A user may now extract more than one dependent variable from the dataset.
\end{itemize}
\item 2012-06-07 R-forge revision 216, for RSienaTest only:
\begin{itemize}
  \item New effects connected with isolates; and with mixed WWX triadic closure
      (in various patterns) for dyadic covariates as well as multiple
      dependent networks.
  \item Modifications to bayes() (seems to run OK now, except that multiple
      groups option does not work for dyadic covariates;
      still not documented for general use).
\end{itemize}
\item 2012-05-18 R-forge revision 213, for RSienaTest only:
    \begin{itemize}
     \item Allow observed networks to have density 0 or 1
     (not that it is generally advisable to use such data sets).
     \item Incorporated argument simOnly in sienaModelCreate() to facilitate
	  simulation without estimation.
     \item Incorporated argument allowOnly in sienaNet() to permit
	  ignoring monotonicity in data and its consequences for upOnly and downOnly.
     \item Some new effects: interactions between reciprocity and
       transitivity.
    \end{itemize}
\item 2012-03-29 R-forge revision 211\\
Fixed bug in effectsDocumentation.
\item 2012-03-29 R-forge revision 210\\
Altered ML code in hope of fixing intermittent ML bug. Just might cause
different answers.
\item 2012-03-25 R-forge revision 208
\begin{itemize}
\item fix bug in bipartite network endowment
  and creation effect scores.
\item Rationalise behavior/network effects for symmetric
  networks in allEffects.csv, effects.r (partially).
\item Fix bug which caused crash creating starting values for sparse matrices
  with movements only in one direction.
\end{itemize}
\item 2012-03-16, 2012-03-21, R-forge revisions 206/207: new behavior rate
  effects.
\item 2012-03-07 R-forge revision 205
\begin{itemize}
\item Bug fix for effects AvSimEgoX, totSimEgoX, avAltEgoX with changing
  covariates.
\item Minor alterations to altDist2, simDist2 and the multi network
  versions.
\item Bug fix in probability in chain for symmetric networks type b models.
\end{itemize}
\item 2012-02-29 R-forge revision 204
\begin{itemize}
\item Fixed bugs in endowment and creation effect statistics for behavior
  Similarity effects.
\item Fixed bug causing occasional failure in bayes routine
\item Fixed bug causing occasional failure in maximum likelihood with
  constraints.
\item Added error message if try to use maximum likelihood with composition
  change.
\item Fixed bug in endowment and creation effect score calculation for symmetric
  network pairwise models.
\item File cluster.out is now removed before recreation.
\item Meta analysis summary now does not contain a list of NULLs at the end.
\item Minor changes to print and messages formats.
\end{itemize}
\item 2012-02-19 R-forge revision 203
\begin{itemize}
\item Fixed minor bug in ML initialisation: will alter results slightly.
\item New check for updated version when using multiple processes.
\item Amended code in manual for making sparse matrices.
\end{itemize}
\item 2012-02-07 R-forge revision 200
\begin{itemize}
\item Bug fix to scores for behavior variable rate effects.
\item Siena07 now stops if cannot get a derivative matrix in phase 1.
\end{itemize}
\item 2012-01-29 R-forge revision 198
Fix bug in initializing rate parameters for bipartite and behavior variables in
maximum likelihood. Will change results slightly.
\item 2012-01-29 R-forge revision 197
\begin{itemize}
\item Fix bug in effFrom with changing covariates. The targets depended on the
compiler.
\item Fix bug in creation effects in Maximum likelihood.
\end{itemize}
\item 2012-01-20 R-forge revision 195
\begin{itemize}
\item NaN's in covariates were causing problems: now treated as though NA
    in C++, as they always were in R.
\item New file ``arclistdata.dat'' added to examples directory
\item New maintainers address: rsiena@stats.ox.ac.uk
\item Print method for sienaFit objects now includes values of fixed parameters,
  rather than NA.
\end{itemize}
\item 2012-01-17 R-forge revision 194
\begin{itemize}
\item fix to prtOutMat to stop crash with null matrix
\item relaxed restrictions on behavior interactions in line with the manual
\item changes to validation of bipartite networks: should now be consistent
\end{itemize}
\item 2012-01-17 R-forge revision 192.
\begin{itemize}
\item minor but extensive changes to manual
\item minor changes to scripts
\end{itemize}
\item 2011-12-15 R-forge revision 191. Some of these may alter results slightly.
\begin{itemize}
\item Altered calculations of probabilities to avoid overflows
\item Fixed bug in storage of MII in bayes
\item Removed endowment effect for IndTies for symmetric networks.
\item Removed code for storing change contributions on ministeps: not
  functioning
\item Set random number type to "default" at start of siena07.
\end{itemize}
\item 2011-12-14 R-forge revision 190
Fixed bug in Bayes left over from R 189.
\item 2011-12-14 R-forge revision 189
 Fixed minor bugs in reports and error messages.
\item 2011-12-04 R-forge revision 186
Fixed some bugs in ML estimation procedure which will alter the results
slightly. Added algorithm functions to RSienaTest package.
\item 2011-11-27 R-forge revision 185
\begin{itemize}
\item Bayes and algorithm code now uses parallel package
\item Fixed memory leaks in ML estimation. Less space needed!
\item Other minor changes to ML with missing values (still incomplete)
\end{itemize}
\item 2011-11-14 R-forge revision 184:
Fix memory leaks in calculation of rate statistics.
\item 2011-11-11 R-forge revision 183:
\begin{itemize}
\item Fix bug stopping interruption in phases 1 and 3 (since recent change)
\item Check whether dfra from maxlike or not when using prevAns
\end{itemize}
\item 2011-11-11 R-forge revision 182:
\begin{itemize}
\item fix bug in ML/Bayes returning
  acceptances.
\item fix bug in sienaTimeFix with multi groups and differing actor set sizes
\end{itemize}
\item 2011-11-04 R-forge revision 181: reset random number type after using
  parallel package.
\item 2011-10-28 R-forge revision 179: fix bug in forking processes
\item 2011-10-27 R-forge revision 177/8:
\begin{itemize}
\item Change to covariance matrix for effects which have been fixed
\item Added new package for parallel running to be used from R 2.14.0. New
  option to use forking processes on non-Windows platforms.
\item Changes from revision 175 copied to RSiena
\item Updates to maximum likelihood estimation: NB this is still under
  development, and should not be used with missing data.
\item Added bayes, updateTheta functions to RSiena
\item sienaTimeTest for finite differences or ML now in RSiena
\item Space saving matrices used for derivatives in RSiena now, and optional by
  wave in ML.
\end{itemize}
\item 2011-10-14 R-forge revision 176 (RSienaTest only)
bug fix in diffusion effects, altered scripts in manual a little
\item 2011-10-06 R-forge revision 175
\begin{itemize}
\item Fix bug with multiple symmetric networks.
\item Limit constraints to be between both symmetric or non-symmetric networks
\item Added scripts to package (RSienaTest only)
\item siena07 called with batch=FALSE no longer crashes if called on mac or
linux with no X11 available. (RSienaTest only)
\end{itemize}
\item 2011-09-19 R-forge revision 172: (RSienaTest only) Diffusion rate effects.
\item 2011-09-07 R-forge revision 171
\begin{itemize}
\item Fix bug in siena08: crashed if underlying effects for interaction were not
  selected. (Or possibly with time dummies!).
\item Fix bug where print from siena08 was not produced if a previous display to
  the screen had occurred.
\item New parameter in siena08 to control number of iterations.
\item RSienaTest only: added validation to updateTheta
\end{itemize}
\item 2011-08-08 RSienaTest only R-forge revision 168/9
\begin{itemize}
\item More work on maximum likelihood.
\item When using finite difference derivative estimation or maxmimum likelihood
  estimation, return of derivatives by wave is optional, controlled by parameter
  byWave to siena07.
\item Format of derivatives by wave has altered: sienaTimeTest will be
  incompatible with older objects which used finite differences or maximum
  likelihood.
\item New function \sfn{updateTheta} to copy theta values from a fit to an
  effects object.
\item Time dummies in siena07 are created before the initial values are updated
  from any prevAns, so values may be copied to time dummies also.
\item Amended headings in print and summary for siena fit objects.
\item New function \sfn{bayes} is now fully available with a help page and no
  need to use RSiena::: when calling it.
\end{itemize}
\item 2011-08-03 R-forge revision 167
\begin{itemize}
\item Fix another display of manual in siena01Gui
\item Added network names to relevant behavior effects if there is more than one
  network.
\item Altered names of interaction effects to remove duplicate network names
\item Renamed avSimX, totSimX, avAltX to avSimEgoX, totSimEgoX, avAltEgoX
\item Trapped error caused by omitting Actors node set when specifying others.
\end{itemize}
\item 2011-07-27 R-forge revision 164:
\begin{itemize}
\item
Include quadratic shape effect by default unless range is less than 2.
\item
Shorten behavior interaction effectnames by removing the repeated variable name.
\item Fix bug when displaying manual from siena01Gui.
\end{itemize}
\item 2011-07-23 R-forge revision 163:
Fix bug in effectsDocumentation, reduce memory size needed for non-ML,
non-finite-difference models.
\item 2011-07-02 R-forge revision 161:
\begin{itemize}
\item Fix problem with bayes routine with single data object only.
\item Fix problems with getRSienaRDocumentation: internal functions within
internal functions  now work (but still not automatically)
and function now runs on non-Windows too.
\end{itemize}
\item 2011-06-24. R-forge revision 160: behavior endowment effects are now
  all defined consistently as current value less previous one, as in the manual.
\item 2011-06-22, 2011-06-23. R-forge revision 158/159: behavior
  interactions. Minor bug fixes to correct effects object and inclusion of
  non-requested underlying effects. Replace influence interaction effects by the
  three options. Time dummies for behavior effects.
\item 2011-06-18 R-forge revision 157: Fixed minor bug in siena07: code
  controlling maximum size of move was incorrect if using prevAns for an exactly
  equivalent fit.
\item 2011-06-13 R-forge revision 156: fixed bug removing density effect for
  bipartite networks with some only waves up or down only.
\item 2011-06-12 R-forge revision 155:
\begin{itemize}
\item Fixed bug with behavior variables with values 10 or 11: the 10th value in
  the matrix had 10 subtracted from it.
\item Fix for short name for egoXaltX effect for non-directed networks. Now
  matches the name for directed networks
\end{itemize}
\item 2011-06-04 R-forge revision 153:
\begin{itemize}
\item Maximum likelihood: this is still under development. Correction for
  bipartite networks and networks with constraints. Variable length of
  permutations will change results (slightly) compared with previous versions.
\item Creation effects: not yet complete.
\item Requested time dummies should now appear on the effects object print.
\item Bayesian routine (still very much under development) has altered.
\end{itemize}
\item 2011-05-27 R-forge revision 150: Removed effect for an absolutely constant
  covariate with two networks.
\item 2011-05-26 R-forge revision 148:
Improvements to sienaGOF, added script to manual.
\item 2011-05-16 R-forge revision 146:
\begin{itemize}
\item Documentation improvements
\item Can read (some) non-directed network from Pajek files
\end{itemize}
\item 2011-04-19 R-forge revision 144:
\begin{itemize}
\item New effects: out trunc effect
\item Enhancements to siena08
\end{itemize}
\item 2011-03-13 R-forge revision 142/3: GWESP effects (RSienaTest only)
\item 2011-02-24 R-forge revision 140: adds functionality to sienaGOF
  for plotting
  image matrices of the simulations, cumulative tests based on the Kolmogorov-
  Smirnov test statistic, and conforms to coding standards.
\item 2011-02-24 R-forge revision 139: fixes for bipartite networks with
  ML. ML is still incomplete, and will not work correctly with missing data or
  endowment effects.
\item 2011-02-22 R-forge revision 137: (RSienaTest only)
Additional work on the goodness of fit functionality (see ?sienaGOF)
\item 2011-02-21 R-forge revision 136:
\begin{itemize}
\item Fixed bug in bipartite network processing. Diagonal (up to number of
  senders) was being zeroed.
\item siena01Gui: corrected test for maximum degree in display.
\end{itemize}
\item 2011-02-05 R-forge revision 134:
\begin{itemize}
\item Enhanced features (and minor bug fixes) in siena08 report. (in revision
  133 in RSienaTest)
\item Bug fix in iwlsm
\item sienaDataCreateFromSession, sienaTimeTest: improved error messages.
\item ML support for bipartite networks (still work in progress,
  particularly for missing data)
\end{itemize}
\item 2011-01-17 R-forge revision 131/2: (RSienaTest only)
New goodness of fit functions: work in progress.
\item 2011-01-16 R-forge revision 130:
\begin{itemize}
\item Fix bug for bipartite networks which usually crashed, but could have given
  incorrect answers.
\item Fix bug with multiple processes and sienaTimeTest.
\item Default value of siena07 argument initC is now \texttt{TRUE}.
\end{itemize}
\item 2011-01-08  R-forge revision 129:
\begin{itemize}
\item fix to sienaTimeFix for time dummies on
  covariate effects etc.
\item Suppressed warning message when loading snow package.
\end{itemize}
\item 2010-12-02 R-forge revision 128:
\begin{itemize}
\item Corrections to scores for symmetric pairwise models
\item ML now runs with missing data. Not yet sure it is correct!
\item New multiple network effects: To, altDist2W, simDist2W.
\item Can now use setEffects to update basic rate initial values
\item multiplication factor for ML now a parameter in sienaModelCreate.
\item Fixed bug meaning that covariate multiple network effects did not appear
  if the covariates was a behavior variable.
\item Can now run sienaTimeTest on fits from finite differences and maximum
  likelihood.
\item User defined interactions (and time dummies) can be expanded
  when printing
  the effects object, use parameter \texttt{expandDummies=TRUE}.
\end{itemize}
\item 2010-11-25 R-forge revision 126:
\begin{itemize}
\item Changed version of RSiena to be 1.0.12 and copied all new features which
  were only in RSienaTest to RSiena. RSiena and RSienaTest are
  functionally the same at this time.
\item New version of sienaTimeTest and sienaTimeFix.
\item Bayesian routine (experimental) can be used with multiple dependent
  variables.
\end{itemize}
\item 2010-11-05 R-forge revision 125:
\begin{itemize}
\item Corrected bug in report from siena07 about detailing network types.
\item Networks appear in data object before behavior variables regardless of
order of submission to sienaDataCreate
\item RSienaTest only: new effect: in structural equivalence
\item RSienaTest only: new models for symmetric networks
\item bug fixed to sienaTimeTest: non included underlying effects for user
  defined interactions, multiple dependent networks and multiple groups.
\end{itemize}
\item 2010-10-22 R-forge revision 124:
\begin{itemize}
\item Fixed bug in sienaTimeTest when only one effect
\item Removed standalone siena01Gui. Still available within \Rn.
\end{itemize}
\item 2010-10-09 R-forge revision 122:
\begin{itemize}
\item Distance two effects: added parameter
\item Bug in calculation of starting values for behavior variables.
(RSiena only)
\end{itemize}
\item 2010-09-20 R-forge revision 120: Bug fixes:
\begin{itemize}
\item Multiple groups with 2 dyadic covariates had incorrect names
\item Multiple processes failed (RSiena only)
\item Minor print format corrections
\item Bug in calculation of starting values for behavior variables.
(RSienaTest only)
\end{itemize}
\item 2010-08-20 R-forge revision 117: RSienaTest only. Documentation updates,
algorithms may work again!
\item 2010-08-20 R-forge revision 116: forgotten
part of change for print of sienaFit (RSiena only)
\item 2010-08-20 R-forge revision 115: fixed bug in siena08 p-values on report,
and minor corrections to layout of print of sienaFit.
\item 2010-07-19 R-forge revision 114: fix a bug in initial report: names of
  multiple behavior variables were incorrect.
\item 2010-07-10 R-forge revision 113: fix bugs
\begin{enumerate}
\item endowment effect unless using finite differences failed
\item could not return bipartite simulations
\end{enumerate}
\item 2010-07-04 R-forge revision 112: fix bug in groups with constant dyadic
  covariates and only 2 waves. (Introduced in revision 109).
\item 2010-07-03 R-forge revision 111: bipartite networks now have a no-change
  option at each ministep of simulation.
\item 2010-06-25 R-forge revision 110: updated manual pages for dyadic
  covariates.
\item 2010-06-25 R-forge revision 109:
\begin{itemize}
\item Dyadic covariates may have missing values and sparse input format.
\item Removed some inappropriate dyadic covariate effects for bipartite
  networks.
\item Score test output now available via summary() on a fit.
\item Corrected conditional estimation for symmetric networks.
\item Now do not need to specify the variable to condition on if it is the first
  in \sfn{sienaModelCreate()}
\end{itemize}
\item 2010-06-21 R-forge revision 108:
\begin{itemize}
\item effects print method with no lines selected no longer gives error, new
  argument includeOnly so you can print lines which are not currently included.
\item effectsDocumentation was failing due to timeDummy column
\item New average alter effects
\item Corrected format of error message if unlikely to finish epoch/
\item Corrected print report for multiple groups via the GUI, and for 8 waves.
\item Fixed names for used defined dyadic interactions.
\item Fixed bug where SienaTimeTest dummies with RateX would not work with
  changing covariates.
\end{itemize}
\item 2010-06-21 R-forge revision 107: RsienaTest only: reinstated
includeTimeDummy.
\item 2010-06-18 R-forge revision 106: new version numbers:
  1.0.11.105 and 1.0.12.105 for RSiena and RSienaTest respectively.
\item 2010-06-18 R-forge revision 105: Fixed siena01Gui bug when trying to edit
  the effects. Problem was introduced in revision 81.
\item 2010-06-10 Updated time heterogeneity script for Tom
\item 2010-06-08 R-forge revision 102: RSienaTest only. Removed
includeTimeDummy.
\item 2010-06-08 R-forge revision 101: RSienaTest only. Fixed RateX so that it
  works with changing actor covariates as well.
\item 2010-06-08 R-forge revision 100: corrected revision numbers in \sfn{ChangeLog}.
\item 2010-06-08 R-forge revision 99
Fix to bug introduced in revision 98: bipartite networks could not have 'loops'
\item 2010-06-08 R-forge revision 98
\begin{itemize}
\item Fix to bug in constant dyadic covariates with missing values.
\item Changes to treament of bipartite networks. The processing of these is
  still under development: we need to add the possibility of 'no change' to the
  ministeps. Code to deal with composition change has been added, and the
  treatment of missing values in sparse matrix format networks has been
  corrected further (the change in revision 96 was not quite correct).
\end{itemize}
\item 2010-06-04 R-forge revision 97 RSiena includeTimeDummy not exported so not
  available to the user.
\item 2010-06-04 R-forge revision 96 RSiena
\begin{itemize}
\item bug fixes as in revisions 92, 93.
\item Changes and bug fixes to sienaTimeTest etc.\ as in revisions 85--89,
\item \sfn{includeInteractions} now will unInclude too.
\end{itemize}
\item 2010-06-04 R-forge revision 93 (RSienaTest only)
\begin{itemize}\item New algorithms function
  (not in package: in the examples directory).
\item Progress on maximum likelihood code.
\item Bug fixes: print empty effects object, misaligned print.sienaFits, crash
  in print.sienaEffects with included interactions.
\item silent parameter now supresses more.
\item Added time dummy field to \sfn{setEffects} and removed from
\sfn{includeEffects}.
\item \sfn{includeInteractions} now will unInclude too.
\item \sfn{includeTimeDummy} now sets or unsets the include flag, and prints the
  changed lines.
\item Using composition change with bipartite networks will give an error
  message -- until this is corrected.
\item Separate help files for sienaTimeTest, plot.sienaTimeTest,
  includeTimeDummy.
\item Bug fix to treatment of missing data in sparse format bipartite networks.
\item Change to error message if an epoch is unlikely to terminate.
\end{itemize}
\item 2010-06-04 R-forge revision 92 (RSienaTest only) New average alter
  effects. Bug fix to effects object for more than two groups.
\item 2010-05-29 R-forge revision 89 (RSienaTest only)
New option to control orthogonalization in sienaTimeTest, changes to
includeEffects and sienaDataCreate (NB changes reverted in revision 93).
\item 2010-05-28 R-forge revision 88 (RSienaTest only)
Time dummies for RateX effects
\item 2010-05-27 R-forge revision 87 (RSienaTest only)
bug fix to plot.sienaTimeTest
\item 2010-05-23 R-forge revision 86 (RSienaTest only)
Bug fix to plot.sienaTimeTest, new function includeTimeDummy
\item 2010-05-22 R-forge revision 85 (RsienaTest only) fixed bug in
  sienaTimeTest with unconditional simulation.
\item 2010-04-24 R-forge revision 81
New print, summary and edit methods for Siena effects objects
\item 2010-04-24 R-forge revision 80
\begin{itemize}
\item fixed bug causing crash with rate effects and bipartite networks.
\item added trap to stop conditional estimation hanging
\item new functions (INCOMPLETE) for maximum likelihood and Bayesian estimation
  (one period (two waves) only, no missing data, one dependent variable only for
  Bayesian model).
\end{itemize}

\item 2010-04-13 R-forge revision 79 new function: sienaTimeTest.
\item 2010-04-12 R-forge revision 78 fix minor bugs in reports, allow character
  input to effect utility functions, include effect1-3 etc on display of
  included effects in siena01Gui().
\item 2010-04-12 R-forge revision 77 (RSiena only) As for RSienaTest revision 76
\begin{itemize}
\item Report of 0 missings corrected
\item display of effect1-effect3 in siena01Gui
\item allow entry of character strings or not in includeEffects etc.
\end{itemize}
\item 2010-04-12 R-forge revision 76 (RSienaTest only) Various bug fixes
\begin{itemize}
\item Memory problems when calculating derivatives with many iterations and
  parameters.
\item Occasional effects not being included correctly due to trailing blanks
\item Some minor details of reports corrected.
\end{itemize}
\item 2010-03-31 R-forge revision 75 fixed bug with dyadic covariates and
  bipartite networks.
\item 2010-03-27 R-forge revision 71 (RSienaTest only)
\begin{itemize}
\item Fixes as for RSiena in revision 68/69/70 for RSiena
\item New version number 1.0.12
\end{itemize}
\item 2010-03-27 R-forge revision 70 (RSiena only)
\begin{itemize}
\item Fix to crash at end of phase 3 with multiple processes and
conditional estimation
\item Correct carry forward/backward/use mode for behavior variables
\item Fix bug causing crash in Finite Differences with only one effect
\end{itemize}
\item 2010-03-24 R-forge revision 69 (RSiena only)
\begin{itemize}
\item New features and bug fixes as for revision 63 in RSienaTest.
\item 4-cycles effect has new shortName: cycle4.
\item some percentages on reports were proportions not percentages
\item Sped up treatment of missing values in sparse format networks.
\item Fix: now allows more than one value to indicate missing in covariates.
\end{itemize}
\item 2010-03-12 R-forge revision 68 new version number for RSiena.\\
In \sfn{siena01Gui}, allow waves for SienaNet inputs to be numbered
arbitrarily, rather than insisting on 1-n. Change simply allows this, the actual
wave numbers are not yet used on reports etc.
\item 2010-03-17 R-forge revision 66
Corrected processing of user-specified interaction effects with multiple
processes. This had originally worked but failed when one no longer had to
include the underlying effects.
\item 2010-03-16 R-forge revision 64
covarBipartite ego effect had been given type dyadic rather than ego.
\item 2010-03-16 R-forge revision 63 (RSienaTest only)
\begin{itemize}
\item new functions \sfn{siena08} and \sfn{iwlsm}, for meta analysis
\item can now use different processes for each wave. Not recommended: usually
  slower than by iteration, but will be useful with ML routines when they are
  completed.
\item No longer crashes with missing dyadic covariates.
\end{itemize}
\item 2010-02-27 R-forge revision 61 (RSiena only) bug fix: random numbers used
  with multiple processes were the same in each run. Now seed is generated
  from the usual \R random number seed. Also fixed a display bug if running
  phase 3 with few iterations.
\item 2010-02-16 R-forge revision 60 (RSienaTest only) added average indegrees
  to reports. Also constraints.
\item 2010-02-12 R-forge revision 59 (RSienaTest only) Fix to bugs in printing
  version numbers and in using multiple processes (would revert to RSiena
  package.) Added a skeleton MCMC routine.
\item 2010-02-11 R-forge revision 57 Fix to bug in siena01Gui where in
  conditional estimation, the
  estimated values were not remembered for the next run.
\item 2010-02-11 R-forge revision 56 (RSiena only)
Multiple network effects, constraints between networks.
\item 2010-02-11 R-forge revision 55 (RSienaTest only)
New silent option for siena07.
\item 2010-02-11 R-forge revision 54 (RSienaTest only)
Fix to covariate behavior effect bug.
\item 2010-02-11 R-forge revision 53
Fixed bug in siena01 GUI which ignored changes to all effeccts
\item 2010-02-07 R-forge revision 52 (RSiena only)
New silent option for siena07.
\item 2010-02-04 R-forge revision 51 (RSiena only)
\begin{itemize}
\item
Fix to covariate behavior effect bug.
\item
Fix to default effects with multiple networks.
\end{itemize}
\item 2010-02-01 R-forge revision 49 (RSienaTest) only
Fixes to bugs in constraints.
\item 2010-01-28 R-forge revision 48
Fix to bug in sorting effects for multiple dependent variables.
\item 2010-01-26 R-forge revision 47 (RSienaTest only)
\begin{itemize}
\item New version: 1.0.10
\item Multiple networks
\item Constraints of higher, disjoint, atLeastOne between pairs of networks.
\end{itemize}
\item 2010-01-19 R-forge revision 45 (RSiena), 46 (RSienaTest)\\
 New documentation for the effects object.
\item 2010-01-18 R-forge revision 43 (RSiena)
\begin{itemize}
\item new behavior effects
\item user specified interactions
\item new utilities to update the effects object
\end{itemize}
\item 2010-01-15 R-forge revision 41 (RSienaTest only)

\begin{itemize}
\item
   new effect: Popularity Alter, and altered effect1-3 to integers to correct
  bug in fix(myeff)
  \item new utility functions to update effects object
  \item no longer
  necessary to include underlying effects for interactions.
  \item user parameter for number of unspecified behavior interactions
  \item  remove extra sqrt roots in standard error of rates for conditional
  estimation (see revision 31)
\end{itemize}
\item 2010-01-15 R-forge revision 40: RSiena only

  remove extra sqrt roots in standard error of rates for conditional
  estimation (see revision 32)


\item 2010-01-02 R-forge revision 34

  Corrected layout of \sfn{print} and \sfn{xtable} for \sfn{SienaFit} objects
  with both behavior and network variables.

\item 2010-01-01 R-forge revision 33

Updated change log and manual in RSiena and \sfn{ChangeLog} in RSienaTest.

\item 2010-01-01 R-forge revision 32
    print07report.r: corrected standard errors for rate estimate for
    conditional estimation: needed square roots. RSiena

\item 2009-12-31 R-forge revision 31
\begin{itemize}
\item
    print07report.r: corrected standard errors for rate estimate for
    conditional estimation: needed square roots. RSienaTest only

\item more behavior effects in RSienaTest.
\end{itemize}

\item 2009-12-17 R-forge revision 30

Fixed bug in dyadic interactions in RSienaTest

\item 2009-12-17 R-forge revision 29

Fixed bug in 3-way interactions in RSienaTest

\item 2009-12-14 R-forge revision 28

 Fixed bug in use of multiple processes for RSiena.

\item 2009-12-14 R-forge revision 27

Fixed bug in use of multiple processes for
  RSienaTest.

\item 2009-12-01 R-forge revision 26

Created RSienaTest which includes user
  specified interactions.

\item 2009-11-20 R-forge revision 25

  \begin{itemize}
  \item  version number 1.0.8
  \item The default method for estimation is conditional if there is only one
    dependent variable.
  \item Movement of behavior variable restricted if all observed changes are in
    one direction. In this case, linear change effects removed.
  \item If all observed changes in a network are in one direction, density
    effects are removed.
  \item If a behavior variable only takes two values the quadratic effects
    are not selected by default.
  \item t-statistics appear on print of \sfn{sienaFit} object.
  \item easier to use \sfn{xtable} method
  \item warning if behavior variables are not integers
  \item Fixed bug in editing all effects in the GUI.
  \item Fixed a bug in effect creation for changing dyadic covariates
  \item Fixed a bug in returning simulated dependent variables
  \item Now fails if there are only two waves but you have a changing
    covariate. In the GUI, can just change the type.
  \end{itemize}

\item 2009-11-08 R-forge revision 24

  \begin{itemize}
  \item
    version Number 1.0.7
  \end{itemize}
\item  2009-11-08 R-forge revision 23

  \begin{itemize}
  \item corrected bug in creation of effects data frame for multi
    group projects and for changing covariates
  \item added effect numbers to the Estimation screen
  \end{itemize}
\item 2009-11-08 R-forge revision 22
  \begin{itemize}
  \item  new option to edit effects for one dependent variable at a time. Model
    options screen layout altered slightly.
  \end{itemize}
\item 2009-11-08 R-forge revision 21
  \begin{itemize}
  \item Fixed a bug causing crashes (but not on Windows!) due to bad calculation
    of derivative matrix.
  \end{itemize}
\item 2009-10-31 R-forge revision 17
\begin{itemize}
\item version Number 1.0.6
    \item xtable method to create \LaTeX tables from the estimation results
      object.
    \item added support for bipartite networks
    \item structural zeros and 1's processing checked and amended
   \item  use more sophisticated random number generator unless parallel
     testing with siena3.
   \end{itemize}
 \end{itemize}
 \end{small}

\newpage
\bibliographystyle{apalike}
%\bibliographystyle{plain}
\bibliography{RSiena}
\end{document}
