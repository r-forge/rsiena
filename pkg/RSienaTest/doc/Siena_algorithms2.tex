\documentclass[a4paper,12pt,fleqn]{article}
% The parameter in [..] can be beamer or handout
% Based on file
% $Header: /cvsroot/latex-beamer/latex-beamer/solutions/generic-talks/generic-ornate-15min-45min.en.tex,v 1.4 2004/10/07 20:53:08 tantau Exp $
% This file is a solution template for:
% - Giving a talk on some subject.
% - The talk is between 15min and 45min long.
% - Style is ornate.
% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.

% When replacing figures, put a % at the end of the line
% to prevent a linebreak being read!



\usepackage[dvipsnames]{xcolor}
\usepackage{pgf}
\usepackage{tikz}
%\usepackage{pgflibraryarrows}
%\usepackage{colortbl}
\usepackage{enumitem}

% For handouts; see pgfmanual
%\usepackage{pgfpages}
%\pgfpagesuselayout{2 on 1}[border shrink=5mm]


\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.
\usepackage{amsmath}
\usepackage{amssymb}


\newcommand{\Reals}{\mbox{I}\hspace{-.07ex}\mbox{R}}
\newcommand{\E}{\mbox{E}}
\renewcommand{\P}{\mbox{P}}
\newcommand{\se}{\mbox{s.e. }}
\newcommand{\var}{\mbox{var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\logit}{\mbox{logit}}
\newcommand{\uh}{\underline{h}}
\newcommand{\tuh}{\tilde{\uh}}
\newcommand{\neqsum}[3]
{\, \sum_{\stackrel{\scriptstyle #1 = 1}{\scriptstyle #2 \neq #3}}^g
\,}

\newcommand{\equat}[1]{$#1$}
\newcounter{savenumi}
\newcounter{savenumi2}
\newcounter{savenumi3}
\newcounter{savenumi4}





% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command:

%\beamerdefaultoverlayspecification{<+->}
\renewcommand{\baselinestretch}{1.1}
\newcommand{\cc}{\color[named]{SeaGreen}}
\newcommand{\itc}{\color[rgb]{0.1,0.6,0.3}}  % itemcolor
\newcommand{\siec}{\color[named]{Sienna}} % Siena color (RawSiena dvipsnames)
\newcommand{\emec}{\color[rgb]{0.3,0.1,0.0}}  %  \color[named]{Emerald}}


\newcommand{\cdiamond}{{\color[named]{MidnightBlue}\diamond}}
\newcommand{\cbullet}{{\color[named]{MidnightBlue}$\bullet$}}
\newcommand{\cques}{{\color[named]{MidnightBlue}?`}}
\newcommand{\rast}{{\color[named]{Red}$\ast$}}
\newcommand{\gast}{{\color[named]{Green}$\ast$}}

\newcommand{\rtar}{{\itc $\Rightarrow$}}
\newcommand{\qques}{\raisebox{1.2ex}{\rotatebox{180}
                    {\color[named]{ForestGreen}\bf\large ?}}}
\newcommand{\excl}{{\color[named]{ForestGreen}\bf\large !}}
% or OliveGreen
\newcommand{\ttimes}{\,\times\,}

\setlength{\parskip}{1.5ex plus0.5ex minus0.5ex}
\setlength{\parindent}{0ex}
\hyphenpenalty=8000
%\tolerance=1000

\title{Siena algorithms}

\author{Tom A.B.\ Snijders }




\newcommand{\sn}{{\scriptstyle N}}
\renewcommand{\sb}{{\scriptstyle B}}
\newcommand{\extraver}{{$\phantom{\Big(}$}}
\newcommand{\extraverr}{{$\phantom{\big(}$}}

\renewcommand{\th}[1]{$\theta_{#1}$}
\newcommand{\ga}[1]{$\gamma_{#1}$}
\newcommand{\be}[1]{$\beta_{#1}$}
\newcommand{\maxr}{\textit{maxbeh}_r}


\newcommand{\vit}{\theenumi}

\newcommand{\mcc}[2]{\multicolumn{#1}{c}{#2}}
\newcommand{\mcp}[2]{\multicolumn{#1}{c|}{#2}}

\newcommand{\equa}[1]{\[#1\]}

\newcommand{\separationb}{\\[0.5ex]\hline\rule{0pt}{2ex}}
\newcommand{\separationg}{\\[0.5ex]\arrayrulecolor{grey}\hline\arrayrulecolor{black}
                         \rule{0pt}{2ex}}

\newcommand{\nm}[1]{\textsf{\small #1}}
\newcommand{\nnm}[1]{\textsf{\small\textit{#1}}}
\newcommand{\nmm}[1]{\nnm{#1}}
\newcommand{\R}{{\sf R }}
\newcommand{\Rn}{{\sf R}}
\newcommand{\ms}{\textsl{\textsf{\small ms}}} % ministep


%\newcommand{\adda}[1]{{\textcolor[named]{Red}{#1}}}  % additions
%\newcommand{\addc}[1]{{\textcolor[named]{MidnightBlue}{#1}}}  % clarifications
\newcommand{\adda}[1]{{\textcolor[named]{Black}{#1}}}  % additions
\newcommand{\addc}[1]{{\textcolor[named]{Black}{#1}}}  % clarifications
\newcommand{\addaa}[1]{{\textcolor[named]{Black}{#1}}}  % additions
\newcommand{\addca}[1]{{\textcolor[named]{Black}{#1}}}  % clarifications
\newcommand{\addab}[1]{{\textcolor[named]{Black}{#1}}}  % additions
\newcommand{\addcb}[1]{{\textcolor[named]{Black}{#1}}}  % clarifications
\newcommand{\addcc}[1]{{\textcolor[named]{Red}{#1  10/03/2010.}}}

\hyphenation{mini-step mini-steps reci-pro-city}
\setlength{\parskip}{1.5ex plus0.5ex minus0.5ex}
\setlength{\parindent}{0ex}

\begin{document}

\maketitle

This paper gives a sketch of the main algorithms used in RSiena.
It is meant as background material for understanding the code of
RSiena. It is intended to be included later on as part of the
programmer's manual of RSiena.


\addaa{Further added content is in  red (except for the end, which is totally new).}

\addca{Further added clarifications are in blue.}

\section{Notation}

\adda{Logarithms (denoted $\log$) are natural logarithms.}

Symbols given \nnm{in italic sf font} refer to the names
of variables used in the \R code.

\emph{Generic symbols for variables}

There are $R_N$ networks and $R_B$ behavior variables.\\
We require $R_N + R_B \geq 1$; if the current structure of RSiena
requires this, then we require $R_N \geq 1$ (but if it is easy to
work with $R_N = 0, R_B \geq 1$ then it would be nice to permit this.)
\begin{tabbing}
$i, j$ \hspace*{1em} \=  \hspace*{6em} \=  actors.\\[1ex]
$m$ \> \> index for time period from $t_{m-1}$ to $t_m$ ($m = 2, \ldots, M$).  \\[1ex]
$M$ \> \nnm{observations}   \> total number of observations\\[1ex]
$x$ \> \> all $R_N$ networks jointly (one outcome).\\[1ex]
$z$ \> \> all $R_B$ behaviors jointly (one outcome).\\[1ex]
$y$ \> \> state: all networks and behaviors jointly (one outcome).\\[1ex]
$W$ \> \> variable with values $N$ or $B$, indicating \\
    \> \> whether something refers to network or behavior.\\[1ex]
$r$ \> \> index number of networks or behaviors,\\
    \> \> ranging from 1 to $R_W$ .\\[1ex]
missing \> \> missingness indicators \\
        \> \>  for ordered triples $(i,j,r)$ referring to networks $r$ \\
        \> \> and for ordered pairs $(i,r)$ referring to behaviors;\\
        \> \> values are F (\nnm{False}) and T (\nnm{True});\\
        \> \> if T, then further specifications are Start / End / Both,\\
        \> \> referring to the observation period from $t_{m-1}$ to $t_m$ .\\[1ex]
$\maxr$ \> \> maximum of the range of the $r'^{\text{th}}$ behavior variable.\\[1ex]
$^N$ \> \> as superscript: refers to network dynamics.\\[1ex]
$^B$ \> \> as superscript: refers to behavior dynamics.\\[1ex]
\end{tabbing}
\medskip

\emph{Changing variables (outcomes)}

\begin{tabbing}
$^{\rm{obs}}$ \hspace*{1em} \=  \hspace*{6em} \= as superscript: refers to observed values.\\[1ex]
$\theta$ \> \nnm{theta} \> vector of all statistical parameters. \\[1ex]
$p$  \>  \nnm{pp}  \> dimension of $\theta$.\\[1ex]
$J$ \> \>  simulated data score function (vector of partial derivatives of log-likelihood) \\
     \>  \>    ($p$-vector).\\[1ex]
$t$ \hspace*{3em} \> \> time.\\[1ex]
$N^{(r)}_{ij}$ \> \> dummy tie variable indicating $ i \stackrel{r}{\rightarrow} j $ for $r^{\text{th}}$ network.\\[1ex]
$B^{(r)}_{i}$ \> \> behavior variable for $r^{\text{th}}$ behavior for actor $i$.
\end{tabbing}
\medskip

Replacing an index by + denotes summation over this index.\\
Toggling a number $a$ in $\{0, 1\}$ means replacing $a$ by $1-a$.
\medskip

\iffalse
earlier:
\begin{tabbing}
$i, j$ \hspace*{1em} \=  \hspace*{6em} \=  actors.\\[1ex]
$m$ \> \> index for time period from $t_{m-1}$ to $t_m$ ($m = 2, \ldots, M$).  \\[1ex]
$M$ \> \nnm{observations}   \> total number of observations\\[1ex]
$x$ \> \> all networks jointly.\\[1ex]
$z$ \> \> all behaviors jointly.\\[1ex]
$r$ \> \> index number of networks or behaviors.\\[1ex]
$^N$ \> \> as superscript: refers to network dynamics.\\[1ex]
$^B$ \> \> as superscript: refers to behavior dynamics.\\[1ex]
$^{\rm{obs}}$ \> \> as superscript: refers to observed values.\\[1ex]
$W$ \> \> variable with values $N$ or $B$.\\[1ex]
$\theta$ \> \nnm{theta} \> vector of all statistical parameters. \\[1ex]
$p$  \>  \nnm{pp}  \> dimension of $\theta$.\\[1ex]
$J$ \> \>  simulated data score function (vector of partial derivatives of log-likelihood) \\
     \>  \>    ($p$-vector).\\[1ex]
\end{tabbing}
\medskip


\emph{Changing variables (outcomes)}

\begin{tabbing}
$t$ \hspace*{3em} \= time.\\[1ex]
$N^{(r)}_{ij}$ \> dummy tie variable indicating $ i \stackrel{r}{\rightarrow} j $ for $r^{\text{th}}$ network.\\[1ex]
$B^{(r)}_{i}$ \> behavior variable for $r^{\text{th}}$ behavior for actor $i$.
\end{tabbing}
\medskip

Replacing an index by + denotes summation over this index.\\
Toggling a number $a$ in $\{0, 1\}$ means replacing $a$ by $1-a$.
\medskip
\fi

\emph{Functions}

\begin{tabbing}
$\lambda^N(r,i,x,z)$ \hspace*{3em} \= rate function, network $r$.\\
                                  \> (0 for inactive actors)\\[1ex]
$\lambda^B(r,i,x,z)$ \hspace*{3em} \> rate function, behavior $r$.\\
                                  \> (0 for inactive actors)\\[1ex]
$f^N(r,i,x,z)$ \hspace*{3em} \> evaluation function function, network $r$.\\[1ex]
$f^B(r,i,x,z)$ \hspace*{3em} \> evaluation function, behavior $r$.\\[1ex]
$g^N(r,i,j,x,z)$ \hspace*{3em} \> endowment function function, network $r$.\\[1ex]
$g^B(r,i,x,z)$ \hspace*{3em} \> endowment function, behavior $r$.\\[1ex]
$\Delta f^N(r,i,j,x,z)$ \hspace*{3em} \> change in $f^N(r,i,x,z)$
                                by toggling $N^{(r)}_{ij}$.\\[1ex]
$\Delta f^B(r,i,v,x,z)$ \hspace*{3em} \> change in $f^B(r,i,x,z)$
                                by changing $B^{(r)}_i$ to $B^{(r)}_i + v$.\\[1ex]
$ \sim E(\lambda)$ \> generate random variable according to exponential distribution\\
                   \> with parameter $\lambda$ (note: expected value $1/\lambda$).\\[1em]
\end{tabbing}
%\medskip

\iffalse
earlier
\begin{tabbing}
$\lambda^N(r,i,x,z)$ \hspace*{3em} \= rate function, network $r$.\\
                                  \> (0 for inactive actors)\\[1ex]
$\lambda^B(r,i,x,z)$ \hspace*{3em} \> rate function, behavior $r$.\\
                                  \> (0 for inactive actors)\\[1ex]
$f^N(r,i,x,z)$ \hspace*{3em} \> evaluation function function, network $r$.\\[1ex]
$f^B(r,i,x,z)$ \hspace*{3em} \> evaluation function, behavior $r$.\\[1ex]
$g^N(r,i,j,x,z)$ \hspace*{3em} \> endowment function function, network $r$.\\[1ex]
$g^B(r,i,x,z)$ \hspace*{3em} \> endowment function, behavior $r$.\\[1ex]
$\Delta f^N(r,i,j,x,z)$ \hspace*{3em} \> change in $f^N(r,i,x,z)$
                                by toggling $N^{(r)}_{ij}$.\\[1ex]
$\Delta f^B(r,i,v,x,z)$ \hspace*{3em} \> change in $f^B(r,i,x,z)$
                                by changing $B^{(r)}_i$ to $B^{(r)}_i + v$.\\[1ex]
$ \sim E(\lambda)$ \> generate random variable according to exponential distribution\\
                   \> with parameter $\lambda$ (note: expected value $1/\lambda$).\\[1em]
\end{tabbing}
\fi

Note. Whether the endowment function makes sense for behavior variables with a range
of more than two values, is doubted. But we keep it included anyway, for the moment.
\medskip

The \R convention is followed of denoting an assignment statement by $a \leftarrow b$,
meaning that the variable $a$ gets the value $b$.


\section{Outline of model dynamics / simulation algorithm}
\label{S_sim}

The tie-based model is defined as a continuous-time Markov chain by the following
algorithm for generating the next change in the outcome.
This is formulated here for the case that the state space includes networks as well as behavior.
If there are no behavior variables $B$, then the steps referring to these variables
can simply be dropped.
In the code this is function \nm{simstats0c}.

To estimate derivatives of expected values of statistics with respect to the
parameters, the score function method (Schweinberger
and Snijders, 2007) is used in the default method to estimate standard errors.
This is indicated by `SF only' and
can be skipped if the
finite differences (`FD') option, which also employs common random numbers,
is used to estimate standard errors.

For each network variable numbered $r$ the following logical (boolean)
variables are defined at the moment of data entry:
\begin{itemize}
\item \nnm{uponly}($r$) = $\big\{\text{for all }i, j, m:
                         x^{(r)\,\rm{obs}}_{ij}(t_{m})  \leq  x^{(r)\,\rm{obs}}_{ij}(t_{m+1}) \big\}$;
\item \nnm{downonly}($r$) = $\big\{\text{for all }i, j, m:
                         x^{(r)\,\rm{obs}}_{ij}(t_{m})  \geq  x^{(r)\,\rm{obs}}_{ij}(t_{m+1}) \big\}$;
\end{itemize}
For each ordered pair of network variables numbered $r$ and $r' \neq r$,
we define the following logical (boolean) variables:
\begin{itemize}
\item \nnm{higher}($r, r'$) = $\big\{\text{for all }i, j, m:
                         x^{(r)\,\rm{obs}}_{ij}(t_{m})  \geq  x^{(r')\,\rm{obs}}_{ij}(t_{m}) \big\}$;
\item  \nnm{disjoint}($r, r'$) = $\big\{\text{for all }i, j, m:
                       \min\{  x^{(r)\,\rm{obs}}_{ij}(t_{m}), \,
                           x^{(r')\,\rm{obs}}_{ij}(t_{m}) \} = 0 \big\}$;
\item \nnm{atleastone}($r, r'$) = $\big\{\text{for all }i, j, m:
                       \max\{  x^{(r)\,\rm{obs}}_{ij}(t_{m}), \,
                           x^{(r')\,\rm{obs}}_{ij}(t_{m}) \} = 1 \big\}$.
\end{itemize}



\emph{Model for microstep}


\begin{enumerate}
\item Initialize  time at $t=0$; initialise networks and behaviors $x, z$ at
      their observations at wave $m-1$.\\
      SF only: initialise the score function at $J_m = 0$.
\item \label{itemstart}
      Current time, networks, behaviors, denoted by $t, x, z$.
\item For all $r$, generate $\Delta t^N_r \sim E(\lambda^N(r,+,x,z))$.
\item For all $r$, generate $\Delta t^B_r \sim E(\lambda^B(r,+,x,z))$.
\item Let $W, r$ be the variable for which $\Delta t^W_r = \min_r\{t^N_r, t^B_r \}$.\\
      If $W = N$, goto \ref{itemx}; if $W = B$, goto \ref{itemz}.\\
      (\emph{Note}. An alternative, mathematically equivalent, is to choose\\
      $(W, r)$ with probabilities proportional to $\lambda^W(r,+,x,z)$ and\\
      only for this $W, r$ generate $\Delta t^W_r \sim E(\lambda^+(+,+,x,z))$.\\
      This is more efficient but the gain in computation time must be negligible.)
\item Choose $i$ with probabilities $\lambda^W(r,i,x,z) / \lambda^W(r,+,x,z)$.
\item Set $t = t + \Delta t^W_r$. (\emph{time step})
\item SF only:
      set
      \[
      J_m \,=\, J_m \,+\, \Big(\partial \ln \big(\lambda^W(r,i,x,z)/\lambda^+(+,+,x,z)\big) / \partial \theta\Big) \,+\,
         \Big(\partial \ln \lambda^W(r,i,x,z) / \partial \theta\Big) .
      \]
      (Note: first added term for generating $W, r, i$; second term for $t$. )
\item \label{itemx}
      Define $C$ as the set of $j$ for which $N_{ij}^{(r)}$ is allowed to change.\\
      This is the set of all $j \in \{1, \ldots, n\}$ from which are excluded
      all $j \neq i$ for which at least one of the following hold:
      \begin{enumerate}
      \item $N_{ij}^{(r)} $ is structurally determined;
      \item \nnm{uponly}($r$) and $N_{ij}^{(r)} = 1$;
      \item \nnm{downonly}($r$) and $N_{ij}^{(r)} = 0$;
      \item for some $r' \neq r$, \nnm{higher}($r, r'$) and $N_{ij}^{(r)} = N_{ij}^{(r')} = 1$;
      \item for some $r' \neq r$, \nnm{higher}($r', r$) and $N_{ij}^{(r)} = N_{ij}^{(r')} = 0$;
      \item for some $r' \neq r$, \nnm{disjoint}($r, r'$) and $N_{ij}^{(r)} = 0, N_{ij}^{(r')} = 1$;
      \item for some $r' \neq r$, \nnm{atleastone}($r, r'$) and $N_{ij}^{(r)} = 1, N_{ij}^{(r')} = 0$.
      \end{enumerate}
      Obviously, in many cases, there are never any excluded $j$; and if there
      is only one dependent network variable, the four last conditions
      are never satisfied.\\
      \adda{If $C$ has one element, this must be $i$; then go to \ref{itemstart}.\\
      (The following steps in this item then are vacuous, so they can be skipped.)\\
      If $C$ is empty, this is an error, and the program must stop with an error message.}

      For all $j \in C$, calculate $h_j = \Delta f^N(r,i,j,x,z)$, and $h_i = 0$.\\
      For all $j \in C$ with $N^{r}_{ij} = 1$, calculate $h_j = h_j - g^N(r,i,j,x,z)$.\\
      Choose $j \in C \cup {i}$ with probabilities
      \begin{equation}
         \pi_j = \frac{\exp(h_j) }{ \sum_k \exp(h_k) }               \label{pij}
      \end{equation}
      SF only: set
      $J_m = J_m + \partial h_j / \partial \theta \,-\, \sum_k \pi_k\, \partial h_k / \partial \theta  $.\\
      If $j \neq i$, toggle $N^{r}_{ij}$. (\emph{network step})\\
      Goto \ref{itemstart}.
\item \label{itemz}
      Let $C$ be the set of $v \in \{-1, 1\}$ \\
      for which $B^{(r)}_i + v$ is
      within the range of $B^{(r)}_i$.\\
      For all $v \in C$, calculate $h_v = \Delta f^B(r,i,v,x,z)$, and $h_0 = 0$.\\
      If $-1 \in C$, calculate $h_{-1} = h_{-1} - g^B(r,i,x,z)$.\\
      Choose $v \in C \cup {0}$ with probabilities
      \begin{equation}
         \pi_v = \frac{  \exp(h_v) }{ \sum_u \exp(h_u) }              \label{piv}
      \end{equation}
      SF only: set
      $J_m = J_m + \partial h_v / \partial \theta \,-\, \sum_u \pi_u \, \partial h_u / \partial \theta  $.\\
      Add $v$ to $B^{r}_{i}$. (\emph{behavior step})\\
      Goto \ref{itemstart}.
\end{enumerate}
\medskip

\emph{Stopping criterion}

\begin{enumerate}
\item In the unconditional estimation option, microsteps continue until
      $t \geq 1$. \\
      Note that, by convention, time duration between waves is set to be unity.\\
      SF only: set \\
      $J_m = J_m - (1 - t^{\rm{last}})
           \big(\partial \ln \lambda^+(+,+,x,z) / \partial \theta\big) $,\\
      where $t^{\rm{last}}$ is the last generated value of $t$ before $t$ exceeded 1.
\item In the conditional estimation option, if the conditioning variable
      is network $N^{(r)}$, microsteps continue until
      \[
      \sum_{i,j} \mid N^{(r)}_{ij} - x^{(r)\,\rm{obs}}_{ij}(t_{m-1}) \mid \geq
       \sum_{i,j} \mid x^{(r)\,\rm{obs}}_{ij}(t_{m})  - x^{(r)\,\rm{obs}}_{ij}(t_{m-1}) \mid \ ,
      \]
      where the sum is over all tie variables that are not structurally fixed
      at $t_{m-1}$ or $t_m$ (note that
      it is possible that tie variables are structurally fixed but have different subsequent values).\\
      If the conditioning variable
      is behavior $B^{(r)}$, microsteps continue until
      \[
      \sum_{i} \mid B^{(r)}_{i} - z^{(r)\,\rm{obs}}_{i}(t_{m-1}) \mid \geq
       \sum_{i} \mid z^{(r)\,\rm{obs}}_{i}(t_{m})  - z^{(r)\,\rm{obs}}_{i}(t_{m-1}) \mid \ ,
      \]
      where the sum is over all actors that are not structurally inactive
      at $t_{m-1}$ or $t_m$.
\end{enumerate}
\medskip

\emph{Score function}
\smallskip

The generated statistics $S$ can be written as $S = \sum_{m=2}^M S_m$, where $S_m$ is calculated
in consequence of the simulation of the process in the period from $t_{m-1}$ to $t_m$.
Denote the value of $J$ generated in this period by $J_m$.
To use the score function method, we calculate
\begin{equation}
%  <\!SJ\!> \,=\, \sum_{m=2}^M  (S_m - s_m^{\rm{obs}})J_m' \ .    \label{SJ}
  <\!SJ\!> \,=\, \sum_{m=2}^M  S_m \, J_m' \ .    \label{SJ}
\end{equation}
This is a $p \times p$ matrix,
and an estimate for $\partial E_{\theta}S/\partial \theta$.\\
(Or do we work with $\sum_{m=2}^M  (S_m - s^{\rm{obs}}) J_m'$
for numerical accuracy?)

The decomposition into the $M-1$ periods is kept because it allows a more efficient
variance reduction (see further down).

(Mathematical note: for simulations taking place according to parameter \th{},
$E_{\theta} J_m = 0$.
We will later subtract a value $s_m J_m '$
for an `almost constant' $s_m$; this does not affect the expected value,
but leads to a considerable variance reduction;
see Schweinberger \& Snijders, 2007.)

\section{Outline of Robbins-Monro algorithm for MoM}

This section is based on the appendix of Snijders (2001), and updated
to include the algorithm changes that were incorporated after 2001.
The implementation of the algorithm in RSiena is function
\nm{robmon}, and has a number of additional
details to improve convergence.

The purpose of the algorithm is to approximate the solution of the
moment equation
\begin{equation}
  \E_\theta S = s\, ,   \label{mom_eq0}
\end{equation}
where $s = s^{\rm{obs}}$, the observed value.
The solution is denoted by $\theta_0$.
The algorithm is a multivariate version of the Robbins-Monro (1951) algorithm.
It uses the idea of Polyak (1990) and Ruppert (1988)
to employ a diagonal matrix $D_0$ in the iteration step (\ref{step})
\begin{equation}
 \hat{\theta}_{N+1} = \hat{\theta}_N \, - \, a_N\, D_0^{-1} \, (S_N - s)~,   \label{step}
\end{equation}
 and estimate
the solution by partial averages of $\hat{\theta}_N$ rather than the
last value; and it uses the idea of Pflug (1990) to let the values of $a_N$ remain
constant if the average products of successive values $(S_N - s)(S_{N-1}-s)$
are positive, since this suggests that the process still is drifting toward its
limit value.
However, the specification used here deviates from Pflug's proposal by requiring,
for the premature decrease of $a_N\,$,
that for {\em each} coordinate the partial sum of the product of successive values
be negative, rather than requiring this only for the sum over the coordinates.
Further, the number of steps for which $a_N$ is constant is bounded between a lower
and an upper limit to ensure that $a_N$ is of order $N^{-c}$.

Whether the algorithm yields an estimate that indeed solves
the moment equation (\ref{mom_eq0}) to a satisfactory degree of precision
is checked in the `third phase' of the algorithm below.

The reason for incorporating the matrix $D_0$ is to achieve better compatibility
between the scales of $S$ and of $\theta$.
The diagonal elements of $D_0$ are defined as the estimated values of the derivatives
$\partial \E_{\theta}(S_k) / \partial \theta_k$ where $\theta$ is
at its initial value.
To see that this leads to compatibility of the scales of $S$ and $\theta$
note that in the extreme case where $\var(S_k) = 0$ and the diagonal elements of $D_0$
are equal to
$\partial \E_{\theta}(S_k) / \partial \theta_k$,
(\ref{step}) for $a_N = 1$ is just the iteration step of the Newton-Raphson
algorithm applied to each coordinate of $S$ separately.
Thus, beginning the algorithm with $a_N$ in the order of magnitude of 1
will imply that the initial steps have an approximately right order of magnitude.

The number of dimensions of \th{} and of $S$ is denoted by $p$
and the initial value is denoted \th{1}.
`Generating $ S \sim \theta $' means to simulate the model
according to parameter value $\theta$ and calculate the statistics $S$.

The estimation of derivatives has two options: finite differences (`FD')
and score function (`SF').
SF is more efficient and unbiased (Schweinberger \& Snijders, 2007)
and therefore is the default,
FD is available for some models for which
the derivatives of the log-likelihood needed for SF have not yet been
worked out.

The FD option is based on disturbing the current parameter values
by adding the value $\epsilon_j$, and using common random numbers.
Because of the discrete nature of the simulated
statistics, a very small $\epsilon_j$ will yield simulated values that
with high probability are equal to the values obtained without
the disturbance. This is undesirable
(see Schweinberger \& Snijders, 2007).
Good values of $\epsilon_j$ must be such that with rather
high probability (say, more than .5) the simulated values are
not identical to those obtained without the disturbance.

\newpage

Symbols given \nnm{in italic sf font} refer to the names
of variables used in the \R code.

The algorithm consists of three phases.

\begin{enumerate}
\item In this phase a small number $n_1$ of steps are made to estimate\\
      \nnm{dfra} = $D(\theta_1) = \big(\partial \E_\theta(S) / \partial \theta\big)
                       \mid_{\theta = \theta_1} $.\\
      The diagonal elements of this
      estimate are used to define $D_0$.
      Denote by $e_j$ the $j'$th unit vector in $p$ dimensions.

     Initialise ${{\rm{Sum}}}_{d} = 0_{p \times p}$,
           ${{\rm{Sum}}}_{S} = 0_{p \times 1}$.\\
     For SF, initialise additionally\\
              ${\rm{Sum}}_{Sm} = 0_{p \times 1}$ and
              ${\rm{Sum}}_{Jm} = 0_{p \times 1}$ for $m = 2, \ldots, M$.\\
     For $N = 1$ to $n_1$, do the following.
     \begin{description}
     \item[(FD)] Generate
     \begin{eqnarray*}
       \nnm{fra} &=& S \sim \theta_1  \\
        && S_{j} \sim \theta_1 + \epsilon_j e_j \ (j = 1, \ldots, p),
     \end{eqnarray*}
      where all these $p+1$ random vectors
      use a common random number stream to make them strongly positively
      dependent and where $\epsilon_j$ are suitable constants.\\
      Compute the difference quotients
      \[
      \nnm{sdf} = d_{j} = \epsilon_j^{-1} (S_{j} - S)~;
      \]
      for small values of $\epsilon_j$ the expected value of the matrix
      $d = (d_{1}, ..., d_{p})$ approximates $D(\theta_1)$.
      However, $\epsilon_j$ must be chosen not too small because otherwise
      the variances of the $d_{j}$ become too large.\\
      Update
            \begin{eqnarray*}
            {\rm{Sum}}_{S}  &=& {\rm{Sum}}_{S} + S \\
            {\rm{Sum}}_{d}  &=& {\rm{Sum}}_{d} + d \\
            \end{eqnarray*}
      \item[(SF)] Generate
           \[
           \nnm{fra} = S \sim \theta_1  \\
           \]
               its components being $S_m \, (m = 2, \ldots, M)$
               (see `Score Function' above),
               the complete-data score functions
               $J_{m}$ ($m = 2, \ldots, M$),\\
               and $d = <\!SJ\!>$ according to (\ref{SJ}).
               Update
               \begin{eqnarray*}
               {\rm{Sum}}_{S}  &=& {\rm{Sum}}_{S} + S \\
               {\rm{Sum}}_{d}  &=& {\rm{Sum}}_{d} + d \\
               {\rm{Sum}}_{Sm}  &=& {\rm{Sum}}_{Sm} + S_m, \ m = 2, \ldots, M \\
               {\rm{Sum}}_{Jm}  &=& {\rm{Sum}}_{Jm} + J_m, \ m = 2, \ldots, M \\
               \end{eqnarray*}
     \end{description}

     At the end of Phase 1, calculate the following results:
      \begin{enumerate}
      \item
      Estimate $E_{\theta_1} S$  by
      \[
      \bar{s} = \frac{{\rm{Sum}}_{S}}{n_1} \ .
      \]
      \item
      Estimate $D(\theta_1)$ by
      \begin{eqnarray*}
      \text{FD:    }   \hat{D} &=& \frac{{\rm{Sum}}_{d}}{n_1} \\
      \text{SF:     }  \hat{D} &=& \frac{{\rm{Sum}}_{d}}{n_1} -
                         \frac{\sum_{m=2}^M {\rm{Sum}}_{Sm}{\rm{Sum}}_{Jm}}{n_1^2} \ .
      \end{eqnarray*}
      \item Diagonal matrix $\tilde{D} = \mbox{diag}(\hat{D})$.
      \item Make one partial estimated Newton-Raphson step,
      \[
       {\hat{\theta}} = \theta_1 - a_1 {\hat{D}}^{-1} \left( \bar{s} - s \right)\, .
      \]
      where
      \[
      \nnm{targets} = s = \text{ observed values} .
      \]
      \end{enumerate}

\item[Phase 2.]
     Repeat for $k = 1, \ldots, k_{\rm{max}}$ (subphases):
     \begin{enumerate}
     \item Initialise \nnm{nit} = $N = 0$, ${\rm{Sum}}_{\hat\theta} = 0_{p \times 1}$,
          $S_{\rm{prev}} = 0_{p \times 1}$, \\
          \nnm{ac} = $\rm{AC} = 0_{p \times p}$.
     \item Generate
           \[
           \nnm{fra} = S \sim \theta
           \]
           or, for multiple processors, as the average of \nnm{int}
           independent replicates of such variables, and update
            \begin{eqnarray*}
             \hat{\theta} &\,=\,&
               \hat{\theta} \,-\, a_N\, \tilde{D}^{-1} \, (S - s) \\
             N & = & N+1 \\
            {\rm{Sum}}_{\hat\theta} & = & {\rm{Sum}}_{\hat\theta} + \hat\theta \\
            \text{if $N \geq 2$, then }  \rm{AC} & = & \rm{AC} + (S - s)(S_{\rm{prev}} - s)' \\
            S_{\rm{prev}} &=& S \ .
            \end{eqnarray*}
     \item  If $N >= n_{2k}^+$ or
            ($N >= n_{2k}^-$ and $\max_k \rm{AC}_{kk} \leq 0$), then\\
            $\big\{$ update $\hat\theta \,=\, N^{-1} {\rm{Sum}}_{\hat\theta}$ ;
                   set $a_k = a_k/2 \big\}$ ;
            else goto 2.
     \end{enumerate}
     In the code, \nnm{theta} = $\theta$, \nnm{gain} = $a_N$, \nnm{ac} = AC,
     \nnm{thav} = ${\rm{Sum}}_{\hat\theta}$, \nnm{nit} = $N$,\\
     \nnm{n2min} = $n_{2k}^-$, \nnm{n2max} = $n_{2k}^+$.
\item[Phase 3.]
      Phase 3 is used only for the estimation of $D(\theta)$ and
      $\Cov(\hat\theta)$,
      and as a check for the (approximate) validity of (\ref{mom_eq0}).
      The value of $\hat{\theta}$ is left unchanged in this phase
      and is equal to the value obtained after last subphase of phase 2.
      The procedure is mainly as in phase 1.

     Initialise ${{\rm{Sum}}}_{d} = 0_{p \times p}$,
           ${{\rm{Sum}}}_{S} = 0_{p \times 1}$,
           ${{\rm{SumSq}}}_{S} = 0_{p \times p}$.\\
     For SF, initialise additionally
              ${\rm{Sum}}_{Sm} = 0_{p \times 1}$ and
              ${\rm{Sum}}_{Jm} = 0_{p \times 1}$ for $m = 2, \ldots, M$.\\
     For $N = 1$ to $n_3$, do the following.
     \begin{description}
     \item[(FD)] Generate
     \begin{eqnarray*}
       \nnm{fra} &=& S \sim \theta  \\
        && S_{j} \sim \theta + \epsilon_j e_j \ (j = 1, \ldots, p),
     \end{eqnarray*}
      where all the $p+1$ random vectors
      use a common random number stream to make them strongly positively
      dependent and where $\epsilon_j$ are suitable constants.
      Compute the difference quotients
      \[
      \nnm{sdf} = d_{j} = \epsilon_j^{-1} (S_{j} - S) \ .
      \]
      Update
            \begin{eqnarray*}
            {\rm{Sum}}_{S}  \phantom{Sq} &=& {\rm{Sum}}_{S} + S \\
            {\rm{SumSq}}_{S}  &=& {\rm{SumSq}}_{S} + S\,S' \\
            {\rm{Sum}}_{d}  \phantom{Sq} &=& {\rm{Sum}}_{d} + d \\
            \end{eqnarray*}
      \item[(SF)] Generate
           \[
           \nnm{fra} = S \sim \theta  \\
           \]
               its components being $S_m \, (m = 2, \ldots, M)$
               (see `Score Function' above),
               the complete-data score functions
               $J_{m}$ ($m = 2, \ldots, M$),\\
               and $d = <\!SJ\!>$ according to (\ref{SJ}).
               Update
               \begin{eqnarray*}
               {\rm{Sum}}_{S} \phantom{Sq}  &=& {\rm{Sum}}_{S} + S \\
               {\rm{SumSq}}_{S}  &=& {\rm{SumSq}}_{S} + S\,S' \\
               {\rm{Sum}}_{d} \phantom{Sq}  &=& {\rm{Sum}}_{d} + d \\
               {\rm{Sum}}_{Sm} \phantom{Sq}  &=& {\rm{Sum}}_{Sm} + S_m, \ m = 2, \ldots, M \\
               {\rm{Sum}}_{Jm} \phantom{Sq}  &=& {\rm{Sum}}_{Jm} + J_m, \ m = 2, \ldots, M \\
               \end{eqnarray*}
     \end{description}
     At the end of Phase 3, calculate the following results:
      \begin{enumerate}
      \item
           Estimate $E_{\hat\theta} S$ and $\Cov_{\hat\theta} S$ by
           \[
           \bar{s} = \frac{{\rm{Sum}}_{S}}{n_3} \ , \hspace{1em}
           \Sigma = \frac{{\rm{SumSq}}_{S}}{n_3} \,-\, \bar{s}\,\bar{s}' \ .
           \]
      \item
           To check (approximate) validity of (\ref{mom_eq0}) compute the
           $t$-ratios for convergence,
           \[
           \nnm{tstat} = t_j = \frac{\bar{s}_j - s^{\rm{obs}}_j}{\sigma_j} \ ,
           \]
           where $\sigma_j$ is the square root of the $j'$th diagonal element
           of $\Sigma$.
      \item
           Estimate $D(\hat\theta)$ by
      \begin{eqnarray*}
      \text{FD:    }   \hat{D} &=& \frac{{\rm{Sum}}_{d}}{n_3} \\
      \text{SF:     }  \hat{D} &=& \frac{{\rm{Sum}}_{d}}{n_3} -
                         \frac{\sum_{m=2}^M {\rm{Sum}}_{Sm}{\rm{Sum}}_{Jm}}{n_3^2} \ .
      \end{eqnarray*}
      \item Estimate the covariance matrix of $\hat\theta$ by
            \begin{equation}
            \Cov (\hat\theta) \,=\,  {\hat D}^{-1}  \Sigma {\hat D }^{' -1} \ .
                      \label{eq:cov}
            \end{equation}
            The standard errors are the square roots of the diagonal elements
            of $\Cov (\hat\theta)$.
      \end{enumerate}

\end{enumerate}


This algorithm contains various constants that can be adapted so as to achieve
favorable convergence properties.
Experience with various data sets led to the following values.

The number of steps in phase 1 is
\[
\nnm{n1} =  n_1 = 7 + 3p \ .
\]
The minimum number of steps in subphase $2.k$ is
\[
\nnm{n2minimum[1]} = n_{2k}^- = ((2.52)^k)\ttimes(7+p)
\]
 which is meant to approximate
$n_{2k}^- = 2^{4(k+2)/3}(7+p)$;
the maximum number is
\[
\nnm{n2maximum[1]} = n_{2k}^+ = n_{2k}^- + 200 \ .
\]
For multiple processors, we use
\[
  n_{2k}^- = ((2.52)^{k-1})\ttimes \max \{5, (7+p)\ttimes 2.52/\nnm{int}\}
\]
where \nnm{int} is the number of processors.
These bounds $n_{2k}^-$ and $n_{2k}^+$ are determined so that
$N^{3/4} a_N$ tends to a finite positive limit.\\
For large $p$ they are rather conservative (i.e., unnecessarily large).\\
The default number of steps in phase 3 in the SF option is \nnm{n3} = $n_3 = 1000$.
For the FD option, 500 is a good default.

The default number of subphases is \nnm{nsub} = 4;
more or fewer subphases could be used
to obtain smaller or larger precision, but 4 seems really a good number.\\
The initial value of $a_N$ in phase 2 is \nnm{firstg} = 0.2,
and for multiple processors $0.2 \ttimes \sqrt{\nnm{int}}$.

The values of \nnm{epsilon} = $\epsilon_j$ in the FD option
are chosen initially as 0.1,
but in Phase 1 a check is made and if
the $j'$th coordinate of $d - d_j$ is exactly 0 for all or most
of the simulations then $\epsilon_j$ is adaptively increased.
The variability obtained
by the use of small values of $\epsilon_j$ is more serious than the bias obtained
by the use of a large value.
An ideal value would be to have $\epsilon_j$ slightly less than the
standard error of $\hat\theta_j$. However, this is known only
after the estimation has finished. (Of course in many cases there
have been done earlier estimations, and the information obtained
from them might be used for this purpose.)

\section{Statistics for MoM}

The statistics used for the MoM also deserve attention as part of the
algorithm. See Snijders (2001) and Snijders, Steglich, and Schweinberger (2007).
I hope later on to have time for elaborating this here.


\section{Likelihood-based calculations:
         \protect\newline Chain structures}

The basic data structure
for likelihood-based calculations
is called a \emph{chain}.
This is a sequence of changes that can take one (`observed') value
of $y$ to a next one.

To allow later generalization to valued networks as easily as possible,
we define a condition $D$ (for dichotomous) that is defined on the
level of variables (networks or behavioral variables);
in our current system $D$ is \nnm{True} for networks and \nnm{False} for
behavioral variables, but this can be different in future uses.

\adda{Comment: In the following the field \textit{lprob}
in the earlier definition of ministep is
replaced by the combination of \nnm{lOptionSetProb}
and \nnm{lChoiceProb}, while
\nnm{rRate} is renamed  to \nnm{rRate}.}

One change is called a \nnm{ministep}, denoted \ms, and is defined as:
\begin{equation}
    \ms \ = (w,i,j,r,d,\nnm{pred},\nnm{succ}, \adda{\nnm{lOptionSetProb}, }
                    \nnm{lChoiceProb}, \nnm{rRate})    \label{ministep}
\end{equation}
where
\begin{tabbing}
$w$ (`aspect') $\phantom{abcdefghij}$ \= = \= `network' or `behavior' (abbreviated to $N$ -- $B$ );\\
$i$ (`actor') \> = \> actor if $w$ = B, sending actor if $w$ = N;\\
$j$ (`actor') \> = \> meaningless 0 if $w$ = B, receiving actor if $w$ = N;\\
$r$ (`variable number') \> = \> number of variable ($1 \leq r \leq R_w$ );\\
$d$ (`difference') \> = \> meaningless 0 if $D$, amount of change if not $D$\\
   \> \>   (where $D $ depends on $w, r$);\\
   \> \>    currently we require $d \in \{-1, 0, 1\}$, but at some \\
   \> \>    later moment exceptions to this rule may be allowed;\\
\nnm{pred} (`predecessor') \> = \> pointer to preceding ministep;\\
\nnm{succ} (`successor') \> = \> pointer to next (succeeding) ministep;\\
\adda{
\nnm{lOptionSetProb} (`log OptionSet probability')} \\
\> = \> \adda{log probability of making a ministep of this OptionSet,}\\
    \> \>  \adda{ where the OptionSet is defined below as $(w,i,r)$;}\\
\adda{
\nnm{lChoiceProb}     (`log choice probability')} \\
\> = \> \adda{ log probability of making a ministep of this choice,}\\
    \> \>  \adda{ where the choice is $(j,d)$, given that $(w,i,r)$;}\\
\nnm{rRate} (`reciprocal rate') \> = \> reciprocal of aggregate (summed) )rate function \\
   \> \>      immediately before this ministep.
\end{tabbing}
To indicate the components/fields of a ministep we use the notation
$\ms.w, \ms.i$, etc.\\
\addc{The precise definitions of \nnm{lOptionSetProb}, \nnm{lChoiceProb},
and \nnm{rRate} are
given below in the specification of function \textit{StepProb }.}
\addca{The values $(w,i,j,r,d)$ may also be called the coordinates of the ministep.}

In Siena 3, $d$, \nnm{pred} and \nnm{succ} are called \textit{difh},
\textit{predh} and \textit{such};
and the program uses rates instead of reciprocal rates, but this was
implemented only very incompletely anyway.

The ministep is practically the same as what is called a microstep
in Section~\ref{S_sim}, but used here in a more
precise way. These words are not intentionally different.
\\
The log probability and reciprocal rate depend not only on the
chain and the ministep, but also on the initial state $y$ or $y(t_{m-1})$
valid before the start of the chain; and on the model specification and
model parameters.
Their computation is done by procedure \textit{StepProb} described in
Section~\ref{S_prob}.

The interpretation is that a ministep operates on (i.e., changes)
outcome $y$ as implemented by the following function.
\begin{enumerate}
\item \textit{ChangeStep}$(y, \ms)$  transforms state $y$ as follows,\\
      where $ \ms \ = (w,i,j,r,d, ...)$;\\
      \addaa{This can also be denoted  \textit{ChangeStep}$(y, (w,i,j,r,d))$;}
      \begin{itemize}
      \item if $w$ = N and $i \neq j$, change $N^{(r)}_{ij}$ to $1 - N^{(r)}_{ij}$;
      \item if $w$ = B,  change $B^{(r)}_{i}$ to $B^{(r)}_{i} + d$.
      \end{itemize}
\end{enumerate}
\addca{The inverse operation is very simple:\\
in general, \textit{Inverse$\big($ChangeStep}$(y, (w,i,j,r,d))\big)$ =
             \textit{ChangeStep}$(y, (w,i,j,r,-d))$;\\
in particular, \textit{Inverse$\big($ChangeStep}$(y, (N,i,j,r,0))\big)$ =
                 \textit{ChangeStep}$(y, (N,i,j,r,0))$.}\\
The definition of \textit{ChangeStep}
implies that only those values of $d$ are allowed that do not lead
$B^{(r)}_{i}$ outside of the bounds of this variable.
I think this should not always be checked except perhaps for in a test phase,
but the creation and transformation of ministeps should contain
checks that ensure this condition.

\textit{ChangeStep} is called a lot, and it will be helpful
that it is implemented in a very fast way.

The \textit{\adda{Option}} of a ministep is defined as
(Network, $i,\, j,\, r$) for Network ministeps,
and as (Behavior, $i, \, r$) for Behavior ministeps.
This defines the variable changing by the ministep.
\adda{Recall that $j$ is meaningless for $w=B$.
In general, we can define the options of a ministep as $(w,i,j,r)$.}
\adda{\textit{Option} is called `kind' in Siena 3.}

The \adda{\textit{OptionSet}} of a ministep is defined as
$(w,i,r)$.
This defines the choice situation / option set for the ministep.


This definition also means that network ministeps with $i = j$ and behavior ministeps
with $d = 0$ have no effect on the outcome. Such ministeps are permitted,
and are called \emph{diagonal} ministeps.

A \emph{chain} from observation $y(t_{m-1})$
to observation $y(t_m)$ is a sequence of ministeps $\ms_1 , \ms_2 , ..., \ms_T$
which, when applied sequentially, transform $y(t_{m-1})$ into $y(t_{m})$.
We then say that the chain \emph{connects}  $y(t_{m-1})$ to $y(t_m)$.
For $M$ observations, therefore, we require a sequence of $M-1$ chains.

For a sequence of ministeps $\ms_1 , \ms_2 , ..., \ms_T$
we define the following functions.
For disregarded values of the ministep (depending on whether it is a N or B
ministep) we use the wildcard symbol *.
\begin{enumerate}[resume]
\item \textit{NetworkNumber}$(i,j,r,S)  =  \,
             \sharp\{ s \mid 1 \leq s \leq S, \textit{\adda{Option}}(\ms_s) = (N,i,j,r)  \} $.\\
     \addc{In words, this is the number of ministeps, up to and including ministep number $S$,
      which imply a change in tie variable $(i,j)$ for Network $r$.}
\item \textit{BehSum}$(i,B,r,S)  = \,   \Sigma_{s=1}^S \, (\ms_s.d_s)\,
                      I\{ \textit{\adda{Option}}(\ms_s) = (B,i,*,r) \} $\\
      where $I$ is the indicator function defined as $I(A) = 1$ if $A$ is \nnm{True}
      and 0 if $A$ is \nnm{False}.\\
     \addc{In words, this is the partial sum, ending at ministep number $S$,
      of the $d$ (difference) values of all ministeps by actor $i$ for Behavior $r$.}
\end{enumerate}

If the outcomes $y(t_{m-1})$ and $y(t_m)$ are completely defined
(without any missing data) then the requirements on this sequence are as follows.

\emph{Networks} : (since changes are defined as toggles)\\
For all $i, j, r$ with $1 \leq r \leq R_N$, $i \neq j$,
\begin{subequations}
\begin{equation}
N^{(r)}_{ij}(t_{m-1}) = N^{(r)}_{ij}(t_m) \ \Leftrightarrow \
       \text{\textit{NetworkNumber}}(i,j,N,r,T) \text{ is even };
 \end{equation}
\addc{which is equivalent to
\begin{equation}
N^{(r)}_{ij}(t_{m-1}) = 1 - N^{(r)}_{ij}(t_m) \ \Leftrightarrow \
       \text{\textit{NetworkNumber}}(i,j,N,r,T) \text{ is odd }.
 \end{equation}
}
\label{netrec}
\end{subequations}
\emph{Behavior} : (since changes are defined as increments)\\
For all $i, r$ with $1 \leq r \leq R_B$,
\begin{eqnarray}
B^{(r)}_{i}(t_{m-1}) \! &+&  \! \text{ \textit{BehSum}}(i,B,r,T) = B^{(r)}_{i}(t_m)  \label{behrec1} \\
\text{and} &&  \nonumber \\
1 \leq B^{(r)}_{i}(t_{m-1}) \!  &+&  \! \text{ \textit{BehSum}}(i,B,r,S) \leq
                             \maxr   \text{ for all } 1 \leq S < T.   \label{behrec2}
\end{eqnarray}


\addaa{For each option there is a missingness indicator
\[
\textit{mis}(w,i,j,r)
\]
which is \nnm{True} or \nnm{False}, depending on whether in at least one of the two
end points of the chain, $y(t_{m-1})$ or $y(t_m)$, the corresponding variable
$N^{(r)}_{ij}$ or $B^{(r)}_{i}$ is missing. The use of these indicators is that
restrictions (\ref{netrec}) and  (\ref{behrec1}) are not required for the missing data.
For missing behavior data, however,
condition (\ref{behrec2}) still is required to ensure that the variable remains within range.
\begin{enumerate}[resume]
\item The number of Network options with missing values is defined as\\
      \[
        \textit{NumMisNet} =
     \sum_{i=1}^n \sum_{\stackrel{\scriptstyle j = 1}{\scriptstyle j \neq i}}^n
                                        I\{\textit{mis}(N,i,j,r) \} \ ,
      \]
      where $I\{\nnm{True}\} = 1$ and  $I\{\nnm{False}\} = 0$ .
\item The number of Behavior options with missing values is defined as\\
      \[
        \textit{NumMisBeh} =
               \sum_{i=1}^n    I\{\textit{mis}(B,i,*,r) \}  \ .
      \]
\end{enumerate}
}

It must be noted that missing data are not handled in the best possible way
in the likelihood-based procedures in Siena 3, and this
is done differently here.
Therefore, results for likelihood-based procedures in Siena 3 and RSiena
will be different.

Classes of functions are required which do the following:
\begin{enumerate}
\item Create and transform chains.
\item Calculate probabilities related to chains.
\item Store chains: read from and write to file.
\end{enumerate}

\section{Likelihood-based calculations:
         \protect\newline Create and transform chains}

\subsection{Data types}
\begin{enumerate}
\item  Ministep. See (\ref{ministep}).\\
       The \emph{\adda{Option}} of a ministep is (Network, $i,\, j,\, r$) for Network ministeps,
       and (Behavior, $i, \, r$) for Behavior ministeps.
       Note that this defines the variable that is being changed by the ministep.\\
       Note that in Siena 3 this is called the \emph{rKind} (\emph{restricted Kind}),
       and the `Kind' there also includes the value $d$.
       A ministep \ms \ is \emph{diagonal} if it is of \adda{Option} (Network, $i,\, j,\, r$)
       with $i = j$, or of \adda{Option} (Behavior, $i, \, r$) with $\ms.d$ = 0.
\item Chain. This is a sequence of ministeps connected by the pointers
      \nnm{pred} and \nnm{succ},
      with a \nnm{first} and \nnm{last} element.
      The \nnm{first} and \nnm{last} elements are dummies, i.e., they are of a special Option
      and OptionSet
      $(\textit{Extreme}, 0, 0, 0)$ which implies no change:\\
      $\textit{ChangeStep}(y,\nnm{first}) = \textit{ChangeStep}(y,\nnm{last}) = y$.\\
      Section \ref{S_struct} on structurally fixed values gives an exception to this rule,
      however, for the \nnm{last} element.\\
      The \nnm{first} and \nnm{last} elements are used just to have handles
      for the start and end of the chain.
      Of course, \nnm{first}.\nnm{pred} =\nnm{last}.\nnm{succ} = nil.\\
      \addaa{Or perhaps it is more convenient to define \nnm{first}.\nnm{pred} = \nnm{first}
      and \nnm{last}.\nnm{succ} = \nnm{last}.}\\
      The \nnm{first} and \nnm{last} ministeps are not \textit{diagonal}.\\
      \\
      The connection implies that if $\ms_a$ and $\ms_b$ are two ministeps
      with \\
      $\ms_b.\nnm{pred} = \ms_a$, then $\ms_a.\nnm{succ} = \ms_b$.
      The \nnm{first} element has a nil \nnm{pred}, and the \nnm{last} element
      has a nil \nnm{succ}.
\end{enumerate}

\subsection{Functions}

In Siena 3, I have defined the ministep type with various other pointers and attributes
useful for navigating in the chain.
These are functions of the chain, and including them in the ministep type
is for the purpose of computational efficiency.
These functions are the following. They are defined as functions of the ministep
in a given chain.
\addaa{They are not important in themselves, but might be useful for updating
the variables relating to CCPs. }

\begin{enumerate}
\item \textit{\adda{nrOption}}. The total number of ministeps in the chain of the same \adda{Option}.
\item \nnm{predOption}.
     Pointer to the last earlier (`preceding') ministep of the same \adda{Option},
     \addaa{and \nnm{first} if such a ministep does not exist.}\\
                         Called \textit{predhrkind} in Siena 3.
\item \nnm{succOption}.
    Pointer to the first later (`succeeding') ministep of the same \adda{Option}
    \addaa{and \nnm{last} if such a ministep does not exist.}\\
                         Called \textit{suchrkind} in Siena 3.
\end{enumerate}

The chain defines an order relation (binary function) of ministeps
in an obvious way, representing the time order in which the ministeps take place.
When there may be the possibility of confusion,
this is called the \emph{chain order}.

\begin{enumerate}
\item $\ms_a < \ms_b$ if there is a sequence $\ms_1, ..., \ms_K$ ($K \geq 0$) of ministeps
      such that $\ms_a.\nnm{succ} = \ms_1, \ms_b.\nnm{pred}= \ms_K$,
      and $\ms_k.\nnm{succ} = \ms_{k+1}$
      for all $k$, $1 \leq k \leq K-1$.
\addaa{
\item For $\ms_a < \ms_b$, we denote by $\textit{length}(\ms_a, \ms_b)$
      the number of ministeps from $\ms_a$ to $\ms_b$,
      including these end points,
      which is the value $K+2$ according to the preceding definition.
\item For $\ms_a < \ms_b$, we denote by $[\ms_a, \ms_b]$
      the interval of ministeps from $\ms_a$ to $\ms_b$,
       i.e., the sequence
      $\ms_a, \ms_1, ..., \ms_K, \ms_b$
      of the definition in (1).\\
      The interval $[\ms_a, \ms_a]$ is defined as the ministep $\ms_a$.
\item In the obvious way, we define recursively
      \begin{align}
        \ms.\nnm{succ}^0 &=  \ms \nonumber \\
        \ms.\nnm{succ}^{k+1} &=  \big(\ms.\nnm{succ}^k\big).\nnm{succ} \ . \nonumber
      \end{align}
      Thus, \textit{length}$(\ms, \ms.\nnm{succ}^{k}) = k+1$ for $k \geq 0$.
}
\end{enumerate}

An ordered pair of ministeps
\addaa{$(\ms_a, \ms_b)$ with $\ms_a < \ms_b$}
is called a CCP (\emph{consecutive canceling pair})
if they are of the same \adda{Option}, not \textit{diagonal},
cancel each other's effect (see next sentence),
have no other ministep of the same \adda{Option} in between,
and there is at least one ministep of a
different \adda{Option} in between
(i.e., \textit{length}$(\ms_a, \ms_b) \geq 3$).
Two non-diagonal ministeps $\ms_a$ and $\ms_b$ cancel each other's effect
if the following hold: either they are both of the same \adda{Option}
(Network, $i,\, j,\, r$) (then they cancel because they toggle the same
binary variable), or both are of the same \adda{Option} (Behavior, $i, \, r$)
and $\ms_a.d + \ms_b.d = 0$.

For example, if the chain contains a total of three ministeps
$\ms_a, \ms_b, \ms_c$
of the \adda{Option} (Network, 1, 2, 1), with $\ms_a < \ms_b < \ms_c$,
and none of which are each others' immediate predecessors/successors,
then $(\ms_a, \ms_b)$ and $(\ms_b, \ms_c)$ are CCP's.

\addca{The reason for this definition is to use it later in
defining changes in the chain,
such that each change has a unique (i.e., exactly one) inverse operation.
Adding a CCP to a chain will not lead to violations of (\ref{netrec}, \ref{behrec1}),
although it may lead to violation of (\ref{behrec2}), which therefore
must be separately checked.
There is a one-to-one correspondence between the set of all operations of
dropping a CCP from a chain, and the set of all operations of
adding the two elements of a CCP to the chain
as immediate predecessors of two ministeps $\ms_a < \ms_b$
for which $\ms_a$ is not the \nnm{first} element, and there
is no ministep $\ms_c$ with $\ms_a < \ms_c < \ms_b$ of the same \textit{Option}
as $\ms_a$ and $\ms_b$, and which do not lead to violation of  (\ref{behrec2}).
All this is elaborated later, and given here only as a motivation for this definition.
}

Basic functions of the chain are the following.\\
\adda{Since these are frequently used, they should be stored
and updated when the chain is changed; this is done in the \textit{Update} function.}\\
\adda{The condition \textit{SimpleRates} is defined below.}
\begin{enumerate}
%\item \textit{Valid}, a boolean indicating whether the chain connects
%      $y(t_{m-1})$ to $y(t_m)$, and the log probabilities and rates
%      have been calculated.
\item \textit{TotNumber}, the number of ministeps of the chain, excluding the \nnm{first};\\
      so an empty chain consisting only of the \nnm{first} and \nnm{last} ministeps
      with \\
      \nnm{first}.\nnm{succ} = \nnm{last} has $\textit{TotNumber} = 1$.
\item \textit{DiagNumber}, the number of \textit{diagonal} ministeps of the chain.
\item \textit{CCPNumber}, the number of CCP's in the chain.
\addaa{
\item \textit{ChainNumMisNet}, the number of ministeps of
     some  \textit{Option} $(N,i,j,r)$ for which \textit{mis}$(N,i,j,r)$ is true.
\item \textit{ChainNumMisBeh}, the number of ministeps of
     some  \textit{Option} $(B,i,*,r)$ for which \textit{mis}$(B,i,*,r)$ is true.
}
\addab{
\item \textit{ChainNumInitMis}, the number of
     \textit{Options} $(w,i,j,r)$ for which
     the initial value $N_{ij}^{(r)}(t_{m-1})$
     or $B_{i}^{(r)}(t_{m-1})$ is a missing value.
}
\adda{
\item Used only if (not \textit{SimpleRates}):\\
      \textit{mu} = $\sum_{s=2}^{T-1} \ms_s.\nnm{rRate}$, where $T = $ \textit{TotNumber}.\\
      Note that the sum is over all ministeps in the chain except the two extremes
      (\nnm{first} and \nnm{last}).
\item Used only if (not \textit{SimpleRates}):\\
      \textit{sigma2} = $\sum_{s=2}^{T-1} (\ms_s.\nnm{rRate})^2$.
}
\end{enumerate}
%Note that \textit{mu} and \textit{sigma2} are used only if not \textit{SimpleRates}.
\adda{The chain can be denoted by
\[
  \ms_0, \ms_1, \ms_2, \ldots, \ms_\textit{TotNumber} \ ,
\]
in which $\ms_0$ and $\ms_\textit{TotNumber}$ are the extreme elements.
}


The following functions may be defined on the \adda{Option}s of ministeps:
\addaa{They are not important in themselves, but might be useful for updating
the variables relating to CCPs. }
\begin{enumerate}
\item \textit{NumberOption}$(w,i,j,r)$, the number of ministeps of the chain
      of \adda{Option} $(w,i,j,r)$.\\
      For the network ministeps this will be a sparse matrix, in the sense that for large networks
      most of the values \textit{NumberOption}$(N,i,j,r)$ will be 0.\\
      This is called \textit{NumberrKind} in Siena 3.
\item \textit{Multiple}$(w,i,j,r)$ = \nnm{True} if \textit{NumberOption}$(w,i,j,r) \geq 2$
      and \nnm{False} if \textit{NumberOption}$(w,i,j,r) \leq 1$.\\
      We say that a \adda{Option} can be multiple or non-multiple.
\end{enumerate}


\subsection{Operations}

Basic operations on chains are the following.
Of course they have to guarantee the consistency of all the
derived variables and pointers.
The consistency of the log probabilities and reciprocal rates
is treated separately (when it is needed), see Section~\ref{S_prob}.
\begin{enumerate}
\item \emph{Create} an empty chain consisting only of the elements (\nnm{first}, \nnm{last}).
%      with \textit{Valid} = \nnm{False}.
%\item \emph{Validate}, check that the chain connects $y(t_{m-1})$ to $y(t_m)$
%      and if so, calculate the log probabilities and rates
%      and set \textit{Valid} to \nnm{True}.
\item \emph{InsertBefore}$(\ms, w,i,j,d,r)$ :\\
      for a currently existing ministep $\ms \neq $  \nnm{first}, insert the ministep
      with values $(w,i,j,d,r)$ between \ms.\nnm{pred} and \ms.
\item \emph{Delete}  a ministep, and link up its predecessor and successor.
\item \emph{RandomElement}      :\\
      draw a random ministep from the chain, excluding the \nnm{first} element;
      note that the probabilities are 1/\textit{TotNumber}.
\item \emph{Connect} : construct randomly a chain that connects
      two outcomes $y(t_{m-1})$ and $y(t_m)$ .\\
      This is done by repeatedly applying \emph{RandomElement} and \emph{InsertBefore}:
      \begin{tabbing}
      For all \= $R_N$ networks:\\
         \> For all \= $(i,j), i \neq j$:\\
          \> \> if $N^{(r)}_{ij}(t_{m-1}) \neq N^{(r)}_{ij}(t_m)$,\\
            \> \> then \textit{InsertBefore}(\textit{RandomElement}, $N,i,j,0,r$);\\
      For all \= $R_B$ behaviors: \\
         \> For all \= $i$:\\
          \> \> Define $D = B^{(r)}_{i}(t_{m}) - B^{(r)}_{i}(t_{m-1})$;\\
            \> \> if $D > 0$, then $D$ times \textit{InsertBefore}(\textit{RandomElement}, $B,i,0,1,r$);\\
            \> \> if $D < 0$, then $-D$ times \textit{InsertBefore}(\textit{RandomElement}, $B,i,0,-1,r$).\\
       \end{tabbing}
\end{enumerate}

\adda{
The \emph{Connect} procedure yields a chain connecting
the two outcomes $y(t_{m-1})$ and $y(t_m)$ which has minimum length.
}

\addaa{
As a pre-burn-in it is good to insert, immediately after
\emph{Connect}, some \textit{diagonal} steps and some mutually canceling pairs of steps
as long as this increases the likelihood of the chain.
This is done as follows, using functions  \textit{MH\_InsertDiag} and \textit{MH\_InsPermute}
explained below.
\begin{enumerate}[resume]
\item Repeat \textit{MH\_InsertDiag}(\textit{pra, accept}) until 5 times `\textit{not accept}'.
\item Repeat \textit{MH\_InsPermute}(\textit{1, misdat, pra, accept}) until 5 times `\textit{not accept}'.
\end{enumerate}
The number 5 is arbitrary but reasonable.
}



The following random draws are not always possible, since the sets
from which a random element is drawn, may be empty.
(It may be noted, however, that usually the set will be non-empty.)
\addaa{ \emph{RandomMultipleOption}  and  \emph{RandomCCPOption} are dropped!
This will be simpler and probably at least as efficient as Siena 3.  }
\begin{enumerate}[resume]
\item \emph{RandomDiagonal}      :\\
      draw a random \textit{diagonal} ministep from the chain;
      note that the probabilities are 1/\textit{DiagNumber}.
\addaa{
\item \emph{RandomCCP}      :\\
      draw a random CCP $(\ms_a, \ms_b)$ from the chain;
      note that the probabilities are 1/\textit{CCPNumber}.
\item \emph{RandomMisNet}      :\\
      draw a random ministep $\ms_a$ from the chain
      of which the \textit{Option} $(w,i,j,r)$ satisfies
      $w=N$ and \textit{mis}$(N,i,j,r)$.\\
      Note that the probabilities are 1/\textit{ChainNumMisNet}.
\item \emph{RandomMisBeh}      :\\
      draw a random ministep $\ms_a$ from the chain
      of which the \textit{Option} $(w,i,j,r)$ satisfies
      $w=B$ and \textit{mis}$(B,i,*,r)$.\\
      Note that the probabilities are 1/\textit{ChainNumMisBeh}.
}
\addab{
\item \emph{RandomInitMis}      :\\
      draw a random \textit{Option} $(w,i,j,r)$
      for which
      the initial value $N_{ij}^{(r)}(t_{m-1})$
      or $B_{i}^{(r)}(t_{m-1})$ is a missing value.\\
      Note that the probabilities are 1/\textit{ChainNumInitMis}.
}
\end{enumerate}


\newpage
\section{Likelihood-based calculations:
     \protect\newline Calculate probabilities related to chains}
\label{S_prob}

\adda{An important special case is the case of state-constant rate functions, i.e., rate functions
$\lambda^W(r,i,y)$ depending only on $W$, $r$, and $i$ but not on $y$,
and therefore not changing as a consequence of the simulations.
This is important also because the majority of users will use
state-constant rate functions.
In the case of state-constant rate functions, everything related to $\lambda$ needs to be
calculated only when parameters are changed.\\
Denote this by the Boolean \textit{ConstantRates}.
}

\adda{We define a special Boolean condition \textit{SimpleRates}.
The default is to let \\
\textit{SimpleRates} = \textit{ConstantRates}, but this
may be changed by the user (not in the gui).
In practice it will be changed only for the purposes of algorithm comparison.
}

Ministeps are interpreted as changes in the chain (procedure \textit{ChangeStep}).
These changes are made with certain probabilities, and the
rate of change has a certain value when the ministep is going to be made.
The probabilities and rates depend on the state immediately before the ministep;
this depends in turn on the state at the start of the chain, and the
sequence of ministeps before the current ministep.
For a ministep \ms \ in the chain with a given initial state $y$
(say, $y = y(t_{m-1})$), the state obtaining before \ms \
can be defined recursively as follows (where \textit{ChangeStep} is treated
as a function with states as outcomes).
\begin{enumerate}
\item $\textit{StateBefore}(\nnm{first}) = y$.
\item $\textit{StateBefore}(\ms.\nnm{succ}) = \textit{ChangeStep}(\textit{StateBefore}(\ms),\ms)$.
\end{enumerate}
Thus, the state before \ms \ is obtained by repeatedly applying \textit{ChangeStep}:
\addaa{\[
\textit{StateBefore}(\ms) =
      \textit{ChangeStep}^{\displaystyle ( \textit{\normalsize length}(\nnm{first},\ms)\displaystyle -1)}(y_{\text{initial}})  \ .
\]}

The log-probabilities and rates are defined by the following procedure.
For the mathematical symbols $\pi_j, \pi_v, \lambda(...), J_m$, see
the notation of Section~\ref{S_sim} where the microstep/ministep
is treated for the purpose of simulation of the model,
and where the same ingredients are used.

\addaa{The functions \textit{StepProb1} to \textit{StepProb3} are often used one after each other,
and utilizing this will lead to efficiency gains.}


\begin{enumerate}
\item \addaa{ \textit{StepProb1}$(\textsf{input}\ y, w,i,r; \textsf{output}\ rr, lospr)$;\\
      this calculates the aggregate rate for current state $y$
      and returns $rr$ as its reciprocal:
      \[
      rr \leftarrow 1/\lambda^+(+,+,y) \ .
      \]
      it calculates the probability of getting the \textit{OptionSet} $(w,i,r)$
      and returns it as $lospr$ :
      \[
      lospr \leftarrow    \log\left(\frac{\lambda^w(r,i,y)}{\lambda^+(+,+,y)}\right)
      \]
      If \textit{ConstantRates} these are trivial look-up operations
      (the values then depend only on the parameters included in the functions $\lambda$,
      not on $y$).}

      \addaa{Note that in some cases this must be done for all $(w,i,r)$, sometimes
      only for one value of $(w,i,r)$. When it is done for all cases,
      this is denoted\\
       \textit{StepProb1}$(y, *; rr, lospr*)$, \\
       and then $lospr*$
      is an output array of suitable dimensions.}
\item \addaa{\textit{StepProb2}$(\textsf{input}\ y, w,i,j,r,d; \textsf{output}\ rr, lospr, lcpr)$;\\
      After doing the same as in \textit{StepProb1}$(y, w, i, r; rr, lospr)$,\\
      this calculates for the current state $y$, conditional on the
      assumption that a ministep of \adda{OptionSet} $(w,i,r)$ is made,
      the log of the conditional probability that this will be the ministep
      with value $(w,i,j,r,d)$;\\
      for $w=N$ (network) this is $lcpr \leftarrow \log(\pi_j)$ using $\pi_j$ defined in (\ref{pij});\\
      for $w=B$ (behavior) this is $lcpr \leftarrow \log(\pi_d)$
      using $\pi_v$ defined in (\ref{piv}).\\
      Output variables $ rr, lospr, lcpr$ are the \nnm{rRate}, \nnm{lOptionSetProb}, and\\
      \nnm{lChoiceProb} of this ministep.}

      \addaa{Note that for a given $(w,i,r)$, in some cases this must be done for all $j$ (if $w=N$)
      or $d$ (if $w=B$), in other cases only for one value of $j$ or $d$.
      If it is done for all $j$ or $d$, the notation is\\
      \textit{StepProb2}$(y, w,i,*,r,*; rr, lospr, lcpr*)$\\
       and again $lcpr*$ is an array
      of suitable dimension.\\
      If the function is denoted \textit{StepProb2}$(y, \ms; rr, lospr, lcpr)$, this is the same as
      \textit{StepProb2}$(y, w,i,j,r,d; rr, lospr, lcpr)$ with the coordinates $w,i,j,r,d$
      for the ministep filled in.
\newpage
\item \textit{StepProb3}$(\textsf{input}\ y, w,i,j,r,d; \textsf{output}\  rr, lospr, lcpr, sc)$;\\
      The first part is the same as
      \textit{StepProb2}$(y, w,i,j,r,d; rr, lospr, lcpr)$;\\
      in addition,  calculate the contribution of this ministep to the
      score function, which in Section~\ref{S_sim}
      is what is added (as described there for three occasions) to $J_m$,
      and store this in the $p$-vector $sc$.}
\end{enumerate}

While operating on the chain, it is important to keep the
log probabilities and rates up to date. This requires the following procedure.
It updates only part of the chain, and is applied when it is known
that the earlier and later parts do not need to be updated.

\begin{enumerate}[resume]
\item \adda{
       \textit{Update}($\ms$) for a ministep \ms:\\
       Update \textit{TotNumber},  \textit{DiagNumber}, \textit{CCPNumber}, \textit{ChainNumMisNet},\\
       \textit{ChainNumMisBeh}.\\
       Use \textit{StepProb2} to update the log probabilities and rates for ministep \ms .\\
       If not \textit{SimpleRates}:
       Update the values of \textit{mu} and \textit{sigma2}.
       }
\item \textit{Update}($\ms_a, \ms_b$) for ministeps $\ms_a < \ms_b$:\\
       Update \textit{TotNumber},  \textit{DiagNumber}, \textit{CCPNumber}, \textit{ChainNumMisNet},\\
       \textit{ChainNumMisBeh}.\\
       Use \textit{StepProb2} to update the log probabilities and rates for all ministeps
       from $\ms_a$ to $\ms_b$ (i.e., all ministeps between these two in the chain order,
       including these two ministeps themselves).\\
       If not \textit{SimpleRates}:
       Update the values of \textit{mu} and \textit{sigma2}.

       This is called \textit{UpdateRateslprobs} in Siena 3.
\end{enumerate}

\adda{In many cases, \textit{StepProb*} has been called just before \textit{Update},
so that the log probabilities and rates are known already and
the expensive procedure \textit{StepProb*} does not have to be called again.}

\addaa{Depending on the implementations, the auxiliary variables for working with CCPs
must also be suitably updated.}

\newpage
\section{Likelihood-based calculations:
         \protect\newline Metropolis-Hastings steps}

A basic required functionality is to simulate from the distribution
of chains that connect $y(t_{m-1})$ to $y(t_m)$,
given the model specification and model parameters.
This is done by repeated application of Metropolis Hastings steps.
These are of the following types, with associated probabilities.
The probabilities are constants with default values that can be changed
by the very experienced user.
\begin{enumerate}
\item \textit{MH\_InsertDiag}\\
      (called \textit{MH\_TryInsertDiag} in Siena 3), associated probability \textit{pridg}.
\item \textit{MH\_CancelDiag}\\
      (called \textit{MH\_TryCancelDiag} in Siena 3), associated probability \textit{prcdg}.
\item \textit{MH\_Permute}, associated probability \textit{prper}.
\addaa{
\item \textit{MH\_InsPermute}, associated probability \textit{pripr}.
\item \textit{MH\_DelPermute}, associated probability \textit{prdpr}.
}
\addab{
\item \textit{MH\_RandomMis}, associated probability \textit{prrms}.
}
\end{enumerate}


\addaa{
Function \textit{MH\_DelPermute} also uses internal probabilities \textit{prmin}
and \textit{prmib}.
These could have the default values
\begin{align}
  \textit{prmin} & \, = \frac{\textit{NumMisNet}}{\textit{NumMisNet} + R_N\, n(n-1)} \\[0.5em]
  \textit{prmib} & \, = \frac{\textit{NumMisBeh}}{\textit{NumMisBeh} + R_B\, n}\
\end{align}
(The reasoning is as follows.
In procedure \textit{MH\_DelPermute} this probability serves to balance
changes in missings with changes in CCPs, and the total available number of variables/options
for which there could be CCPs is $R_N\, n(n-1)$ and $R_B \,n$, respectively).}

\addab{The probability \textit{prrms} associated with function \textit{MH\_RandomMis}
could have the default value
\[
\textit{prrms} = \frac{\textit{ChainNumInitMis}}{R_N\, n(n-1) \,+\, R_B \,n} \ .
\]
}

\newpage
\addaa{The definitions of these procedures have three parts:
\begin{itemize}
\item[A.] Choose the proposal.
\item[B.] Calculate the probability (usually \textit{pra}) for this proposal.
\item[C.] With probability \textit{pra} carry it out in practice.
\end{itemize}
The earlier (version before February 1) description only contained parts B and C.
What were the input parameters for those earlier versions now are calculated in part A,
and therefore now only have an internal role.
The only remaining input parameter is $c_0$, the maximal order of the permutations.
}

\addaa{
Functions \textit{MH\_InsertDiag} and \textit{MH\_CancelDiag} are each other's inverses.
Similarly, \textit{MH\_InsPermute} and \textit{MH\_DelPermute} are each other's inverses.
Function \textit{MH\_Permute} is the inverse of another \textit{MH\_Permute},
for a suitable other permutation.
}
\addab{Function \textit{MH\_RandomMis} is a Gibbs step, and therefore
its inverse is not important.}

\addaa{
Function \textit{MH\_Permute} basically is part of the two functions
\textit{MH\_InsPermute} and \textit{MH\_DelPermute}. Including it in those functions
is done for computational efficiency (most of the calculations have to be done anyway).
}



As notation I use the \R convention of denoting an assignment statement by $a \leftarrow b$,
i.e., the variable $a$ gets the value $b$.

\subsection{Diagonal Insert}


The function
\textit{MH\_InsertDiag}$(%\textsf{input}\ \ms, w,i,r;
\textsf{output}\ \textit{pra, accept})$
is roughly described as follows.
The interpretation is that
the proposal is made to insert a \textit{diagonal} element of \adda{\textit{OptionSet}}
$(w,i,r)$ immediately before a ministep \ms;
according to a random decision with probability \textit{pra},
computed within the function,
this proposal is put into effect (yielding \textit{accept} = \nnm{True})
or not (yielding \textit{accept} = \nnm{False}).


\addaa{
Part \emph{A}:
\begin{enumerate}
\item \ms\ $ \leftarrow $ \textit{RandomElement}
\item $y \leftarrow $ \textit{StateBefore}(\ms)
\item \textit{StepProb1}$(y, *; \textsf{output}\ rr, lospr*)$
\item With probabilities defined by $\exp(lospr*)$ choose \textit{OptionSet} $(w,i,r)$.\\
      If $i$ is not active, or $w=B$ and $B^{(r)}(i)$ is structurally fixed, then exit.
\end{enumerate}
Note: the proposal probability here is
\[
\frac{ \exp(lospr)}{\textit{TotNumber}}
\]
which is used below in the definition of \textit{pra}.
}

Part \emph{B}:
\begin{enumerate}[resume]
\item \textit{StepProb2}$(y, w,i,i,r,0 ;  rr, lospr, lcpr)$\\
      \addca{($lospr$ was already calculated above)}
\item If \textit{SimpleRates}, let
      \addaa{
      \begin{equation}
      \textit{KappaFactor} \leftarrow \frac{1}{rr \times(\textit{TotNumber } + 1)}
      \end{equation}
      (this change is mathematically equivalent to the earlier value, but uses the fact that
      $rr$ is calculated above)}\\
      else
      \begin{equation}
      \textit{KappaFactor} \leftarrow \sqrt{ \frac{\textit{sigma2}}{\textit{sigma2} + rr^2} }
                  \ttimes \exp\left( \frac{\left(1 - \textit{mu} \right)^2}{2\ttimes\textit{sigma2}}
                   - \frac{\left(1 - \textit{mu}  - rr \right)^2}{2\,(\textit{sigma2} + rr^2)}  \right) \ .
      \end{equation}
\item \begin{equation}
     \textit{pra}  \leftarrow \textit{KappaFactor} \ttimes \exp( lcpr) \ttimes
                                   \frac{\textit{TotNumber}\ttimes\textit{prcdg}}
                                    {(\textit{DiagNumber}+1) \ttimes\textit{pridg}}
    \end{equation}
    \addaa{Check the use of $lospr$ and $ lcpr$, which may be different
    from the earlier version.}\\
    Note: the proposal probability and the new chain probability both include
    factors $\exp(lospr)$ which cancel out.\\
    if (\textit{pra} $ > 1$), then  \textit{pra} $ \leftarrow 1 $.
\end{enumerate}
\newpage
Part \emph{C}:
\begin{enumerate}[resume]
\item With probability \textit{pra} let \textit{accept} $\leftarrow$ \nnm{True}, else
      \textit{accept} $\leftarrow$ \nnm{False}.
\item If \textit{accept}, then
      \begin{enumerate}
      \item \textit{InsertBefore}$(\ms,w,i,i,r,0)$\\
      \addaa{Earlier the order was wrong: it said $w,i,i,0,r$ instead of $w,i,i,r,0$. }
      \item \textit{Update}(\ms)
      \end{enumerate}
\end{enumerate}

\subsection{Diagonal Delete}

The function
\textit{MH\_CancelDiag}$(%\textsf{input}\ \ms;
\textsf{output}\ \textit{pra, accept})$
is roughly described as follows.\\
The interpretation is that
the proposal is made to delete a \textit{diagonal} ministep \ms;
according to a random decision with probability \textit{pra},
computed within the function,
this proposal is put into effect (yielding \textit{accept} = \nnm{True})
or not (yielding \textit{accept} = \nnm{False}).

\addaa{
Part \emph{A}:
\begin{enumerate}
\item \ms\ $ \leftarrow $ \textit{RandomDiagonal}
\end{enumerate}
Note: the proposal probability here is
\[
\frac{ 1 }{\textit{DiagNumber}}
\]
which is used below in the definition of \textit{pra}.
}

Part \emph{B}:
\begin{enumerate}[resume]
\item $rr \leftarrow $ \ms.\nnm{rRate}
\newpage
\item \addaa{If \textit{SimpleRates}, let
      \begin{equation}
      \textit{KappaFactor} \leftarrow  rr \,\times\, \textit{TotNumber }
      \end{equation}
      (in contrast with the preceding procedure, here the change is an error correction); } \\
      else
      \begin{equation}
      \textit{KappaFactor} \leftarrow \sqrt{ \frac{\textit{sigma2}}{\textit{sigma2} - rr^2} }
                  \ttimes \exp\left( \frac{\left(1 - \textit{mu} \right)^2}{2\ttimes\textit{sigma2}}
                   - \frac{\left(1 - \textit{mu}  + rr \right)^2}{2\,(\textit{sigma2} - rr^2)}  \right) \ .
      \end{equation}
\item  \addaa{
     \begin{align}
     \textit{pra}  \leftarrow \  & \textit{KappaFactor} \ttimes
                    \exp(-\, \ms.\nnm{lChoiceProb} )
                    % \nonumber \\  & \hspace*{1em}
                    \ttimes
              \frac{\textit{DiagNumber}\ttimes \textit{pridg}}
                                    {(\textit{TotNumber}+1)\ttimes\textit{prcdg}} \ . \nonumber
    \end{align}
    Check the use of \nnm{lOptionSetProb} and \nnm{lChoiceProb}, which may be different
    from the earlier version.}\\
    Note: the proposal probability and the new chain probability both include
    factors $\exp(\ms.\nnm{lOptionSetProb})$ which cancel out.\\
    if (\textit{pra} $ > 1$), then  \textit{pra} $ \leftarrow 1 $.
\end{enumerate}
Part \emph{C}:
\begin{enumerate}[resume]
\item With probability \textit{pra} let \textit{accept} $\leftarrow$ \nnm{True}, else
      \textit{accept} $\leftarrow$ \nnm{False}.
\item If \textit{accept}, then
      \begin{enumerate}
      \item  \textit{Delete}(\ms)
      \item  If (not \textit{SimpleRates}), let
           \begin{enumerate}
           \item \textit{mu} $\leftarrow \textit{mu} - rr$ \ ;
           \item \textit{sigma2} $\leftarrow \textit{sigma2} - rr^2 $ \ .
           \end{enumerate}
      \end{enumerate}
\end{enumerate}

\newpage
\subsection{Permute}
\addaa{In this section, various formulations are changed but the main content is the same;
from the next section to Section \ref{S_struct}, the text is new.
This is not indicated by colour any more.}

A rough description of the function\\
\textit{MH\_Permute}$(\textsf{input}\ c_0; \textsf{output}\ \textit{pra, accept})$
is as follows.\\
The input parameter $c_0$ is a relatively small integer --
in Siena 3 it is determined adaptively with a maximum value of 40. \\
Within the function,
if $\ms_a.\nnm{succ}^{(c_0-1)} < \nnm{last}$
then $c = c_0$, else $c$ is truncated to $\textit{length}[\ms_a, \nnm{last}]-1$;
and $\ms_b = \ms_a.\nnm{succ}^{(c-1)}$.
Thus, $\ms_a$ and $\ms_b$ are two non-extreme ministeps with  $\ms_a < \ms_b$
and $c = \textit{length}[\ms_a, \ms_b] \leq c_0$.
Further, \textit{perm} is a permutation of the numbers
$1, 2, \ldots, c$.\\
The proposal made is to permute the $c$ ministeps in the interval $[\ms_a, \ms_b] $
by \textit{perm};
according to a random decision with probability \textit{pra},
computed within the function,
this proposal is put into effect (yielding \textit{accept} = \nnm{True})
or not (yielding \textit{accept} = \nnm{False}).

%\newpage
Part \emph{A}:
\begin{enumerate}
\item repeat $\ms_a \leftarrow $ \textit{RandomElement} until $\ms_a \neq \nnm{last}$.
\item $c \leftarrow \min \{c_0, \textit{length}(\ms_a, \nnm{last}) - 1\}$.\\
      If $c = 1$ then exit.
\item Let \textit{perm} be a random permutation of the numbers $1$ to $c$,\\
      and denote $\ms_b = \ms_a.\nnm{succ}^{(c-1)}$.
\item $y \leftarrow  \textit{StateBefore}(\ms_a)$
\item For all $r, 1 \leq r \leq R_B$, check (\ref{behrec2}) for the permuted chain \\
      (this condition needs to be checked
      here only for ministeps from $\ms_a$ to $\ms_b$).\\
      If the variable $(w,r)$ is involved in a condition of the kind
      \nnm{uponly}, \nnm{downonly}, \nnm{higher}, \nnm{disjoint}, or \nnm{atleastone}, then similarly check these conditions
      for the potential new chain.\\
      If at least one of these conditions are not satisfied, exit.
\end{enumerate}
The inverse of the proposal is a proposal of exactly the same kind. The
proposal probability is
\[
   \frac1{(\textit{TotNumber}-1) \ttimes c!}
\]
but this needs not be used, since the proposal probability is the same as the
probability of the inverse proposal.

Part \emph{B}:
\begin{enumerate}[resume]
\item \[ \textit{sumlprob} \leftarrow \sum_{s=1}^{c}
             (\ms_a.\nnm{succ}^{s-1}).(\nnm{lChoiceProb} + \nnm{lOptionSetProb}) \ ;
      \]
      If (not \textit{SimpleRates}), then below we use
      the values \textit{mu} and \textit{sigma2}; \\
      these refer to the current chain.
      \[
      \textit{sumlprob\_new}  \leftarrow 0 \ ;
      \]
      \[
      \textit{mu\_new}  \leftarrow \textit{mu} -  \sum_{s=1}^{c}
             (\ms_a.\nnm{succ}^{s-1}).(\nnm{rRate}) \ ;
      \]
      \[
      \textit{sigma2\_new}  \leftarrow \textit{sigma2} -  \sum_{s=1}^{c}
             (\ms_a.\nnm{succ}^{s-1}).(\nnm{rRate})^2 \ ;
      \]
\item Note that still $y =  \textit{StateBefore}(\ms_a)$ as was assigned above.\\
      For $1 \leq s \leq c$ \ denote by $\nnm{Coordinates}_s$ the values
      $(w,i,j,r,d)$ of $\ms_a.\nnm{succ}^{s-1}$.\\
      For $s$ running from 1 to $c$, do:
      \begin{enumerate}
      \item \textit{StepProb2}$(y, \nnm{Coordinates}_{\textit{perm}(s)};
                                            rr_s, lospr_s, lcpr_s)$;
      \item \textit{sumlprob\_new} $ \leftarrow \textit{sumlprob\_new} + lcpr_s + lospr_s $ ;
      \item If (not \textit{SimpleRates}), then
        \begin{enumerate}
        \item  \textit{mu\_new} $ \leftarrow \textit{mu\_new} + rr_s $ ;
        \item  \textit{sigma2\_new} $ \leftarrow \textit{sigma2\_new}  + (rr_s)^2  $ ;
        \end{enumerate}
      \item \textit{ChangeStep}$(y, \nnm{Coordinates}_{\textit{perm}(s)})$;
      \end{enumerate}
\item If \textit{SimpleRates}, let
      \begin{equation}
      \textit{KappaFactor} \leftarrow 1
      \end{equation}
      else
      \begin{equation}
      \textit{KappaFactor} \leftarrow \sqrt{ \frac{\textit{sigma2}}{\textit{sigma2\_new}} }
                  \ttimes \exp\left( \frac{\left(1 - \textit{mu} \right)^2}{2\ttimes\textit{sigma2}}
                   - \frac{\left(1 - \textit{mu\_new} \right)^2}{2\ttimes\textit{sigma2\_new}}  \right) \ .
      \end{equation}
\item \begin{equation}
     \textit{pra}  \leftarrow \textit{KappaFactor} \ttimes \exp(\textit{sumlprob\_new} - \textit{sumlprob})
    \end{equation}
    if (\textit{pra} $ > 1$), then  \textit{pra} $ \leftarrow 1 $.
\end{enumerate}
Part \emph{C}:
\begin{enumerate}[resume]
\item With probability \textit{pra} let \textit{accept} $\leftarrow$ \nnm{True}, else
      \textit{accept} $\leftarrow$ \nnm{False}.
\item If \textit{accept}, then permute the chain from $\ms_a$ to $\ms_b$ by \textit{perm},\\
      and  \textit{Update}$(\ms_a, \ms_b)$.
\end{enumerate}

\subsection{Insert -- Permute}

The function
\textit{MH\_InsPermute}
$(\textsf{input}\ c_0; % \ms_a, \ms_b, c, \textit{perm}, w,i,j,r,d ;
   \textsf{output}\ \textit{misdat, pra, accept})$
is defined as follows.\\
The input parameter $c_0$ is a relatively small integer --
in Siena 3 it is determined adaptively with a maximum value of 40.

First a rough description is given.
\medskip

First a vector of coordinates $(w_0,i_0,j_0,r_0,d_0)$ is selected.
The output variable \textit{misdat} indicates whether option
$(w_0,i_0,j_0,r_0)$ is missing (see function \textit{mis} defined above).

In the regular case, where \textit{misdat} = \nnm{False},
the proposal is made to insert the non-diagonal coordinates  $(w_0,i_0,j_0,r_0,d_0)$ before
a random ministep $\ms_a$
and insert $(w_0,i_0,j_0,r_0,-d_0)$ before some ministep $\ms_b$
with $\ms_a < \ms_b$,
such that the two inserted ministeps will be a CCP.
This requires the following:\\
$\blacktriangleright \Big((w_0 = N) \Rightarrow i_0 \neq j_0\Big)$ and
     $\Big((w_0 = B) \Rightarrow d_0 \neq 0\Big)$;\\
%$\blacktriangleright $ there is at least one ministep between $\ms_a$ and $\ms_b$
%(i.e., $\textit{length}(\ms_a,\ms_b) \geq 3$);\\ omitted 10-03-10
     \addcc{Condition omitted }\\
$\blacktriangleright $ there are no ministeps of  the type  $(w_0,i_0,j_0,r_0)$ in the
interval  $[\ms_a, \ms_b.\nnm{pred}]$.
\     \addcc{ changed }

The number $c$ is $\min\{c_0, \textit{length}(\ms_a,\ms_b)-1\}$.
If $c \geq 2$,
\textit{perm} is a permutation of the numbers $ 1, 2, \ldots, c$,
and the proposal includes permuting the ministeps in the interval
$[\ms_a, \ms_a.\nnm{succ}^{{c-1}}]$ by \textit{perm}.

If  \textit{misdat} = \nnm{True},
the proposal is made to insert the non-diagonal ministep \\
$(w_0,i_0,j_0,r_0,d_0)$ before
a random ministep $\ms_a$, and permute the $c$ ministeps starting with $\ms_a$,
where again $c$ is $c_0$ truncated to the number of available places.

This proposal has  probability \textit{pra}, and
with this probability the proposal is put into effect (yielding \textit{accept} = \nnm{True})
or not (yielding \textit{accept} = \nnm{False}).

The steps taken in the function are as follows.

Part \emph{A}:
\begin{enumerate}
\item Repeat $\ms_a \leftarrow $ \textit{RandomElement} \ until
%       $\ms_a.\nnm{succ} < \nnm{last}$.  changed 10-03-10
       $\ms_a < \nnm{last}$. \ \addcc{Changed }
\item $y \leftarrow  \textit{StateBefore}(\ms_a) $
\item \textit{StepProb1}$(y, *;  rr, lospr*)$ \\
       With probabilities defined by $\exp(lospr*)$ choose \textit{OptionSet} $(w_0,i_0,r_0)$.\\
      If $i_0$ is not active, exit.
\item \textit{StepProb2}$( y, w_0,i_0,*,r_0,*;  rr, lospr, lcpr*)$ \\
      With probabilities defined by $\exp(lcpr*)$: \\
      if $w_0=N$ choose $j_0$ and let $d_0 = 0$,
      if $w_0=B$ choose $d_0$ and let $j_0=0$.\\
      If $(w_0,i_0,j_0,r_0,d_0)$ is diagonal then exit.\\
      If $w_0=N$ and $N^{(r_0)}(i_0,j_0)$ is structurally fixed,
      or $w_0=B$ and $B^{(r_0)}(i_0)$ is structurally fixed, then exit.

      Denote the log-probability of the realized choice by $lcpr$;\\
      note that also $lospr$ now is the log-probability of the  option set choice
      realized in the preceding step, so it was already calculated earlier.
\item $\textit{misdat}  \leftarrow \textit{mis}(w_0,i_0,j_0,r_0)$
\newpage
\item \begin{enumerate}
      \item If (not \textit{misdat}):
             \begin{enumerate}
              \item             Let $\ms_d$ be \\
                the first ministep in the chain after $\ms_a$
                of \textit{Option} $(w_0,i_0,j_0,r_0)$; \\
                or the \nnm{last} ministep
                if there is no ministep after $\ms_a$ of this \textit{Option}.\\
                This can be determined using the pointer \nnm{succOption}.
             \item    $\textit{ChoiceLength} \leftarrow \textit{length}(\ms_a, \ms_d ) - 1$
                \   \addcc{Changed }
                \\ \addcc{Condition (iii) omitted }
  %           \item             If $\textit{ChoiceLength} \leq 0$ then exit.
             \end{enumerate}
      \item If \textit{misdat}:\\
            $\textit{ChoiceLength} \leftarrow 1 $
      \end{enumerate}
\item \begin{enumerate}
       \item  If (not \textit{misdat}):\\
%              Let $\ms_b$ a random ministep in the interval $[\ms_a.\nnm{succ}^2, \ms_d ]$.\\
               Let $\ms_b$ a random ministep in the interval $[\ms_a.\nnm{succ}, \ms_d ]$.
               \  \addcc{Changed } \\
              Note that the number of choices here is \textit{ChoiceLength}.
       \item  If \textit{misdat}:\\
              $\ms_b \leftarrow \nnm{last}$
       \end{enumerate}
\item $\textit{ThisLength} \leftarrow \textit{length}(\ms_a, \ms_b) -1$ \\
      $c \leftarrow \min\{c_0, \textit{ThisLength} \}$ \\
      $\ms_e \leftarrow \ms_a.\nnm{succ}^{(c-1)}$
\item Let \textit{perm} be a random permutation of the numbers $1$ to $c$.
\item For all $r, 1 \leq r \leq R_B$, check (\ref{behrec2}) for the chain
      with:\\
        $(w_0,i_0,j_0,r_0,d_0)$ inserted before $\ms_a$,\\
      if (not \textit{misdat}): $(w_0,i_0,j_0,r_0,-d_0)$ inserted before $\ms_b$, \\
       and  the interval
      $[\ms_a, \ms_e]$ permuted according to \textit{perm}. \\
      If the variable $(w_0,r_0)$ is involved in a condition of the kind
      \nnm{uponly}, \nnm{downonly}, \nnm{higher}, \nnm{disjoint}, or \nnm{atleastone},
      then similarly check these conditions
      for the potential new chain.\\
      If at least one of these conditions are not satisfied, exit.
\end{enumerate}
The proposal probability is
\[
%  \frac{\exp{(lospr + lcpr)}}{(\textit{TotNumber}-2)\ttimes \textit{ChoiceLength} \ttimes (c!)}
  \frac{\exp{(lospr + lcpr)}}{(\textit{TotNumber}-1)\ttimes \textit{ChoiceLength} \ttimes (c!)}
\]
 \addcc{Changed } \\
This is used in \textit{pra} below.
We also need the probability of the inverse proposal
(except for the factor $c! $ which cancels),
and therefore calculate the following.
\begin{enumerate}[resume]
\item
      \begin{eqnarray*}
      \text{if (not } \textit{misdat}): & pr_1 \leftarrow &
                \frac{1 - \textit{prmin} - \textit{prmib}}{\textit{CCPNumber}+1 } \ ; \\[1em]
       \text{if } \textit{misdat} \text{ and } w_0 = N:   & pr_1 \leftarrow &
                              \frac{\textit{prmin}}{\textit{ChainNumMisNet}+1 } \ ; \\[1em]
       \text{if } \textit{misdat} \text{ and } w_0 = B:  & pr_1 \leftarrow  &
                 \frac{\textit{prmib}}{\textit{ChainNumMisBeh}+1 } \ .
      \end{eqnarray*}
\end{enumerate}

Part \emph{B}:
\begin{enumerate}[resume]
\item \[ \textit{sumlprob} \leftarrow \sum_{s=1}^{\textit{ThisLength}}
             (\ms_a.\nnm{succ}^{s-1}).(\nnm{lChoiceProb} + \nnm{lOptionSetProb}) \ ;
      \]
      If (not \textit{SimpleRates}), then below we use
      the values \textit{mu} and \textit{sigma2}; \\
      these refer to the current chain.\\
      \[
      \textit{sumlprob\_new}  \leftarrow 0 \ ;
      \]
      \[
      \textit{mu\_new}  \leftarrow \textit{mu} -  \sum_{s=1}^{\textit{ThisLength}}
             (\ms_a.\nnm{succ}^{s-1}).(\nnm{rRate}) \ ;
      \]
      \[
      \textit{sigma2\_new}  \leftarrow \textit{sigma2} -  \sum_{s=1}^{\textit{ThisLength}}
             (\ms_a.\nnm{succ}^{s-1}).(\nnm{rRate})^2 \ ;
      \]
\item Note that still $y =  \textit{StateBefore}(\ms_a)$ as was assigned above.\\
      \textit{StepProb2}$(y,w_0,i_0,j_0,r_0,d_0;  rr_0, lospr_0, lcpr_0)$;\\
        \textit{sumlprob\_new} $ \leftarrow \textit{sumlprob\_new} + lcpr_0 + lospr_0 $ ;\\
      If (not \textit{SimpleRates}), then
      \begin{enumerate}
      \item \textit{mu\_new} $ \leftarrow  \textit{mu\_new} + rr_0 $;
      \item \textit{sigma2\_new} $ \leftarrow \textit{sigma2\_new}  + (rr_0)^2  $.
      \end{enumerate}
      \textit{ChangeStep}$(y, (w_0,i_0,j_0,r_0,d_0))$
\item For $1 \leq s \leq \textit{ThisLength}$ \
      denote by $\nnm{Coordinates}_s$ the values
      $(w,i,j,r,d)$ of $\ms_a.\nnm{succ}^{s-1}$.
\item For $s$ running from 1 to $c$, do:
      \begin{enumerate}
      \item \textit{StepProb2}$(y, \nnm{Coordinates}_{\textit{perm}(s)}; rr_s, lospr_s, lcpr_s)$
      \item  \textit{sumlprob\_new} $ \leftarrow \textit{sumlprob\_new} + lcpr_s + lospr_s $
      \item If (not \textit{SimpleRates}), then
        \begin{enumerate}
        \item \textit{mu\_new} $ \leftarrow \textit{mu\_new} + rr_s $\ ;
        \item \textit{sigma2\_new} $ \leftarrow   \textit{sigma2\_new}  + (rr_s)^2  $ \ .
        \end{enumerate}
      \item\textit{ChangeStep}$(y, \nnm{Coordinates}_{\textit{perm}(s)})$
      \end{enumerate}
\item For $s$ running from $c+1$ to \textit{ThisLength} do:
      \begin{enumerate}
      \item \textit{StepProb2}$(y, \nnm{Coordinates}_{s}; rr_s, lospr_s, lcpr_s)$
      \item \textit{sumlprob\_new} $ \leftarrow \textit{sumlprob\_new} + lcpr_s + lospr_s $
      \item If (not \textit{SimpleRates}), then
        \begin{enumerate}
        \item \textit{mu\_new} $ \leftarrow  \textit{mu\_new} + rr_s $
        \item \textit{sigma2\_new} $ \leftarrow \textit{sigma2\_new}  + (rr_s)^2  $
        \end{enumerate}
      \item \textit{ChangeStep}$(y, \nnm{Coordinates}_{s})$
      \end{enumerate}
%\newpage
\item if (not \textit{misdat}):
      \begin{enumerate}
      \item \textit{StepProb2}$(y,w_0,i_0,j_0,r_0,-d_0; rr_0, lospr_0, lcpr_0)$
      \item \textit{sumlprob\_new} $ \leftarrow \textit{sumlprob\_new} + lcpr_0 + lospr_0 $
      \item If (not \textit{SimpleRates}), then
         \begin{enumerate}
         \item  \textit{mu\_new} $ \leftarrow \textit{mu\_new} + rr_0 \ $ ;
         \item \textit{sigma2\_new} $ \leftarrow \textit{sigma2\_new}  + (rr_0)^2 \ $ .
         \end{enumerate}
      \item \textit{ChangeStep}$(y, (w_0,i_0,j_0,r_0,-d_0))$ \\
            Note that at this point, $y$ has been transformed to
            \textit{StateBefore}$(\ms_b)$ of the current (`old') chain.
      \end{enumerate}
\item If \textit{SimpleRates}, then
      \begin{enumerate}
      \item if (not \textit{misdat}):
        \begin{equation}
        \textit{KappaFactor} \leftarrow \frac{1}{rr^2
                      \times(\textit{TotNumber } + 1) \times(\textit{TotNumber } + 2)} \nonumber
        \end{equation}
      \item if \textit{misdat}:
        \begin{equation}
        \textit{KappaFactor} \leftarrow \frac{1}{rr \times(\textit{TotNumber } + 1) } \nonumber
        \end{equation}
      \end{enumerate}
      else (i.e., if not \textit{SimpleRates})
      \begin{equation}
      \textit{KappaFactor} \leftarrow \sqrt{ \frac{\textit{sigma2}}{\textit{sigma2\_new}} }
                  \ttimes \exp\left( \frac{\left(1 - \textit{mu} \right)^2}{2\ttimes\textit{sigma2}}
                   - \frac{\left(1 - \textit{mu\_new} \right)^2}{2\ttimes\textit{sigma2\_new}}  \right) \ .
      \end{equation}
\item \begin{align}
     \textit{pra}  \leftarrow &
        \textit{KappaFactor} \ttimes \exp(\textit{sumlprob\_new} - \textit{sumlprob}) \nonumber \\
  \nonumber
%     & \ttimes  \frac{prdpr \ttimes pr_1 \ttimes (\textit{TotNumber}-2)\ttimes \textit{ChoiceLength} }
      & \ttimes  \frac{prdpr \ttimes pr_1 \ttimes (\textit{TotNumber}-1)\ttimes \textit{ChoiceLength} }
                     {pripr \ttimes \exp{(lospr + lcpr)}}
    \end{align}
 \addcc{Changed } \\
    if (\textit{pra} $ > 1$), then  \textit{pra} $ \leftarrow 1 $.
\end{enumerate}
Part \emph{C}:
\begin{enumerate}[resume]
\item With probability \textit{pra} let \textit{accept} $\leftarrow$ \nnm{True}, else
      \textit{accept} $\leftarrow$ \nnm{False}.
\item If \textit{accept}, then
       \begin{enumerate}
       \item insert $(w_0,i_0,j_0,r_0,d_0)$ before $\ms_a$;
       \item if (not \textit{misdat}), insert $(w_0,i_0,j_0,r_0,-d_0)$ before $\ms_b$;
       \item permute the chain from $ms_a$ to $\ms_a.\nnm{succ}^{c-1}$ by \textit{perm};
       \item  \textit{Update} the chain for the changed part.
       \end{enumerate}
\end{enumerate}

\subsection{Delete -- Permute}

The function
\textit{MH\_DelPermute}
$(\textsf{input}\ c_0;%  \ms_a, \ms_b, c, \textit{perm} ;
   \textsf{output}\ \textit{misdat, $w_0$, pra, accept})$
is defined as follows.\\
The input parameter $c_0$ is a relatively small integer --
in Siena 3 it is determined adaptively with a maximum value of 40.

First a rough description is given.

At the start, there is a choice between deleting a ministep
for a missing data variable, reflected by \textit{misdat} = \nnm{True}; or deleting a CCP,
reflected by \textit{misdat} = \nnm{False}.
Although this seems to be quite different, still it has been
combined in one procedure because the overlap in the
missing and non-missing cases is so large.

If \textit{misdat} = \nnm{False} (the regular case),
the proposal is made to delete two ministeps
$\ms_a$ and $\ms_b$ that together are a CCP.\\
Then the number $c$ is $\min\{c_0, \textit{length}(\ms_a,\ms_b)-2\}$.
\\
If \textit{misdat} = \nnm{True},
the proposal is made to delete one ministep
for a missing data variable, $\ms_a$.\\
Then $c = \min\{c_0, \textit{length}(\ms_a,\nnm{last})-2\}$.

In both cases, the output parameter $w_0$ is the aspect
(Network or Behavior) of ministep $\ms_a$.
The reason for having this output is the possibility to tune
the values of the probabilities \textit{prmin} and  \textit{prmib}.

In addition, if $c \geq 2$,
\textit{perm} is a permutation of the numbers $ 1, 2, \ldots, c$,
and the proposal includes permuting the ministeps in the interval
$[\ms_a.\nnm{succ}, \ms_a.\nnm{succ}^{c}]$ by \textit{perm}.

This proposal has  probability \textit{pra}, and
with this probability the proposal is put into effect (yielding \textit{accept} = \nnm{True})
or not (yielding \textit{accept} = \nnm{False}).

The steps taken in the function are as follows.


Part \emph{A}:
\begin{enumerate}
\item With probability \textit{prmin} + \textit{prmib}
      let $\textit{misdat} \leftarrow \nnm{True}$,\\
      else $\textit{misdat} \leftarrow \nnm{False}$.
\item \begin{enumerate}
      \item if (not \textit{misdat}):
            \begin{enumerate}
            \item If \textit{CCPNumber} = 0, then exit.
            \item $(\ms_a, \ms_b) \leftarrow $ \textit{RandomCCP}
            \item $\textit{ThisLength} \leftarrow \textit{length}(\ms_a, \ms_b)$
            \end{enumerate}
      \item if \textit{misdat}:\\
            \begin{enumerate}
            \item  With probability
                   \[
                      \frac{\textit{prmin}}{\textit{prmin} + \textit{prmib}}
                   \]
                   let $w_0 \leftarrow N$,  else  $w_0 \leftarrow B$.
            \item  if $w_0 = N$, then
                    \begin{enumerate}
                    \item if \textit{ChainNumMisNet} = 0, then exit.
                    \item $\ms_a \leftarrow $ \textit{RandomMisNet}
                    \end{enumerate}
            \item  if $w_0 = B$, then
                    \begin{enumerate}
                    \item if \textit{ChainNumMisBeh} = 0, then exit.
                    \item $\ms_a \leftarrow $ \textit{RandomMisBeh}
                    \end{enumerate}
            \item $\textit{ThisLength} \leftarrow \textit{length}(\ms_a, \nnm{last})$
            \end{enumerate}
      \end{enumerate}
\item  $c \leftarrow \min\{c_0, \textit{ThisLength} - 2\}$.\\
      Note that in the case (not \textit{misdat}) the definition of a CCP implies $c \geq 1$.\\
      If \textit{misdat}, it is possible that $c=0$, which simply means that
      the permutation \textit{perm} is nil but formally everything below is OK.
\item Let \textit{perm} be a random permutation of the numbers $1$ to $c$.
\item $y \leftarrow  \textit{StateBefore}(\ms_a)$ .
\item For all $r, 1 \leq r \leq R_B$, check (\ref{behrec2}) for the chain
      with   $\ms_a$ and $\ms_b$ deleted,  and with
      the ministeps in the interval $[\ms_a.\nnm{succ}, \ms_a.\nnm{succ}^{c}]$
      permuted according to \textit{perm}. \\
      $(w_0,i_0,j_0,r_0,d_0) \leftarrow \textit{Coordinates}(\ms_a)$.\\
      If the variable $(w_0,r_0)$ is involved in a condition of the kind
      \nnm{uponly}, \nnm{downonly}, \nnm{higher}, \nnm{disjoint}, or \nnm{atleastone},
      then similarly check these conditions
      for the potential new chain.\\
      If at least one of these conditions are not satisfied, exit.
\end{enumerate}
To calculate the proposal probabilities of this proposal and the inverse proposal,
used in $pra$ below,
we need to calculate the following.
\begin{enumerate}[resume]
\item
      \begin{eqnarray*}
      \text{if (not } \textit{misdat}): & pr_1 \leftarrow &  \frac{1 - \textit{prmin} - \textit{prmib}}{\textit{CCPNumber} } \ ; \\[1em]
       \text{if } \textit{misdat} \text{ and } w_0 = N:   & pr_1 \leftarrow &
                              \frac{\textit{prmin}}{\textit{ChainNumMisNet} } \ ; \\[1em]
       \text{if } \textit{misdat} \text{ and } w_0 = B:  & pr_1 \leftarrow  &
                 \frac{\textit{prmib}}{\textit{ChainNumMisBeh} } \ .
      \end{eqnarray*}
 \item If (not \textit{misdat}):
      \begin{enumerate}
      \item let $\ms_d$ be \\
          the first ministep in the chain after $\ms_b$
          of the same \textit{Option} $(w_0,i_0,j_0,r_0)$; \\
          or the \nnm{last} ministep
          if there is no ministep after $\ms_b$ of this \textit{Option}.\\
          This can be determined using the pointer \nnm{succOption}.
      \item       Let $\textit{ChoiceLength} \leftarrow \textit{length}(\ms_a, \ms_d ) - 3$.\\
      Note that \textit{ChoiceLength}$ \geq 1$.\\
      The information we need in the following is only \textit{ChoiceLength},
      we can forget about $\ms_d$ itself.
      \end{enumerate}
\item If \textit{misdat}, $\textit{ChoiceLength} \leftarrow 1$ . \\
\end{enumerate}
The probability of this proposal is
\[
\frac{pr_1}{c!} \ .
\]

%\newpage
Part \emph{B}:
\begin{enumerate}[resume]
\item \[ \textit{sumlprob} \leftarrow \sum_{s=1}^{\textit{ThisLength}}
             (\ms_a.\nnm{succ}^{s-1}).(\nnm{lChoiceProb} + \nnm{lOptionSetProb}) \ ;
      \]
      If (not \textit{SimpleRates}), then below we use
      the values \textit{mu} and \textit{sigma2}; \\
      these refer to the current chain.
      \[
      \textit{sumlprob\_new}  \leftarrow 0 \ ;
      \]
      \[
      \textit{mu\_new}  \leftarrow \textit{mu} -  \sum_{s=1}^{\textit{ThisLength}}
             (\ms_a.\nnm{succ}^{s-1}).(\nnm{rRate}) \ ;
      \]
      \[
      \textit{sigma2\_new}  \leftarrow \textit{sigma2} -  \sum_{s=1}^{\textit{ThisLength}}
             (\ms_a.\nnm{succ}^{s-1}).(\nnm{rRate})^2 \ ;
      \]
\item $lpr_0 \leftarrow \ms_a.(\nnm{lChoiceProb} + \nnm{lOptionSetProb}) $\\
      (This is part of the log probability for the reverse proposal.)
\item For $1 \leq s \leq \textit{ThisLength}-2$ \
      denote by $\nnm{Coordinates}_s$ the values
      $(w,i,j,r,d)$ of $\ms_a.\nnm{succ}^{s}$.
\item Note that still $y =  \textit{StateBefore}(\ms_a)$ as was assigned above.\\
      For $s$ running from 1 to $c$, do:
      \begin{enumerate}
      \item \textit{StepProb2}$(y, \nnm{Coordinates}_{\textit{perm}(s)};
                                            rr_s, lospr_s, lcpr_s)$
      \item
        \textit{sumlprob\_new} $ \leftarrow \textit{sumlprob\_new} + lcpr_s + lospr_s $
      \item If (not \textit{SimpleRates}), then
         \begin{enumerate}
          \item \textit{mu\_new} $ \leftarrow  \textit{mu\_new} + rr_s  $
          \item \textit{sigma2\_new} $ \leftarrow \textit{sigma2\_new}  + (rr_s)^2 $
         \end{enumerate}
      \item \textit{ChangeStep}$(y, \nnm{Coordinates}_{\textit{perm}(s)})$
      \end{enumerate}
%\newpage
\item For $s$ running from $c+1$ to $\textit{ThisLength} -2$ do:
      \begin{enumerate}
      \item \textit{StepProb2}$(y, \nnm{Coordinates}_{s};
                                            rr_s, lospr_s, lcpr_s)$
      \item
        \textit{sumlprob\_new} $ \leftarrow \textit{sumlprob\_new} + lcpr_s + lospr_s $
      \item If (not \textit{SimpleRates}), then
         \begin{enumerate}
         \item  \textit{mu\_new} $ \leftarrow \textit{mu\_new} + rr_s  $
         \item   \textit{sigma2\_new} $ \leftarrow \textit{sigma2\_new}  + (rr_s)^2 $
         \end{enumerate}
      \item \textit{ChangeStep}$(y, \nnm{Coordinates}_{s})$;\\
            note that at this point, if (not \textit{misdat}), $y$ has been transformed to
            \textit{StateBefore}$(\ms_b)$ of the current (`old') chain.
      \end{enumerate}
\item If \textit{SimpleRates}, then
      \begin{enumerate}
      \item if (not \textit{misdat}):
        \begin{equation}
        \textit{KappaFactor} \leftarrow rr^2
                      \times \textit{TotNumber } \times(\textit{TotNumber } -1) \nonumber
        \end{equation}
      \item if \textit{misdat}:
        \begin{equation}
        \textit{KappaFactor} \leftarrow rr \times \textit{TotNumber }  \nonumber
        \end{equation}
      \end{enumerate}
      else (i.e., if not \textit{SimpleRates})
      \begin{equation}
      \textit{KappaFactor} \leftarrow \sqrt{ \frac{\textit{sigma2}}{\textit{sigma2\_new}} }
                  \ttimes \exp\left( \frac{\left(1 - \textit{mu} \right)^2}{2\ttimes\textit{sigma2}}
                   - \frac{\left(1 - \textit{mu\_new} \right)^2}{2\ttimes\textit{sigma2\_new}}  \right) \ .
      \end{equation}
\item \begin{align}
     \textit{pra}  \leftarrow \ &
        \textit{KappaFactor} \ttimes \exp(\textit{sumlprob\_new} - \textit{sumlprob}) \nonumber \\
%          & \ \ttimes  \frac{pripr \ttimes \exp(lpr_0)}{prdpr \ttimes pr_1 \ttimes \textit{TotNumber}
           & \ \ttimes  \frac{pripr \ttimes \exp(lpr_0)}{prdpr \ttimes pr_1 \ttimes
                                                  \textit{(TotNumber+1)}
                                           \ttimes \textit{ChoiceLength} }
    \end{align}
 \addcc{Changed } \\
    if (\textit{pra} $ > 1$), then  \textit{pra} $ \leftarrow 1 $.
\end{enumerate}
Part \emph{C}:
\begin{enumerate}[resume]
\item With probability \textit{pra} let \textit{accept} $\leftarrow$ \nnm{True}, else
      \textit{accept} $\leftarrow$ \nnm{False}.
\item If \textit{accept}, then
       \begin{enumerate}
       \item permute the chain from $ms_a$ to $\ms_a.\nnm{succ}^{c-1}$ by \textit{perm};
       \item delete $\ms_a$;
       \item if (not \textit{misdat}), delete $\ms_b$;
       \item  \textit{Update} the chain for the changed part.
       \end{enumerate}
\end{enumerate}

\subsection{Randomize Missings}
%\addab{This section is new in the version of February 8, 2010.}

The function
\textit{MH\_RandomMis}
$( \textsf{output}\  w_0,i_0,j_0,r_0,\, \textit{pr})$
is defined as follows.
First a rough description is given.

This function is called only when there is at least
one missing value at the start of the period,
 in $y(t_{m-1})$.
A random selection is made among the variables for which
this is the case.
This yields the output values $(w_0,i_0,j_0,r_0)$.\\
For this variable,
a Gibbs sampling step is taken.
This means that
the initial value $N_{ij}^{(r)}(t_{m-1})$
or $B_{i}^{(r)}(t_{m-1})$, respectively, is determined
according to a random draw from its conditional
distribution given the rest of the chain.

This distribution is the probability vector \textit{pr},
which also is output.
The reason for wanting this output is that for
the prediction of the missing value, using this probability
vector is much more efficient than using
the realized random draw.

The steps taken in the function are as follows.
\newpage
Part \emph{A}:
\begin{enumerate}
\item If \textit{ChainNumInitMis} $ = 0$, then exit.
\item \[
        (w_0,i_0,j_0,r_0) \leftarrow \emph{RandomInitMis}
       \]
\end{enumerate}
Proposal probabilities are not relevant here,
as this is a Gibbs step.

%\newpage
Part \emph{B}:
\begin{enumerate}[resume]
\item \[ \textit{sumlprob} \leftarrow \sum_{\nnm{chain}}
             (\ms.(\nnm{lChoiceProb} + \nnm{lOptionSetProb}) \ ;
      \]
      The summation over the \nnm{chain} means that
      the sum is taken over all ministeps from
      \nnm{first}.\nnm{succ} to \nnm{last}.\nnm{pred}.\\
      If (not \textit{SimpleRates}), then below we use
      the values \textit{mu} and \textit{sigma2}; \\
      these refer to the current chain.
\item
      \[
       y  \leftarrow  \textit{StateBefore}(\nnm{first}) \ ;
      \]
      Note that this is $y(t_{m-1})$, with some values
      currently filled in for the missing values
      in this observation.
\item For each ministep \ms\ in the chain, denote by $\nnm{Coordinates}_{\ms}$ the values
      $(w,i,j,r,d)$ of \ms.\\
      Given the choice of $(w_0,i_0,j_0,r_0)$ and given $y$,
      if $w_0 = N$, we denote $V = \{0,1\}$,
      and the initial value of $N_{ij}^{(r)}(t_{m-1})$
      is determined and can be denoted by $v_0 \in \{0, 1\}$;
      if $w_0 = B$, we denote $V = \{1, \ldots, \maxr\}$
      (the range of $B_{i}^{(r)}$),
      and the initial value of $B_{i}^{(r)}(t_{m-1})$
      is determined and can be denoted by $v_0 \in \{1, \ldots, \maxr \}$.
\item \[
       \textit{pr}(v_0) \leftarrow 1
       \]
\item
      For $v \in V \backslash \{v_0\}$, do:
      \begin{enumerate}
      \item
            \[
             y  \leftarrow  \textit{StateBefore}(\nnm{first}) \ ;
             \]
             Note that this is $y(t_{m-1})$, with some values
             currently filled in for the missing values
             in this observation.
            \[
                \ms \leftarrow \nnm{first} \ ;
            \]
            \[
            \textit{sumlprob\_new}  \leftarrow 0 \ ;
            \]
            \[
            \textit{mu\_new}  \leftarrow 0 \ ;
            \]
            \[
            \textit{sigma2\_new}  \leftarrow 0 \ ;
            \]
      \item Repeat :
            \begin{enumerate}
            \item \[
                  \ms \leftarrow \ms.\nnm{succ}
                   \]
            \item \textit{StepProb2}$(y, \nnm{Coordinates}_{\ms}; rr, lospr, lcpr)$;
            \item \textit{sumlprob\_new} $ \leftarrow
                      \textit{sumlprob\_new} + lcpr + lospr $ ;
            \item If (not \textit{SimpleRates}), then
              \begin{enumerate}
              \item  \textit{mu\_new} $ \leftarrow \textit{mu\_new} + rr $ ;
              \item  \textit{sigma2\_new} $ \leftarrow \textit{sigma2\_new}  + (rr)^2  $ ;
              \end{enumerate}
            \item \textit{ChangeStep}$(y, \nnm{Coordinates}_{\ms})$;
            \end{enumerate}
            until (\ms = \nnm{last}.\nnm{pred}).
       \item If \textit{SimpleRates}, let
             \begin{equation}
             \textit{KappaFactor} \leftarrow 1
             \end{equation}
             else
             \begin{equation}
             \textit{KappaFactor} \leftarrow \sqrt{ \frac{\textit{sigma2}}{\textit{sigma2\_new}} }
                         \ttimes \exp\left( \frac{\left(1 - \textit{mu} \right)^2}{2\ttimes\textit{sigma2}}
                          - \frac{\left(1 - \textit{mu\_new} \right)^2}{2\ttimes\textit{sigma2\_new}}  \right) \ .
             \end{equation}
       \item \begin{equation}
            \textit{pr}(v)  \leftarrow \textit{KappaFactor} \ttimes \exp(\textit{sumlprob\_new} - \textit{sumlprob})
           \end{equation}
      \end{enumerate} % end of for $v \in V$ loop
\item \[
       \textit{spr} \leftarrow \sum_{v \in V} \textit{pr}(v)
      \]
\item For all $v \in V$ do:
      \[
      \textit{pr}(v) \leftarrow \frac{\textit{pr}(v)}{\textit{spr}}
      \]
\end{enumerate}

Part \emph{C}:
\begin{enumerate}[resume]
\item Choose a random $v \in V$ according to probabilities \textit{pr}$(v)$.\\
      If $v = v_0$, then exit.
\item Replace, if $w_0 = N$, the initial value of $N_{ij}^{(r)}$
      by $v$; and, if $w_0 = B$,
      the initial value of $B_{i}^{(r)}$ by $v$.
\item \textit{Update}$(\nnm{first}, \nnm{last})$.
\end{enumerate}



\section{Likelihood-based calculations:
         \protect\newline Simulation complete-data log-likelihoods}
\label{S_colol}


THIS SECTION IS INCOMPLETE, TO BE ADDED TO.

BASIC IDEA: \\
Many calls of the MH\_* functions of the preceding sections.\\
For the finally resulting chain:
output sums over ministeps of the score functions produced by
\textit{StepProb4}.\\
Also output total number of MH\_* function calls used
for the various functions,
categorized by their binary output variables \textit{misdat, $w_0$, accept}.

\section{Likelihood-based calculations:
         \protect\newline Robbins-Monro algorithm}
\label{S_MLRM}


THIS SECTION IS INCOMPLETE, TO BE ADDED TO.

BASIC IDEA: \\
The Robbins-Monro algorithm as above, with minor modifications.

\section{Likelihood-based calculations:
         \protect\newline Store chains}
\label{S_store}

For communication with users and with other programs,
it is necessary to have a way of reading chains from files
and writing them to files.
Chains also have to be communicated to R.

For writing, I propose to have two ways of writing them.
Always, one line for each ministep, in their natural order.
Numbers within lines separated by separator that can be space, tab, (comma \& space).
\begin{enumerate}
\item brief: the line gives $w, r, i, j, d$ in this order (note $r$ comes second).
\item long: the line gives $w, r, i, j, d, \nnm{rRate}, \nnm{lOptionSetProb},
             \nnm{lChoiceProb} $ in this order.
\end{enumerate}

\section{Likelihood-based calculations:
         \protect\newline Structurally fixed values}
\label{S_struct}

If $N^{r}(i,j)$ is structurally fixed and $N^{r}(i,j)(t_{m-1}) = N^{r}(i,j)(t_m)$,
then the chain for period $m$ must not contain any ministeps of Option (Network, $i,j,r$).\\
If $B^{r}(i)$ is structurally fixed and $B^{r}(i)(t_{m-1}) = B^{r}(i)(t_m)$,
then the chain for period $m$ must not contain any ministeps of Option (Behavior, $i,*, r$).

For the variables that are structurally fixed but
have values at $t_m$ different from their
values at $t_{m-1}$, the principle is that these changes are enforced
either directly before the \nnm{last} ministep, or as part of the \nnm{last} ministep
(whichever is the simpler or more elegant;
I think the latter). These changes
do not contribute anything to probabilities or rates; this can be implemented
formally by omitting them from sums or by defining \nnm{lChoiceProb} = 0
and \nnm{rRate} = 0.
If there are several such variables, the order in which these changes are enforced
does not matter (and is inconsequential).

\iffalse
\section{Meta-analysis }
\label{S_meta}

Results from several independent network data sets can be combined
in a meta-analysis according to the method of Snijders \& Baerveldt
(2003), who applied the method of Cochran (1954)
(also described by Hedges and Olkin, 1985) to this type of analysis.

Suppose we have $N$ independent network data sets, in which the
same sets of covariates are used, and that were analyzed
by the same model specification. The meta-analysis is done for
each parameter separately.
Thus, for this explanation we
focus on any coordinate of the parameter vector,
and denote this coordinate by \th{}.
From the $j'$th data set we obtain estimate $\hat\theta_j$
with standard error $s_j$.
The model postulates that
\begin{equation}
 \hat\theta_j = \theta_j + E_j,
\end{equation}
where $\theta_j$ for $j = 1, \ldots, N$ is an i.i.d.\ sample
from a distribution with mean $\mu_\theta$ and variance
$\sigma^2_\theta$; and $E_j$ is independent of $\theta_j$
and has mean 0 and standard deviation $s_j$.
Thus, we ignore in this analysis the error in the estimation
of the estimation error $\var(E_j)$.
The purpose of the meta-analysis is
estimating and testing $\mu_\theta$ and $\sigma^2_\theta$.

What we observe from data set $j$ is not \th{j} but
the estimate ${\hat{\theta}}_j\,$. This is a random variable
with mean $\mu_\theta$ and variance $\sigma^2_\theta + s_j^2\,$.
In the following, an unbiased estimator for $\sigma^2_\theta$ and
a two-stage estimator for the mean $\mu_\theta$ are given.

A preliminary unbiased estimator for $\mu_\theta$ is given by
\begin{equation}
{\hat{\mu}}_\theta^{\mbox{\tiny OLS}} = \frac{1}{N}\, \sum_j {\hat{\theta}}_j \ .
         \label{muols}
\end{equation}
This estimator does not take into account the fact that the standard errors
$s_j^2$ may be different.
This implies that, although it is unbiased, the estimator may be inefficient.
Its standard error is
\begin{equation}
 \mbox{s.e.}\left( {\hat{\mu}}_\theta^{\mbox{\tiny OLS}} \right) =
    \sqrt{\frac{1}{N} \left( \sigma^2_\theta + {\bar{s}}^2 \right) }
\end{equation}
where
\begin{equation}
{\bar{s}}^2 =  \frac{1}{N} \sum_j s^2_j\ .
\end{equation}
An unbiased estimator for the variance $\sigma^2_\theta$ is
\begin{equation}
 {\hat{\sigma}}^{2, \mbox{\tiny OLS}}_\theta =
   \frac{1}{N-1} \sum_j \left( {\hat{\theta}}_j -
                         {\hat{\mu}}^{\mbox{\tiny OLS}}_\theta \right)^2
               \, - \, {\bar{s}}^2  \ .          \label{sigmahat}
\end{equation}
If this yields a negative value, it will be good to truncate it to 0.

Given that the latter estimator has been calculated, it can be used for an improved
estimation of $\mu_\theta$, viz., by the weighted least squares
(WLS) estimator
\begin{equation}
 {\hat{\mu}}_\theta^{\mbox{\tiny WLS}} =
       \frac{ \sum_j \left( {\hat{\theta}}_j / ({\hat{\sigma}}^{2, \mbox{\tiny OLS}}_\theta
                    + s^2_j ) \right) }
            { \sum_j \left( 1/({\hat{\sigma}}^{2, \mbox{\tiny OLS}}_\theta + s^2_j ) \right)} \ .
                                               \label{muwls}
\end{equation}
This is the 'semi-weighted mean' of Cochran (1954)
treated also in Hedges and Olkin (1985, Section 9.F).
Its standard error can be calculated as
\begin{equation}
 \mbox{s.e.}\left( {\hat{\mu}}_\theta^{\mbox{\tiny WLS}} \right) =
     \frac {1}
     {\sqrt{ \sum_j 1/({\hat{\sigma}}^{2, \mbox{\tiny OLS}}_\theta + s^2_j ) } } \ .  \label{se1}
\end{equation}

It is also possible to continue and iterate the two equations
\begin{eqnarray*}
 {\hat{\sigma}}^2 &=& \max\left\{
   \frac{1}{N-1} \sum_j \left( {\hat{\theta}}_j -
                         {\hat{\mu}} \right)^2
               \, - \, {\bar{s}}^2
               , \, 0 \right\}                     \\            \label{sigma2}
 {\hat{\mu}} &=&
       \frac{ \sum_j \left( {\hat{\theta}}_j / ({\hat{\sigma}}^2
                    + s^2_j ) \right) }
            { \sum_j \left( 1/({\hat{\sigma}}^2 + s^2_j ) \right)}
                                               \label{mu2}
\end{eqnarray*}
until convergence. (Normally, a few iteration steps should suffice.)
The results of this iteration scheme will be denoted by
${\hat{\mu}}_\theta^{\mbox{\tiny IWLS}}$ and
${\hat{\sigma}}_\theta^{2, \mbox{\tiny IWLS}}$.

The standard error
of  $\hat\mu_\theta^{\mbox{\tiny IWLS}}$ can be calculated as
\begin{equation}
 \mbox{s.e.}\left( {\hat{\mu}}_\theta^{\mbox{\tiny IWLS}} \right) =
     \frac {1}
     {\sqrt{ \sum_j 1/({\hat{\sigma}}^{2, \mbox{\tiny IWLS}}_\theta + s^2_j ) } } \ .  \label{se2}
\end{equation}

For testing $\mu_\theta$ and $\sigma^2_\theta$,
it is assumed that the parameter estimates ${\hat{\theta}}_j$
conditional on $\theta_j$
are approximately normally distributed with mean \th{j} and variance $s^2_j$.
The first null hypothesis to be tested is that the effects are 0 in all groups.
This can be tested by the test statistic
\begin{equation}
 T^2 = \sum_j \left( \frac{{\hat{\theta}}_j}{s_j} \right)^2     \label{T^2}
\end{equation}
which has an approximate $\chi^2$ distribution with $N$ degrees of freedom
under the null hypothesis.
The test that the mean effect $\mu_\theta$ is zero can be tested
on the basis of the $t$-ratio
\begin{equation}
 t_{\mu_\theta} =   \frac{{\hat{\mu}}_\theta}
                    { \mbox{s.e.}\left( {\hat{\mu}}_\theta \right) }
\end{equation}
which has approximately a standard normal distribution
under the null hypothesis.
Finally, the test that the variance of the effects $\sigma^2_\theta$ is zero
can be tested using the test statistic
\begin{equation}
 Q = T^2 - {\tilde{t}}^2                                  \label{Q}
\end{equation}
where
\begin{equation}
 \tilde{t} = \frac{\sum_j {\hat{\theta}}_j / s^2_j }
                  {  \sqrt{ \sum_j 1/s^2_j  } }         \label{ttilde}
\end{equation}
which has under the null hypothesis approximately a chi-squared distribution
with $N-1$ degrees of freedom.

\subsection{Fisher combination of $p$-values}

Calculate $p_j^+$ and $p_j^-$ being the right and left one-sided
$p$-values:
\begin{eqnarray*}
   p_j^+ &=& 1 - \Phi\left(\frac{\hat\theta_j}{s_j}\right) \\
   p_j^- &=&  \Phi\left(\frac{\hat\theta_j}{s_j}\right) \ ,
\end{eqnarray*}
where $\Phi$ is the c.d.f.\ of the standard normal distribution.
The Fisher combination statistic is defined as
\begin{eqnarray*}
  C^+_j &=& - 2\, \sum_{j=1}^N \ln\left(p_j^+\right) \\
  C^-_j &=& - 2\, \sum_{j=1}^N \ln\left(p_j^-\right) \ .
\end{eqnarray*}
Both of these must be tested in a $\chi^2$ distribution with
$2\,N$ degrees of freedom.

\subsection{Differences in model specification}

In practice, it can happen that a set of data sets is being
offered for a meta-analysis in which the model specifications
are not identical. An example is the case where one of the
independent variables has variance 0 in some data sets
(e.g.: an analysis of networks in schools, with pupils' sex
as an independent variable; there may be some all-girls or
all-boys schools).

This then must be noted in the output; and the data sets combined
as if this parameter here has an estimate 0 but with an infinite
standard error -- in other words, this parameter should be ignored
for this data set;
and this data set should not add to the degrees of freedom
for this particular parameter.


\subsection{Output to be generated}

\fi


\end{document}

\section{Effects}

Effects are calculated as
\begin{equation}
  f_i(x) \,=\, \sum_k \text{AlterFunction}_k\,x_{ij}
\end{equation}

\section{Interactions}

Users can specify two-effect and three-effect interactions.

I think your construction indeed allows
what I call user-defined interactions.
The following specifies what I think is needed for this;
this includes two-effect but also three-effect interactions.
It is more or less the same as what is used in Siena 3.
I use the names RSiena and CSiena to refer to the R and C
parts of the program code.
Whether the following works exactly as it should
depends also on the precise way in which AlterFunction
is used in the calculation of statistics.
Could you give me the specification of that?

\begin{enumerate}


\item  RSiena: The dataframe of effects must contain
three extra columns ef1, ef2, ef3 which will be used
only for interaction effects. Let us call these effect specifiers.
They define the effects that are interacting: ef1 and ef2 are required;
if ef3 is undefined or zero, then it is a two-effect interaction,
if ef3 is defined then it is a three-effect interaction.
The values ef1, ef2, ef3 refer to the index number
of the effects (or whatever identified is convenient;
I suppose the index number is a good way of referring to it).
\item  Csiena: Effects must have a tag kind with values
{ego, dyadic, interaction, other}.
Ego effects are those depending only on the value of ego
on an actor variable (actor covariate or dependent behavior variable).
Dyadic effects are those depending only on (ego, alter)
and not on other actors.
Interaction variables are the ones we are now defining.
\item  Four types of interaction are allowed:
A: ef1 is an ego effect, ef2 is not an interaction effect, ef3 is undefined.
B: ef1 and ef2 are ego effects, ef3 is defined and not an interaction effect.
C: ef1 and ef2 are dyadic effects, ef3 is undefined.
D: ef1, ef2, ef3 are dyadic effects.
\item  If RSiena passes a non-permitted combination of
effect specifiers to CSiena, then CSiena uses the value 0
for the effect and for the statistic, and transmits to RSiena
a message that the combination of effect specifiers is not allowed.
\item  For types A and C, CSiena uses ProductFunction applied
to the AlterFunction of effects with index numbers ef1 and ef2.
\item  For types B and D, CSiena uses TripleProductFunction
applied to the AlterFunction of effects with index numbers
ef1 and ef2 and ef3, where TripleProductFunction
is just the product of three factors.
\end{enumerate}
