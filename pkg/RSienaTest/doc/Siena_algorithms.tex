\documentclass[a4paper,fleqn,12pt]{article}
% The parameter in [..] can be beamer or handout
% Based on file
% $Header: /cvsroot/latex-beamer/latex-beamer/solutions/generic-talks/generic-ornate-15min-45min.en.tex,v 1.4 2004/10/07 20:53:08 tantau Exp $
% This file is a solution template for:
% - Giving a talk on some subject.
% - The talk is between 15min and 45min long.
% - Style is ornate.
% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.

% When replacing figures, put a % at the end of the line
% to prevent a linebreak being read!



\usepackage{pgf}
%\usepackage[dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{pgflibraryarrows}
\usepackage{colortbl}
\usepackage{amsmath}
\usepackage{latexsym}

% For handouts; see pgfmanual
%\usepackage{pgfpages}
%\pgfpagesuselayout{2 on 1}[border shrink=5mm]


\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:


\newcommand{\Reals}{\mbox{I}\hspace{-.07ex}\mbox{R}}
\newcommand{\E}{\mbox{E}}
\renewcommand{\P}{\mbox{P}}
\newcommand{\se}{\mbox{s.e. }}
\newcommand{\var}{\mbox{var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\logit}{\mbox{logit}}
\newcommand{\uh}{\underline{h}}
\newcommand{\tuh}{\tilde{\uh}}
\newcommand{\neqsum}[3]
{\, \sum_{\stackrel{\scriptstyle #1 = 1}{\scriptstyle #2 \neq #3}}^g
\,}

\newcommand{\equat}[1]{$#1$}
\newcounter{savenumi}
\newcounter{savenumi2}
\newcounter{savenumi3}
\newcounter{savenumi4}





% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command:

%\beamerdefaultoverlayspecification{<+->}
\renewcommand{\baselinestretch}{1.1}
\newcommand{\cc}{\color[named]{SeaGreen}}
\newcommand{\itc}{\color[rgb]{0.1,0.6,0.3}}  % itemcolor
\newcommand{\siec}{\color[named]{Sienna}} % Siena color (RawSiena dvipsnames)
\newcommand{\emec}{\color[rgb]{0.3,0.1,0.0}}  %  \color[named]{Emerald}}


\newcommand{\cdiamond}{{\color[named]{MidnightBlue}\diamond}}
\newcommand{\cbullet}{{\color[named]{MidnightBlue}$\bullet$}}
\newcommand{\cques}{{\color[named]{MidnightBlue}?`}}
\newcommand{\rast}{{\color[named]{Red}$\ast$}}
\newcommand{\gast}{{\color[named]{Green}$\ast$}}

\newcommand{\rtar}{{\itc $\Rightarrow$}}
\newcommand{\qques}{\raisebox{1.2ex}{\rotatebox{180}
                    {\color[named]{ForestGreen}\bf\large ?}}}
\newcommand{\excl}{{\color[named]{ForestGreen}\bf\large !}}
% or OliveGreen


\setlength{\parskip}{1.5ex plus0.5ex minus0.5ex}
\setlength{\parindent}{0ex}

\title{Siena algorithms}

\author{Tom A.B.\ Snijders }




\newcommand{\sx}{{\scriptstyle X}}
\newcommand{\sz}{{\scriptstyle Z}}
\newcommand{\extraver}{{$\phantom{\Big(}$}}
\newcommand{\extraverr}{{$\phantom{\big(}$}}

\renewcommand{\th}[1]{$\theta_{#1}$}
\newcommand{\ga}[1]{$\gamma_{#1}$}
\newcommand{\be}[1]{$\beta_{#1}$}


\newcommand{\vit}{\theenumi}

\newcommand{\mcc}[2]{\multicolumn{#1}{c}{#2}}
\newcommand{\mcp}[2]{\multicolumn{#1}{c|}{#2}}

\newcommand{\equa}[1]{\[#1\]}

\newcommand{\separationb}{\\[0.5ex]\hline\rule{0pt}{2ex}}
\newcommand{\separationg}{\\[0.5ex]\arrayrulecolor{grey}\hline\arrayrulecolor{black}
                         \rule{0pt}{2ex}}

\newcommand{\nm}[1]{\textsf{\small #1}}
\newcommand{\nnm}[1]{\textsf{\small\textit{#1}}}
\newcommand{\nmm}[1]{\nnm{#1}}
\newcommand{\R}{{\sf R }}
\newcommand{\Rn}{{\sf R}}


\begin{document}

\maketitle

This paper gives a sketch of the main algorithms used in RSiena.
It is meant as background material for understanding the code of
RSiena. Hopefully it will later on be included as part of the
programmer's manual of RSiena.


\section{Notation}


Symbols given \nnm{in italic sf font} refer to the names
of variables used in the \R code.

\emph{Generic symbols for variables}

\begin{tabbing}
$i, j$ \hspace*{1em} \=  \hspace*{6em} \=  actors.\\[1ex]
$m$ \> \> index for time period from $t_{m-1}$ to $t_m$ ($m = 2, \ldots, M$).  \\[1ex]
$M$ \> \nnm{observations}   \> total number of observations\\[1ex]
$x$ \> \> all networks jointly.\\[1ex]
$z$ \> \> all behaviors jointly.\\[1ex]
$r$ \> \> index number of networks or behaviors.\\[1ex]
$^X$ \> \> as superscript: refers to network dynamics.\\[1ex]
$^Z$ \> \> as superscript: refers to behavior dynamics.\\[1ex]
$^{\rm{obs}}$ \> \> as superscript: refers to observed values.\\[1ex]
$W$ \> \> variable with values $X$ or $Z$.\\[1ex]
$\theta$ \> \nnm{theta} \> vector of all statistical parameters. \\[1ex]
$p$  \>  \nnm{pp}  \> dimension of $\theta$.\\[1ex]
$J$ \> \>  simulated data score function (vector of partial derivatives of log-likelihood) \\
     \>  \>    ($p$-vector).\\[1ex]
\end{tabbing}
\medskip


\emph{Changing variables (outcomes)}

\begin{tabbing}
$t$ \hspace*{3em} \= time.\\[1ex]
$X^{(r)}_{ij}$ \> dummy tie variable indicating $ i \stackrel{r}{\rightarrow} j $ for $r^{\text{th}}$ network.\\[1ex]
$Z^{(r)}_{i}$ \> behavior variable for $r^{\text{th}}$ behavior for actor $i$.
\end{tabbing}
\medskip

Replacing an index by + denotes summation over this index.\\
Toggling a number $a$ in $\{0, 1\}$ means replacing $a$ by $1-a$.
\medskip

\emph{Functions}

\begin{tabbing}
$\lambda^X(r,i,x,z)$ \hspace*{3em} \= rate function, network $r$.\\
                                  \> (0 for inactive actors)\\[1ex]
$\lambda^Z(r,i,x,z)$ \hspace*{3em} \> rate function, behavior $r$.\\
                                  \> (0 for inactive actors)\\[1ex]
$f^X(r,i,x,z)$ \hspace*{3em} \> evaluation function function, network $r$.\\[1ex]
$f^Z(r,i,x,z)$ \hspace*{3em} \> evaluation function, behavior $r$.\\[1ex]
$g^X(r,i,j,x,z)$ \hspace*{3em} \> endowment function function, network $r$.\\[1ex]
$g^Z(r,i,x,z)$ \hspace*{3em} \> endowment function, behavior $r$.\\[1ex]
$\Delta f^X(r,i,j,x,z)$ \hspace*{3em} \> change in $f^X(r,i,x,z)$
                                by toggling $X^{(r)}_{ij}$.\\[1ex]
$\Delta f^Z(r,i,v,x,z)$ \hspace*{3em} \> change in $f^Z(r,i,x,z)$
                                by changing $Z^{(r)}_i$ to $Z^{(r)}_i + v$.\\[1ex]
$ \sim E(\lambda)$ \> generate random variable according to exponential distribution\\
                   \> with parameter $\lambda$ (note: expected value $1/\lambda$).\\[1em]
\end{tabbing}
Note. Whether the endowment function makes sense for behavior variables with a range
of more than two values, is doubted. But we keep it included anyway, for the moment.
\medskip





\section{Outline of model dynamics / simulation algorithm}

The tie-based model is defined as a continuous-time Markov chain by the following
algorithm for generating the next change in the outcome.
This is formulated here for the case that the state space includes networks as well as behavior.
If there are no behavior variables $Z$, then the steps referring to these variables
can simply be dropped.
In the code this is function \nm{simstats0c}.

To estimate derivatives of expected values of statistics with respect to the
parameters, the score function method (Schweinberger
and Snijders, 2007) is used in the default method to estimate standard errors.
This is indicated by `SF only' and
can be skipped if the
finite differences (`FD') option, which also employs common random numbers,
is used to estimate standard errors.

For each network variable numbered $r$ the following logical (boolean)
variables are defined at the moment of data entry:
\begin{itemize}
\item \nnm{uponly}($r$) = $\big\{\text{for all }i, j, m:
                         x^{(r)\,\rm{obs}}_{ij}(t_{m})  \leq  x^{(r)\,\rm{obs}}_{ij}(t_{m+1}) \big\}$;
\item \nnm{downonly}($r$) = $\big\{\text{for all }i, j, m:
                         x^{(r)\,\rm{obs}}_{ij}(t_{m})  \geq  x^{(r)\,\rm{obs}}_{ij}(t_{m+1}) \big\}$;
\end{itemize}
For each ordered pair of network variables numbered $r$ and $r' \neq r$,
we define the following logical (boolean) variables:
\begin{itemize}
\item \nnm{higher}($r, r'$) = $\big\{\text{for all }i, j, m:
                         x^{(r)\,\rm{obs}}_{ij}(t_{m})  \geq  x^{(r')\,\rm{obs}}_{ij}(t_{m}) \big\}$;
\item  \nnm{disjoint}($r, r'$) = $\big\{\text{for all }i, j, m:
                       \min\{  x^{(r)\,\rm{obs}}_{ij}(t_{m}), \,
                           x^{(r')\,\rm{obs}}_{ij}(t_{m}) \} = 0 \big\}$;
\item \nnm{atleastone}($r, r'$) = $\big\{\text{for all }i, j, m:
                       \max\{  x^{(r)\,\rm{obs}}_{ij}(t_{m}), \,
                           x^{(r')\,\rm{obs}}_{ij}(t_{m}) \} = 1 \big\}$.
\end{itemize}



\emph{Model for microstep}


\begin{enumerate}
\item Initialize  time at $t=0$; initialise networks and behaviors $x, z$ at
      their observations at wave $m-1$.\\
      SF only: initialise the score function at $J_m = 0$.
\item \label{itemstart}
      Current time, networks, behaviors, denoted by $t, x, z$.
\item For all $r$, generate $\Delta t^X_r \sim E(\lambda^X(r,+,x,z))$.
\item For all $r$, generate $\Delta t^Z_r \sim E(\lambda^Z(r,+,x,z))$.
\item Let $W, r$ be the variable for which $\Delta t^W_r = \min_r\{t^X_r, t^Z_r \}$.\\
      If $W = X$, goto \ref{itemx}; if $W = Z$, goto \ref{itemz}.\\
      (\emph{Note}. An alternative, mathematically equivalent, is to choose\\
      $(W, r)$ with probabilities proportional to $\lambda^W(r,+,x,z)$ and\\
      only for this $W, r$ generate $\Delta t^W_r \sim E(\lambda^+(+,+,x,z))$.\\
      This is more efficient but the gain in computation time must be negligible.)
\item Choose $i$ with probabilities $\lambda^W(r,i,x,z) / \lambda^W(r,+,x,z)$.
\item Set $t = t + \Delta t^W_r$. (\emph{time step})
\item SF only:
      set
      \[
      J_m \,=\, J_m \,+\, \Big(\partial \ln \big(\lambda^W(r,i,x,z)/\lambda^+(+,+,x,z)\big) / \partial \theta\Big) \,+\,
         \Big(\partial \ln \lambda^W(r,i,x,z) / \partial \theta\Big) .
      \]
      (Note: first added term for generating $W, r, i$; second term for $t$. )
\item \label{itemx}
      Define $C$ as the set of $j$ for which $X_{ij}^{(r)}$ is allowed to change.\\
      This is the set of all $j \in \{1, \ldots, n\}$ from which are excluded
      all $j \neq i$ for which at least one of the following hold:
      \begin{enumerate}
      \item $X_{ij}^{(r)} $ is structurally determined;
      \item \nnm{uponly}($r$) and $X_{ij}^{(r)} = 1$;
      \item \nnm{downonly}($r$) and $X_{ij}^{(r)} = 0$;
      \item for some $r' \neq r$, \nnm{higher}($r, r'$) and $X_{ij}^{(r)} = X_{ij}^{(r')} = 1$;
      \item for some $r' \neq r$, \nnm{higher}($r', r$) and $X_{ij}^{(r)} = X_{ij}^{(r')} = 0$;
      \item for some $r' \neq r$, \nnm{disjoint}($r, r'$) and $X_{ij}^{(r)} = 0, X_{ij}^{(r')} = 1$;
      \item for some $r' \neq r$, \nnm{atleastone}($r, r'$) and $X_{ij}^{(r)} = 1, X_{ij}^{(r')} = 0$.
      \end{enumerate}
      Obviously, in many cases, there are never any excluded $j$; and if there
      is only one dependent network variable, the four last conditions
      are never satisfied.





      For all $j \in C$, calculate $h_j = \Delta f^X(r,i,j,x,z)$, and $h_i = 0$.\\
      For all $j \in C$ with $X^{r}_{ij} = 1$, calculate $h_j = h_j - g^X(r,i,j,x,z)$.\\
      Choose $j \in C \cup {i}$ with probabilities $\pi_j = \exp(h_j) / \sum_k \exp(h_k)$.\\
      SF only: set
      $J_m = J_m + \partial h_j / \partial \theta \,-\, \sum_k \pi_k\, \partial h_k / \partial \theta  $.\\
      If $j \neq i$, toggle $X^{r}_{ij}$. (\emph{network step})\\
      Goto \ref{itemstart}.
\item \label{itemz}
      Let $C$ be the set of $v \in \{-1, 1\}$ \\
      for which $Z^{(r)}_i + v$ is
      within the range of $Z^{(r)}_i$.\\
      For all $v \in C$, calculate $h_v = \Delta f^Z(r,i,v,x,z)$, and $h_0 = 0$.\\
      If $-1 \in C$, calculate $h_{-1} = h_{-1} - g^Z(r,i,x,z)$.\\
      Choose $v \in C \cup {0}$ with probabilities $\pi_v = \exp(h_v) /\{ \sum_u \exp(h_u)\}$.\\
      SF only: set
      $J_m = J_m + \partial h_v / \partial \theta \,-\, \sum_u \pi_u \, \partial h_u / \partial \theta  $.\\
      Add $v$ to $Z^{r}_{i}$. (\emph{behavior step})\\
      Goto \ref{itemstart}.
\end{enumerate}
\medskip

\emph{Stopping criterion}

\begin{enumerate}
\item In the unconditional estimation option, microsteps continue until
      $t \geq 1$. \\
      Note that, by convention, time duration between waves is set to be unity.\\
      SF only: set \\
      $J_m = J_m - (1 - t^{\rm{last}})
           \big(\partial \ln \lambda^+(+,+,x,z) / \partial \theta\big) $,\\
      where $t^{\rm{last}}$ is the last generated value of $t$ before $t$ exceeded 1.
\item In the conditional estimation option, if the conditioning variable
      is network $X^{(r)}$, microsteps continue until
      \[
      \sum_{i,j} \mid X^{(r)}_{ij} - x^{(r)\,\rm{obs}}_{ij}(t_{m-1}) \mid \geq
       \sum_{i,j} \mid x^{(r)\,\rm{obs}}_{ij}(t_{m})  - x^{(r)\,\rm{obs}}_{ij}(t_{m-1}) \mid \ ,
      \]
      where the sum is over all tie variables that are not structurally fixed
      at $t_{m-1}$ or $t_m$ (note that
      it is possible that tie variables are structurally fixed but have different subsequent values).\\
      If the conditioning variable
      is behavior $Z^{(r)}$, microsteps continue until
      \[
      \sum_{i} \mid Z^{(r)}_{i} - z^{(r)\,\rm{obs}}_{i}(t_{m-1}) \mid \geq
       \sum_{i} \mid z^{(r)\,\rm{obs}}_{i}(t_{m})  - z^{(r)\,\rm{obs}}_{i}(t_{m-1}) \mid \ ,
      \]
      where the sum is over all actors that are not structurally inactive
      at $t_{m-1}$ or $t_m$.
\end{enumerate}
\medskip

\emph{Score function}
\smallskip

The generated statistics $S$ can be written as $S = \sum_{m=2}^M S_m$, where $S_m$ is calculated
in consequence of the simulation of the process in the period from $t_{m-1}$ to $t_m$.
Denote the value of $J$ generated in this period by $J_m$.
To use the score function method, we calculate
\begin{equation}
%  <\!SJ\!> \,=\, \sum_{m=2}^M  (S_m - s_m^{\rm{obs}})J_m' \ .    \label{SJ}
  <\!SJ\!> \,=\, \sum_{m=2}^M  S_m \, J_m' \ .    \label{SJ}
\end{equation}
This is a $p \times p$ matrix,
and an estimate for $\partial E_{\theta}S/\partial \theta$.\\
(Or do we work with $\sum_{m=2}^M  (S_m - s^{\rm{obs}}) J_m'$
for numerical accuracy?)

The decomposition into the $M-1$ periods is kept because it allows a more efficient
variance reduction (see further down).

(Mathematical note: for simulations taking place according to parameter \th{},
$E_{\theta} J_m = 0$.
We will later subtract a value $s_m J_m '$
for an `almost constant' $s_m$; this does not affect the expected value,
but leads to a considerable variance reduction;
see Schweinberger \& Snijders, 2007.)

\section{Outline of Robbins-Monro algorithm for MoM}

This section is based on the appendix of Snijders (2001), and updated
to include the algorithm changes that were incorporated after 2001.
The implementation of the algorithm in RSiena is function
\nm{robmon}, and has a number of additional
details to improve convergence.

The purpose of the algorithm is to approximate the solution of the
moment equation
\begin{equation}
  \E_\theta S = s\, ,   \label{mom_eq0}
\end{equation}
where $s = s^{\rm{obs}}$, the observed value.
The solution is denoted by $\theta_0$.
The algorithm is a multivariate version of the Robbins-Monro (1951) algorithm.
It uses the idea of Polyak (1990) and Ruppert (1988)
to employ a diagonal matrix $D_0$ in the iteration step (\ref{step})
\begin{equation}
 \hat{\theta}_{N+1} = \hat{\theta}_N \, - \, a_N\, D_0^{-1} \, (S_N - s)~,   \label{step}
\end{equation}
 and estimate
the solution by partial averages of $\hat{\theta}_N$ rather than the
last value; and it uses the idea of Pflug (1990) to let the values of $a_N$ remain
constant if the average products of successive values $(S_N - s)(S_{N-1}-s)$
are positive, since this suggests that the process still is drifting toward its
limit value.
However, the specification used here deviates from Pflug's proposal by requiring,
for the premature decrease of $a_N\,$,
that for {\em each} coordinate the partial sum of the product of successive values
be negative, rather than requiring this only for the sum over the coordinates.
Further, the number of steps for which $a_N$ is constant is bounded between a lower
and an upper limit to ensure that $a_N$ is of order $N^{-c}$.

Whether the algorithm yields an estimate that indeed solves
the moment equation (\ref{mom_eq0}) to a satisfactory degree of precision
is checked in the `third phase' of the algorithm below.

The reason for incorporating the matrix $D_0$ is to achieve better compatibility
between the scales of $S$ and of $\theta$.
The diagonal elements of $D_0$ are defined as the estimated values of the derivatives
$\partial \E_{\theta}(S_k) / \partial \theta_k$ where $\theta$ is
at its initial value.
To see that this leads to compatibility of the scales of $S$ and $\theta$
note that in the extreme case where $\var(S_k) = 0$ and the diagonal elements of $D_0$
are equal to
$\partial \E_{\theta}(S_k) / \partial \theta_k$,
(\ref{step}) for $a_N = 1$ is just the iteration step of the Newton-Raphson
algorithm applied to each coordinate of $S$ separately.
Thus, beginning the algorithm with $a_N$ in the order of magnitude of 1
will imply that the initial steps have an approximately right order of magnitude.

The number of dimensions of \th{} and of $S$ is denoted by $p$
and the initial value is denoted \th{1}.
`Generating $ S \sim \theta $' means to simulate the model
according to parameter value $\theta$ and calculate the statistics $S$.

The estimation of derivatives has two options: finite differences (`FD')
and score function (`SF').
SF is more efficient and unbiased (Schweinberger \& Snijders, 2007)
and therefore is the default,
FD is available for some models for which
the derivatives of the log-likelihood needed for SF have not yet been
worked out.

The FD option is based on disturbing the current parameter values
by adding the value $\epsilon_j$, and using common random numbers.
Because of the discrete nature of the simulated
statistics, a very small $\epsilon_j$ will yield simulated values that
with high probability are equal to the values obtained without
the disturbance. This is undesirable
(see Schweinberger \& Snijders, 2007).
Good values of $\epsilon_j$ must be such that with rather
high probability (say, more than .5) the simulated values are
not identical to those obtained without the disturbance.

\newpage

Symbols given \nnm{in italic sf font} refer to the names
of variables used in the \R code.

The algorithm consists of three phases.

\begin{enumerate}
\item In this phase a small number $n_1$ of steps are made to estimate\\
      \nnm{dfra} = $D(\theta_1) = \big(\partial \E_\theta(S) / \partial \theta\big)
                       \mid_{\theta = \theta_1} $.\\
      The diagonal elements of this
      estimate are used to define $D_0$.
      Denote by $e_j$ the $j'$th unit vector in $p$ dimensions.

     Initialise ${{\rm{Sum}}}_{d} = 0_{p \times p}$,
           ${{\rm{Sum}}}_{S} = 0_{p \times 1}$.\\
     For SF, initialise additionally\\
              ${\rm{Sum}}_{Sm} = 0_{p \times 1}$ and
              ${\rm{Sum}}_{Jm} = 0_{p \times 1}$ for $m = 2, \ldots, M$.\\
     For $N = 1$ to $n_1$, do the following.
     \begin{description}
     \item[(FD)] Generate
     \begin{eqnarray*}
       \nnm{fra} &=& S \sim \theta_1  \\
        && S_{j} \sim \theta_1 + \epsilon_j e_j \ (j = 1, \ldots, p),
     \end{eqnarray*}
      where all these $p+1$ random vectors
      use a common random number stream to make them strongly positively
      dependent and where $\epsilon_j$ are suitable constants.\\
      Compute the difference quotients
      \[
      \nnm{sdf} = d_{j} = \epsilon_j^{-1} (S_{j} - S)~;
      \]
      for small values of $\epsilon_j$ the expected value of the matrix
      $d = (d_{1}, ..., d_{p})$ approximates $D(\theta_1)$.
      However, $\epsilon_j$ must be chosen not too small because otherwise
      the variances of the $d_{j}$ become too large.\\
      Update
            \begin{eqnarray*}
            {\rm{Sum}}_{S}  &=& {\rm{Sum}}_{S} + S \\
            {\rm{Sum}}_{d}  &=& {\rm{Sum}}_{d} + d \\
            \end{eqnarray*}
      \item[(SF)] Generate
           \[
           \nnm{fra} = S \sim \theta_1  \\
           \]
               its components being $S_m \, (m = 2, \ldots, M)$
               (see `Score Function' above),
               the complete-data score functions
               $J_{m}$ ($m = 2, \ldots, M$),\\
               and $d = <\!SJ\!>$ according to (\ref{SJ}).
               Update
               \begin{eqnarray*}
               {\rm{Sum}}_{S}  &=& {\rm{Sum}}_{S} + S \\
               {\rm{Sum}}_{d}  &=& {\rm{Sum}}_{d} + d \\
               {\rm{Sum}}_{Sm}  &=& {\rm{Sum}}_{Sm} + S_m, \ m = 2, \ldots, M \\
               {\rm{Sum}}_{Jm}  &=& {\rm{Sum}}_{Jm} + J_m, \ m = 2, \ldots, M \\
               \end{eqnarray*}
     \end{description}

     At the end of Phase 1, calculate the following results:
      \begin{enumerate}
      \item
      Estimate $E_{\theta_1} S$  by
      \[
      \bar{s} = \frac{{\rm{Sum}}_{S}}{n_1} \ .
      \]
      \item
      Estimate $D(\theta_1)$ by
      \begin{eqnarray*}
      \text{FD:    }   \hat{D} &=& \frac{{\rm{Sum}}_{d}}{n_1} \\
      \text{SF:     }  \hat{D} &=& \frac{{\rm{Sum}}_{d}}{n_1} -
                         \frac{\sum_{m=2}^M {\rm{Sum}}_{Sm}{\rm{Sum}}_{Jm}}{n_1^2} \ .
      \end{eqnarray*}
      \item Diagonal matrix $\tilde{D} = \mbox{diag}(\hat{D})$.
      \item Make one partial estimated Newton-Raphson step,
      \[
       {\hat{\theta}} = \theta_1 - a_1 {\hat{D}}^{-1} \left( \bar{s} - s \right)\, .
      \]
      where
      \[
      \nnm{targets} = s = \text{ observed values} .
      \]
      \end{enumerate}

\item[Phase 2.]
     Repeat for $k = 1, \ldots, k_{\rm{max}}$ (subphases):
     \begin{enumerate}
     \item Initialise \nnm{nit} = $N = 0$, ${\rm{Sum}}_{\hat\theta} = 0_{p \times 1}$,
          $S_{\rm{prev}} = 0_{p \times 1}$, \\
          \nnm{ac} = $\rm{AC} = 0_{p \times p}$.
     \item Generate
           \[
           \nnm{fra} = S \sim \theta
           \]
           or, for multiple processors, as the average of \nnm{int}
           independent replicates of such variables, and update
            \begin{eqnarray*}
             \hat{\theta} &\,=\,&
               \hat{\theta} \,-\, a_N\, \tilde{D}^{-1} \, (S - s) \\
             N & = & N+1 \\
            {\rm{Sum}}_{\hat\theta} & = & {\rm{Sum}}_{\hat\theta} + \hat\theta \\
            \text{if $N \geq 2$, then }  \rm{AC} & = & \rm{AC} + (S - s)(S_{\rm{prev}} - s)' \\
            S_{\rm{prev}} &=& S \ .
            \end{eqnarray*}
     \item  If $N >= n_{2k}^+$ or
            ($N >= n_{2k}^-$ and $\max_k \rm{AC}_{kk} \leq 0$), then\\
            $\big\{$ update $\hat\theta \,=\, N^{-1} {\rm{Sum}}_{\hat\theta}$ ;
                   set $a_k = a_k/2 \big\}$ ;
            else goto 2.
     \end{enumerate}
     In the code, \nnm{theta} = $\theta$, \nnm{gain} = $a_N$, \nnm{ac} = AC,
     \nnm{thav} = ${\rm{Sum}}_{\hat\theta}$, \nnm{nit} = $N$,\\
     \nnm{n2min} = $n_{2k}^-$, \nnm{n2max} = $n_{2k}^+$.
\item[Phase 3.]
      Phase 3 is used only for the estimation of $D(\theta)$ and
      $\Cov(\hat\theta)$,
      and as a check for the (approximate) validity of (\ref{mom_eq0}).
      The value of $\hat{\theta}$ is left unchanged in this phase
      and is equal to the value obtained after last subphase of phase 2.
      The procedure is mainly as in phase 1.

     Initialise ${{\rm{Sum}}}_{d} = 0_{p \times p}$,
           ${{\rm{Sum}}}_{S} = 0_{p \times 1}$,
           ${{\rm{SumSq}}}_{S} = 0_{p \times p}$.\\
     For SF, initialise additionally
              ${\rm{Sum}}_{Sm} = 0_{p \times 1}$ and
              ${\rm{Sum}}_{Jm} = 0_{p \times 1}$ for $m = 2, \ldots, M$.\\
     For $N = 1$ to $n_3$, do the following.
     \begin{description}
     \item[(FD)] Generate
     \begin{eqnarray*}
       \nnm{fra} &=& S \sim \theta  \\
        && S_{j} \sim \theta + \epsilon_j e_j \ (j = 1, \ldots, p),
     \end{eqnarray*}
      where all the $p+1$ random vectors
      use a common random number stream to make them strongly positively
      dependent and where $\epsilon_j$ are suitable constants.
      Compute the difference quotients
      \[
      \nnm{sdf} = d_{j} = \epsilon_j^{-1} (S_{j} - S) \ .
      \]
      Update
            \begin{eqnarray*}
            {\rm{Sum}}_{S}  \phantom{Sq} &=& {\rm{Sum}}_{S} + S \\
            {\rm{SumSq}}_{S}  &=& {\rm{SumSq}}_{S} + S\,S' \\
            {\rm{Sum}}_{d}  \phantom{Sq} &=& {\rm{Sum}}_{d} + d \\
            \end{eqnarray*}
      \item[(SF)] Generate
           \[
           \nnm{fra} = S \sim \theta  \\
           \]
               its components being $S_m \, (m = 2, \ldots, M)$
               (see `Score Function' above),
               the complete-data score functions
               $J_{m}$ ($m = 2, \ldots, M$),\\
               and $d = <\!SJ\!>$ according to (\ref{SJ}).
               Update
               \begin{eqnarray*}
               {\rm{Sum}}_{S} \phantom{Sq}  &=& {\rm{Sum}}_{S} + S \\
               {\rm{SumSq}}_{S}  &=& {\rm{SumSq}}_{S} + S\,S' \\
               {\rm{Sum}}_{d} \phantom{Sq}  &=& {\rm{Sum}}_{d} + d \\
               {\rm{Sum}}_{Sm} \phantom{Sq}  &=& {\rm{Sum}}_{Sm} + S_m, \ m = 2, \ldots, M \\
               {\rm{Sum}}_{Jm} \phantom{Sq}  &=& {\rm{Sum}}_{Jm} + J_m, \ m = 2, \ldots, M \\
               \end{eqnarray*}
     \end{description}
     At the end of Phase 3, calculate the following results:
      \begin{enumerate}
      \item
           Estimate $E_{\hat\theta} S$ and $\Cov_{\hat\theta} S$ by
           \[
           \bar{s} = \frac{{\rm{Sum}}_{S}}{n_3} \ , \hspace{1em}
           \Sigma = \frac{{\rm{SumSq}}_{S}}{n_3} \,-\, \bar{s}\,\bar{s}' \ .
           \]
      \item
           To check (approximate) validity of (\ref{mom_eq0}) compute the
           $t$-ratios for convergence,
           \[
           \nnm{tstat} = t_j = \frac{\bar{s}_j - s^{\rm{obs}}_j}{\sigma_j} \ ,
           \]
           where $\sigma_j$ is the square root of the $j'$th diagonal element
           of $\Sigma$.
      \item
           Estimate $D(\hat\theta)$ by
      \begin{eqnarray*}
      \text{FD:    }   \hat{D} &=& \frac{{\rm{Sum}}_{d}}{n_3} \\
      \text{SF:     }  \hat{D} &=& \frac{{\rm{Sum}}_{d}}{n_3} -
                         \frac{\sum_{m=2}^M {\rm{Sum}}_{Sm}{\rm{Sum}}_{Jm}}{n_3^2} \ .
      \end{eqnarray*}
      \item Estimate the covariance matrix of $\hat\theta$ by
            \begin{equation}
            \Cov (\hat\theta) \,=\,  {\hat D}^{-1}  \Sigma {\hat D }^{' -1} \ .
                      \label{eq:cov}
            \end{equation}
            The standard errors are the square roots of the diagonal elements
            of $\Cov (\hat\theta)$.
      \end{enumerate}

\end{enumerate}


This algorithm contains various constants that can be adapted so as to achieve
favorable convergence properties.
Experience with various data sets led to the following values.

The number of steps in phase 1 is
\[
\nnm{n1} =  n_1 = 7 + 3p \ .
\]
The minimum number of steps in subphase $2.k$ is
\[
\nnm{n2minimum[1]} = n_{2k}^- = ((2.52)^k)\times(7+p)
\]
 which is meant to approximate
$n_{2k}^- = 2^{4(k+2)/3}(7+p)$;
the maximum number is
\[
\nnm{n2maximum[1]} = n_{2k}^+ = n_{2k}^- + 200 \ .
\]
For multiple processors, we use
\[
  n_{2k}^- = ((2.52)^{k-1})\times \max \{5, (7+p)\times 2.52/\nnm{int}\}
\]
where \nnm{int} is the number of processors.
These bounds $n_{2k}^-$ and $n_{2k}^+$ are determined so that
$N^{3/4} a_N$ tends to a finite positive limit.\\
For large $p$ they are rather conservative (i.e., unnecessarily large).\\
The default number of steps in phase 3 in the SF option is \nnm{n3} = $n_3 = 1000$.
For the FD option, 500 is a good default.

The default number of subphases is \nnm{nsub} = 4;
more or fewer subphases could be used
to obtain smaller or larger precision, but 4 seems really a good number.\\
The initial value of $a_N$ in phase 2 is \nnm{firstg} = 0.2,
and for multiple processors $0.2 \times \sqrt{\nnm{int}}$.

The values of \nnm{epsilon} = $\epsilon_j$ in the FD option
are chosen initially as 0.1,
but in Phase 1 a check is made and if
the $j'$th coordinate of $d - d_j$ is exactly 0 for all or most
of the simulations then $\epsilon_j$ is adaptively increased.
The variability obtained
by the use of small values of $\epsilon_j$ is more serious than the bias obtained
by the use of a large value.
An ideal value would be to have $\epsilon_j$ slightly less than the
standard error of $\hat\theta_j$. However, this is known only
after the estimation has finished. (Of course in many cases there
have been done earlier estimations, and the information obtained
from them might be used for this purpose.)

\section{Statistics for MoM}

The statistics used for the MoM also deserve attention as part of the
algorithm. See Snijders (2001) and Snijders, Steglich, and Schweinberger (2007).
I hope later on to have time for elaborating this here.

\section{Meta-analysis }

Results from several independent network data sets can be combined
in a meta-analysis according to the method of Snijders \& Baerveldt
(2003), who applied the method of Cochran (1954)
(also described by Hedges and Olkin, 1985) to this type of analysis.

Suppose we have $N$ independent network data sets, in which the
same sets of covariates are used, and that were analyzed
by the same model specification. The meta-analysis is done for
each parameter separately.
Thus, for this explanation we
focus on any coordinate of the parameter vector,
and denote this coordinate by \th{}.
From the $j'$th data set we obtain estimate $\hat\theta_j$
with standard error $s_j$.
The model postulates that
\begin{equation}
 \hat\theta_j = \theta_j + E_j,
\end{equation}
where $\theta_j$ for $j = 1, \ldots, N$ is an i.i.d.\ sample
from a distribution with mean $\mu_\theta$ and variance
$\sigma^2_\theta$; and $E_j$ is independent of $\theta_j$
and has mean 0 and standard deviation $s_j$.
Thus, we ignore in this analysis the error in the estimation
of the estimation error $\var(E_j)$.
The purpose of the meta-analysis is
estimating and testing $\mu_\theta$ and $\sigma^2_\theta$.

What we observe from data set $j$ is not \th{j} but
the estimate ${\hat{\theta}}_j\,$. This is a random variable
with mean $\mu_\theta$ and variance $\sigma^2_\theta + s_j^2\,$.
In the following, an unbiased estimator for $\sigma^2_\theta$ and
a two-stage estimator for the mean $\mu_\theta$ are given.

A preliminary unbiased estimator for $\mu_\theta$ is given by
\begin{equation}
{\hat{\mu}}_\theta^{\mbox{\tiny OLS}} = \frac{1}{N}\, \sum_j {\hat{\theta}}_j \ .
         \label{muols}
\end{equation}
This estimator does not take into account the fact that the standard errors
$s_j^2$ may be different.
This implies that, although it is unbiased, the estimator may be inefficient.
Its standard error is
\begin{equation}
 \mbox{s.e.}\left( {\hat{\mu}}_\theta^{\mbox{\tiny OLS}} \right) =
    \sqrt{\frac{1}{N} \left( \sigma^2_\theta + {\bar{s}}^2 \right) }
\end{equation}
where
\begin{equation}
{\bar{s}}^2 =  \frac{1}{N} \sum_j s^2_j\ .
\end{equation}
An unbiased estimator for the variance $\sigma^2_\theta$ is
\begin{equation}
 {\hat{\sigma}}^{2, \mbox{\tiny OLS}}_\theta =
   \frac{1}{N-1} \sum_j \left( {\hat{\theta}}_j -
                         {\hat{\mu}}^{\mbox{\tiny OLS}}_\theta \right)^2
               \, - \, {\bar{s}}^2  \ .          \label{sigmahat}
\end{equation}
If this yields a negative value, it will be good to truncate it to 0.

Given that the latter estimator has been calculated, it can be used for an improved
estimation of $\mu_\theta$, viz., by the weighted least squares
(WLS) estimator
\begin{equation}
 {\hat{\mu}}_\theta^{\mbox{\tiny WLS}} =
       \frac{ \sum_j \left( {\hat{\theta}}_j / ({\hat{\sigma}}^{2, \mbox{\tiny OLS}}_\theta
                    + s^2_j ) \right) }
            { \sum_j \left( 1/({\hat{\sigma}}^{2, \mbox{\tiny OLS}}_\theta + s^2_j ) \right)} \ .
                                               \label{muwls}
\end{equation}
This is the 'semi-weighted mean' of Cochran (1954)
treated also in Hedges and Olkin (1985, Section 9.F).
Its standard error can be calculated as
\begin{equation}
 \mbox{s.e.}\left( {\hat{\mu}}_\theta^{\mbox{\tiny WLS}} \right) =
     \frac {1}
     {\sqrt{ \sum_j 1/({\hat{\sigma}}^{2, \mbox{\tiny OLS}}_\theta + s^2_j ) } } \ .  \label{se1}
\end{equation}

It is also possible to continue and iterate the two equations
\begin{eqnarray*}
 {\hat{\sigma}}^2 &=& \max\left\{
   \frac{1}{N-1} \sum_j \left( {\hat{\theta}}_j -
                         {\hat{\mu}} \right)^2
               \, - \, {\bar{s}}^2
               , \, 0 \right\}                     \\            \label{sigma2}
 {\hat{\mu}} &=&
       \frac{ \sum_j \left( {\hat{\theta}}_j / ({\hat{\sigma}}^2
                    + s^2_j ) \right) }
            { \sum_j \left( 1/({\hat{\sigma}}^2 + s^2_j ) \right)}
                                               \label{mu2}
\end{eqnarray*}
until convergence. (Normally, a few iteration steps should suffice.)
The results of this iteration scheme will be denoted by
${\hat{\mu}}_\theta^{\mbox{\tiny IWLS}}$ and
${\hat{\sigma}}_\theta^{2, \mbox{\tiny IWLS}}$.

The standard error
of  $\hat\mu_\theta^{\mbox{\tiny IWLS}}$ can be calculated as
\begin{equation}
 \mbox{s.e.}\left( {\hat{\mu}}_\theta^{\mbox{\tiny IWLS}} \right) =
     \frac {1}
     {\sqrt{ \sum_j 1/({\hat{\sigma}}^{2, \mbox{\tiny IWLS}}_\theta + s^2_j ) } } \ .  \label{se2}
\end{equation}

For testing $\mu_\theta$ and $\sigma^2_\theta$,
it is assumed that the parameter estimates ${\hat{\theta}}_j$
conditional on $\theta_j$
are approximately normally distributed with mean \th{j} and variance $s^2_j$.
The first null hypothesis to be tested is that the effects are 0 in all groups.
This can be tested by the test statistic
\begin{equation}
 T^2 = \sum_j \left( \frac{{\hat{\theta}}_j}{s_j} \right)^2     \label{T^2}
\end{equation}
which has an approximate $\chi^2$ distribution with $N$ degrees of freedom
under the null hypothesis.
The test that the mean effect $\mu_\theta$ is zero can be tested
on the basis of the $t$-ratio
\begin{equation}
 t_{\mu_\theta} =   \frac{{\hat{\mu}}_\theta}
                    { \mbox{s.e.}\left( {\hat{\mu}}_\theta \right) }
\end{equation}
which has approximately a standard normal distribution
under the null hypothesis.
Finally, the test that the variance of the effects $\sigma^2_\theta$ is zero
can be tested using the test statistic
\begin{equation}
 Q = T^2 - {\tilde{t}}^2                                  \label{Q}
\end{equation}
where
\begin{equation}
 \tilde{t} = \frac{\sum_j {\hat{\theta}}_j / s^2_j }
                  {  \sqrt{ \sum_j 1/s^2_j  } }         \label{ttilde}
\end{equation}
which has under the null hypothesis approximately a chi-squared distribution
with $N-1$ degrees of freedom.

\subsection{Fisher combination of $p$-values}

Calculate $p_j^+$ and $p_j^-$ being the right and left one-sided
$p$-values:
\begin{eqnarray*}
   p_j^+ &=& 1 - \Phi\left(\frac{\hat\theta_j}{s_j}\right) \\
   p_j^- &=&  \Phi\left(\frac{\hat\theta_j}{s_j}\right) \ ,
\end{eqnarray*}
where $\Phi$ is the c.d.f.\ of the standard normal distribution.
The Fisher combination statistic is defined as
\begin{eqnarray*}
  C^+_j &=& - 2\, \sum_{j=1}^N \ln\left(p_j^+\right) \\
  C^-_j &=& - 2\, \sum_{j=1}^N \ln\left(p_j^-\right) \ .
\end{eqnarray*}
Both of these must be tested in a $\chi^2$ distribution with
$2\,N$ degrees of freedom.

\subsection{Differences in model specification}

In practice, it can happen that a set of data sets is being
offered for a meta-analysis in which the model specifications
are not identical. An example is the case where one of the
independent variables has variance 0 in some data sets
(e.g.: an analysis of networks in schools, with pupils' sex
as an independent variable; there may be some all-girls or
all-boys schools).

This then must be noted in the output; and the data sets combined
as if this parameter here has an estimate 0 but with an infinite
standard error -- in other words, this parameter should be ignored
for this data set;
and this data set should not add to the degrees of freedom
for this particular parameter.


\subsection{Output to be generated}

\end{document}

\section{Effects}

Effects are calculated as
\begin{equation}
  f_i(x) \,=\, \sum_k \text{AlterFunction}_k\,x_{ij}
\end{equation}

\section{Interactions}

Users can specify two-effect and three-effect interactions.

I think your construction indeed allows
what I call user-defined interactions.
The following specifies what I think is needed for this;
this includes two-effect but also three-effect interactions.
It is more or less the same as what is used in Siena 3.
I use the names RSiena and CSiena to refer to the R and C
parts of the program code.
Whether the following works exactly as it should
depends also on the precise way in which AlterFunction
is used in the calculation of statistics.
Could you give me the specification of that?

\begin{enumerate}


\item  RSiena: The dataframe of effects must contain
three extra columns ef1, ef2, ef3 which will be used
only for interaction effects. Let us call these effect specifiers.
They define the effects that are interacting: ef1 and ef2 are required;
if ef3 is undefined or zero, then it is a two-effect interaction,
if ef3 is defined then it is a three-effect interaction.
The values ef1, ef2, ef3 refer to the index number
of the effects (or whatever identified is convenient;
I suppose the index number is a good way of referring to it).
\item  Csiena: Effects must have a tag “kind” with values
{ego, dyadic, interaction, other}.
Ego effects are those depending only on the value of ego
on an actor variable (actor covariate or dependent behavior variable).
Dyadic effects are those depending only on (ego, alter)
and not on other actors.
Interaction variables are the ones we are now defining.
\item  Four types of interaction are allowed:
A: ef1 is an ego effect, ef2 is not an interaction effect, ef3 is undefined.
B: ef1 and ef2 are ego effects, ef3 is defined and not an interaction effect.
C: ef1 and ef2 are dyadic effects, ef3 is undefined.
D: ef1, ef2, ef3 are dyadic effects.
\item  If RSiena passes a non-permitted combination of
effect specifiers to CSiena, then CSiena uses the value 0
for the effect and for the statistic, and transmits to RSiena
a message that the combination of effect specifiers is not allowed.
\item  For types A and C, CSiena uses ProductFunction applied
to the AlterFunction of effects with index numbers ef1 and ef2.
\item  For types B and D, CSiena uses TripleProductFunction
applied to the AlterFunction of effects with index numbers
ef1 and ef2 and ef3, where TripleProductFunction
is just the product of three factors.
\end{enumerate}
